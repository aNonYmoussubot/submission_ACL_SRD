[
  {
    "text": "create partition on centos server?. i have a headless centos server that i'd like to create a new partition on so i have a separate boot and data partition. i have an existing server with the setup that i want to achieve and running fdisk -l looks like this:disk /dev/cciss/c0d0: 299.9 gb, 299966445568 bytes255 heads, 63 sectors/track, 36468 cylindersunits = cylinders of 16065 * 512 = <phone> bytes device boot start end blocks id system/dev/cciss/c0d0p1 * 1 13 104391 83 linux/dev/cciss/c0d0p2 14 36468 292824787+ 8e linux lvmdisk /dev/cciss/c0d1: 899.8 gb, 899898718208 bytes255 heads, 63 sectors/track, 109406 cylindersunits = cylinders of 16065 * 512 = <phone> bytes device boot start end blocks id system/dev/cciss/c0d1p1 * 1 109406 878803663+ 83 linuxhere's the same command on my server:disk /dev/cciss/c0d0: 587.1 gb, 587128266752 bytes255 heads, 63 sectors/track, 71380 cylindersunits = cylinders of 16065 * 512 = <phone> bytes device boot start end blocks id system/dev/cciss/c0d0p1 * 1 13 104391 83 linux/dev/cciss/c0d0p2 14 71380 573255427+ 8e linux lvmi've been told it's not as straightforward as creating a partition and setting mount-points to it because of the additional logical volume layer on centos. how can i create a partition without causing problems to the data structure?",
    "present_kp": [
      "centos",
      "partition"
    ],
    "absent_kp": []
  },
  {
    "text": "governance models for multi-institution open source projects. i'm working on an open source project that has full time professional developers from several universities, plus a couple of other organisations. the product has something like a dozen deployments, various variations, plugins, related components etc. generally development so far has been driven by institutions scratching their own itch, but with an effort to merge improvements back to a central code base.as it's starting to mature, i'm interested in possible models of open source governance to follow. (so this question isn't what are some good things to do, it's specifically what existing, tested models are worth looking at and possibly following)specific aspects that such models might cover:how decisions about big-impact changes are made (and what happens if someone makes big changes without discussing them first)who manages the product's public image (product marketing, for want of a better term)who represents the product in any comparisons with competing productswhether enhancements become core, plugins, related products etcwhether and how roadmaps are created and publishedhow variations on the product are handled (in this case, versions for different academic disciplines)expectations and obligations of participants in the projectexpectations and obligations of the institutions for which those developers workwe'll be looking for something as lightweight and informal as practical.",
    "present_kp": [
      "open source"
    ],
    "absent_kp": [
      "management",
      "community",
      "distributed development"
    ]
  },
  {
    "text": "how to find the min of a column in every nth intervals of a file, using sed, sort, tail?. i want to find the minimum of the 5th column of a file in every 12th interval of that and save the associated line into a new file. to find the minimum of the last 12th line i can usetail -n 12 $filename | sort -g -k 5,5 | head -1| awk '{print}'> tmp.outbut how can i perform such a process iteratively?i have triedwhile read $filenamedo ....donewhich was not successful.the file looks like4.7 0.17 0.529 0 4.48464.7 0.17 0.529 1 4.54374744.7 0.17 0.529 2 5.632297394.7 0.17 0.529 3 4.<phone>.7 0.17 0.529 4 4.<phone>.7 0.17 0.529 5 4.<phone>.7 0.17 0.529 6 4.<phone>.7 0.17 0.529 7 3.699997174.7 0.17 0.529 8 4.69999984.7 0.17 0.529 9 2.74.7 0.17 0.59 10 3.99999984.7 0.17 0.59 11 4.699999999985 1 0.59 0 4.495698465 1 0.59 1 4.543305745 1 0.59 2 4.637396535 1 0.59 3 3.672339575 1 0.59 4 4.<phone> 1 0.59 5 4.<phone> 1 0.59 6 4.69993295 1 0.59 7 4.699999997175 1 0.59 8 4.699999985 1 0.59 9 3.25475 1 0.529 10 4.699999999985 1 0.529 11 4.69999999998with almost 2000 lines.",
    "present_kp": [
      "awk",
      "sed"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "are copyleft and share-alike synonyms?. copyleft and share-alike are two very similar types of licences. here is how wikipedia defines them:copyleft (a play of the word copyright) is the practice of offering people the right to freely distribute copies and modified versions of a work with the stipulation that the same rights be preserved in derivative works down the line. (source)share-alike is a copyright licensing term, originally used by the creative commons project, to describe works or licences that require copies or adaptations of the work to be released under the same or similar licence as the original. copyleft licences are free content or free software licences with a share-alike condition. (source)are there any meaningful distinctions between these concepts, or is the only real difference their heritage and most common uses (software vs media)?",
    "present_kp": [
      "copyleft"
    ],
    "absent_kp": [
      "terminology"
    ]
  },
  {
    "text": "creating a function when user clicks on element to toggle another element. i use a lot of when user clicks on element then another element will be displayed as visible/hidden... aka toggle. so i'm trying to make a general function to abide the dry principal.before jumping into the code, i just wanted to state that there are still bugs. i just want to know before continuing if writing a function like the one below is necessary or if i should just ignore the dry in this case and have lots of separate toggle functions. or if it's necessary, would there be a more efficient method? jsfiddle*brief description of code -there are 4 parametersthe first two are mandatory, the last two are optionalthe index parameter is a string of numbers ex. 1.0,1the reason i need the last two parameters is because i have elements that can't be easilytargeted. for example, they don't have an #id. so to grab those generic elements, i use getelementsbytagnamethen i'll use the index parameter to get the element in the array.index parameter: the number before '.' is the index of the clickelementand the number after '.' is the index of the toggleelement. clickelement = 1. toggleelement = 0. function toggleclick(clickelement, toggleelement, condition, index) { var toggleindex; var clickindex; if(condition === false){ if(index.indexof('.') != -1){ //indexof returns -1 if '.' is not found. // checks to see if two index is entered indexarray = index.split('.'); clickindex = indexarray[0]; toggleindex = indexarray[1]; clickelement = document.getelementsbytagname(clickelement)[clickindex]; toggleelement = document.getelementsbytagname(toggleelement)[toggleindex]; }else{ //if there is no '.', that means only one index was entered. // by function requirement, it should be the index of clickelement clickelement = document.getelementsbytagname(clickelement)[index]; } } $(clickelement).click(function(){ $(toggleelement).toggle(); }); } this is one of my first functions, and so i need some guidance on whether i'm writing bad code. yes, this might be broad because there may be many different ways to write this function. but i just need to know if there's a more efficient way or if my way is okay.",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "jquery",
      "event handling"
    ]
  },
  {
    "text": "how can i find out when i subscribed to a youtube channel?. i am trying to find out when i subscribed to a certain youtube channel. i don't think i did. i have searched and cannot find any way. is there any way to learn when or how long i have been subscribed to a youtube channel?",
    "present_kp": [
      "youtube"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i create and automatically sync a merged directory from multiple other directories without duplicating files?. if i have some number of source directories, e.g. dir1, dir2... dir5, how can i create an automatically syncing merged destination directory that has all the files and directories of the source directories but doesn't involve duplicating files?for example, i have the following source directory structure...dir1/ - a - bdir2/ - b <-- note the duplicate name, this one is more recent than dir1 - c - dir2.1/ <-- subdirectories present too. - zdir3/ - d... which when merged would look like this:merge/ - dir2.1/ - z - a - b <-- which one to show is based on modified time; most recent first. - c - d(assume there could be dozens of directories with thousands of files and subdirectories.)all the files and directories in the source list should remain in place and unchanged and the merged destination directory should take up no addition storage; i.e. it's possibly just all symlinks managed by some daemon using inotify. the source directories are also having files and subdirectories added and removed frequently and this needs to be reflected, as soon as possible, in the merged directory too.some usage examples:i create a new file, dir3/e, and it automatically and immediately (or within a few seconds) appears in the merge directory.i remove the file dir1/a and it automatically and immediately (or within a few seconds) disappears from the merge directory.i edit dir3/d by opening merge/di call touch on dir1/b so it it has a newer modified date than dir2/b and so merge/b automatically updates to point to dir1/b as it is the most recent.i remove dir1/b and now merge/b will point to the older file dir2/b.i attempt to create a file in merge but get an error because doing so makes no sense!",
    "present_kp": [
      "directory"
    ],
    "absent_kp": [
      "linux",
      "debian"
    ]
  },
  {
    "text": "writing an effective method that reflects good oo design and fixes this broke method. i'm working on my personal project and have recently had a bit of trouble with a method i wrote during the week.this method compares user input from the same jcombobox. a before and after, if you will. it then makes an appropriate adjustment to a 2nd combobox depending on the user's input into the first box. it took me a bit of effort to figure this out. when i finally did, i was pretty happy with myself. until i realized that the method uses a class variable and ruins any concept of good object-oriented design. /**** missilebalancer compares the users input before and after selection and adjusts the contents of the oh missile count box as necessary.** @param jcombobox combobox is the combobox concerning the op counts, jcombobox combobox1 is the combobox concerning the oh counts, prevoh is the masteroh count.** @return** @throws**/public void missilebalancer(jcombobox combobox, jcombobox combobox1, int prevop){ int difference = 0; int newoh = 0; int newop = (int) combobox.getselecteditem(); //current op count int oldoh = (int) combobox1.getselecteditem();//current oh count --adjusting this by the appropriate amount is the goal of this method int oldop = prevop; //oldop is the op that we are testing against it needs to be set by the program into a var that we can use in our test. if(newop < oldop){ oldpac3 = newop;//we need to keep track of our count outside of the method. }else if(newop > oldop){ difference = newop - oldop; newoh = oldoh - difference; combobox1.setselecteditem(newoh); if(newoh < 0){//you cannot set selected item to a jcombobox with a negative number so in all cases where newoh is less than zero we simply set the selected item to 0. combobox1.setselecteditem(0); } oldpac3 = newop; }}//end missile balancerthe problem is with the user of the oldpac3 variable. the method cannot always use this variable. i have variables for oldgemt and oldgemc, that this method needs to modify as appropriate. i can think of a couple ways to make this work, but i don't think any of them are very clean. i want the code for this method to be concise and elegant. any help or some guidance in the right direction would be great.this is the rewritten method. it does what needs doing, but i think it is ugly. i'm posting it because i don't want to give the impression that i'm looking for other people to solve my problems for me. i really just want to write better code. /**** missilebalancer compares the users input before and after selection and adjusts the contents of the oh missile count box as necessary.** @param jcombobox combobox is the combobox concerning the op counts, jcombobox combobox1 is the combobox concerning the oh counts, prevoh is the masteroh count.** @return** @throws**/public void missilebalancer(jcombobox combobox, jcombobox combobox1, int prevop){ int difference = 0; int newoh = 0; int newop = (int) combobox.getselecteditem(); //current op count int oldoh = (int) combobox1.getselecteditem();//current oh count --adjusting this by the appropriate amount is the goal of this method int oldop = prevop; //oldop is the op that we are testing against it needs to be set by the program into a var that we can use in our test. if(newop < oldop){ if(combobox.equals(pac_3opcount)){ oldpac3 = newop;//we need to keep track of our count outside of the method. } else if(combobox.equals(gemcopcount)){ oldgemc = newop; } else if(combobox.equals(gemtopcount)){ oldgemt = newop; } }else if(newop > oldop){ difference = newop - oldop; newoh = oldoh - difference; combobox1.setselecteditem(newoh); if(newoh < 0){//you cannot set selected item to a jcombobox with a negative number so in all cases where newoh is less than zero we simply set the selected item to 0. combobox1.setselecteditem(0); } if(combobox.equals(pac_3opcount)){ oldpac3 = newop;//we need to keep track of our count outside of the method. } else if(combobox.equals(gemcopcount)){ oldgemc = newop; } else if(combobox.equals(gemtopcount)){ oldgemt = newop; } } }//end missile balancer",
    "present_kp": [],
    "absent_kp": [
      "java",
      "object oriented"
    ]
  },
  {
    "text": "remote syslog command line client. i use logger pretty regularly, but is there a foss command line tool for remote submission of syslog messages over the network? right now, i have to configure a facility/priority pair to submit to a remote server on the rsyslogd side. i'd like to cut out the middleman and not have to modify my local syslog daemon's configuration. does such a tool exist?",
    "present_kp": [
      "syslog",
      "logger"
    ],
    "absent_kp": []
  },
  {
    "text": "feedburner does not get links right. feedburner doesn't get my feed links right. i tried resyncing and pinging and everything at my disposal but it doesn't seem to work. then i emailed my problem to <email> and i got no response. i just can't stand to see my feed getting wrong links.e.g: <url> is the link in the actual feed (<url>) while feedburner links go to <url>",
    "present_kp": [
      "feedburner"
    ],
    "absent_kp": []
  },
  {
    "text": "what was the first mechanical turing-complete machine ever constructed?. we know that charles babbage designed the first turing-complete mechanical machine - the analytical engine - in the 1800s, but it was never actually built (not yet anyway).in recent history, at least one mechanical turing machine has been built. (this example is in fact a universal turing machine, albeit with finite storage space.) but was this the first one, or are there earlier examples?what was the first mechanical turing-complete machine constructed, who built it and when?edit: by mechanical, i mean no electronics are used.",
    "present_kp": [
      "history"
    ],
    "absent_kp": [
      "computer architecture",
      "turing completeness"
    ]
  },
  {
    "text": "where could distributed version control systems currently be in gartner's hype cycle?. edit: given the recent downvoting (+8/-6 at this point) it was made clear to me that gartner's lifecycle is a biased metric from a programmer's perspective. this is something that is part of a paper i'm going to present to management, and management types are part of gartner's audience. giving dvcs exposure & enthusiasm (that could be deemed as hype, or at least attacked as such), think about the following question when reading this one: how could i use gartner's hype cycle to convince management that dvcss are ready (or ready-enough) for us, and that it is not just hypejust asking if dvcss is hype wouldn't be constructive, gartner's hype cycle is a more objective instrument than just asking that (even if this instrument is regarded as biased). if you know any other instrument please, by all means, mention it.edit #2: i agree that gartner's life cycle is not for every technology, but i consider it may have generated enough buzz to be considered hype by some, so it maybe deserves to be at least evaluated/pondered as such by using this instrument in order to prove/disprove it to whatever degree. i'm an advocate of dvcs, btw.edit #3: thanks for your answers. bounty goes to caleb for answering my question with detail and practical advise. accepted answer goes to philosodad for providing another useful instrument and answering beyond my question.i'm doing research for a whitepaper i'm writing in favor of dvcs adoption at company and i stumbled upon the concept of social proof. i want to prove that the social proof of dvcs adoption is not necessarily cargo cult and doing further research i now stumbled upon gartner's hype cycle which describes technology maturity in 5 phases.my question is: what could be an indicator of the current location of distributed version control systems (i mean git, mercurial, bazaar, etc. in general) at a particular phase in the hype cycle?... in other (less convoluted) words, would you say that currently expectations of dvcss are a) starting, b)inflated, c)decreasing (disillusionment), d)increasing (enlightenment) or e)stabilizing (mature) and (more importantly) why?i know it is a hard question and there is subjectivity involved, but i'll grant the answer (and the traditional cookie) to the clearest argument/evidence for a particular phase.",
    "present_kp": [
      "research",
      "dvcs"
    ],
    "absent_kp": [
      "cvcs"
    ]
  },
  {
    "text": "detailed description of malware content. i have just started my journey into the vast and intersting field of malware analysis. i would like to know if there is any website/book or another resource that explains what a particular block of assembly code does. a detailed description of the code would be well appreciated. i know assembly language to some extent and is familiar with all the concepts,function call procedure etc. but i have very little knowledge on how all these applies when it come to windows. like what happens when a dll is used,etc... i would be very glad if someone could tell me where to find a resource that provides a step by step detailed analysis of any malware or any program for that matter.i have already a considerable experience in reverse engineering windows applications, most of the knowledge been taken from the 'legend of r4ndom' and woodman websites. i need something that clearly explains how a particular assembly code interacts with windows dlls, resources like menu bars text boxes, etc..",
    "present_kp": [
      "malware"
    ],
    "absent_kp": []
  },
  {
    "text": "kickstart: one network card with dhcp, one with static ip?. i am using kickstart to automate a centos install. i wanted one of the interfaces to have static ip so i wrote -network --onboot yes --bootproto static \\ -ip=intended ip -netmask=intended netmask \\ -gateway=intented gateway --device eth0*i also wanted the other ethernet to have dynamic ip so i also configured a dhcp server for my network and for the other interface card wrotenetwork --onboot yes --device eth1 --bootproto dhcpbut to my surprise the ethernet to be configured static was also provided with dynamic ip. what is wrong here?",
    "present_kp": [
      "centos",
      "ip",
      "kickstart"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "extract line number of a file which is having a non zero value before a specified string. i'm having a file which contains following data1. verification: 10 passed 0 failed2. verification: 10 passed 0 failed3. verification: 10 passed 1 failed4. verification: 10 passed 3 failed5. verification: 10 passed 0 failedi want to know the line numbers of 3 and 4.",
    "present_kp": [
      "string"
    ],
    "absent_kp": [
      "grep",
      "numbering"
    ]
  },
  {
    "text": "given a csl formula, how can we generate an automaton that accepts the formula?. the problem is same as the title, given a continous stochastic logic(csl) formula how can we create a machine which accepts the formula? any intuitive ideas or references will be appreciated.",
    "present_kp": [],
    "absent_kp": [
      "lo.logic",
      "model checking"
    ]
  },
  {
    "text": "cohen-sutherland clipping. specify individually the translation and scaling matrices required to transform a 2dwindow of [xmin=-234, ymin=156] and [xmax=66, ymax=456] to a display viewportof [umin=45, vmin=35] and [umax=245, vmax=185].ignore the question above since i solved the matrix, the information is just relevant for the question i'm stuck oni was asked to compute the view-port positions (u1,v1) and (u2,v2) for two points a (-100,300)and b (30,-40) in a 2d window and determine if these two points are inside the view-port.based on the transformation matrix i found (u1,v1) to be (403/3, 407) and (u2,v2) to be (221, -103). it turns out that both these points are outside our view-port but part of the line between them is inside.now i'm confused about this part below:apply a 2d clipping method to the line segment between the two points a and b asgiven in above.my attemptdelta x = 221-(403/3) = 260/3delta y = -103 - 406 = -510m = delta y / delta x = -5.88i started with u1,v1 since it is above our viewport:y = 185x = 403/3 + (185-407)*(delta x/ delta y)x = 279.48point 1 - (172, 185) is this correct? since the point is now within the view-port. do i then do the same for the second point?",
    "present_kp": [
      "clipping"
    ],
    "absent_kp": []
  },
  {
    "text": "do search engines follow the additionaltype url in microdata?. for example <div itemscope itemtype=<url> <meta itemprop=additionaltype content=<url> </div>if so, which vocabulary(?) is more descriptive?productontology.orgdbpedia.orgwikipedia.org ?",
    "present_kp": [
      "microdata"
    ],
    "absent_kp": [
      "seo",
      "html5",
      "schema.org"
    ]
  },
  {
    "text": "command to skip process if file exists. i have been using a for loop to run a pipeline for multiple files but unfortunately the terminal froze halfway. i would like to run the pipeline again but because of time i would like to skip the directories that already has the output files created. basically nest a if statement - if file output file exists, ignore if not run pipeline. is this possible?for f in /volumes/my\\ passport/documents/projects/untitled\\ folder\\ 2/untitled\\ folder\\ 3/untitled\\ folder\\ 2/untitled\\ folder/*/*_1.fastq; dosubdir=${f%/*}pushd $subdir &>/dev/nullfile1=${f##*/}file2=${file1%_1.fastq}_2.fastqadapter=/volumes/my\\ passport/documents/adapters.fareference=/volumes/my\\ passport/documents/ucsc_hg19/ucsc.hg19.fastadbsnp=/volumes/my\\ passport/documents/ucsc_hg19/dbsnp_138.hg19cosmic=/volumes/my\\ passport/documents/ucsc_hg19/cosmiccodingmuts.vcfinterval=/volumes/my\\ passport/documents/plist.bedsjdb=/volumes/my\\ passport/documents/ucsc_hg19/ucsc.hg19.gtffile3=${file1%_1.fastq}_1_trimmed.fastqfile4=${file2%_2.fastq}_2_trimmed.fastq#preqc (cutadapt -o subtracted, prinseq -min_qual_score 4 -ns_max_p 2 subtracted)~/desktop/utsw/applications/bbmap/bbduk.sh -xmx120g in1=${file1} in2=${file2} out1=${file1%_1.fastq}_1_trimmed.fastq out2=${file2%_2.fastq}_2_trimmed.fastq ref=${adapter} trimq=10paste - - - - < ${file3} | sort -k1,1 -t | tr > ${file3%_1_trimmed.fastq}_trimmed_sorted_1.fastqpaste - - - - < ${file4} | sort -k1,1 -t | tr > ${file4%_2_trimmed.fastq}_trimmed_sorted_2.fastqparallel -j $parallel_tasks perl ~/utsw/applications/prinseq-lite-0.20.4/prinseq-lite.pl -fastq ${file3%_1_trimmed.fastq}_trimmed_sorted_1.fastq -fastq2 ${file4%_2_trimmed.fastq}_trimmed_sorted_2.fastq -no_qual_header -trim_right 1 -custom_params a 75%;t 75%;g 75%;c 75% min_qual_mean 25 -min_len 40 -out_format 3 -out_good ${f%.*}_qc -out_bad null -logdone",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "scripting",
      "macintosh"
    ]
  },
  {
    "text": "numbering of computable functions. is there a numbering (not gdel numbering) of all computable functions $u(p, x)$, such that the set of numbers of functions defined in zero is exactly the set of even numbers. more formally: $i = \\{p,\\ |\\ u(p, 0)\\ \\mathrm{defined}\\} = 2\\mathbb{n}$.my guess that it's true. but i'm not sure how to prove it.ideas:we can construct a numbering of all computable functions, defined in zero using the function $f(p, x, t)$ which is equal to $0$ if $u(p, x)$ hasn't finished work in $t$ steps and $1$ in other case. we can do it because set of pairs $(p, t)$ is enumerable.then, having this function $v(p, x)$ and some other numbering $u(p, x)$ we can construct numbering$$u'(p, x) = egin{cases}v( rac{p}{2}, x)\\ \\ if\\ p dots 2\\u( rac{p + 1}{2}, x)\\ \\ if\\ p otdots 2\\end{cases}$$",
    "present_kp": [],
    "absent_kp": [
      "computability",
      "discrete mathematics"
    ]
  },
  {
    "text": "what is copyleft?. straight up: i've never heard of the term 'copyleft' before. the fact that i get that little red squiggle under it tells me it's not really a word. concisely, my question is, what does it mean to you? i saw it tagged on a few questions so i read the tag description:for questions about the copyleft concept (also known as share-alike), a concept that promotes or enforces the use of the same or compatible license for derived works.and i read the wikipedia page on it. my understanding is that copyleft has attributes of share-alike but the author must disclose any other terms alongside it. to me, it seems like a bit of a useless term. why describe it as copyleft if you need to add a licence to it anyway? would you not be better off describing it as copyright with already-agreed-upon licenses? otherwise it's only another word for share-alike.",
    "present_kp": [
      "copyleft"
    ],
    "absent_kp": [
      "terminology"
    ]
  },
  {
    "text": "composed architecture. when refactoring and old class in php, i noticed that it contained a lot of business logic and thus was not allowing code reuse. so i thought about composition in order to achieve horizontal code reuse (since inheritance permits only vertical reuse) and the possibility to do dependency injection eventually. di gives then the possibility to use mock services in order to test the classes.basically, that class permits sending sms using the api of a third-party and we have hundreds of apis we need to deal with, so this is why the idea of horizontal code reuse would be useful.when we send an sms, we need to:send an http request to some url provided by the carrier with the right body contents (phone number, sms title, sms content and other information, depending on the carrier) and in the right format (xml, json, soap, depending on the carrier)log the sent sms*in the database (phone number, title, contents, delivery_status). the table where it is logged is used for tracking all sent smsses. also, we attach a delivery_status code (1 for delivered, -1 for not delivered) because some carriers send us then a delivery report (by requesting a script on our end) if the phone acknowledges the delivery.log the sent sms specifically for that carrier in another dedicated table that contains more fields than (phone_number, title, message, delivery_status). those fields could be used in the future for special purposes.i decided to separate the logic in mainly three classes:loggerservice: class that logs the sent sms informations in the database (also logs the carrier-specific sent sms informations)requestmaker: trait that simply makes http requests and returns the result without any further processingserializerservice: service that serializes the body of the request (converts from a dictionary of parameters to a specific format required by the carrier like xml or json, etc.). xmlbodyserializer is one implementation of that service. jsonbodyserializer is another.smssender: the core class that is using the requestmaker trait and the two other services in order to perform an api call to the specific carrier's api. if a carrier named mycarrier exists, we would have a mycarriersender class inheriting smssender. the main task of that class would be to build the right request body and to pass it to the serializer, then to the request maker which will call the api. finally, the class should fill the sent sms dto that will the be logged using the loggerservice currently in use.do you think it is a good idea to adopt this design? in other words, does it meet the goals of:decoupling business logiccode reusingpermitting testabilityhere is an implementation of the architecture:interface smssender { public function initservices( iloggerservice $resultloggerservice, // that logs information about sent sms in the databse ibodyserializer $serializerservice, // request body serializer ); public function sendtext( $msisdn, $title=, $text=, $options=array());}trait requestmaker { public function makeget($url, $params=array()); public function makepost($url, $params=array(), $body); public function buildurl($url, $params=array()); public function request($url, $method=null, $params=array(), $body=array());}interface iresultloggerservice { // logs the sms sent to the database public function logresult($sms2dto); // logs sent sms specific informations for that carrier public function loginmt($specificmtdto);}/*** request body serializer (xmlbodyserializer, jsonbodyserializer implements it) that serializes the body of the request*/interface ibodyserializer { public function serialize($data); public function parse($response);}/** * example of an sms sender for a specific carrier*/class mycarriersmssender implements smssender { use requestmaker; public function __construct() { $this->initservices( new mycarrierloggerservice(), new xmlbodyserializer() // will use xml for communication with the carrier's api ); } protected function presend($msisdn, $title, $text, $options) { /** * performs some verifications, prepares some variables * .... */ // example : $sentsms = new sms2dto(); $sentsms->setmsisdn($msisdn); // etc. $this->setsms2(); // set the sent sms dto } public function sendtext($msisdn, $title, $body, $options = array()) { $this->presend($msisdn, $title, $body, $options); $data = { // .... prepare request data } // serialize data using the injected service $raw_data = $this->getserializerservice()->serialize($data); // call request() from the requestmaker trait $raw_result = $this->request($url, array(), $raw_data, post); // deserialize api's response $result= $this->getserializerservice()->parse($raw_result); // interprets api's response and returns a success or fail status code $status = $this->interpretresult($result); $this->postsend($status); return $status; } protected function postsend($status) { if($status == success) { // log sent sms $this->getloggerservice()->logresult($this->getsms2dto()); // log specific sent sms by this carrier (contains more useful and specific info to that carrier) $this->getloggerservice()->loginmt($this->getmtdto()); } }}there are also dtos: sms2dto and {carrier}mtdto for every carrier.before that design, everything here was done in one class. there was a class for each carrier so a lot of code was repeated.",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "design patterns"
    ]
  },
  {
    "text": "diff between a string and a file. basically i want to check the difference of the same file before and after a sedtried to run:diff /opt/posttrades.sh <<< $(sed 's/1\\ min/10\\ min/g' /opt/posttrades.sh)anddiff <<< $(sed 's/1\\ min/10\\ min/g' /opt/posttrades.sh) < /opt/posttrades.sh anddiff <<< (sed 's/1\\ min/10\\ min/g' /opt/posttrades.sh) < /opt/posttrades.shalways getting:diff: missing operand after '/opt/posttrades.sh'diff: try 'diff --help' for more information.what's the correct way to do it?thanks.",
    "present_kp": [
      "diff"
    ],
    "absent_kp": [
      "here document",
      "here string"
    ]
  },
  {
    "text": "mobile ios application to server interaction design?. i've built a set of what will be server-side programs in python. essentially they crawl the net and index news articles.the ios mobile application will be what the user interacts with. so it needs to query the server somehow to get the results back. i.e. if the user types in 'google' or 'goog' it will return news articles concerning google.i'm assuming the server needs to be sent the query, the server produces the results by going over the hosted data and then sends it back, but how does it all work?i'm looking for a set of basic design principles for this sort of thing. although if you would like to give a breakdown that would be even better.",
    "present_kp": [
      "server",
      "mobile"
    ],
    "absent_kp": [
      "search engine"
    ]
  },
  {
    "text": "can't get user $home over su on solaris and aix. i'm trying to get user $home variable over su. solaris# su oracle$ echo $home/rootaix# su oracle$ echo $home/linux# su oracle$ echo $home/home/oraclecan someone explain why on solaris and aix when i try to get $home variable it gets the root's $home directory?updateusing login with with - or -l works, but i can't use su - on my script. any thoughts on how to overcome this?i was trying to not use a solution like the above but i'm getting out of optionscat /etc/passwd | grep oracle | cut -d: -f 6or as thomas suggested:cat /etc/passwd | awk -f: '$1 ~ /^'oracle'$/ {print $6;}'",
    "present_kp": [
      "solaris",
      "aix",
      "su"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i see in google analytics where my users came from?. i am using google analitics and struggling to find where my users came from. i can see demographics (country / city) information, but struggling to find what site have they came from.i found this answer:from your dashboard on the left side clicktraffic sourcesources all trafficbut can not see this on my left side. it hasdashboardsshortcutsintelligence eventsreal-timeaudienceacquisitionbehaviorconversionscan someone help me?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": [
      "referrer"
    ]
  },
  {
    "text": "merge two csvfiles by column header. i have two csv files:success.csvid,legacy id,field1, field21,1111,google,news2,2222,yahoo,newserror.csvlegacy id,field1,field2,message3333,aol,news,failed to upload data 4444,cbs,news,alredy existshow can i merge these two files and create a new file as shown below? i cannot use indexes as the size and order of fields will keep changing.results.csvid,legacy id,message1,1111,2,2222,,3333,failed to upload data,4444,alredy existsthe requirement is to create the results.csv file with only three columns from both success.csv and error.csv.if the row is successfully loaded then we get id in the success file as the first column with no message columnif it's failed we get an error in the message field which is always the last field in the file. in this case the id will be empty.read the values from success.csv as follows:awk '{print $1, $2;}' success.csvread the values from error.csv as follows:awk '{print $1, nf;}' error.csvi am not able to figure out a way to combine both the statements and write the result to a file.",
    "present_kp": [
      "awk",
      "csv"
    ],
    "absent_kp": [
      "command line",
      "text processing",
      "scripting"
    ]
  },
  {
    "text": "what is volume in terms of databases?. i was reading a text. it said,information presentation must be compatible with the response time needs of systems. the response time should be short enough that the information does not lose its freshness and value but it should be long enough to reduce volume (and costs) and reveal important trends that signal the need for actionwhat does volume mean in it? please help out. thanks",
    "present_kp": [
      "database"
    ],
    "absent_kp": []
  },
  {
    "text": "printing problems with ddst (aka pcl6) printer ricoh aficio sp c240dn. i'm having big problems printing on a ricoh aficio sp c240dn (a color laser printer). cups/openprinting doesn't have a driver for exactly this printer. there are similar numbers but not 240dn. it also seems there is no ppd file for this printer, as it doesn't accept postscript at all. there are only so-called ddst and icm drivers for windows and mac, but no ppd as opposed to slightly older models from ricoh (320dn for example). the technician at the company where i bought the printer said that ddst is a stripped-down version of pcl6.the connection to the printer works, i can access the web interface for management, i can print test pages via buttons on the printer or via the web interface. if i try any other driver (320dn for example), the printer shows that it is receiving data, the spool on the computer is processing, and then it just thinks the job is finished and done but the printer does nothing.i'm planning to return it, but was wondering if somebody could explain a bit about drivers (what is ddst?), and if somebody knows if there is any chance that such driver for linux will be out in any time soon.i'm actually ready to donate a small amount to somebody who would hack an open-source driver (for cups).",
    "present_kp": [
      "printing",
      "cups",
      "postscript"
    ],
    "absent_kp": []
  },
  {
    "text": "is this code structure beneficial in any way?. i was recently thrown into a java web application project, and ive come across a number of classes that follow this type of format:public class mythingy { private final int p1; private final string p2; public mythingy (int p1, string p2, ) { this.p1 = p1; this.p2 = p2; } public static void dosomething(int p1, string p2, ) throws throwable { final mythingy mythingy = new mythingy(p1, p2, ); mythingy.execute(); } private void execute() throws throwable { //do stuff }}it seems like this could be accomplished with the following code, which to me seems way easier to read.public class mythingy { public static void dosomething (int p1, string p2, ) throws throwable { //do stuff }}the only possible benefit i can see from doing it the first way, is that if you had to break up execute() into smaller pieces, they could all share the initial parameters without having to explicitly pass them around. but this maybe only benefits the lazy coder, as it becomes difficult for the reader to tell which methods need which parameters and when the values might be changed (akin to global variables.)is there something i'm missing? threading, performance?edit:i should have mentioned, although the constructor is public, it is not called. the only usage is like this:mythingy.dosomething(p1, p2...);aside from this in itself being problematic for testing, i can't see any reason not to put the logic of execute() directly into dosomething(). even if we were to get rid of the static function, the constructor still doesn't make sense to me; i think the parameters should be passed directly to the method that will use them.",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "coding style"
    ]
  },
  {
    "text": "recommended method for shared data store writeable by all users. i have a few users sharing a computer and accessing content (pictures, audio, video recordings etc) that other users save. i need a shared drive for this content. file permissions, access control or overwriting is not an issue - just need a simple method to share files, in fact, without worrying about ownership and read-write privileges.i used to have a hard-drive partition that was formatted ntfs which so far served this purpose, but i am getting tired to having to run chkdsk every now and then so am looking for a solution that is more native to linux.unlike this question, this is not about the path of the directory, but about the way to implement the store - e.g., filesystem, share configuration etc.,.this setting is required only for this shared folder- otherwise, these users and their (other) data needs to be kept private like in any standard linux installation.",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "is there any specific reason to use else if clause?. we all use if ..else if.. else.but still i'm confused as to why we use else if. where if does the same thing as else if.so why are we using else if?any specific reasons behind this?is there any algorithm where it's mandatory to use else if?",
    "present_kp": [],
    "absent_kp": [
      "programming languages",
      "algorithms"
    ]
  },
  {
    "text": "validator class in php. i am trying to create a validation class that can be used to validate many forms of my webpage in general. it makes use of the database as well to verify records. the problem with it is that it looks bad and somewhat inefficient. i couldn't find any alternatives and i have used too many if-else if statements. and also dob makes use of an arbitrary variable. overall the code seems bad, i know. but i couldn't find an alternative. any help is extremely appreciated. i would also be happy if you could comment on the design and efficiency. i am willing to rewrite the whole code needed. this works, but it's all messed up. thanks! class validate { //take the user input into the data put it to a class. protected $data; //function argument private $err; // boolean protected $empty; private $error; private $clean; private $query; public function __construct() { $this->query= new dbhandler(); } private function basicsanitize($data) { //basic level input santization to be used by other functions only. $data=htmlspecialchars($data, ent_quotes); $data=trim($data); return $data; } public function sanitize($data) { // sanitization at a massive level to sanitize a lot of inputs at one go. foreach ($data as $k =>$v) { $data[$k]= $this->basicsanitize($v); } return $this->clean=$data; } public function showerror($type,$data) { return $this->error[$type.$data]; } private function basicemptycheck($data) { if($data==|| empty($data) || !isset($data) || $data==-1) { return true; } } public function isempty($data) { foreach ($data as $k =>$v) { if($this->basicemptycheck($v)){ $this->error['empty']=there is an empty field; return true; } } } private function checklength($data,$min,$max) { if(strlen($data)>=$min && strlen($data)<=$max) { return true; } } private function lengtherr($data,$min,$max) { if(strlen($data)>$max) { return too long; } else if (strlen($data)<$min) { return too short; } } public function name($data) { if(!$this->checklength($data,3,100)) { $this->error['name'.$data]=name .$this->lengtherr($data,3,100); } else if(!preg_match(/^[a-za-z ]+$/,$data)) { $this->error['name'.$data] = please don't include special characters in names; } else return true; } private function isuniqueemail($data) { $sql= select stuff1 from tablename where stuff2=?; if(!$this->query->checkifexists($sql, s, 'jells')) { return true; //the value set here jells is for testing purposes only. this will be replaced by $data } } public function email($data) { if (!$this->checklength($data,8,254)) { $this->error['email'.$data]= enter a valid email; } else if (!filter_var($data, filter_validate_email)) { $this->error['email'.$data] = enter a valid email; } else if (!$this->isuniqueemail($data)) { $this->error['email'.$data]= this email already exists; } else return true; } public function password($data) { if (!$this->checklength($data,8,128)) { $this->error['pass'.$data]='password '.$this->lengtherr($data, 8, 128); } else if (count(array_keys($this->clean,$data))>1) { $this->error['pass'.$data]='password is too obvious'; } else return true; } private function agecheck($month,$day,$year,$limit) { # object oriented $date=$year.-.$month.-.$day; $from = new datetime($date); $to = new datetime('today'); if($some=$from->diff($to)->y>=$limit) { return 1; } } public function age($data,$month, $day, $year,$limit) { if(!is_numeric($day) || !is_numeric($month) || !is_numeric($year)) { $this->error['age'.$data] = please enter a valid date; } else if(!checkdate($month, $day, $year)){ $this->error['age'.$data] = please enter a valid date; } else if(!$this->agecheck($month,$day, $year,$limit)) { $this->error['age'.$data] = you must have a minimum of .$limit. of age to sign up; } else return true; } public function sex($data) { if($data=='m' || $data=='f') { return true; } else { $this->error['sex'.$data]='add a valid sex'; } } public function errorexists() { if(isset($this->error)) { return true; } } }",
    "present_kp": [
      "php",
      "validation"
    ],
    "absent_kp": []
  },
  {
    "text": "problems implementing the remez algorithm. so first off:*** this code is not being used in production software.it is a personal project of mine, trying to understand approximation theory and advanced curve fitting. in other words, i'm trying to understand how it works, not trying to get a currently existing solution.so i have been trying to implement the remez algorithm for polynomial approximation.i sort of/maybe/kind of have it working (not really).my current solution generate ok polynomials, but a) the coefficients are not converging&b) while monitoring the coefficients at each stage, i've noticed that the x-values seem to slip past each other.i'll give some examples to show what i mean.my base function i'm trying to model is the square root function with a 4 degree polynomial on the domain [0.25, 1]round 1x[0] = 0.25x[1] = 0.4x[2] = 0.55x[3] = 0.7x[4] = 0.85x[5] = 1round 2x[0] = 0.25x[1] = 0.595076928220583x[2] = 0.493988453622788x[3] = 0.714333640596557x[4] = 1.14135676154991x[5] = 1round 3x[0] = 0.25x[1] = 0.638393337463021x[2] = 0.63752199068821x[3] = 0.538600997945798x[4] = 1.07101841739164x[5] = 1round 4x[0] = 0.25x[1] = 0.559423143598625x[2] = 0.560673538304964x[3] = 0.580378820375143x[4] = 1.04454592077508x[5] = 1so here's a look at my actual code.template <typename func_t>type_t minimax(size_t degree, const type_t& lowerlimit, const type_t& upperlimit, unsigned char iterations, func_t f0, func_t f1, func_t f2){ // (c) jacob wells 2015 // this code is licensed under the bsd 3-clause license // <url> if((degree < 1) || (iterations < 1)) { return (type_t)nan; } const type_t one(1), neg1(-1), zero(0); matrix_t<type_t> m(degree + 2, degree + 3); vector<type_t> xval; type_t delta, sign, pow, err; type_t d1, d2; size_t i, j; delta = (upperlimit - lowerlimit) / (degree + 1); xval.resize(degree + 2); coef.resize(degree + 1); sign = one; for(i = 0; i < (degree + 2); i++) // generate our initial x-values { xval[i] = (i * delta) + lowerlimit; } do { sign = neg1; for(i = 0; i < (degree + 2); i++) { pow = one; m[i][degree + 1] = sign; // enters the alternating error sign m[i][degree + 2] = f0(xval[i]); // enters the f(x) value sign *= neg1; for(j = 0; j <= degree; j++) // evaluates the polynomial for each power { m[i][j] = pow; pow *= xval[i]; } } rref(degree + 2, m); // use row reduction echelon form to find the polynomial coefficients err = m[degree + 1][degree + 2]; for(i = 0; i <= degree; i++) // copy the coefficients into the polynomial class' array { coef[i] = m[i][degree + 2]; } if(iterations > 1) { for(i = 1; i <= degree; i++) // use newton's method to find our new x-values { d1 = nth_deriv(xval[i], 1) - f1(xval[i]); d2 = nth_deriv(xval[i], 2) - f2(xval[i]); if((d1 != zero) && (d2 != zero)) { xval[i] -= (d1 / d2); } } } }while(--iterations != 0); return err;} a quick little guide to some of my code: f0, f1, & f2 are, respectively, the square root functions, it's first derivative, and it's second derivative.nth_deriv calculate the nth derivative of the current polynomial.rref reduces the matrix to row reduction echelon formmatrix_t is a bare bones matrix class i came up with.now i have done a lot of testing on these functions, and i haven't found a single error with them, so i feel very confident that the problem is in the minimax function.edit: my barebones matrix classtemplate <typename type_t>class matrix_t{ public: ~matrix_t() {} matrix_t(size_t coll, size_t rowl) { arr.resize(coll * rowl); rowlen = rowl; } type_t* operator [] (size_t i) { return &arr[i * rowlen]; } const type_t* operator [] (size_t i) const { return &arr[i * rowlen]; } type_t at(size_t i) { return arr[i]; } private: size_t rowlen; vector<type_t> arr; matrix_t(); matrix_t(const matrix_t& m); void operator = (const matrix_t& m);};",
    "present_kp": [
      "polynomials",
      "curve fitting"
    ],
    "absent_kp": [
      "regression",
      "approximation algorithms"
    ]
  },
  {
    "text": "what is the state of art in geometric lod in games?. how do modern games do geometry level-of-detail for object meshes like characters, terrain, and foliage? there are two parts to my question:what does the asset pipeline look like? do artists make a high-poly model which is later decimated? if so, what decimation algorithms are most popular? are lod meshes sometimes done by hand?how do engines transition between different object lods at run time? are there any smooth or progressive transitions?the answer might be different studios use different techniques. if so, please identify some of the most common practices. it would also be great if you could point me to whitepapers/slides that cover specific examples.",
    "present_kp": [
      "geometry"
    ],
    "absent_kp": []
  },
  {
    "text": "getting re error: repetition-operator operand invalid on osx sed. i'm copy a sed script form ubuntu debian to osx but gettingre error: repetition-operator operand invalidwhat is wrong?$ . sed_shorter_version_user_extensions_to_ruby.shsed: 22: ### delete whole lines ...: re error: repetition-operator operand invalidinspecting 1 file......the script is:(i left the line numbers in in case the 22 means line 22). 1 sed ' 2 ### delete whole lines 3 /\\/\\//d 4 /^$/d 5 ### change large chunks 6 s/^storedvars\\[/ def / 7 s/sad/sad/ 8 s/happy/happy/ 9 s/\\][[:space:]]*=[[:space:]]*/\\ 10 / 11 s/;/\\ 12 end\\ 13 / 14 ### change small chunks 15 s/css=// 16 s/link=// 17 s/label=// 18 ### change specific lines 19 ### scoped corrections for clarity 20 /def insurance_expiration/ { 21 /expiration_month/ { 22 s/value=.*\\+1)/(date.new + 1.month).strftime(%b)/ 23 } 24 /expiration_year/ { 25 s/value=.*fullyear())/(date.new + 1.month).strftime(%y)/ 26 } 27 } 28 ### unable to combine these for the %b and %y despite several tries mdd 9/13/2015 29 /date.*new.*month/ { 30 s///g 31 s/%b/%b/ 32 s/%y/%y/ 33 } 34 /choose_submodel_text/ { 35 s/ \\] =/ / 36 } 37 /email.*albert.*random/ { 38 s/(albert.*gmail\\.com)/faker::internet.email/ 39 } 40 ' variables/user-extensions.js | awk ' 41 ### add header and footer 42 begin { print # page object methods; print module pageobject # variable values } 43 { print } 44 end { print end } '> rspec_conversions/new_page_object_methods.rb 45 rubocop -a rspec_conversions/new_page_object_methods.rb",
    "present_kp": [
      "debian",
      "sed",
      "osx"
    ],
    "absent_kp": [
      "shell"
    ]
  },
  {
    "text": "is meta name=verify-v1 essentially google webmaters verification meta?. if a website uses meta name=verify-v1 within the head, does this mean they are using google webmaster tools? and is it associated with any other services?",
    "present_kp": [],
    "absent_kp": [
      "google search console",
      "meta tags"
    ]
  },
  {
    "text": "asymptotic approximation of a recurrence relation (akra-bazzi doesn't seem to apply). suppose an algorithm has a runtime recurrence relation:$ t(n) = \\left\\{ egin{array}{lr} g(n)+t(n-1) + t(\\lfloor\\delta n floor ) & : n \\ge n_0\\ f(n) & : n < n_0 \\end{array} ight.$ for some constant $0 < \\delta < 1$. assume that $g$ is polynomial in $n$, perhaps quadratic. most likely, $f$ will be exponential in $n$.how would one go about analyzing the runtime ($\\theta$ would be excellent)? the master theorem and the more general akra-bazzi method do not seem to apply.",
    "present_kp": [
      "recurrence relation"
    ],
    "absent_kp": [
      "asymptotics"
    ]
  },
  {
    "text": "does verification that owner of domain undergo on google ever expire?. recently i've logged into my webmaster tools and noticed that i still got verifications on some of the sites that i do not own anymore, for like several years already. it suddenly brought multitude of questions to my mind, for example there were sites that i did together with some ex-partners, that i do not communicate with anymore, because of personal reasons. does this mean that they still own some rights to my sites from googles point of view? shouldn't verification auto expire at some point in time?",
    "present_kp": [
      "domain"
    ],
    "absent_kp": [
      "google apps"
    ]
  },
  {
    "text": "can cognito form work offline and be embedded in ipad app?. can cognito form work offline? i need a form that works both online and offline. when offline, user can still fill in the form. data is stored in the app and be sent to database once the ipad is connected to internet again.can cognito form be embedded in ipad app?",
    "present_kp": [],
    "absent_kp": [
      "cognito forms"
    ]
  },
  {
    "text": "how to edit rpm's header and name-version-release. is there's a way or a tool that can modify the header and the name-version-release for an existing rpm without installing/rebuilding it?",
    "present_kp": [
      "rpm"
    ],
    "absent_kp": [
      "package management"
    ]
  },
  {
    "text": "why was my site not aproved for adsense?. our new site <url> has failed to get approval for adsense.even though site look reasonably better we cant figure out what is the real issue for disapproval can somebody help regarding this?email we got : we did not approve your application for the reasons listed below.issues:site does not comply with google policiesfurther detail:site does not comply with google policies: we're unable to approve your adsense application at this time because we feel that your site does not comply with google adsense policies or webmaster quality guidelines. it's our goal to provide our advertisers sites that offer rich and meaningful content, receive organic traffic, and allow us to serve well-targeted ads to users. we believe that currently your site does not fulfill this criteria.please help us find out the real factor which caused disapproval.",
    "present_kp": [
      "google adsense"
    ],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "which principle is it to fetch only needed data?. it often makes sense to fetch only what you need for example if i should display only 10 rows of data then i should not fetch the entire data set because it would waste resources for a large data set. a practical example is the sql limit keyword. select * from users order by added limit 10i wonder if we can connect that to a software principle. there is the keep-it-simple principle but maybe it is a case of rule of the least power but for data instead of programs?",
    "present_kp": [],
    "absent_kp": [
      "principles",
      "workload estimation"
    ]
  },
  {
    "text": "remote text mode terminal shell screen. i know it is possible to have remote vnc screen on server and connect to it and see, what is happening there.is it possible to have the same in text-mode shell?i would connect to remote machine with ssh, then connect to such remote screen and see, what my program does there?the general task is following:i have python script, that is scrapping the web. this script just prints what it does to stdout. currently i am running the script in ssh terminal. from time to time i am switching to ssh window and see, how my script feels: either it is still working, or it is crashed with error report.but in this situation, if i reboot my machine or network disconnect, my ssh session will quit and all containin programs will stop.how to avoid this? how to have something like text-mode vnc?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "background process"
    ]
  },
  {
    "text": "pci passthrough device memory access incorrect. i have a wrlinux yocto system running on an intel haswell processor. here we pass through a pcie device (broadcom switch) to the vm, launched using qemu/kvm. the guest is able to detect the device via config space and is allocating memory space based on bar, but the device memory access seems incorrect. perhaps the guest physical address mapping went wrong? access doesn't fail, it returns invalid data. how to debug whether the dma remapping to guest is properly setup or not?",
    "present_kp": [
      "memory",
      "kvm",
      "pci passthrough"
    ],
    "absent_kp": [
      "virtual machine"
    ]
  },
  {
    "text": "unable to use yum repos whether with baseurl or mirrorlist in centos 6.5. since a couple of days, i'm unable to retrieve repositories data with yum, in my centos 6.5 server.i did yum clean all a dozen of times, it emptied all but didn't solved the problem.i tried to retrieve things by restricting to the single base repo :[base]name=centos-$releasever - basemirrorlist=<url> --verbose update results in :loading fastestmirror pluginloading priorities pluginconfig time: 0.010yum version: 3.2.29setting up package sacksdetermining fastest mirrorscould not retrieve mirrorlist <url> error was14: pycurl error 22 - the requested url returned error: 403 forbiddenerror: cannot find a valid baseurl for repo: baseand when i configure a baseurl instead of a mirrorlist, i get this : loading fastestmirror pluginloading priorities pluginconfig time: 0.010yum version: 3.2.29setting up package sacksdetermining fastest mirrorshttp://mirror.centos.org/centos/6/os/x86_64/repodata/repomd.xml: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.error: cannot retrieve repository metadata (repomd.xml) for repository: base. please verify its path and try againthe server pings mirror.centos.org and i can reach without any problem the mirrorlist and the repomd.xml in a web browser. disabling the plugins changed nothing.the mirrorlist gives a 403 error and a baseurl 404... rpm -q --verify -f /etc/yum.repos.d/* results in : s.5....t. c /etc/issue.......t. c /etc/yum.repos.d/centos-base.repo.......t. c /etc/yum.repos.d/centos-debuginfo.repo.......t. c /etc/yum.repos.d/centos-media.repo.......t. c /etc/yum.repos.d/centos-vault.repos.5....t. c /etc/issue.......t. c /etc/yum.repos.d/centos-base.repo.......t. c /etc/yum.repos.d/centos-debuginfo.repo.......t. c /etc/yum.repos.d/centos-media.repo.......t. c /etc/yum.repos.d/centos-vault.repos.5....t. c /etc/issue.......t. c /etc/yum.repos.d/centos-base.repo.......t. c /etc/yum.repos.d/centos-debuginfo.repo.......t. c /etc/yum.repos.d/centos-media.repo.......t. c /etc/yum.repos.d/centos-vault.repos.5....t. c /etc/issue.......t. c /etc/yum.repos.d/centos-base.repo.......t. c /etc/yum.repos.d/centos-debuginfo.repo.......t. c /etc/yum.repos.d/centos-media.repo.......t. c /etc/yum.repos.d/centos-vault.repo.......t. c /etc/yum.repos.d/epel-testing.repo.......t. c /etc/yum.repos.d/epel.repo.......t. c /etc/yum.repos.d/epel-testing.repo.......t. c /etc/yum.repos.d/epel.repole fichier /etc/yum.repos.d/isv:owncloud:community.repo n'appartient aucun paquetage.......t. c /etc/yum.repos.d/jpackage.repole fichier /etc/yum.repos.d/jpackage.repo.rpmsave n'appartient aucun paquetagen'appartient aucun paquetage means doesn't belong to any package, in french...those problems occur with whatever repo i enable/disable.",
    "present_kp": [
      "centos",
      "yum",
      "rpm"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "when is {a,b,c} expanded in bash, when is it not?. a bash script that containsfor i in {a,b}-{1,2}; do echo $i;doneprintsa-1a-2b-1b-2when executed. this is what i expected - as the {a,b} construct is expanded.however, when (another) script containsv={a,b}-{1,2}echo $vit prints{a,b}-{1,2}which is not what i expected. i expected it to print a-1 a-2 b-1 b-2. obviously, the {a,b} construct is not expanded.i can make it expand like sov=$(echo {a,b}-{1,2})based on these observations i have two questions: 1) when is the {a,b} construct expanded? 2) is $(echo {a,b}-{1,2}) the preferred way to trigger an expansion when required?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "brace expansion"
    ]
  },
  {
    "text": "how to make 'xargs' ignore child's exit and keep processing further. i sometimes run long xargs jobs overnight and it is really annoying to discover in the morning that xargs died somewhere in the middle, for example because of a segmentation fault in one single special case, as happened this night.if even one xargs child is killed, it does not process any more input:console 1:[09:35:48] % seq 40 | xargs -i --max-procs=4 bash -c 'sleep 10; date +%h:%m:%s {};'xargs: bash: terminated by signal 1509:35:58 309:35:58 409:35:58 2<exit with code 125>console 2:[09:35:54] kill 5601can i somehow prevent xargs from stopping to process any more input once a child process dies and instead continue processing?",
    "present_kp": [
      "kill",
      "xargs"
    ],
    "absent_kp": [
      "signals"
    ]
  },
  {
    "text": "change library location. i've got different versions of the libnet library installed in different locations on the same system:whereis libnetlibnet: /usr/lib/libnet.la /usr/lib/libnet.a /usr/lib/libnet.so /usr/local/lib/libnet.la /usr/local/lib/libnet.a /usr/local/lib/libnet.so /usr/include/libnet.h /usr/include/libnet /usr/man/man3/libnet.3i have some problems with compiling a program that depends on these libnet libraries so i want to remove the usr/local/....-ones. can you tell me how to do that, i.e, when i whereis libnet on the command line i want to not see the /usr/local/... references ?!thank you!",
    "present_kp": [],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "wikipath stack in java - part ii/iv - the implicit wikipedia article graph. this question is the continuation of the wikipath stack series: the two classes that - given a wikipedia article \\$a\\$ - return the lists of neighbour articles. the forward node expander return the list of articles to which \\$a\\$ links, and the backward node expander return the list of articles that link to \\$a\\$. since both are available, we can perform a bidirectional search for a shortest path. also, note that whenever given two terminal nodes (the source article \\$s\\$ and the target article \\$t\\$), and both the expander classes, we can construct implicitly the wikipedia article graph. by implicit we mean that only needed nodes (articles) are actually generated.as an overview of the entire software stack, i repost the diagram:the part in this question is the wikipediagraphnodeexpanders.below is my code:abstractwikipediagraphnodeexpander.java:package net.coderodde.wikipedia.graph.expansion;import com.google.gson.jsonarray;import com.google.gson.jsonobject;import com.google.gson.jsonparser;import java.io.ioexception;import java.io.unsupportedencodingexception;import java.net.url;import java.net.urlencoder;import java.nio.charset.charset;import java.util.arraylist;import java.util.hashmap;import java.util.list;import java.util.map;import java.util.objects;import java.util.regex.pattern;import net.coderodde.graph.pathfinding.uniform.delayed.abstractnodeexpander;import org.apache.commons.io.ioutils;/** * this abstract class specifies the facilities shared by both forward and * backward node expanders. * * @author rodion rodde efremov * @version 1.6 (aug 6, 2016) */public abstract class abstractwikipediagraphnodeexpanderextends abstractnodeexpander<string> { protected static final map<character, string> encoding_map = new hashmap<>(); static { encoding_map.put(' ', _); encoding_map.put('', %22); encoding_map.put(';', %3b); encoding_map.put('<', %3c); encoding_map.put('>', %3e); encoding_map.put('?', %3f); encoding_map.put('[', %5b); encoding_map.put(']', %5d); encoding_map.put('{', %7b); encoding_map.put('|', %7c); encoding_map.put('}', %7d); encoding_map.put('?', %3f); } /** * the script url template for expanding forward. */ private static final string forward_request_api_url_suffix = ?action=query + &titles=%s + &prop=links + &pllimit=max + &format=json; /** * the script url template for expanding backwards. */ private static final string backward_request_api_url_suffix = ?action=query + &list=backlinks + &bltitle=%s + &bllimit=max + &format=json; /** * the pattern for wikipedia urls. */ private static final pattern wikipedia_url_pattern = pattern.compile(^(https://|http://)?..+\\.wikipedia.org/wiki/.+$); /** * the https protocol prefix. */ private static final string secure_http_protocol_prefix = https://; /** * the http protocol prefix. */ private static final string http_protocol_prefix = http://; /** * the <tt>wiki</tt> directory token. */ private static final string wiki_dir_token = /wiki/; /** * the api script path. */ private static final string api_script_name = /w/api.php; /** * caches the basic wikipedia article url. for example, the basic url of * <tt><url> is * <tt>en.wikipedia.org</tt>. */ protected final string basicurl; /** * caches the textual representation of the url pointing to the * <a href=<url> api</a>. */ private final string apiurl; /** * constructs a graph node expander for the language subgraph specified in * the input url. * * @param wikipediaurl the entire wikipedia article url. */ protected abstractwikipediagraphnodeexpander(string wikipediaurl) { final string originalwikipediaurl = wikipediaurl; objects.requirenonnull(wikipediaurl, the input wikipedia article is null.); if (!wikipedia_url_pattern.matcher(wikipediaurl).matches()) { throw new illegalargumentexception( [input error] the input url is not a valid wikipedia + article url: \\ + originalwikipediaurl + \\.); } wikipediaurl = removeprotocolprefix(wikipediaurl); if (wikipediaurl.contains(://)) { throw new illegalargumentexception( [input error] the input url specifies unknown protocol: + \\ + originalwikipediaurl + \\.); } this.apiurl = constructapiurl(wikipediaurl); this.basicurl = wikipediaurl. substring(0, wikipediaurl.indexof(wiki_dir_token)); } /** * returns the raw wikipedia url. for example, for * <tt><url> this method will * return <tt>en.wikipedia.org</tt>. this is used for making sure that a * particular language (<tt>en</tt> in the example above) is selected. * * @return the basic wikipedia url. */ public string getbasicurl() { return basicurl; } /** * {@inheritdoc } */ @override public boolean isvalidnode(final string node) { return !expand(node).isempty(); } /** * constructs a wikipedia api url from the raw {@code wikipediaurl}. the * input {@code wikipediaurl} is of the form <tt>en.wikipedia.org</tt>. the * idea here is that the search may be applied to article subgraphs with * different languages. * * @param wikipediaurl the wikipedia url. * @return full url to wikipedia api. */ private string constructapiurl(final string wikipediaurl) { return secure_http_protocol_prefix + wikipediaurl.substring(0, wikipediaurl.indexof(wiki_dir_token)) + api_script_name; } /** * if the input string {@code url} has a prefix http:// or https://, * removes it from the url and returns the url. * * @param url the url to process. * @return the url without the protocol selector. */ private string removeprotocolprefix(final string url) { if (url.startswith(secure_http_protocol_prefix)) { return url.substring(secure_http_protocol_prefix.length()); } if (url.startswith(http_protocol_prefix)) { return url.substring(http_protocol_prefix.length()); } return url; } /** * the actual implementation of the method producing the neighbors of a * graph node. * * @param node the node to expand. * @param forward specifies the direction of the node expansion operation. * if {@code forward} is {@code true}, generates the child * nodes of {@code node}. otherwise, generates the parent * nodes of {@code node}. * @return */ protected list<string> basegetneighbors(final string node, final boolean forward) { string jsondataurl; try { jsondataurl = apiurl + string.format(forward ? forward_request_api_url_suffix : backward_request_api_url_suffix, urlencoder.encode(node, utf-8)); } catch (final unsupportedencodingexception ex) { throw new illegalstateexception(ex.getmessage(), ex); } string jsontext; try { jsontext = ioutils.tostring(new url(jsondataurl), charset.forname(utf-8)); } catch (final ioexception ex) { throw new illegalstateexception( [i/o error] failed loading the json data from the + wikipedia api: + ex.getmessage(), ex); } return forward ? extractforwardlinktitles(jsontext) : extractbackwardlinktitles(jsontext); } /** * returns all the wikipedia article titles that the current article links * to. * * @param jsontext the data in json format. * @return a list of wikipedia article titles parsed from {@code jsontext}. */ private static list<string> extractforwardlinktitles(string jsontext) { list<string> linknamelist = new arraylist<>(); jsonarray linknamearray; try { jsonobject root = new jsonparser().parse(jsontext).getasjsonobject(); jsonobject queryobject = root.get(query).getasjsonobject(); jsonobject pagesobject = queryobject.get(pages).getasjsonobject(); jsonobject mainobject = pagesobject.entryset() .iterator() .next() .getvalue() .getasjsonobject(); linknamearray = mainobject.get(links).getasjsonarray(); } catch (nullpointerexception ex) { return linknamelist; } linknamearray.foreach((element) -> { int namespace = element.getasjsonobject().get(ns).getasint(); if (namespace == 0) { string title = element.getasjsonobject() .get(title) .getasstring(); linknamelist.add(encodewikipediastyle(title)); } }); return linknamelist; } /** * returns all the wikipedia article titles that link to the current * article. * * @param jsontext the data in json format. * @return a list of wikipedia article titles parsed from {@code jsontext}. */ private static list<string> extractbackwardlinktitles(string jsontext) { list<string> linknamelist = new arraylist<>(); jsonarray backlinkarray; try { jsonobject root = new jsonparser().parse(jsontext).getasjsonobject(); jsonobject queryobject = root.get(query).getasjsonobject(); backlinkarray = queryobject.get(backlinks).getasjsonarray(); } catch (nullpointerexception ex) { return linknamelist; } backlinkarray.foreach((element) -> { int namespace = element.getasjsonobject() .get(ns) .getasint(); if (namespace == 0) { string title = element.getasjsonobject() .get(title) .getasstring(); linknamelist.add(encodewikipediastyle(title)); } }); return linknamelist; } /** * encodes some special characters using percent encoding. * * @param s the string to encode. * @return the encoded version of {@code s}. */ private static string encodewikipediastyle(final string s) { final stringbuilder sb = new stringbuilder(); for (final char c : s.tochararray()) { string encoder = encoding_map.get(c); if (encoder != null) { sb.append(encoder); } else { sb.append(c); } } return sb.tostring(); }}forwardwikipediagraphnodeexpander.java:package net.coderodde.wikipedia.graph.expansion;import java.util.list;/** * this class implements a forward node expander in the wikipedia article graph. * if article <tt>a</tt> has a link to <tt>b</tt>, this expander will generate * <tt>b</tt> whenever asked to process <tt>a</tt>. we can say that this * expander traverses each directed arc from tail to head. * * @author rodion rodde efremov * @version 1.6 (aug 6, 2016) */public class forwardwikipediagraphnodeexpander extends abstractwikipediagraphnodeexpander { public forwardwikipediagraphnodeexpander(final string wikipediaurl) { super(wikipediaurl); } @override public list<string> expand(string node) { return basegetneighbors(node, true); }}backwardwikipediagraphnodeexpander.java:package net.coderodde.wikipedia.graph.expansion;import java.util.list;/** * this class implements a backward node expander in the wikipedia article * graph. if article <tt>a</tt> has a link to <tt>b</tt>, this expander will generate * <tt>a</tt> whenever asked to process <tt>b</tt>. we can say that this * expander traverses each directed arc from head to tail. * * @author rodion rodde efremov * @version 1.6 (aug 6, 2016) */public class backwardwikipediagraphnodeexpander extends abstractwikipediagraphnodeexpander { public backwardwikipediagraphnodeexpander(final string wikipediaurl) { super(wikipediaurl); } @override public list<string> expand(final string node) { return basegetneighbors(node, false); }}demonstrationyou can see the expanders in action at <url> requesti want to improve anything there is to improve, yet i don't see myself any opportunity for that, so tell my anything that comes to mind.component list so farwikipediagraphnodeexpandersdelayedgraphsearchlibrary",
    "present_kp": [
      "java",
      "json",
      "graph",
      "pathfinding"
    ],
    "absent_kp": [
      "web scraping"
    ]
  },
  {
    "text": "find all combinations of a number sequence which is first increasing then decreasing. given an integer n(natural number), a program/algorithm to find the remainder of arrangements that can be obtained by rearranging the numbers 1, 2, ...., n. input format: one line containing the integer n output format: an integer m, giving the remainder of the number of arrangements that could be obtained from 1, 2, ...., n is divide by mod constraints:mod = 10^9+7n 10^9 example 1 input3 output2 explanation: consider the first three natural numbers 1, 2, 3. these can be arranged in the following ways: 2, 3, 1 and 1, 3, 2. in both of these arrangements, the numbers increase to a certain point and then decrease. there are two such arrangements: 2, 3, 1 and 1, 3, 2. example 2input4 output6 explanation: the six arrangements are (1, 2, 4, 3), (1,3,4,2), (1,4,3,2), (2,3,4,1), (2,4,3,1), (3,4,2,1).#include<stdio.h>#include<stdlib.h>#define m 1000000007unsigned long long int power(unsigned long long int x, unsigned long long int n){ unsigned long long int res = 1; while(n > 0){ if(n & 1){ res = res * x; res = res%m; } x = x * x; x= x%m; n >>= 1; } return res;}int main(){ unsigned long long int n,res=0,temp=1,i; scanf(%llu, &n); if(n==1 || n==0){ printf(0 ); return 0; } temp = power(2, n-1); temp--; temp--; printf(%llu , temp); return 0;}can anyone solve this with better time complexity?",
    "present_kp": [
      "algorithm",
      "c"
    ],
    "absent_kp": [
      "performance",
      "combinatorics"
    ]
  },
  {
    "text": "why would a c executable be smaller when compared to c++ executable. i'm trying to understand why the output file sizes are significantly different when using a c and a c++ compiler.i was writing a small hello world program in c and c++, i noticed that in c version, the size of the executable was 93.7kb and in c++, the size of the same hello world program was 1.33mb. i am not sure why that is. i think it may be because c++ has more libraries and namespaces to use so i removed the using namespace std line and simply used std::cout and still the result was the same. c#include <stdio.h>int main(){ printf(hello world); return 0;}// size 93.7kbc++#include <iostream>int main(){ std::cout<<hello world; return 0;}// size 1.33mbthere doesn't seem to be much difference in the code above. is there some sort of compiler difference that creates the differing file sizes?",
    "present_kp": [
      "c++",
      "c"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the relationship between the number of states in quantum finite automata and the number of non-regular languages they can recognize?. it is has been shown that quantum finite automata can recognize at least some non-regular languages. what is the relationship between the number of states in a qfa and the number of non-regular languages it can recognize? is there a relationship at all or has it not yet been established?i have been unable to find a paper that addresses this in an overtly and understandable way. more specifically, for any one specific type (ex/ 1-way mm-qfa), has any such relationship been established for the class it recognizes? i know different types of qfas have different closure properties and other characteristics that can make them vastly different and bounds have been established for some, but i'm wondering if anyone knows of, has seen, or knows who to contact regarding the relationship between teh number of states in a qfa and its recognition properties? or, if this question is totally mute and i'm looking at it wrong, tell me why. i have read into some of freivalds' research where he touches on this, but can't find any theorems, proofs, lemmas, ect. that hammer it out, if anyone has done so at all. there is a possibility that this question is open and that's why i havent found an answer. any help you can give would be appreciated.",
    "present_kp": [],
    "absent_kp": [
      "fl.formal languages",
      "automata theory",
      "probabilistic automata"
    ]
  },
  {
    "text": "updating freebsd 8.0 to 8.1 (methods and policy). i have 8.0-release-p4 + few ports installed. i wonder wheather i should update to 8.1.how long is 8.0 supported?how to update the system? i couldn't find anything about it in handbook.solution (based on gvkv answer): i take the liberty of describing all steps i've done at the end: # step 1: revert to generic kernelcd /tmp wget -r <url> pub/freebsd/releases/i386/8.0-release/kernels/sha256 generic.* install.sh | diff - checksum.sha256./install.sh genericnextboot -k generic# step 2: upgrade - part 1freebsd-update upgrade -r 8.1-release # ignore kernel warning. fix configurationfreebsd-update installshutdown -r now# step 3: upgrade - part 2nextboot -k genericfreebsd-update installshutdown -r now# step 4: upgrade - part 3rm -rfv /usr/objportmaster -raf # rebuilds all packages. if you don't use portmaster use other tool or do it manuallycd /usr/srcmake buildkernel kernconf=custom # rebuild kernelmake installkernel kernconf=custom # install kernelshutdown -r now",
    "present_kp": [
      "freebsd",
      "upgrade"
    ],
    "absent_kp": []
  },
  {
    "text": "is collection.stream().filter().foreach() inefficient compared to a standard for each loop?. intellij idea recommended to me just now to replace the following for-each loop with a java 8 foreach call: for (object o : objects) { if (o instanceof someobject) { dosomething(); } }the recommended call would like like this:objects.stream().filter(o -> o instanceof someobject).foreach(o -> dosomething());unless i'm misunderstanding how the underlying functionality of stream works, it seems to me like using stream is an o(2n) operation as opposed to an o(n) operation for the standard for-each loop.",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "performance",
      "java8"
    ]
  },
  {
    "text": "computing the circumference of two circles. this is a program which computes the circumference of two circles and gives some information such as the difference between circumferences. i want to know whether the method declarations and method calling in my code is correct. i didn't face any errors.import java.text.*;import javax.swing.*;class q5main{ public static void main(string args[]){ double smallcircum; double largecircum; inputhandler input = new inputhandler(); question5 myq = new question5(); double a = input.getdouble(radius for the smaller circle:); smallcircum = (myq.start(a));//calculate the small circle circumference a = input.getdouble(radius for the larger circle: ); largecircum = (myq.start(a));//calculate the large circle circumference myq.showdetails(smallcircum, largecircum); }}class question5{ decimalformat df = new decimalformat(0.000); private double circumference;//to store circumference //carry out the full process public double start(double value){ return circum(value); } //compute the circumference private double circum(double radius){ circumference = 2 * math.pi * radius; return circumference; } public void showdetails(double smallcircum, double largecircum){ system.out.println(circumference of smaller circle: +df.format(smallcircum)); system.out.println( ); system.out.println(circumference of larger circle: +df.format(largecircum)); system.out.println( ); system.out.println(difference: +df.format((largecircum-smallcircum))); }}class inputhandler{ private static final string double_default_prompt = enter integer: ; public double getdouble(){ return getdouble(double_default_prompt); } public static double getdouble(string prompt){ string instr; instr = joptionpane.showinputdialog(null,prompt); return double.parsedouble(instr); }}",
    "present_kp": [
      "java"
    ],
    "absent_kp": []
  },
  {
    "text": "what other personality traits are proved to correlate with self-discipline?. are there any studies that prove other personality traits being correlated with the big5 facet c5 - self-discipline? (i'm looking for links to scientific reports)",
    "present_kp": [
      "personality"
    ],
    "absent_kp": []
  },
  {
    "text": "moving tcp flows between interfaces and recovering traffic. lets say, i have two machines a and b.both have a 2 port 10g nic. let their interfaces names be eth0 and eth1 respectively.let eth0 of machine a be connected to eth0 of machine b.and eth1 of machine a be connnected to eth1 of machine b.i have the following questions.i have a tcp application (some web application) that starts sending some data using eth0 port (machine a), so it will be received at eth0 port (machine).after a few seconds, i want to move the tcp application from eth0 port to eth1 port (in machine a). how can i do this?as soon as i move the data to eth1 port (in machine a), i want to capture the data in eth1 port (in machine b). same mechanism as above.now, part of the data (packets) was passed through eth0 port and part of the data would have passed through eth1 port. i presume this will break the tcp connection. how can i recover the data at machine b (ie, unify and recover packets that were obtained in eth0 and eth1 interfaces).any pointers or help is greately appreciated.",
    "present_kp": [
      "tcp"
    ],
    "absent_kp": [
      "linux",
      "networking"
    ]
  },
  {
    "text": "svn best practices - different code logic in branches. while working with one project i was assigned to, i noticed a small problem with our svn strategy. a few months ago, someone created a new feature branch from our trunk. in this branch he implemented a second implementation of an already implemented feature (but in a more efficient way). he changed actually only one class.after this action some of the classes methods are common for both places - trunk and feature branch - but some methods are specific for each implementation. it was decided that we have to support both version so sometimes we create a deploy from branch, sometimes from trunk (some business assumptions). now i have some problems with merging - normally i want to merge only these code parts which are common for trunk and branch. it makes each merge more complicated because each time i have conflicts to solve (and i have many of them) i have to pay extra attention to what action should i take for each conflicted line. my question is: am i right in claiming that the decision of creating a new version which should be supported as a feature branch was a bad idea? what are the best practices in such case?",
    "present_kp": [
      "svn"
    ],
    "absent_kp": [
      "branching"
    ]
  },
  {
    "text": "are there any known android phones planned which will work on project fi besides nexus 5x and nexus 6p?. i know project fi recently rolled out and currently requires a nexus 5x or nexus 6p. at the time i'm writing this, no other phones currently support project fi, but are there any others in the pipeline that will work, which will be released (or have been released later)?",
    "present_kp": [
      "android",
      "project fi"
    ],
    "absent_kp": [
      "smartphones"
    ]
  },
  {
    "text": "when writing tests for a wordpress plugin, should i run them inside wordpress or in a normal browser?. i have started using bdd for a wordpress plugin i'm working on and i'm rewriting the js codebase to do tests. i've encountered a few problems but i'm going steady now, i was wondering if i had the right approach, because i'm writing test that should pass in a normal browser environment and not inside wordpress.i choose to do this because i want my plugin to be totally indipendent from the wordpress environment, i'm using requirejs in a way that i don't expose any globals and i'm loading my version of jquery that doesn't override the one that ships with wordpress. in this way my plugin would work the same on every wordpress version and my code would not break if they cheange the jquery version or someone use my plugin on an old wordpress version.i wonder if this is the right approach or if i should always test inside the environment i'm working in. since wordpress implies some globals i had to write some function purely for testing purpose, likeget_ajax_url: function() { if( typeof window.ajaxurl === undefined ) { return <url> } else { return window.ajaxurl; }}, but apart from that i got everything working right. what do you think?",
    "present_kp": [
      "bdd",
      "wordpress"
    ],
    "absent_kp": [
      "javascript",
      "unit testing",
      "plugins"
    ]
  },
  {
    "text": "vim c++ clang_complete doesn't work for std::cin.get(). i'm using vim to do c++ projects on mac os x.to auto complete, i use this plugin: clang_completefor most of cases, such as members of user-defined classes, members of namespaces, it works very well.for example, when i type std::, many things such as cout, cin will popup.however, when i type std::cin., or std::string str; str. nothing popups and i got an error:pattern not foundit seems that user-defined classes' members can popup automatically whereas c++ library stuff's members can't. i don't know why.here is my .vimrc file:",
    "present_kp": [
      "vimrc"
    ],
    "absent_kp": [
      "autocompletion",
      "filetype c++",
      "plugin clang complete"
    ]
  },
  {
    "text": "what's the difference between 'mkdir -p' and 'install -d'?. what, precisely, is the difference in what is being performed by mkdir -p and install -d, in terms of what changes the two commands are doing to the system?",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "coreutils"
    ]
  },
  {
    "text": "wild and changing business rules implemented with functional programming. i attempted the business rules kata. here's a video overview.however, i am not confident that going functional is a good strategy for the following objective:how can you tame these wild business rules? how can you build a system that will be flexible enough to handle both the complexity and the need for change? and how can you do it without condemning yourself to years and years of mindless support?is there an alternative fp approach that satisfies the objective stated above?module paymentsystem(*types*)type productid = productid of stringtype memberid = memberid of stringtype email = email of stringtype agent = agenttype royaltydepartment = royaltydepartmenttype packingslip = { memberid:memberid productid:productid}type physicalproducts = | book | video | othertype membershiptype = | membership of memberid | upgrade of memberidtype paymentfor = | physicalproduct of physicalproducts * packingslip | membership of membershiptypetype packingslipoptions = | packingslip of packingslip | duplicateslips of packingslip | withfirstaidvideo of packingsliptype paymentresponse = | packingslip of packingslipoptions | activatemembership of memberid | upgrademembership of memberid | emailowner of membershiptype | commissionpayment of agent(*functions*)let publish payload = () // stublet getagent productid = agent // stublet respondto (payment:paymentfor) = match payment with | physicalproduct (kind , packingslip) -> publish (commissionpayment (getagent packingslip.productid)) match kind with | book -> publish (duplicateslips packingslip) | video -> publish (withfirstaidvideo packingslip) | other -> publish packingslip | membership kind -> publish(emailowner kind) match kind with | membershiptype.membership memberid -> publish(activatemembership memberid) | membershiptype.upgrade memberid -> publish(upgrademembership memberid)",
    "present_kp": [],
    "absent_kp": [
      "f#"
    ]
  },
  {
    "text": "if i like a post that is shared with friends but the original post was public, who can see that i liked the shared post?. if i like a post that is shared by a friend with their friends but the original post was public, who can see that i liked the shared post?in other words, if friend a (let's call her anna) shares a post from a general page b (let's call this fb page bananas) - and the original bananas post was public but anna is only sharing that bananas post with her friends, who can see my 'like' to this shared post?",
    "present_kp": [],
    "absent_kp": [
      "facebook like",
      "facebook privacy"
    ]
  },
  {
    "text": "implications of faster randomized $circuit sat$ algorithm. in here on page $13$ proposition $1$ it says 'if $circuit$ $sat$ on $n$ inputs and $m$ gates is in $2^{n^{o(1)}}poly(m)$ time, then $exp ot\\subseteq p/poly$'.can we have randomized $2^{n^{o(1)}}poly(m)$ time in above statement?is there a similar result that would give $e ot\\subseteq size(2^{\\delta n})$ (this would give $p=bpp$)?how large can $o(1)$ be in the statement above and in 1. if applicable (can it be as large as $1/\\log\\log n$)?",
    "present_kp": [],
    "absent_kp": [
      "big picture",
      "derandomization"
    ]
  },
  {
    "text": "find files with path of a directory exclude subdirectories. how can i use find to traverse a directory, but not recurse into its subdirectories?i tried -prune and it does not work. and there is no -maxdepth option.find /opt/projectname/bin -type f /opt/projectname/bin -prune -o -printfind: missing conjunction/opt/projectname/bin/file_1_is_printed/opt/projectname/bin/file_2_is_printed/opt/projectname/bin/directory_within_bin/some_file_should_not_be_printed/opt/projectname/bin/directory_2_within_bin/some_file_2_should_not_be_printed/usr/bin/find: find.c $date: 2011/08/12 15:04:36 $revision: r11.31/4 patch_11.31 (phco_42158) libcpio.c $date: 2008/05/27 16:08:10 $revision: r11.31/2 patch_11.31 (phco_36666) $revision: @(#) find r11.31_bl2011_0923_2 patch_11.31 phco_42158this question is not a repeat question. there is no gnu here. although the question may be a repeat question, the answers posted on those questions ask installations of gnu tools. hence if the answers here help solve, this is a unique thread.",
    "present_kp": [
      "find"
    ],
    "absent_kp": []
  },
  {
    "text": "how to tell apt to use the latest package by default?. i put jessie-backports in my /etc/apt/sources.list, but it seems that apt will not automatically use the packages from backports but older packages.however, if i use apt-cache show to check the version it shows the latest, and i am able to use apt install xxx=<latest-version> to install it.how to tell apt always use the latest package by default?",
    "present_kp": [
      "apt"
    ],
    "absent_kp": [
      "debian"
    ]
  },
  {
    "text": "spotify is not working at all after cancelling premium. everytime i double-click a song in my library (saved, not local) i get an error that the current song cannot be played. i cancelled premium and i've played a few songs in my app, but the desktop software and web player will not play anything. help appreciated!",
    "present_kp": [
      "spotify"
    ],
    "absent_kp": []
  },
  {
    "text": "collisions in independent hashing. let $h$ be a $s$-wise independent family of hash functions from $\\{1,\\ldots,m\\}$ to $\\{1,\\ldots,n\\}$. it is easy to bound one collision, but are there good bounds for muliple collision ?",
    "present_kp": [
      "hash"
    ],
    "absent_kp": [
      "computability",
      "data structures",
      "probability theory",
      "hash tables"
    ]
  },
  {
    "text": "check accuracy of model provided by consultant. my company has recently engaged a consultant firm to develop a predictive model to detect defective works.i understand that there are many ways to validate the model, for example, using k-fold cross-validation and i believe that the consultant firm will carry out the validation before submitting the model to us.however, at the employer's side, how can i check the accuracy of the model developed by the consultant firm ?? someone suggested that i can give 2000-2015 data to the consultant firm and keep 2016 data for our own checking. however, a model with good accuracy on 2016 data does not imply that it will have good predictive power in the future. in my view, keeping 2016 data for checking seems like adding one more test set for validation, which in my view, is unnecessary since i already hv k-fold cross validation.could someone advise what the employer can do to check the consultant's model?",
    "present_kp": [
      "cross validation",
      "accuracy"
    ],
    "absent_kp": [
      "machine learning",
      "predictive modeling"
    ]
  },
  {
    "text": "update .profile in /etc in unix. how can i append the following text in .profile in folder /etc/security of unix os?ps1='hostname -s':$logname'[$pwd]'i tried:print 'export ps1='hostname -s':$logname'[$pwd]' ' >> profilemy output gives:export ps1='hostname -s':$logname[/etc]with [/etc].",
    "present_kp": [],
    "absent_kp": [
      "shell",
      "quoting",
      "prompt"
    ]
  },
  {
    "text": "proper use or convenience, or both?. in my current project, i am working with a lot of json objects that contain arrays, er.. lists so i setup a decorator for convienece when the list is one item or multiple. even though this is convienent in the current project, is it reusable code?def collapse(function): @functools.wraps(function) def func(*args, **kwargs): call = function(*args, **kwargs) if isinstance(call, (list, tuple)) and (len(call) == 1): return call[0] return call return func@collapsedef get_results(query, wrapper=none): # get json object. result = result.json() # using the requests library. if wrapper: return result[wrapper] return resultso, get_results() has the potential of returning either a list or a dict. in most cases, the code knows when what type is returned, so using the @collapse decorator changes [result_dict] to just result_dictis this a good practice, or should i write a decorator that takes a limit parameter@limit(1) # def limit(items=none): ... return data[0:items] if items else datadef get_results(query, wrapper=none):just wrote out the limit decorator...def limit(items=none, start=0, collapse=false): if items and (start > 0): items += start def wrapper(function): @functools.wraps(function) def func(*args, **kwargs): call = function(*args, **kwargs) if isinstance(call, (list, tuple)): results = call[start:items] if items else call if collapse and (len(results) == 1): return results[0] else: return results return call return func return wrapper",
    "present_kp": [],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "count occurrence of a word in google spreadsheet. i've got a ton of cells (say 6x20) that have various names in them. i'd like to total the number of times a name in another field matches any of the other cells.alice bob clairedoug alice chrisbob claire bobit seems like there should be a way to look at the example 3x3 above (or my actually much larger group of names) and extract how many bobs or alices or whatever occur. my spreadsheet-fu is weak and i haven't been able to find an answer via google (probably because i just don't know the right term for what i want to do).here's a sample of what i'm trying for: count occurenceit uses if statements, but since each cell needs it's own if statement this is not really a viable way to make the spreadsheet, especially as more people can be added in at later points.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "git and sshfs: status is inaccurate. i am mounting a git repository on a virtual machine over sshfs onto my host machine. so far so good. however, git claims that there are many uncommitted changes when viewing the repository over sshfs. why is that?the relevant bit from /etc/fstab, if that helps:sshfs#usr@virtual:/home/user/repos /home/user/repos/ fuse noauto,user,uid=1000,gid=1000,umask=0,workaround=rename 0 0note: cloning, push, and pull operations could done instead but the code needs to compile on the virtual machine os and not on the host machine -- long story, it has to be this way. i do not fancy doing a commit per compile, that's just silly.",
    "present_kp": [
      "git",
      "sshfs"
    ],
    "absent_kp": []
  },
  {
    "text": "disable search option for resolv.conf. we are running a script that tries to resolve thousands of domains for a research project. the issue we are having is that a lot of domains are not resolvable for example foo.com. if we ping foo.com the system will do a lookup for foo.com. if that does not resolve, it will do a lookup for foo.com.ourdomain.com. it /etc/resolv.conf we had:# generated by networkmanagersearch ourdomain.comnameserver 8.8.8.8nameserver 4.2.2.2the above result is expected since we had the search setting set. if we changed it to say:# generated by networkmanagersearch ourdomain.netnameserver 8.8.8.8nameserver 4.2.2.2then as expected any non-resolvable query will be queried again with ourdomain.net at the end.the issue that we have is if we remove the search line completely from resolv.conf then system goes back to using ourdomain.com as the search. what we want is if a dns lookup does not resolve to not then look it up with the domain that was set in resolv.conf (which is also the domain of the box).",
    "present_kp": [
      "resolv.conf"
    ],
    "absent_kp": [
      "centos"
    ]
  },
  {
    "text": "crontab order run with differents schedule. i have a crontab with different time to execute some task, for example every minute, every 10 min, 1 hour, daily... and i have a question, when some of this cron coincide in the same time for example, when 10 minutes execute, also execute 1 min cron and this cron execute in parallel... but i want to execute in sequence, for example all jobs in 1 minute, and the all jobs in 10 min... how can i do this??",
    "present_kp": [
      "cron"
    ],
    "absent_kp": [
      "executable"
    ]
  },
  {
    "text": "how to convert a colored file to mail readable in bash?. i have a file which was created by a script which will be colored when i open using cat. but when i tried to send that file as attachment, it is not showing properly. like below it is showing.^[[33m================================================================================^[[m ^[[34m172.29.0.110^[[m^[[33m================================================================================^[[mfilesystem size used avail use% mounted on/dev/mapper/centos 109g 13g 91g 13% //dev/mapper/mpatha 1.6t 1.3t 277g 83% /var/lib/sql^[[33m================================================================================^[[m ^[[34m172.29.8.110^[[m^[[33m================================================================================^[[mfilesystem size used avail use% mounted on/dev/mapper/centos 117g 9.1g 102g 9% //dev/mapper/mpatha 1.6t 1.4t 109g 93% /var/lib/sql^[[33m================================================================================^[[m ^[[34m172.29.16.110^[[m^[[33m================================================================================^[[mfilesystem size used avail use% mounted on/dev/mapper/centos 117g 18g 94g 17% //dev/mapper/vg01-lv 1.5t 812g 590g 58% /var/lib/sql^[[33m================================================================================^[[m ^[[34m172.29.26.110^[[m^[[33m================================================================================^[[mfilesystem size used avail use% mounted on/dev/mapper/logvol02 117g 22g 90g 20% //dev/mapper/mpathm 1.6t 1.1t 435g 71% /var/lib/sqlthe script(part of the script) that creates the file is ::for ip in $(cat file.txt); do (echo -e \\e[33m$line\\e[m echo -e \\e[34m$ip\\e[m echo -e \\e[33m$line\\e[m echo -e filesystem size used avail use% mounted on ssh $ssh_arg -q user@${ip} df -ph | egrep -iv 'filesystem|boot|tmpfs') >> /disk_${date}_log echo -e \\e[33m$line\\e[m echo successful for $ipdonecat disk_${date}_log | mail -s disk space <email> can remove those echo's that creating colors, but i want to know is there any way i can send this file properly by mail or can i do something in mail command to solve this?",
    "present_kp": [
      "bash",
      "files"
    ],
    "absent_kp": [
      "linux",
      "sendmail"
    ]
  },
  {
    "text": "any way to download from scribd?. is there any way i can download from scribd? i need to download a few documents for my research.",
    "present_kp": [
      "scribd"
    ],
    "absent_kp": []
  },
  {
    "text": "is it possible to select tabs as tabs with mouse in urxvt?. i am running urxvt on arch linux. i can select the output with mouse for copy / paste. the problem occurs when output contains tabulators. all tabulators are selected and copied as spaces. that makes it really difficult to preserve the structure of some outputs when copying them.is there any way to fix this behaviour?edit: i am using zsh if that has any effect on the issue.",
    "present_kp": [
      "mouse",
      "rxvt"
    ],
    "absent_kp": [
      "terminal",
      "clipboard"
    ]
  },
  {
    "text": "theta estimation of two functions. i'm in a data structures class, and am working on an assignment right now that asks me to find the theta complexity of certain loops. i missed class the day we were introduced to the topic, and everything i can find online expects more prior knowledge than i feel i have. can someone just explain this in beginners terms for me? i don't know what big-o or theta even refer to in this notation. i think i have a loose idea of what complexity refers to (a measure of how efficient code is, depending on how long a function will take in different circumstances?)the problem in question:demonstrate the $\\theta$-complexity of the functions below. in order to demonstrate that $f(n) = \\theta(g(n))$ you must find two constants $c_1$ and $c_2$ such that$$ c_1g(n) f(n) c_2g(n). $$a.) $f(n) = n^3 - 3n^2 + 5$.b.) $f(n) = 2\\log_2 n - 4$.",
    "present_kp": [],
    "absent_kp": [
      "asymptotics",
      "landau notation"
    ]
  },
  {
    "text": "how to check the file usage summary in google drive. after sharing the folder/file in google drive to some other mail address, how can i monitor the log activity, like when the respective user has accessed the file, what are the modifications done etc.?is this possible in google drive?",
    "present_kp": [
      "google drive"
    ],
    "absent_kp": []
  },
  {
    "text": "reverse engineering a whole website. how do i reverse engineer every single aspect and functionality of a website so that i get an exact fully working copy of it?. all interactions including javascript, cascade style sheets, php to make a perfect clone of it?",
    "present_kp": [],
    "absent_kp": [
      "websites"
    ]
  },
  {
    "text": "bash operations on a for loop object. i'm attempting to run a bash command on a forloop object but it's trying to look for a file instead of use the forloop object.example:the input file contains lines in the format of user:passwordfor item in $(cat myitems);do user = cat $item | cut -d : -f1 pass = cat $item | cut -d : -f2donethe result of this is that it says file $item isn't foundi also triedfor item in $(cat myitems);do user = $(cat $item | cut -d : -f1) pass = $(cat $item | cut -d : -f2)done",
    "present_kp": [],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "can't install libcairo / x11-common. i was trying to install libcairo which required x11-common. however, upon installation it sayssetting up x11-common (1:7.7+7) ...update-rc.d: warning: start and stop actions are no longer supported; falling back to defaultsinsserv: warning: script 'node-influenza.sh' missing lsb tags and overridesinsserv: there is a loop between service monit and node-influenza.sh if stoppedinsserv: loop involving service node-influenza.sh at depth 2insserv: loop involving service monit at depth 1insserv: stopping node-influenza.sh depends on monit and therefore on system facility '$all' which can not be true!insserv: exiting now without changing boot order!update-rc.d: error: insserv rejected the script headerdpkg: error processing package x11-common (--configure): subprocess installed post-installation script returned error exit status 1processing triggers for systemd (215-17+deb8u5) ...errors were encountered while processing: x11-commone: sub-process /usr/bin/dpkg returned an error code (1)i suspect it's a problem with the post install - however i have no idea on how to fix it. i tried pretty much installing and uninstalling everything by hand, to no avail. strangely, on my debian 8 vm it works fine.i uploaded the x11-common.postinst if it is needed.",
    "present_kp": [
      "debian",
      "dpkg"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "does reinforcement learning require the help of other learning algorithms?. can't reinforcement learning be used without the help of other learning algorithms like svm and mlp back propagation? i consulted two papers:paper 1paper 2both have used other machine learning methods in the inner loop.",
    "present_kp": [
      "machine learning",
      "reinforcement learning"
    ],
    "absent_kp": []
  },
  {
    "text": "how big is the variance of the treewidth of a random graph in g(n,p)?. i am trying to find how close $tw(g)$ and $e[tw(g)]$ really are, when $g \\in g(n,p=c/n)$and $c>1$ is a constant not depending on n (so $e[tw(g)] = \\theta(n)$). my estimate is that $tw(g) \\leq e[tw(g)] + o(n)$ w.h.p, but i haven't been able to prove it.",
    "present_kp": [
      "treewidth"
    ],
    "absent_kp": [
      "graph theory",
      "co.combinatorics",
      "random graphs"
    ]
  },
  {
    "text": "is traversing an unconnected graph possible?. i have been assigned a fun project: design and implement a program that maintains the data of a simple social network. each person in the network should have a profile that contains his name, current status, and a friends list.i think it is clear that the project calls for the use of the adt graph. each vertex represents a person in the network and an edge between vertices a friendship. now, the graph may not be connected because some members do not have any friends in the network. with that in mind, consider this feature that must be implemented:the network must have a feature that computes the emergency phone chain, make sure that each member in the network is contacted, and only by one person. any of the people in the network may initiate the first call. utilize a depth-first graph traversal algorithm.now, what i think my professor is suggesting is merely a full traversal of the graph. how is that possible for an unconnected graph? any suggestions?(btw, the wording above is somewhat unclear - does the professor mean that everyone in the network is contact by the same one person? thoughts? i would ask her, but she is unavailable until next week.)",
    "present_kp": [],
    "absent_kp": [
      "graphs",
      "weighted graphs"
    ]
  },
  {
    "text": "fetch elapsed time value from a file. i need to fetch elapsed time output from file. i need the value just before elapsed that is 2:10:42.file content :312.90user 15.57system 2:10:42elapsed 4%cpu (0avgtext+0avgdata 0maxresident)k0inputs+0outputs (1major+152440minor)pagefaults 0swaps",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "text processing"
    ]
  },
  {
    "text": "how to compare files from solaris and linux. i want to compare the contents of same file present there in both solaris and linux for our testing purpose.i there is any tool available for that.if i want to develop new tool, haw can i achieve that?we are migrating project from solaris to linux.we want to verify the final output with is there in binary format by comparing them.both the files are there in different systems.please suggest me how we will do that comparison.",
    "present_kp": [
      "linux",
      "solaris"
    ],
    "absent_kp": []
  },
  {
    "text": "given a truth table, force a contradiction. suppose i have a formula, and a lying witness is attempting to make it evaluate to false.given a truth table $c(f_1,, f_n)$, how could you force a lying witness to contradict herself?a contradiction is simply when the witness's statements are logically impossible; i.e. that $x_1,x_2$ are each true, but $x_1 \\space and\\space x_2$ is false.how can i characterize the set of all formula for which i force the witness to contradict herself?what complexity class does this problem fall in?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "computability",
      "np complete",
      "closure properties",
      "decision problem"
    ]
  },
  {
    "text": "epiphany shuts down as it is loading. on my raspberry pi, epiphany starts up and then after loading 'most visited'... it closes. i reinstalled epiphany after doing a full update, and the same thing still is happening. other programs are running ok, including the dillo browser.",
    "present_kp": [],
    "absent_kp": [
      "debian"
    ]
  },
  {
    "text": "can pre-populating html and ajax replacing it when scrolled be a good lazy loading strategy for seo?. so i've read several posts here regarding seo and lazy loading as well as the google page for lazy loading your site's content. since setting up html snapshots for an ajax website is a large amount of work after the learning curve, i propose the following alternative to serving static content to a crawler.i have prepopulated my content divs with seo optimized, bare html content. my asynchronous content is loaded in replacing the original static content (per scrolling trigger of course).i cannot think of a reason why this isn't a smooth way to serve up the static html for crawlers. i mean if they really can't index asynchronous content then they shouldn't even recognize that the above process is happening after seeing the original content.am i missing something here?",
    "present_kp": [
      "seo",
      "ajax"
    ],
    "absent_kp": []
  },
  {
    "text": "wifi stopped working, unknown symbol wireless_nlevent_flush. as of this afternoon the wifi on my dell xps 13 stopped working (running debian sid with kernel 4.4.0-1-amd64). lspci detects my wifi card, but ifconfig -a shows only the loopback interface.i tried plugging in a usb wifi dongle which i have used recently with this laptop, and this also does not get recognized as a network interface. both during startup and immediately after plugging in a usb wifi dongle, the following message appears in dmesg:cfg80211: unknown symbol wireless_nlevent_flush (err 0)cfg80211 sounds like it would be used for configuring 802.11 (i.e. wifi) so i suspect this kernel module isn't getting loaded correctly. indeed, if i try to modprobe cfg80211 i receive the following error:modprobe: error: could not insert 'cfg80211':? unknown symbol in module, or unknown parameter (see dmesg)and checking dmesg i see the same message as above.googling for unknown symbol wireless_nlevent_flush yields zero results, although googling for just wireless_nlevent_flush seems to imply that it relates to wext somehow. one page suggested that rfkill must be loaded before cfg80211, but rfkill is already loaded. i would be very grateful for any advice.",
    "present_kp": [
      "wifi",
      "dmesg"
    ],
    "absent_kp": [
      "kernel modules"
    ]
  },
  {
    "text": "is polynomial time reducibility reversible?. if a language $a$ is reducible to some language $b$, does it follow that $b$ is reducible to $a$?my guess is no, it having something to do with the function $f$ in the definition of $a$ reducing to $b$ needing to be invertible.",
    "present_kp": [
      "polynomial time"
    ],
    "absent_kp": [
      "complexity theory",
      "reductions"
    ]
  },
  {
    "text": "how to build the reduction from hamiltonian cycle problem to subgraph isomorphism?. i'm trying to prove that the subgraph isomorphism problem is npc using the hamiltonian cycle problem.unfortunately i feel (or don't understand) that the solution is empty and doesn't explain the hamiltonian cycle - subgraph isomorphic connection, @luke mathieson says that hamiltonian cycle to subgraph isomorphism is really just rephrasing what it means for a graph to have a hamiltonian cycle - but i don't get it.how does one transforms from hamiltonian cycle to subgraph isomorphism?i read reducing from hamiltonian cycle to subgraph isomorphism and <url> and couldn't understand how should a proper reduction look like, how to build one that proves the subgraph problem?your help in simplifying the problem(s) will be very appreciated.",
    "present_kp": [
      "graph isomorphism"
    ],
    "absent_kp": [
      "complexity theory",
      "np complete",
      "reductions",
      "hamiltonian path"
    ]
  },
  {
    "text": "completeness and first order logic with least fixed point operator (lfp). is there any result about the extension of first order logic with least fixed point operator, being complete (as logic in general on infinite structures too) or not? in other words does the goedel completeness theorem of first order logic extent to such fo-lfp logic ?",
    "present_kp": [
      "first order logic"
    ],
    "absent_kp": [
      "descriptive complexity"
    ]
  },
  {
    "text": "install app on tiny core. how do you install mysql on tiny core? also how do you install clamav? can you install apt-get or yum on tiny core?all should be done in command line / terminal",
    "present_kp": [
      "mysql"
    ],
    "absent_kp": [
      "tinycore"
    ]
  },
  {
    "text": "sharing zsh and vim configuration with root user. i have modified my .zshrc and .vimrc to my likings. both files source other files containing more configuration and plugins (vundle, antibody). now i would like to use these configurations when i change to the root user as well.currently my .zshrc looks like this# .zshrc# sources the files in .shell directoryexport shell_conf_dir='/home/myuser/.shell'source $shell_conf_dir/initshell.shinitshell.sh does the following# initshell.sh# sources further scripts. $shell_conf_dir/antibody.sh. $shell_conf_dir/compinstall.sh. $shell_conf_dir/configuration.sh. $shell_conf_dir/options.sh. $shell_conf_dir/aliases.sh. $shell_conf_dir/variables.sh. $shell_conf_dir/virtualenv.sh. $shell_conf_dir/functions.sh. $shell_conf_dir/keybindings.sh. $shell_conf_dir/xorg.shi want to manage my .vimrc in a similar fashion.now the root users .zshrc is just a symlink to my normal users .zshrc. this works pretty well but i think, concerning security, this might not be an ideal solution. so where should i actually put all this configuration and how should i handle it so the root user can use it, too? or is this actually the wrong approach? i know that i can preserve environment variables with sudo -e but that doesn't work when doing sudo -i.",
    "present_kp": [
      "sudo",
      "environment variables",
      "root",
      "vimrc"
    ],
    "absent_kp": [
      "bashrc"
    ]
  },
  {
    "text": "is it safe to just use mysqli?. i have developed an open source php application and currently it uses both the mysqli or mysql extension for backwards compatibility. i'm wondering about switching it over to only be compatible with mysqli since php now no longer supports the mysql. another reason i'd like to get away from supporting both mysql and mysqli is that i'm basically using mysqli the same way i do as with the old mysql extension. can anyone explain to me if this is a good or bad idea?",
    "present_kp": [
      "php",
      "mysql",
      "compatibility"
    ],
    "absent_kp": [
      "backward compatibility"
    ]
  },
  {
    "text": "how can i decouple query and context in a query object scenario?. i'm using a query object pattern (similar to this) to manage disparate queries while avoiding bloaded facades/repositories.a query object takes a number of constructor parameters, representing query arguments. the query is then passed to an iqueryhandler by the caller, into which is injected the idatacontext. the idatacontext is then passed into an execute method of the iquery.the thing i don't like is this:public interface iquery<tresult>{ public tresult execute(idatacontext context);}because the idatacontext is passed into the method and thus explicitly declared in the interface, there is no option to have a query that fetches things via a different mechanism - iquery is coupled to whatever defines the idatacontext interface. suppose, for example, i want to switch from an sql db store to a document db.i've tried a couple of alternatives, but neither quite gets me where i want to be.the first is to inject the data context into the query's constructor and use a factory to generate the query objects. this successfully decouples the interfaces, but now working with the queries is more cumbersome. instead of using the constructor/object initializer to set up the query, callers have to do something like this:var query = _queryfactory.create<personquery, person>(); // second type argument can't be inferred from first due to limitations in generic type inference.query.name = bob;query.age = 32;var result = query.execute();the second is to abstract the execution of the query - and thus the dependency on idatacontext - to a handler class, then have another class that resolves a handler for each query, which again abstracts the dependency away from any interfaces:public class isomequeryhandler : iqueryhandler<somequery, somequeryresult>{ private readonly idatacontext _context = ...; public somequeryresult execute(somequery query) { ... }}i don't like this option because it means every new query involves writing two classes, which, again, is cumbersome and increases the potential for a query to exist with no way of handling it (it also involves an empty marker interface for queries since the execute method is moved to the handler, which always feels off). it also involves some rather funky convention-based dependency resolution to get the right handler for each query.creating an abstraction over idatacontext is not really feasible due to its complexity.is there a happy medium i haven't seen?",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "design patterns"
    ]
  },
  {
    "text": "is there any research on the notion of weak isolation?. (first of all, sorry for the long article which makes you want to skip through, but since the background and motivations are important to this question or it would be nonsense to the main problem, forgive me if this makes you sleep. i owe you a cup of coffee.)backgroundisolation lemma, one of the best tool in complexity theory invented by k. mulmuley, u. vazirani and v. vazirani in matching is as easy as matrix inversion, have been used to prove many amazing results like an rnc-algorithm for matching in the above paper; valiantvazirani theorem which is a randomized reduction from np problems to usat; nl/poly=ul/poly; and many others. surveys and introduction in blogs are also all over the web. in the center of the isolation lemma, we use randomization to assign weights on the base set $u$, such that for a family $\\mathcal{f}$ of subsets of $u$, there is a unique minimum weighted subset in $f$ with high probability. formally,lemma. let $u$ be a set of size $n$, and $\\mathcal{f}$ be a non-empty family containing elements which are the subsets of $u$. uniform-randomly assign integral weights in $[2n]$ on the set $u$, then there exist a unique minimum weighted subset in $\\mathcal{f}$ with probability at least $1/2$.a stronger form which covers a collection of $\\mathcal{f_1}, \\ldots, \\mathcal{f_m}$ that is used in practical situations can be found in the survey. there are also some variants that may reduced the use of random bits, or derandomized the lemma to get a deterministic weight assigning algorithm when the size of $\\mathcal{f}$ is not too large.problemafter a search of literature, it seems that all the research on this topic were all focus on isolating a unique subset of $u$. i want to know whether there is any obvious reason that we don't have a weak isolation lemma, in the sense that the number of minimum weighted subsets is bounded by a particular bound, and the requirement for the weak lemma is less than the original one. for example, do we have a lemma that only isolates $o(\\log n)$ minimum weighted subsets? how about linear or polynomial? since the size of $\\mathcal{f}$ is at most $2^n$, when the bound is set to $2^n$, the result becomes trivial since no isolation is needed.problem. is there any research on the notion of weak isolation, that only limits the number of minimum weighted subsets instead of a unique one? if so, is there any references? if not, what is the most obvious obstacle toward such a result?i've been trying to prove such a lemma with some approaches, but despite of using the exactly same techniques (thus the same requirements) which is clearly no better than the original one (since with the same requirements you can indeed isolate a unique subset), there is no success to reduce any conditions we need, even in the case that we only need a loose bound on the number of minimum subsets, say polynomial. (please read on if you need motivations to the problem! the part below contains some technical details to the usage of the lemma, and some applications to log-space computations.)motivationi am working on the problems in log-space computations, precisely the relation between classes $\\mathsf{nl}$, $\\mathsf{ul}$, and many other classes below and in between.consider the above lemma, which requires $o(n \\log n)$ random bits if we assign weights to $u$ accordingly. a random-bit-saving version of the lemma is presented in this paper by chari et al., which states:lemma. let $u$ be a set of size $n$, and $\\mathcal{f}$ be a non-empty family containing elements which are the subsets of $u$. there is a way of assigning weights in $[n^7]$ on $u$ with $o(\\log|f|+\\log n)$ random bits, such that there exist a unique minimum weighted subset in $\\mathcal{f}$ with probability at least $1/4$.that gives us an $\\mathsf{uspace}[o(\\log|f|+\\log n)]$ algorithm for reachability. of course this is a pity bound, since by savitch's theorem we have $\\mathsf{nl} \\subseteq \\mathsf{l}^2 \\subseteq \\mathsf{ul}^2$.but what if we consider the reachability problem with a restriction that there are at most $f(n)$ paths from the source to any node in the graph? this defines the problem $\\mathtt{reach}[f(n)]$, and we have $\\mathtt{reach}[2^n]$ to be the normal reachability problem. by setting $f(n)$ a polynomial, applying the above lemma together with an $\\mathsf{ul}$-algorithm for reachability in graphs with a minimum unique path (see the paper for more details), we can solve $\\mathtt{reach}[n^{o(1)}]$ in $\\mathsf{ul}$. (the result occurs in this recent paper. in fact they use a stronger version of the lemma, which isolates every paths in the graph by a constructive way.)if a weaker isolation lemma is known to have less restrictions on either the size of $\\mathcal{f}$, or the number of random bits being used, we can provide better bounds on the problem $\\mathtt{reach}[f(n)]$, with the help of some modifications to solve reachability in graphs with few minimum paths. hopefully if the lemma is weak enough to set $f(n) = 2^n$, and we can obtain some better bounds about the important class $\\mathsf{nl}$.any comments on the proof techniques or obstacles will give insight to the question, and i would like to know that whether this idea has a tiny little chance of success, or it is just a completely impossible concept.",
    "present_kp": [],
    "absent_kp": [
      "cc.complexity theory",
      "randomness"
    ]
  },
  {
    "text": "gnome boxes: proper network configuration?. i've got a problem with gnome boxes:i've 2 machines, cloned 1 from other, with centos. both machines get same ip addr on gnome boxes, so when i boot 2nd, 1st gets disconnected from network, and vice-versa. this is not acceptable behaviour,and i've been struggling to find out why does this happen for quite some time.",
    "present_kp": [
      "gnome"
    ],
    "absent_kp": [
      "networking",
      "virtual machine"
    ]
  },
  {
    "text": "wordpress redirects to ip instead of domain. following this blog post i set up wordpress on an ec2 instance. i've pointed a records to my amazon ec elastic ip address. after propagation, when i open my website with the domain name, it works. but wheni click on other page, it just redirects me to my ip address instead.",
    "present_kp": [
      "wordpress"
    ],
    "absent_kp": [
      "domains",
      "amazon ec2"
    ]
  },
  {
    "text": "how to view flash and other videos on linux systems?. i'm running fedora 17 and firefox 12. when i navigate to some sites i'm unable to view videos because i'm missing some plugin. when i click 'installl missing plugin' i'm still not able to view the video.any idea i can view them without installing flash player (not open source i believe)? what directory are these web plugins stored?",
    "present_kp": [
      "fedora",
      "firefox"
    ],
    "absent_kp": [
      "adobe flash"
    ]
  },
  {
    "text": "delete string between two regex patterns. i have a file with following contents..\\..\\src\\modules\\core\\abc\\abc.cpp..\\..\\src\\modules\\core\\something\\xyz\\xyz.cpp..\\..\\src\\other_modules\\new_core\\something\\pqr\\pqr.cpp..\\..\\src\\other_modules\\new_core\\something\\pqr\\abc.cppthe result i am expecting is ..\\..\\src\\abc\\abc.cpp..\\..\\src\\xyz\\xyz.cpp..\\..\\src\\pqr\\pqr.cpp..\\..\\src\\pqr\\abc.cpphow can i achieve this using sed?i am unable to write an regular expression to capture two groups at the same time.initial group (....\\src) - this will be same in all the linesvariable group (abc\\abc.cpp) or (xyz\\xyz.cpp) or (pqr\\pqr.cpp) or (pqr\\abc.cpp)",
    "present_kp": [
      "sed"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "how to add a caa record on debian. i currently have a let's encrypt ssl certificate for my debian server, and would like to implement caa (certification authority authorization, rfc 6844) on it.i'm a bit confused as to how to implement it however, as i don't seem to be able to add it to my zone file on my registrar's site. (gandi.net)is it a file i add to the root of the web server, or do i have to wait until my registrar supports it?",
    "present_kp": [
      "ssl"
    ],
    "absent_kp": [
      "dns",
      "openssl"
    ]
  },
  {
    "text": "largest embeddable hypersphere given membership oracle. i have a membership oracle to tell me whether a point is inside of some set, s. i would like to find the radius of the largest (origin-centered) hypersphere that is contained in s.do you know any good references for this problem? (i'm looking for an algorithm along with a confidence that the hypersphere is fully contained in s).",
    "present_kp": [],
    "absent_kp": [
      "cg.comp geom"
    ]
  },
  {
    "text": "possible to open office documents in office web apps by default?. is it possible to set office web apps as the default application for office documents on windows? i figure this can't be done at the system level, so i'd be happy with a firefox extension or ie add-on that could accomplish this.i found a chrome extension that does what i'm looking for is there any equivalent in firefox or ie?",
    "present_kp": [],
    "absent_kp": [
      "office online"
    ]
  },
  {
    "text": "is it good idea to write variable names that match application specific terms?. let us say i am writing a facebook like application.i write code like below$this->get_user_friends(); then next morning the boss says that we don't want to call friends friends anymore, we will call them pal. then all the templates are changed but what about the code above? after 2 years when some programmer will have to look into it he is likely to get confused isnt it ?what do you guys really do ?",
    "present_kp": [],
    "absent_kp": [
      "variables",
      "naming",
      "coding standards"
    ]
  },
  {
    "text": "new values for categorical variable in prediction dataset. i am performing regression task using *random forest**.in my prediction set i am having *new levels for categorical variable** which are not present in training data .currently i am performing one hot encoding to handle this.at present i am not getting considerable results. this article is saying that it is not good to perform one hot encoding.how to handle this case?",
    "present_kp": [
      "regression",
      "random forest"
    ],
    "absent_kp": [
      "machine learning",
      "statistics",
      "categorical data"
    ]
  },
  {
    "text": "how to use a shell command to only show the first column and last column in a text file?. i need some help to figure out how to use the sed command to only show the first column and last column in a text file. here is what i have so far for column 1:cat logfile | sed 's/\\|/ /'|awk '{print $1}'my feeble attempt at getting the last column to show as well was:cat logfile | sed 's/\\|/ /'|awk '{print $1}{print $8}'however this takes the first column and last column and merges them together in one list.is there a way to print the first column and last columns clearly with sed and awk commands?sample input:foo|dog|cat|mouse|lion|ox|tiger|bar",
    "present_kp": [
      "shell",
      "sed",
      "awk"
    ],
    "absent_kp": []
  },
  {
    "text": "setting up a personal domain name. possible duplicate:how to find web hosting that meets my requirements? i'm looking to set up a personal website, but i know very little about web hosting. could somebody recommend a (not very expensive) host? what should i look for when choosing a host? also, i'm rather icky about atriyasen.com because people can't make out if i'm atriya sen (which i am) or atri yasen! would you recommend atriya-sen.com? atriya_sen.com? finally, what about other tlds like .name?",
    "present_kp": [],
    "absent_kp": [
      "domains",
      "looking for hosting"
    ]
  },
  {
    "text": "creating emacs tags file. i am working through the emacs lisp intro book within emacs 23.4.1 on debian wheezy (crunchbang waldorf).section 4.1 discusses the find-tags command and the tags file. instructions are included to build/install the tags file if necessary.how do i do this in debian? the folders mentioned are not present on my system and i cannot locate a tags file.i'm not sure that i have the source of emacs installed? i installed it using apt-get. my sources.list file does not include any deb-src lines, if that is relevant.",
    "present_kp": [
      "debian",
      "emacs"
    ],
    "absent_kp": []
  },
  {
    "text": "will uploading our .docx files on scribd and embedding the files on our website affect search engine rankings?. we have prepared notes for university students which are on .docx format. and we want it to put on our website for viewing. we tried one option. uploading the files on scribd and embedding it on our website for viewing on scribd viewer. will making documents available on srcibd viewer on our website affect search engine rankings ? will search engines treat it as duplicate content as those are already uploaded on scribd and we are embedding it on our website ?on scribd we have set the uploaded documents as 'private' though.and if it affects, can you suggest any suitable way to make .docx files to be viewed on our website that doesn't affect search engine rankings ?",
    "present_kp": [
      "embed"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "protocol agnostic robots sitemap. recently, i have enabled all my servers to serve everything over http and https. users can access any site via <url> or <url>. all pages are identical between the versions, so <url> is the same as <url> and so on.urls are relative, so they do not mention the protocol with one exception. in other words, if the page is loaded with http, it will link to other pages, images, css, javascript over http and the same with https, as to avoid mixed content warnings.now about that exception. it is in robots.txt:sitemap: <url> this url must be absolute.now the problem i see if that when google reads <url> it gets an http sitemap! the documentation on robots.org says that one can specify multiple sitemaps but if i am not sure that putting both the http and https sitemap is a good idea since they will contain each a list of identical pages (one with http and one with https).how should sitemap in robots.txt be handled for websites that accept http and https?some ideas that came to mind:specify both sitemaps (as mentioned above). afraid this would cause duplicate content issues.only specify the https sitemap. that gives access to all unique pages anyway.find a magical (apache) way to sent a different robots.txt via http and https. is that even possible? could it cause issues?",
    "present_kp": [
      "sitemap",
      "robots.txt"
    ],
    "absent_kp": []
  },
  {
    "text": "configuring org-mode to open pdfs with evince. i'm starting to use org-mode to export text to latex.my problem is that it opens the generated pdf with ebook-viewer (it is a epub, chm reader) instead of using evince.questiondoes anyone know how to change this behaviour and configure evince to be the default viewer?",
    "present_kp": [
      "pdf"
    ],
    "absent_kp": [
      "emacs",
      "file opening",
      "org mode"
    ]
  },
  {
    "text": "multi-threaded socket server high load. i'm trying to make a backend for quizup like application: user connects to a server, sends credentials and gets paired up with another user. after that server handles each pair, periodicaly sending server messages to each user in a pair and also redirecting user's mesages between them.server class:private static class server{ private static final int num_threads = 2400; private executorservice executorservice; private serversocket serversocket; private int listeningport; public volatile boolean isrunning; private thread mainthread; private volatile map<string, conn> playrequests; public server(int port){ try { executorservice = executors.newfixedthreadpool(num_threads); listeningport = port; serversocket = new serversocket(listeningport); isrunning = true; playrequests = new concurrenthashmap<string, conn>(); mainthread = new thread(new runnable(){ @override public void run() { handleincomingconnections(); } }); } catch (ioexception e) { system.out.println(e.tostring()); } } public void run(){ mainthread.start(); } private void handleincomingconnections(){ while(isrunning){ try { final socket client = serversocket.accept(); runnable gamerunnable = new runnable(){ @override public void run() { try{ bufferedreader reader = new bufferedreader(new inputstreamreader(client.getinputstream())); printwriter writer = new printwriter(new bufferedwriter(new outputstreamwriter(client.getoutputstream())), true); string read = null; string id = null; boolean isrequesting = false; string rid = null; while(!(read = reader.readline()).equals(fin_1)){ string[] str = read.split(#); if(str[0].equals(id)){ id = str[1]; }else if(str[0].equals(isrequesting)){ isrequesting = (str[1].equals(1)); }else if(str[0].equals(rid)){ rid = str[1]; } } conn connection = new conn(client, isrequesting, id, writer, reader); if(isrequesting){ playrequests.put(rid, connection); }else{ if(playrequests.containskey(id)){ conn conn = playrequests.get(id); playrequests.remove(id); handlegame(conn, connection); } } }catch(exception e){ system.out.println(e.tostring()); } } }; executorservice.execute(gamerunnable); } catch (ioexception e) { // todo auto-generated catch block e.printstacktrace(); } } } private void handlegame(conn a, conn b){ new gamehandler(a, b).execute(); }}gamehandler class:private class gamehandler{ private volatile conn a; private volatile conn b; private thread areadthread; private thread breadthread; private thread messagethread; private runnable areadrunnable; private runnable breadrunnable; private runnable messagerunnable; private volatile printwriter awriter; private volatile printwriter bwriter; private volatile bufferedreader areader; private volatile bufferedreader breader; private volatile boolean aisready; private volatile boolean bisready; private volatile boolean isgamerunning; public gamehandler(final conn s1, final conn s2){ this.a = s1; this.b = s2; isgamerunning = true; try { awriter = a.writer; bwriter = b.writer; areader = a.reader; breader = b.reader; } catch (exception e) { try { isgamerunning = false; a.close(); b.close(); } catch (ioexception e1) { // todo auto-generated catch block e1.printstacktrace(); } system.out.println(e.tostring()); } messagerunnable = new runnable(){ @override public void run() { system.out.println(a.id + + b.id); messagethread = thread.currentthread(); for(int i = 0; i < 6; i++){ if(isgamerunning){ try{ thread.sleep(4000); }catch(interruptedexception e){ } } } //end game isgamerunning = false; try { a.close(); b.close(); } catch (ioexception e) { // todo auto-generated catch block e.printstacktrace(); } } }; areadrunnable = new runnable(){ @override public void run() { areadthread = thread.currentthread(); string line = null; try { while (isgamerunning && (line = areader.readline()) != null && !(line = areader.readline()).equals(fin)){ bwriter.println(line); } a.close(); system.out.println(a.id + done); } catch (exception e) { try { isgamerunning = false; a.close(); b.close(); } catch (ioexception e1) { // todo auto-generated catch block e1.printstacktrace(); } system.out.println(e.tostring()); } } }; breadrunnable = new runnable(){ @override public void run() { breadthread = thread.currentthread(); string line = null; try { while (isgamerunning && (line = breader.readline()) != null && !(line = breader.readline()).equals(fin)){ awriter.println(line); } b.close(); system.out.println(b.id + done); } catch (exception e) { try { isgamerunning = false; a.close(); b.close(); } catch (ioexception e1) { // todo auto-generated catch block e1.printstacktrace(); } system.out.println(e.tostring()); } } }; } public void execute() { executorservice.execute(messagerunnable); executorservice.execute(areadrunnable); executorservice.execute(breadrunnable); } } and a container class for each users to hold open socket, in/out streams, credentials, etc:private class conn{ public socket s; public boolean isrequesting; public printwriter writer; public string id; public bufferedreader reader; conn(socket s, boolean isrequesting, string id, printwriter writer, bufferedreader reader){ this.s = s; this.isrequesting = isrequesting; this.id = id; this.writer = writer; this.reader = reader; } public void close() throws ioexception{ s.close(); } }the logic is following:server has a mainthread, where it accepts incoming connections and creates client sockets. for each new socket it creates a gamerunnable, where it listens for client's credentials (whether this client is the one requesting connection, id of the user it wants to connect to, id of itself). after receiving credentials, server creates a new conn object, storing all the info(id, and also socket and in/out streams, so it doesn't have to open it again after) there, and than places it in the map (playrequests) with requested user id as a key. if there is a matching pair in a map, server creates a new gamehandler for these two conn objects (all this still goes inside the gamerunnable). each gamehandler contains three runnables: messagerunnable to send messages from server to both users, and two runnables (areadrunnable and breadrunnable) to read incoming data from both sockets. so basically, each communication session (game) requires 4 threads (1 to get credentials and start a game, and three to maintain the game before the end). here are the questions i have:are there any design/implementation issues you see here? please be as picky as possible because i'd really not want it to crash under high load. if you see smth, you are more than welcome to give your solutionsi know that having large and uncontrolled number of threads is a bad practice, so i'm using an executer with fixed thread pool to execute all the runnables. however, due to the game features, i can't make users who are requesting connections wait for empty threads in a pool, what is obviously going to happen if i have a lot of incoming connections. so is usage of thread pool reasonable here? if yes, what number of threads should i use, given that i need 4 threads per game, and each game lasts approximately 2 minutes.am i closing all the sockets correctly? are there any memory leaks?other questions regard server deploying:i'm planning to run it on amazon ec2. should i use tomcat server for this, or can i just run it as a plain java program on jvm?i tested it on my laptop, and having many simultaneous connections, heap size is not enough to handle all of them. should i increase heap size before lunch as much as possible, or it may affect performance?",
    "present_kp": [
      "java",
      "socket",
      "server"
    ],
    "absent_kp": [
      "multithreading"
    ]
  },
  {
    "text": "two exact copies of folder using ftp and command-line only. i'm looking for any solution that will allow me to emulate functionallity similar to dropbox/rsync using only ftp protocol and command-line.the general problem is, that i have to run it on a very limited linux (actually nas), so i can't install / use to complex solutions (not enough resources to run) and/or gui utils, as i have no gui there. ssh also works weak on that nas and is not present at all on one of destinations.what i need, is to have a command-line (bash) script or program that i will be able to run periodically (via cron) that will assure that source and destination are identical:all files on both sides copied to both sides,if two files of the same name exists, copy newest version of a file to both sides,delete on one side all files that are missing on another one.of course, this solution must support iteration on all subfolders of both source and destination, for this to work succesfully -- there will be a large directory structure on both sides.i've tried many backups solutions, but most of them failed for one of these reasons:unable to create exact duplicate copy of both sides and offering incremental backup instead,not able to be run directly from command-line, on very limited linux distro.i was advised to use unison and give it a good try. this really looks good, but it uses ssh, and i'm unable to establish ssh connection to one of my destinations (not supported) -- i.e. ftp access is the only available way.the perfect solution for me would be anything that i can run (command-line or configuration) like this:something.sh path/to/local/folder <url> it does exists at all...",
    "present_kp": [
      "backup",
      "ftp"
    ],
    "absent_kp": []
  },
  {
    "text": "how to get disk name that contains a specific partition. if i know that a partition is for example /dev/sda1 how can i get the disk name (/dev/sda in this case) that contains the partition ? the output should be only a path to disk (like /dev/sda). it shouldn't require string manipulation, because i need it to work for different disk types.",
    "present_kp": [
      "partition",
      "disk"
    ],
    "absent_kp": [
      "linux",
      "block device"
    ]
  },
  {
    "text": "create a file that's really a network port. i have a program running on a cluster, and the output of the program is written to a log file which i specify. however, instead of writing it to a file, i want to write it to a network port, so that it can be read with e.g. node.js.for example, i want to be able to specify a file along the lines of /dev/127.0.0.1:3000currently, i'm using node.js to watch the log file, re-read all the data when it changes, compare the new data with the old data to see what was added, and then process that. but that's quite inefficient.",
    "present_kp": [],
    "absent_kp": [
      "files",
      "filesystems",
      "serial port"
    ]
  },
  {
    "text": "rename the 10 most-recently modified files on aix. i have some .xls files in a defined directory (say in /a/b). i want to rename top 10 latest files and append -bkp in their names.i tried, not workingls -lt *.xls | head -1 | awk '{print mv $9 $9-bkp}' | shi tried find and -exec but how do we get top l0 latest modified files",
    "present_kp": [
      "files",
      "rename",
      "aix"
    ],
    "absent_kp": []
  },
  {
    "text": "wpa supplicant: no network configuration found for current ap - carl9170-driven wifi adapter glitching on debian 7. i've got a debian 7 machine with linux3.2 kernel and a usb wifi adapter with atheros chipset (d-link dwa-16 xtreme n dual band), which in theory should work. indeed, i managed to establish a wifi communication with networkmanager and it worked more or less fine for ~30 minutes, but then disconnected and failed to reestablish the connection.i failed to reestablish the connection with networkmanager, it successfully associates and authenticates, starts 4-way handshake, but then deauthenticates due to reason 15 (4-way handshake timeout).then i tried to do the same via the good old ifupdown by creating an entry in /etc/network/interfaces:allow-hotplug wlan1iface wlan1 inet static wpa-ssid mynet wpa-psk <my key hash generated by 'wpa_passphrase mynet key'> address 192.168.1.2 netmask 255.255.255.0 broadcast 192.168.1.255 gateway 192.168.1.1 dns-nameservers a.b.c.dwhen i sudo ifup wlan1, it behaves reasonably, until:wpa_supplicant[8258]: wlan1: associated with <router's mac>wpa_supplicant[3402]: wlan1: no network configuration found for the current ap(from /var/log/syslog). wireshark sees arp packages going from my wifi adapter to the router, but the router doesn't reply.do you have any ideas about what could that mean and how to troubleshoot this?solution:thanks to suggestion by peterph, i tried to create wpa_supplicant.conf and run wpa_supplicant as a standalone program both in foreground and background and then used wpa-conf wpa_supplicant.conf in /etc/network/interfaces.sudo wpa_supplicant -iwlan1 -c/etc/wpa_supplicant/wpa_supplicant.conf -dsudo wpa_supplicant -iwlan1 -c/etc/wpa_supplicant/wpa_supplicant.conf -bi had the first part of troubles (with spontaneous disconnect after status: associated) disappear, when i killed a running instance of networkmanager. it seems to have interfered.second part of trouble was with the 4-way handshake failing. it passed ok, when i disabled mac address filtration on the access point. my wifi interface's mac was in the list of available macs, but for some reason it still was failing to connect with mac filtering on the router.update 2: the problems are back. 4-way handshake is failing again. reload of the driver won't help.",
    "present_kp": [
      "debian",
      "wifi",
      "wpa supplicant"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "how do i differentiate 404 messaging with no dynamic language ability on the web server?. depending on the type of page visited (for example, static content vs. product page), we have a requirement to show different error messaging when the page requested is not found. given that we are on a two tier architecture and have no dynamic language ability on the web servers, we are using http status codes in the 400 range to display this messaging using the errordocument setting in apache configuration.these status codes, of course, show up in google webmaster tools as http errors rather than not found errors and there is concern that these 400 range errors will not cause search engines to remove these pages from their indexes.is there anyone else who has had this type of requirement with the limitation of no dynamic languages on the web server - and if so - have you solved this problem differently?thanks",
    "present_kp": [
      "search engines",
      "apache"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "how can i perform a triangle inside test in polygon meshes?. i have 3 vertices (v1, v2, v3) randomly selected on a regular triangle mesh. for these 3 vertices, i have computed the geodesic distance and the path (by using dijkstra) among them and formed a triangle-like surface as in the above figure. now, i have the vertices that lie in each path and can compute geodesic distances from a given vertex.what i want to do is to get the vertices or triangles that lies in triangle-like area. how can i do this?",
    "present_kp": [
      "mesh"
    ],
    "absent_kp": [
      "triangulation"
    ]
  },
  {
    "text": "mounting a shared drive from windows with cifs. what i'm trying to achieve is mounting some drives shared on my network (one a time capsule, 3 shared drives from a windows 10 machine) on a raspberry pi 2 running ubuntu 14.04 with read and write permissions. i have been able to get the drives to mount by using this://10.0.1.2/movies /home/kev/networkdrives/movies cifs username=user,password=password 0 0obviously using the correct info for username and password.using this line in the /etc/fstab file achieves mounting the drives.i am able to read the files and copy them to my local storage but i can not write to the mounted drives and i can not find out what is wrong.this is new territory for me so your help is appreciated.",
    "present_kp": [
      "mount",
      "ubuntu"
    ],
    "absent_kp": []
  },
  {
    "text": "how to install d-link dwa-510 for debian 7?. i just bought a d-link dwa-510. but i can't install it on my debian 7 32 bits. and i want to use in a runlevel 3. how can i use this d-link? thanks!",
    "present_kp": [
      "debian"
    ],
    "absent_kp": [
      "wifi",
      "drivers"
    ]
  },
  {
    "text": "how do i create sequentially numbered file names in bash?. i need a script that will create a file with the next file in a sequence. each execution of the script should only create one file and the script could be run zero or more times on any given day. the files should be named after the current date in format %y%m%d with the second file having -01 appended, the third file to be created on a given date would have -02 etc. for example:20170125.txt // first file create on the day.20170125-01.txt // 2nd file20170125-02.txt // 3rd fileso far i've got this super basic script that creates my first daily file but i'm stumped as to how to do the incremental numbering after that.#! /bin/bashdate='date +%y%m%d'touch $date.txt",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell script",
      "scripting"
    ]
  },
  {
    "text": "not getting libglib2.0-dev (updated libraries) even after upgrading from ubuntu 14.04 to 16.06. i wanted to compile and install something-for-reddit from git.as i went with ./configure.ac it showed below error../configure: line 5088: glib_gsettings: command not found./configure: line 5089: syntax error near unexpected token '1.42.0'./configure: line 5089: 'gobject_introspection_check(1.42.0)'as i searched here in stackoverflow, it showed me that the glib_gsettings are found in libglib2.0-dev but as i tried to install it through sudo apt-get install libglib2.0again it threw below error reading package lists... donebuilding dependency tree reading state information... donenote, selecting 'libglib2.0-0-refdbg' for regex 'libglib2.0'note, selecting 'libglib2.0-cil-dev' for regex 'libglib2.0'note, selecting 'libglib2.0-tests' for regex 'libglib2.0'note, selecting 'libglib2.0-0-dbg' for regex 'libglib2.0'note, selecting 'libglib2.0-bin' for regex 'libglib2.0'note, selecting 'libglib2.0-cil' for regex 'libglib2.0'note, selecting 'libglib2.0-dbg' for regex 'libglib2.0'note, selecting 'libglib2.0-dev' for regex 'libglib2.0'note, selecting 'libglib2.0-doc' for regex 'libglib2.0'note, selecting 'libglib2.0-data' for regex 'libglib2.0'note, selecting 'libglib2.0-0' for regex 'libglib2.0'libglib2.0-0 is already the newest version (2.48.1-1~ubuntu16.04.1).libglib2.0-data is already the newest version (2.48.1-1~ubuntu16.04.1).libglib2.0-bin is already the newest version (2.48.1-1~ubuntu16.04.1).some packages could not be installed. this may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of incoming.the following information may help to resolve the situation:the following packages have unmet dependencies: libglib2.0-0-dbg : depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed libglib2.0-0-refdbg : depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed libglib2.0-dev : depends: libglib2.0-0 (= 2.48.0-1ubuntu4) but 2.48.1-1~ubuntu16.04.1 is to be installed depends: libglib2.0-bin (= 2.48.0-1ubuntu4)i have upgraded the system from 14.04 to 16.04 one month back, did i miss something or am i doing something wrong now .the something for reddit git source is here. <url> you can check all the dependencies here too, package details: something-for-reddit-git 0.1-1",
    "present_kp": [
      "ubuntu",
      "libraries"
    ],
    "absent_kp": [
      "github"
    ]
  },
  {
    "text": "what should be in the /etc/shadow file if i want my root account to be disabled?. on one of my machines it's root::somenumber[...]::: with somenumber[...] being the same as for my actual account (after what appears to be the encrypted passphrase) and the logcheck account (after :*:). on another machine it's root :!:somenumber[...]::: with somenumber[...] being the same for all accounts until the most recently added ones starting with postfix:*:.i didn't enter a root password during installation for both of these machines. however i accidentally set it for one of them and had to remove it again using the passwd -d root command. i'm running debian 9.1 with kde.what exactly should be in there if i wish for my root account to be locked (i use the sudo command)? are those file contents fine?and related to this would also be this question: how can i view a history of changes to the shadow file including info on which user changed what and when.",
    "present_kp": [
      "debian",
      "root",
      "shadow"
    ],
    "absent_kp": []
  },
  {
    "text": "ssh-agent terminating on network change. my work computer is a painfully out of date ubuntu 16.04 machine. i have it configured such that that lightdm invokes ssh-agent (not gnome-keyring-daemon) and ssh-agent invokes my session. this is not too dissimilar to how i have my personal laptop configured, except there i use arch and use login on a tty instead of lightdm. my .xinitrc invokes ssh-agent which invokes my window manager. in the end, in both cases, x has been started in an environment that is a child process of ssh-agent, so every shell gets the ssh_auth_sock environment variable.the odd thing about my work computer is that when i switch networks (either one wifi network to another or wired <-> wifi) there is a high probability that ssh-agent will terminate and my session's process will get reparented. this is super frustrating because i can't easily start a new ssh-agent and reparent my session under it - i have to log out and back in again.i have not found any log messages containing ssh-agent or even agent in the systemd journal nor dmesg. the only debugging options ssh-agent seems to have is the -d option to run it in the foreground, i have not tried that yet because it is invoked by lightdm and i don't know if i would even be able to see the output.are there any debugging steps or known issues i should be aware of with the ssh-agent from openssh-client 1:7.2p2-4ubuntu2.2 ?",
    "present_kp": [],
    "absent_kp": [
      "ssh agent"
    ]
  },
  {
    "text": "diamondize a matrix. the task is to output a representation of the matrix where the top left element is on top, the anti-diagonal is the central row and the bottom right element is at the bottom.for example, consider the following matrix:1 23 45 6the diamond version of this matrix is: 1 3 25 4 6which would correspond to a nested array of [[1],[3,2],[5,4],[6]].this is my program:fnulq=y+y=<email>_1=qxqn<@qnh;fnulq=qxqn_@qn;=q>q1;pq;how it works:(q is implicitly assigned to the evaluation of input)fnulq=y+y=qxqn+y@qn;fnulq ; for n in range(len(q)): =y+y y = y+ =qxqn+y@qn q[n] = y+q[n]=q.tq; assign('q',transpose(q))fnulq=hx@qninh_1=qxqn<@qnh;fnulq for n in range(len(q)): =hx@qn h = q[n].index_of() inh_1 if h != -1: =qxqn<@qnh q[n] = q[n][:h]fnulq=qxqn_@qn;fnulq ; for n in range(len(q)): =qxqn_@qn q[n] = reverse(q[n])=q>q1; q = q[1:]pq; print(q)i am especially interested in advice on the readability of my code.link to my first attempt.",
    "present_kp": [],
    "absent_kp": [
      "pyth"
    ]
  },
  {
    "text": "how to convert html to pdf using php?. pdf or portable document format is a popular file type that is often used for online documents. it's great for distributing downloadable written content, and is frequently used by governments and businesses alike. because it's a format that's familiar to all, many applications allow the user to convert other document types to the pdf format. php is one programming language that has a built-in ability to convert to pdf. php scripts can be used to transform file types such as html into pdf files.",
    "present_kp": [],
    "absent_kp": [
      "software"
    ]
  },
  {
    "text": "fast field extraction with grep. the problemi have a 32m lines file with the following formattoken^iname^iurl$where ^i is the tab escape sequence, and $ is the end-of-line.i need to get the url corresponding to not more than 10k matches with the field name.what i've done is# get second columncut -f2 <myfile> |# find the word and line numbergrep -nwi <matchword> |# get just the numbercut -f1 -d ':' |# not more than 10khead -n10000and then, for each entry of the previous output# print line number sed -n '<number>{p;q}' <myfile># get 3rd fieldcut -f3now, this last operation with sed is ridiculously slow.i am wondering how to get the all of this by using grep only, or any other way that doesn't slow down after the first 1k matches.ideait would be just perfect to be able to operate grep on the whole line (without cut -f2), targeting only the second column, and then cut -f3, but i don't have a clue of how to do it.exampleline xyzqwertyuiop^ibananas are yellow^ihttp://mignons.cool$match word yellow in field name -> give me <url> is needed, because i don't want to match stuff in the field token and url.if i send to grep a cut of myfile, then i no longer have access to the url field, which i am interested in.input and expected outputinput file:mxp4edoy-ixkuwsuofs0eq^ilegal yellow pad paper^i0/3/3031.jpg$aes7tgmlvffbhousr9yy5q^ihelicopter parking only sign^i0/3/3032.jpg$8dl-vixsjg4y0fpx9f5kha^iwritten list ^i0/3/3033.jpg$xyvkzc3d_jswly8spl-zlq^ihelicopter parking only road sign^i0/3/3034.jpg$xf6zpvphcmfphp2mmt2fvg^irun menu windows programming^i0/3/3035.jpg$mcjvv2rxomitlbkmzlyiwq^icoffee mug^i0/3/3040.jpg$ziobhk_dlsn-q921kpjuta^icarpet^i0/3/3197.jpg$xfrbgomfvml0weqvact27a^iwater jugs^i0/3/3199.jpg$where ^i is the tab escape sequence, and $ is the end-of-line.match word helicopter.expected output (not more than 10k lines):0/3/3032.jpg0/3/3034.jpgpotential solutionsince the url field contains only numbers, i couldcut -f 2,3 <myfile> | grep <matchword> | cut -f2 | head -n10000but it would be nicer to grep the second field only...",
    "present_kp": [
      "grep"
    ],
    "absent_kp": [
      "shell script",
      "regular expression"
    ]
  },
  {
    "text": "bash: count # of words in each line of a document. i need to identify patterns in a text file for further analysis. so the input files may contain semi-structured text as follows;file1905:john: abc123: <email> us 920:eric: ericaa: <email> us 1000: rio: ri0ri0: <email> in file2 nathen <tab> <email> <tab> 764323545 <tab> ukthomas <tab> <email> <tab> 563363421 <tab> ukian <tab> <email> <tab> <phone> <tab> spnumber of words in a line may vary for each document. delimiter also vary but unique for each document. what i want is to count number of words per each line in each document.output would be:for file1 5 5 5 5 for file2 4 4 4 4i want generalize this for any file with any delimiter. it could be - | : \\space+ ab+. some files are as follows:| <email> | er34532 | | <email> | 764474 |",
    "present_kp": [
      "bash",
      "patterns"
    ],
    "absent_kp": []
  },
  {
    "text": "how to edit a person's name in the new gmail chat?. previously in gmail chat, i was just able to click on the name of a person to edit his name. now, the name acts as a link which opens contacts, where the editing can happen. the old way was faster. can i edit the names the old way somehow?for example, here aardvark is a link, and is not directly editable.",
    "present_kp": [
      "gmail",
      "chat"
    ],
    "absent_kp": [
      "gmail contacts"
    ]
  },
  {
    "text": "auto-populate google apps hangouts roster?. i want every user in my organization to have every other user in their hangouts roster. is there a way to do this, or even a way to manually populate those rosters for them to give them a starting point?",
    "present_kp": [
      "google apps"
    ],
    "absent_kp": []
  },
  {
    "text": "lualatex not available in debian wheezy. i want to use lualatexfor compiling latex document based on luatex. i have installed those packages: luatex, texlive-binaries, texlive-luatex but no lualatexbinary can be found. what did i miss?",
    "present_kp": [
      "debian",
      "latex"
    ],
    "absent_kp": []
  },
  {
    "text": "even after i press publish release, github release stays as draft. creating a github release usually works well, but for one particular project i can't seem to be able to publish: the draft stays a draft and never gets published.it happens both for forks and for projects i created from scratch.happens with both firefox and chrome.",
    "present_kp": [
      "github"
    ],
    "absent_kp": []
  },
  {
    "text": "dconf-warning **: failed to commit changes to dconf: the connection is closed. whenever i open any software through terminal i get following errors and eventually the software opensdconf-warning **: failed to commit changes to dconf: the connection is closed(gedit:3609): dconf-warning **: failed to commit changes to dconf: the connection is closed(gedit:3609): dconf-warning **: failed to commit changes to dconf: the connection is closederror creating proxy: the connection is closed (g-io-error-quark, 18)error creating proxy: the connection is closed (g-io-error-quark, 18)error creating proxy: the connection is closed (g-io-error-quark, 18)error creating proxy: the connection is closed (g-io-error-quark, 18)error creating proxy: the connection is closed (g-io-error-quark, 18)what can be the possible issue?",
    "present_kp": [
      "dconf"
    ],
    "absent_kp": []
  },
  {
    "text": "banning unresolved ip addresses. my server has run out of memory a few times in the past two days, because of which the site crashed. i checked awstats and found that hundreds of unresolved ip addresss have been logged, and the number of hits from them seems unreasonable:i'm going to ban the top 10 ip addresses as they all seem spammy to me. but there are other hundreds of ip addresses that seems to be causing thousands of hits, and i really don't know if they are legitimate request from users using browsers. i could ban all of them using htaccess, but that doesn't seem very practical nor is a long term solution. (the site gets around 3 million pageviews/month.)my questions are:how do i filter out legitimate users from unwanted bots or ip addresses that are scraping content?should i go ahead and ban all unresolved ip addresses?is there an automated way of banning spammy ip addresses?",
    "present_kp": [
      "ip address"
    ],
    "absent_kp": []
  },
  {
    "text": "show that tqbf $ otin$ space$((\\log{n})^4)$?. how do i show that tqbf $ otin$ space$((\\log{n})^4)$? i know that tqbf is pspace complete, but is this the right approach?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory"
    ]
  },
  {
    "text": "new site not showing in google for unique name. i have launched a site for myself and now i'm doing some simple seo for it.the site uses my name and it's unique and has no competition on search engines, but i don't know why google crawlers haven't done anything on my site.i have added my site's url to google (via addurl) and i have also signed in to google webmaster tools.the title and the url of my site is also related to my name, but even when i google my name google returns nothing about my site, and google webmaster tools also shows no keywords for my site. do you have any idea why this happens?[update] ok, i won't link my site here, i launched it about 5 days ago, and it's on my name (completely unique). i just want it to be shown everytime some one googles my name - just that simple, but it seems google hasn't done anything with my site yet, is this normal?",
    "present_kp": [
      "google",
      "seo"
    ],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "automatically starting smuxi-server. smuxi (isn't that a weird name?) is an irc client, which has a decoupled server and client setup. the server sits in some always-on machine in the cloud and the client connects to it from a local machine. this is particularly useful if the client machine does not have good or reliable connectivity.if the client loses the connection, it can reconnect to the server, and not lose any of the ongoing chat.so, that brings me to my question. the smuxi server documentation is a little sparse, it saysif you want the smuxi-server to automatically start in the background when your system boots, continue reading the following sections. this is highly dependent of your operating system as each system provides its own way to auto start services.there are then some highly instructive blank spaces starting with words like debian, ubuntu, and other linux.the section then hasto always start the smuxi-server automatically when the linux server boots, add this to your /etc/rc.local file:sudo -u your_linux_user bash -c 'nohup smuxi-server > $home/smuxi-server.log &'i'm not sure whether i should be taking this advice.i use debian, and this script has the wordsthis script is executed at the end of each multiuser runlevel.i'm not sure what that means. does that mean it executes multiple times? isn't that a bad thing?anyway, i'm looking for advice (or possibly scripts) for a way to start the server automatically on boot, and also a way to run it manually and have it background automatically. i could run it inside screen, but that feels a little... hacky.since i'm using debian wheezy, i'd like a method that would work with that systems default setup.",
    "present_kp": [
      "debian"
    ],
    "absent_kp": [
      "init script"
    ]
  },
  {
    "text": "md5 string and file different. why do i become a different hash when i try:md5 <<< hellomd5 -s hellois it because of a possible line break in the first example?",
    "present_kp": [],
    "absent_kp": [
      "shell",
      "hashsum"
    ]
  },
  {
    "text": "guessing game (heads or tails). you guess heads or tails by clicking one of the buttons on easygui. if it's right, you will get a good job message. if it's wrong, you will get a wrong message! after that, there is an option to play again.please give me some feedback on how i can make my code better, if there is room for improvement.import randomimport timeimport easyguiimport syswhile true: rand = random.choice([heads, tails]) firstguess = easygui.buttonbox(pick one, choices= [heads, tails]) if firstguess == rand: easygui.msgbox(wow you win!) else: easygui.msgbox(sorry you guessed wrong!) time.sleep(2) answer = easygui.buttonbox(play again?, choices=[yes,no]) if answer == yes: pass else: breakeasygui.msgbox(ok, see you later!)sys.exit(0)",
    "present_kp": [
      "game"
    ],
    "absent_kp": [
      "python",
      "beginner"
    ]
  },
  {
    "text": "doubt when compiling usb/ip drivers. i need to install a usb 3g modem to a windows virtual machine (running on ovm).the modem will be plugged on a linux host. (would windows be easier?)i don't understand what the following readme file says. for newer kernels ( >=2.6.28 ), try linux-staging code!this directory contains the source code of usbip drivers for mainline kernel.[how to make usb/ip drivers] 1. cd $(top)/drivers/{version}/ 2. make ksource=/usr/src/kernel-source-2.6.20 ksource is the directory that your kernel was built. 3. if succeed, usbip_common_mod.ko, vhci-hcd.ko and usbip.ko are built. 4. copy these kernel modules to client and server hosts. 5. don't forget to make usb/ip tools. see $(top)/src/readme.the result of my cat /proc/version is:linux version 2.6.39-400.209.1.el6uek.x86_64 (<email>) (gcc version 4.4.6 20110731 (red hat 4.4.6-3) (gcc) )what is this linux-staging code? it says i'll need it.another thing is that the make call requires the ksource location, but i've checked it and it's empty. i should download and extract the 2.6.39 kernel source there, right?where should i put the generated .ko files as instructed by item 4?",
    "present_kp": [
      "kernel",
      "compiling",
      "drivers"
    ],
    "absent_kp": []
  },
  {
    "text": "updating a news pages written in html. i was wondering how to update a page with new stuff like a new news article or something. (the website is html based). the only thing i could think of is by uploading and replacing the whole .html page with the new article etc. but isn't there an easier way? like in wordpress where you just sign in and write the article and post it.",
    "present_kp": [
      "html"
    ],
    "absent_kp": []
  },
  {
    "text": "can speech dysarthria occur in schizophrenia without other neurological or medication-induced disruptions?. as i understand it, acquired dysarthria of speech is caused due to problems with motor neurons or other neurological, cerebral and peripheral, conditions in the cns affecting those. and schizophrenia is primarily a problem in mesolimbic and mesocortical dopaminergic pathways, amongst possibly other problems. can a purely schizophrenic or psychiatric condition without neurological diagnoses cause dysarthria as a symptom by itself? or is acquired dysarthria always a sign of a comorbid neurological diagnosis?",
    "present_kp": [
      "schizophrenia",
      "speech"
    ],
    "absent_kp": []
  },
  {
    "text": "how to login by ssh when default shell is wrong. i have change default root shell to wrong path. now the first line of /etc/passwd is look like the following string:root:x:0:0:root:/root:/usr/bin/bashthen i logout from server and now cannot log in by root.there is no other user on server.i know, here is much stupid mistakes, but how i can fix it?access to server is available only by ssh.updatethe mission is impossible.i found a way to execute any command as www-data user.how can i change /etc/passwd as non-sudo user?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": []
  },
  {
    "text": "small command-line helper tool. i've coded a small command line helper tool for this library i'm working on. the library provides tools for the use of virtual texturing on ios devices (mainly games).this little command line helper is still pretty much a prototype that i coded as quick as i could, for testing a new file format. some feedback would be appreciated before i expand it further:// virtual texturing library:#include vt_tool_image.hpp#include vt_tool_pagefile_builder.hpp#include vt_tool_platform_utils.hpp// standard library:#include <cstdarg>#include <cstdio>#include <cstdlib>#include <cstring>#include <string>namespace {// ======================================================// local data:// ======================================================vt::tool::pagefilebuilderoptions cmdlineopts;std::string inputfile, outputfile;// ======================================================// printhelpandexit()// ======================================================void printhelpandexit(){ std::printf( usage: $ vtmake <input_file> <output_file> [--flags=] flags accepted: --help : prints help text with list of commands. --filter : (str) type of mipmapping filter: box, tri, quad, cubic, bspline, mitchell, lanczos, sinc, kaiser. --page_size : (int) total page size in pixels, including border. --content_size : (int) size in pixels of page content, not including border. --border_size : (int) size in pixels of the page border. --max_levels : (int) max mipmap levels to generate. --flip_v_src : (bool) flip the source image vertically. --flip_v_tiles : (bool) flip each individual tile/page vertically. --stop_on_1_mip : (bool) stop subdividing when mip 0 is reached. --add_debug_info : (bool) print debug text to each page. --dump_images : (bool) dump each page as an image file (tga format). --verbose : (bool) print stuff to stdout while running. ); std::exit(0);}// ======================================================// error():// ======================================================void error(const char * format, ...){ va_list valist; char buffer[1024]; va_start(valist, format); std::vsnprintf(buffer, sizeof(buffer), format, valist); va_end(valist); buffer[sizeof(buffer) - 1] = ''; // ensure a null at the end throw vt::tool::pagefilebuildererror(buffer);}// ======================================================// parsefiltername():// ======================================================vt::tool::filtertype parsefiltername(const char * str){ // find the value after the '=' sign, if any: while ((*str != '=') && (*str != '')) { ++str; } if (*str == '=') { ++str; } if (std::strcmp(str, box ) == 0) { return vt::tool::filtertype::box; } if (std::strcmp(str, tri ) == 0) { return vt::tool::filtertype::triangle; } if (std::strcmp(str, quad ) == 0) { return vt::tool::filtertype::quadratic; } if (std::strcmp(str, cubic ) == 0) { return vt::tool::filtertype::cubic; } if (std::strcmp(str, bspline ) == 0) { return vt::tool::filtertype::bspline; } if (std::strcmp(str, mitchell) == 0) { return vt::tool::filtertype::mitchell; } if (std::strcmp(str, lanczos ) == 0) { return vt::tool::filtertype::lanczos; } if (std::strcmp(str, sinc ) == 0) { return vt::tool::filtertype::sinc; } if (std::strcmp(str, kaiser ) == 0) { return vt::tool::filtertype::kaiser; } std::printf(warning: unknown filter '%s'! defaulting to box filter. , str); return vt::tool::filtertype::box;}// ======================================================// parseint():// ======================================================int parseint(const char * str){ // find the value after the '=' sign, if any: while ((*str != '=') && (*str != '')) { ++str; } if (*str == '=') { ++str; } return std::stoi(str);}// ======================================================// parsebool():// ======================================================bool parsebool(const char * str){ // find the value after the '=' sign, if any: while ((*str != '=') && (*str != '')) { ++str; } if (*str == '=') { ++str; } if ((std::strcmp(str, false) == 0) || (std::strcmp(str, no) == 0) || (std::strcmp(str, 0) == 0)) { return false; } // assume true for anything else, including an invalid value or an empty string. // (results in true for --flag with no =value part) return true;}// ======================================================// startswith():// ======================================================bool startswith(const char * str, const char * prefix){ const size_t prefixlen = std::strlen(prefix); if (prefixlen == 0) { return false; } return std::strncmp(str, prefix, prefixlen) == 0;}// ======================================================// parsecmdline():// ======================================================void parsecmdline(const int argc, const char * argv[]){ // possible --help call if ((argc == 2) && startswith(argv[1], --help)) { printhelpandexit(); } // must have at least argv[0], in_file and out_file if (argc < 3) { error(not enough arguments!); } /* argc[0] == vtmake (prog name) */ inputfile = argv[1]; outputfile = argv[2]; for (int i = 3; i < argc; ++i) { if (startswith(argv[i], --help)) { printhelpandexit(); } else if (startswith(argv[i], --filter)) { cmdlineopts.texturefilter = parsefiltername(argv[i]); } else if (startswith(argv[i], --page_size)) { cmdlineopts.pagesizepixels = parseint(argv[i]); } else if (startswith(argv[i], --content_size)) { cmdlineopts.pagecontentsizepixels = parseint(argv[i]); } else if (startswith(argv[i], --border_size)) { cmdlineopts.pagebordersizepixels = parseint(argv[i]); } else if (startswith(argv[i], --max_levels)) { cmdlineopts.maxmiplevels = parseint(argv[i]); } else if (startswith(argv[i], --flip_v_src)) { cmdlineopts.flipsourcevertically = parsebool(argv[i]); } else if (startswith(argv[i], --flip_v_tiles)) { cmdlineopts.fliptilesvertically = parsebool(argv[i]); } else if (startswith(argv[i], --stop_on_1_mip)) { cmdlineopts.stopon1pagemip = parsebool(argv[i]); } else if (startswith(argv[i], --add_debug_info)) { cmdlineopts.adddebuginfotopages = parsebool(argv[i]); } else if (startswith(argv[i], --dump_images)) { cmdlineopts.dumppageimages = parsebool(argv[i]); } else if (startswith(argv[i], --verbose)) { cmdlineopts.stdoutverbose = parsebool(argv[i]); } else { std::printf(warning: unknown command line argument: '%s' , argv[i]); } } if (cmdlineopts.stdoutverbose) { std::printf(input file: \\%s\\n, inputfile.c_str()); std::printf(output file: \\%s\\n, outputfile.c_str()); cmdlineopts.printself(); }}// ======================================================// runpagefilebuilder():// ======================================================void runpagefilebuilder(){ if (inputfile.empty()) { error(no input filename!); } if (outputfile.empty()) { error(no output filename!); } vt::tool::pagefilebuilder pagefilebuilder(inputfile, outputfile, cmdlineopts); pagefilebuilder.generatepagefile(); std::printf(done! );}} // namespace {}// ======================================================// main():// ======================================================int main(int argc, const char * argv[]){ try { parsecmdline(argc, argv); runpagefilebuilder(); return 0; } catch (std::exception & e) { std::printf(error: %s , e.what()); return -1; }}the main purpose of this code, as you can see, is to parse and validate command line args. the heavy work is then done by the library. it looks very c-ish, i'll admit. since i wrote it quickly for testing, i didn't bother much. also, command args validation is still pretty weak. i might consider refactoring it into a class and using less char* and more std::string.",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "c++11",
      "console"
    ]
  },
  {
    "text": "can i use a project code which has new bsd license but uses a gpl license library?. i want to use the icsopenvpn project source code in my commercial application.if we see the icsopenvpn project, it states that its license is new bsd but the libopenvpn.so library it uses is under gnu gplv2 license.as per faq for version 2 of gnu gpl if a library is released under the gpl (not the lgpl), does that mean that any program which uses it has to be under the gpl? the answer says: yes, because the program as it is actually run includes the library.also, how could icsopenvpn change the license to new bsd?",
    "present_kp": [
      "gpl",
      "bsd license"
    ],
    "absent_kp": [
      "android"
    ]
  },
  {
    "text": "my reverse-ssh tunnel is using keepalives but they're not helping. i have an ssh client machine picard behind multiple unreliable internet connections - all with nat.i have my server time, reliable with a static ip.i want to be able to access picard thorugh time. i've done this before:ssh -n -r 19999:localhost:22 <email> works, but if there is a problem it exits and does not restart, and it doesn't start on boot, so now i add a sydtemd service to run:/bin/bash -c while true; do /usr/bin/ssh -i <unencrypted key> -o serveraliveinterval=10 -v -o serveralivecountmax=6 -n -r 19999:localhost:22 <email> sleep 5; donewhile true ... sleep 5 re-runs ssh if it exits-o serveraliveinterval=10 sends a keep-alive every 10 secnods-o serveralivecountmax=6 exits if 6 keep-alives go out with no response-v keeps debug info in /var/log/messages through systemdon the server side i added a couple of lines to sshd_config:keepalive yesclientaliveinterval 10clientalivecountmax 6same idea as the client - break the connection after 60s of inactivity.unfortunately it seems to take a lot longer than a minute to restart:< tunnel is up and keepalives are coming in >jun 7 17:31:02 picard bash[135]: debug1: client_input_global_request: rtype <email> want_reply 1jun 7 17:31:12 picard bash[135]: debug1: client_input_global_request: rtype <email> want_reply 1jun 7 17:31:15 picard bash[135]: debug1: client_input_channel_open: ctype forwarded-tcpip rchan 2 win <phone> max 32768jun 7 17:31:15 picard bash[135]: debug1: client_request_forwarded_tcpip: listen localhost port 19998, originator 127.0.0.1 port 38267jun 7 17:31:15 picard bash[135]: debug1: connect_next: host localhost ([127.0.0.1]:22) in progress, fd=4jun 7 17:31:15 picard bash[135]: debug1: channel 0: new [127.0.0.1]jun 7 17:31:15 picard bash[135]: debug1: confirm forwarded-tcpipjun 7 17:31:15 picard bash[135]: debug1: channel 0: connected to localhost port 22jun 7 17:31:20 picard systemd-logind[137]: new session 1 of user main_username.< i break eth0 and plug it back in after nm sees it's down >< eth0 is back up within a few seconds >< nothing happens with my ssh connection for a long time >jun 7 17:54:16 picard bash[135]: write failed: broken pipejun 7 17:54:22 picard bash[135]: openssh_6.1p1, openssl 1.0.1c-fips 10 may 2012jun 7 17:54:22 picard bash[135]: debug1: reading configuration data /etc/ssh/ssh_configjun 7 17:54:22 picard bash[135]: debug1: /etc/ssh/ssh_config line 50: applying options for *jun 7 17:54:22 picard bash[135]: debug1: connecting to my.domain [123.234.123.234] port 22.jun 7 17:54:22 picard bash[135]: debug1: connection established.jun 7 17:54:23 picard bash[135]: debug1: identity file /home/test/.ssh/id_rsa type 1jun 7 17:54:23 picard bash[135]: debug1: identity file /home/test/.ssh/id_rsa-cert type -1jun 7 17:54:23 picard bash[135]: debug1: remote protocol version 2.0, remote software version openssh_5.8p1 debian-1ubuntu3jun 7 17:54:23 picard bash[135]: debug1: match: openssh_5.8p1 debian-1ubuntu3 pat openssh_5*jun 7 17:54:23 picard bash[135]: debug1: enabling compatibility mode for protocol 2.0jun 7 17:54:23 picard bash[135]: debug1: local version string ssh-2.0-openssh_6.1jun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_kexinit sentjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_kexinit receivedjun 7 17:54:23 picard bash[135]: debug1: kex: server->client aes128-ctr hmac-md5 nonejun 7 17:54:23 picard bash[135]: debug1: kex: client->server aes128-ctr hmac-md5 nonejun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_kex_dh_gex_request(1024<1024<8192) sentjun 7 17:54:23 picard bash[135]: debug1: expecting ssh2_msg_kex_dh_gex_groupjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_kex_dh_gex_init sentjun 7 17:54:23 picard bash[135]: debug1: expecting ssh2_msg_kex_dh_gex_replyjun 7 17:54:23 picard bash[135]: debug1: server host key: rsa 7a:19:72:9d:f5:39:f5:03:cf:16:b2:ee:fc:a4:e6:bajun 7 17:54:23 picard bash[135]: debug1: host 'my.domain' is known and matches the rsa host key.jun 7 17:54:23 picard bash[135]: debug1: found key in /home/test/.ssh/known_hosts:1jun 7 17:54:23 picard bash[135]: debug1: ssh_rsa_verify: signature correctjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_newkeys sentjun 7 17:54:23 picard bash[135]: debug1: expecting ssh2_msg_newkeysjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_newkeys receivedjun 7 17:54:23 picard bash[135]: debug1: roaming not allowed by serverjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_service_request sentjun 7 17:54:23 picard bash[135]: debug1: ssh2_msg_service_accept receivedjun 7 17:54:23 picard bash[135]: debug1: authentications that can continue: publickey,passwordjun 7 17:54:23 picard bash[135]: debug1: next authentication method: publickeyjun 7 17:54:23 picard bash[135]: debug1: offering rsa public key: /home/test/.ssh/id_rsajun 7 17:54:23 picard bash[135]: debug1: server accepts key: pkalg ssh-rsa blen 279jun 7 17:54:23 picard bash[135]: debug1: read pem private key done: type rsajun 7 17:54:24 picard bash[135]: debug1: authentication succeeded (publickey).jun 7 17:54:24 picard bash[135]: authenticated to my.domain ([123.234.123.234]:22).jun 7 17:54:24 picard bash[135]: debug1: remote connections from localhost:19999 forwarded to local address localhost:22jun 7 17:54:24 picard bash[135]: debug1: requesting <email> 7 17:54:24 picard bash[135]: debug1: entering interactive session.jun 7 17:54:24 picard bash[135]: debug1: remote forward success for: listen 19999, connect localhost:22jun 7 17:54:24 picard bash[135]: debug1: all remote forwarding requests processedjun 7 17:54:44 picard bash[135]: debug1: client_input_global_request: rtype <email> want_reply 1jun 7 17:54:45 picard bash[135]: debug1: client_input_channel_open: ctype forwarded-tcpip rchan 2 win <phone> max 32768jun 7 17:54:45 picard bash[135]: debug1: client_request_forwarded_tcpip: listen localhost port 19999, originator 127.0.0.1 port 60222jun 7 17:54:45 picard bash[135]: debug1: connect_next: host localhost ([127.0.0.1]:22) in progress, fd=4jun 7 17:54:45 picard bash[135]: debug1: channel 0: new [127.0.0.1]jun 7 17:54:45 picard bash[135]: debug1: confirm forwarded-tcpipjun 7 17:54:45 picard bash[135]: debug1: channel 0: connected to localhost port 22jun 7 17:54:50 picard systemd-logind[137]: new session 3 of user main_username.< whenever i connect the keepalive debug messages stop coming, not sure if this is normal >i'm sure i've overlooked something. i've seen some projects like autossh that do pretty much the same thing i'm doing now, but i'd like to be able to fix this if possible. how do i get the delay down to 2-3 minutes instead of 23 minutes?",
    "present_kp": [
      "ssh",
      "sshd"
    ],
    "absent_kp": [
      "ssh tunneling"
    ]
  },
  {
    "text": "how do i find out the license for each of my installed applications/packages?. i am using ubuntu-15.10.i have installed many applications apart from vanilla installations.now, i would like to find out how many installed packages are licensed under the gpl or third-party licenses (e.g. fluendo).is there any way to find this out? or do i need to check manually each and every license of each installed application?edit:following snippet i used to list out the name of various installed license files.find /usr/share/doc -type f -name copyright -exec grep license\\: {} + | cut -f3 -d: | sort -u",
    "present_kp": [
      "ubuntu",
      "licenses"
    ],
    "absent_kp": []
  },
  {
    "text": "zsh: quickly bookmark commands. i just had an idea, i'm sure it must exist though i could not find anything on the web.this topic gets close to my idea but not enough:how to quickly store and access often used commands?i'd like to have a .bookmark.zsh file in which i store commands, not often used (i could create an alias for these), but more those which were a pain in the ass to write down, and that i could use some other times.like i just typed: rake db:drop --trace && echo 'dropped' && \\ rake db:create --trace && echo 'created' && \\ rake db:migrate --trace && echo 'migrated' && \\ rake db:seed --trace && echo 'seed'and i want to save it, so i type bm -save 'description' and it adds rake db:drop --trace && echo 'dropped' && \\ rake db:create --trace && echo 'created' && \\ rake db:migrate --trace && echo 'migrated' && \\ rake db:seed --trace && echo 'seed' # description'in my .bookmark.zsh file.and then i can do bm -find 'description' (or ideally 'descr' 'desc' etc.) and i find the command back. like bookmarks work!i'm pretty bad at shell so any tip would be super nicely welcomed!",
    "present_kp": [
      "zsh"
    ],
    "absent_kp": [
      "command history"
    ]
  },
  {
    "text": "modeline for dell u2415 1920x1200 resolution. i'm trying here to run my secondary display (u2415) on the native resolution 1920x1200. xrandr unfortunately reports only 1920x1080, which is not satisfactory.$ xrandr screen 0: minimum 8 x 8, current 3286 x 1080, maximum 32767 x 32767lvds1 connected 1366x768+1920+312 (normal left inverted right x axis y axis) 344mm x 194mm 1366x768 59.97*+ 1024x768 60.00 800x600 60.32 56.25 640x480 59.94 dp1 disconnected (normal left inverted right x axis y axis)hdmi1 disconnected (normal left inverted right x axis y axis)vga1 connected 1920x1080+0+0 (normal left inverted right x axis y axis) 509mm x 286mm 1920x1080 60.00*+ 1680x1050 59.95 1280x1024 75.02 60.02 1440x900 74.98 59.89 1280x960 60.00 1280x800 59.81 1152x864 75.00 1024x768 75.08 70.07 60.00 800x600 75.00 60.32 640x480 75.00 60.00 os:linux arch 3.19.3-3-arch #1 smp preempt wed apr 8 14:10:00 cest 2015 x86_64 gnu/linuxhw:$ lspci -nnks 00:02.000:02.0 vga compatible controller [0300]: intel corporation core processor integrated graphics controller [8086:0046] (rev 02) subsystem: lenovo device [17aa:3920] kernel driver in use: i915 kernel modules: i915i've googled it and it seems that intel gma has no problem whatsoever to run 1920x1200 via vga.the following command gives me my modeline which i've tried and which works, but not quite really - it produces worse quality image than on the 1920x1080 and entire desktop is shifted to the left. furthermore, when i go the osd menus on the display i see that i'm getting 1600x1200 60hz :($ gtf <phone> 60 -x # 1920x1200 @ 60.00 hz (gtf) hsync: 74.52 khz; pclk: 193.16 mhz modeline 1920x1200_60.00 193.16 <phone> 2256 2592 <phone> <phone> -hsync +vsynci've also tried something called 915resolution, well it's patched version from this location. but it didn't work very well either. by following examples in their readme i've tried:# ./915resolution 30 1920 1200intel 800/900 series vbios hack : version 0.5.3chipset: hdgraphicsbios: type 1mode table offset: $c0000 + $268mode table entries: 36patch mode 30 to resolution 1920x1200 complete# ./915resolution -lintel 800/900 series vbios hack : version 0.5.3chipset: hdgraphicsbios: type 1mode table offset: $c0000 + $268mode table entries: 36mode 30 : 640x480, 8 bits/pixelmode 32 : 800x600, 8 bits/pixelmode 34 : 1024x768, 8 bits/pixelmode 38 : 1280x1024, 8 bits/pixelmode 3a : 1600x1200, 8 bits/pixelmode 3c : 1920x1440, 8 bits/pixelmode 41 : 640x480, 16 bits/pixelmode 43 : 800x600, 16 bits/pixelmode 45 : 1024x768, 16 bits/pixelmode 49 : 1280x1024, 16 bits/pixelmode 4b : 1600x1200, 16 bits/pixelmode 4d : 1920x1440, 16 bits/pixelmode 50 : 640x480, 32 bits/pixelmode 52 : 800x600, 32 bits/pixelmode 54 : 1024x768, 32 bits/pixelmode 58 : 1280x1024, 32 bits/pixelmode 5a : 1600x1200, 32 bits/pixelmode 5c : 1920x1440, 32 bits/pixelyou can see, that mode 30 remains on 640x480...and finally last but not least important, i'm running all this via qumox vga to hdmi converter. their specs clearly state, that they support 1920x1200 resolutions, but i've started to doubt it.so dear sirs, what else i may try, to make my ultra cool display operate on the correct resolution??thanks",
    "present_kp": [
      "kernel modules",
      "xrandr",
      "pci"
    ],
    "absent_kp": [
      "x11"
    ]
  },
  {
    "text": "coffeescript beautification and refactoring. as much as i try, i cannot seem to get this coffeescript code to look beautiful (i'd like to think it is possible). i have tried both javascript and coffeescript. just to be clear, this code works fine, but it is hard to read, for reasons that i am unable to pinpoint.how can it be refactored, reorganized, and what changes to coding style can be made to make it more appealing to read?define [ plugins/ui/ui, ./js/highlight], (ui, highlight) -> editor = {} jquery ($) -> # a widget to view source code. $.widget 'core.editor', _create: -> $editor = $(this.element) $editor .addclass('editor') .append($('<ul spellcheck=false contenteditable> <li></li> </ul>')) # move the gutter along with the editable area. this.lines().bind 'scroll', (event) -> $this = $(this) $this.siblings(.gutter).css(top: $this.scrolltop() * -1) # highlight the sourceview using the given language. # the language's json rule file is loaded. highlight: (language) -> this.language = language require [text!plugins/editor/js/#{ language }.json], (json) => this._rules = json.parse(json) return # update the 'left' of the '<ul>' based on the gutter width. # each time the number of digits in the gutter changes, it becomes wider or # narrower, and the editor needs the shift accordingly. updategutterwidth: () -> # the '8' is the gutter's left padding. this.lines().css(left: this.gutter().width() + 8) # add or remove line numbers if the number of lines has changed. # 'change' is a modification the the line count (in case the character was not yet # typed). updatelinenumbers: (change = 0) -> $gutter = this.gutter() count = this.lines().children(li).length current = $gutter.children(span).length count += change # add lines if (count > current) for i in [current..(count - 1)] ele = document.createelement(span) ele.innertext = #{ i + 1 } $gutter[0].appendchild(ele) # remove lines else if (current > count) for j in [count..(current - 1)] $gutter.children(span:last-child).remove() this.updategutterwidth() if current != count return # set whether or not the gutter should be visible. linenumbers: (bool) -> if bool == true and !this.number $(this.element) .prepend('<div class=gutter></div>') this.lines() .css(left: 20) this.updatelinenumbers() else if bool == false and this.number this.gutter().remove() $(this.element) .css(left: 1) this.number = bool # return the gutter (a jquery object). gutter: () -> this._gutter ?= $(this.element).children(div.gutter) return this._gutter # return a jquery '<ul>'. each '<li>' is a line of the source viewer. lines: -> return $(this.element).children('ul') # a hash of syntax highlighting rules. rules: -> return this._rules # re-highlight the text. $(.editor > ul).live 'keyup', (event) -> # 13: enter # 37, 38, 39, 40: arrow keys # 33, 34: page up / down # 16, 17, 18, 91: shift, ctrl, alt, meta # 35, 36: home / end if !(event.which in [13, 37, 38, 39, 40, 33, 34, 16, 17, 18, 91, 35, 36]) and !event.altkey and !event.ctrlkey # prevent an annoying error when backspacing to the beginning of a line. selection = window.getselection() # store the cursor position before highlighting. cursorpos = selection.getrangeat(0) if cursorpos.getclientrects()[0] clickx = cursorpos.getclientrects()[0].left clicky = cursorpos.getclientrects()[0].top # highlight $li = $(selection.focusnode).closest(li) rules = $li.closest(.editor).editor('rules') highlight.highlight($li, rules) # restore cursor position. cursorpos = document.caretrangefrompoint(clickx, clicky) window.getselection().addrange(cursorpos) # line numbering update. $(.editor > ul).live 'keydown', (event) -> # redo line numbering for enter, backspace, delete. if (event.which in [13, 8, 46]) $this = $(this) newline = switch event.which when 13 then 1 when 8 then -1 else 0 $this.parent().editor('updatelinenumbers', newline) # correction settimeout(() -> $this.parent().editor('updatelinenumbers', 0) , 300) # ##################### main ########################## $(.frame).frame('tabs').last().tab(content) .append(<div id='sourceview'></div>) $(#sourceview) .css position: 'absolute' left: 1 right: 1 top: 1 bottom: 1 .editor() .editor('theme', 'plugins/editor/themes/idlefingers.css') .editor(highlight, javascript) .editor(linenumbers, true) return editor",
    "present_kp": [
      "javascript",
      "jquery",
      "coffeescript"
    ],
    "absent_kp": [
      "jquery ui"
    ]
  },
  {
    "text": "doubly linked list: iterator/pointer arithmetic. i'm using a doubly linked list container i've written as the working example. the textbook i'm using is from 2001, so feel free to point out where later versions of the c++ standard should be used instead.notes:list::iterator functionality mimics pointer arithmetic.unlike most containers, list beginning is marked by a specific element which holds no data, to make reverse iteration easier: [begins][data][data][data][data][data][ends]de-referencing begin/end will deference the closest data element, so *begin = data@0 & *end = <email> list container plays more elegantly with basic loops (see main).list.h:#ifndef guard_list_h#define guard_list_htemplate <class t>struct element { element<t> *prev = null; element<t> *next = null; t data = null; int elem_id = null; char t_flag = null;};template <class t>struct elem_iter { elem_iter() { target = null; } elem_iter(element<t>* e) { target = e; } element<t>* target; element<t>* elem_iter::operator++(void) { if (target->next->t_flag == 'e'){ return null; } target = target->next; return target; } element<t>* elem_iter::operator--(void){ if (target->prev->t_flag == 'b'){ return null; } target = target->prev; return target; } t elem_iter::operator*(void){ if (target->t_flag == 'e'){ target = target->prev; return target->data; } else if (target->t_flag == 'b'){ target = target->next; return target->data; } return target->data; } bool elem_iter::operator!=(elem_iter& rhs){ return (rhs.target != this->target); } bool elem_iter::operator>=(elem_iter& rhs){ return (this->target->elem_id >= rhs.target->elem_id); } bool elem_iter::operator<=(elem_iter& rhs){ return (this->target->elem_id <= rhs.target->elem_id); } bool elem_iter::operator>(elem_iter& rhs){ return (this->target->elem_id > rhs.target->elem_id); } bool elem_iter::operator<(elem_iter& rhs){ return (this->target->elem_id < rhs.target->elem_id); } elem_iter elem_iter::operator+(int val){ for (int i = 0; i < val; i++){ this->target = this->target->next; } return *this; } elem_iter elem_iter::operator-(int val){ for (int i = 0; i < val; i++){ this->target = this->target->prev; } return *this; }};template <typename t>class list {public: list::list(void) { element_count = 0; // create begin element<t>* b = new element <t>; b->t_flag = 'b'; begins = b; // create end element<t>* e = new element <t>; e->t_flag = 'e'; ends = e; // double link: begins & ends begins->next = ends; ends->prev = begins; element_count = 0; } typedef elem_iter<t> iterator; iterator begin(void) { iterator it(begins); return it; } iterator end(void) { iterator it(ends); return it; } void push_back(t val) { element<t>* elem = new element<t>; // create: new-elem elem->data = val; // set data elem->elem_id = element_count++; // set id elem->prev = ends->prev; // link: new-elem to last-data-elem ends->prev->next = elem; // link: last-data-elem to new-element elem->next = ends; // link: new-elem to list-end ends->prev = elem; // link: list-end to new-elem ends->elem_id = element_count; // update: ends-id when list grows } t at(size_t pos) { return get_element(pos)->data; } void del(size_t pos) { element<t>* elem = get_element(pos); // get: element for deletion elem->prev->next = elem->next; // rejoin: double link elem->next->prev = elem->prev; // rejoin: double link delete elem; ends->elem_id = (element_count--); // update: when list shrinks } void clear(void) { element<t>* ep = begins->next; element<t>* ep_next = ep->next; while (ep->t_flag != 'e'){ delete ep; ep = ep_next; ep_next = ep->next; } begins->next = ends; ends->prev = begins; begins->data = null; ends->elem_id = null; element_count = 0; } size_t size(void) const { return element_count; } bool empty(void) const { if (element_count == 0){ return true; } else { return false; } }private: element<t>* begins; // list begins element<t>* ends; // list ends size_t element_count; // list size element<t>* get_element(size_t pos) { if (empty()) { std::cerr << no element - empty list; throw; } if (pos < 0 || pos >= element_count){ std::cerr << no element - out of range; throw; } iterator it; // determine the more efficent iteration direction(forward or reverse) ? if ((element_count / 2) > pos) { it = begin(); for (size_t i = 0; i <= pos; i++){ it++; } } else { it = end(); for (size_t i = size() - pos; i > 0; i--){ it--; } } return it.target; }};#endiftypedef list<int> container;main.cpp:#include <iostream>#include <vector>#include <list>#include list.hint main() { container ls; container::iterator begin = ls.begin(); container::iterator end = ls.end(); container::iterator iter = begin; std::cout << attempt to retrieve data from empty list: ls.at(3) << std::endl; std::cout << -------------------------------------------------- << std::endl; //std::cout << ls.at(3) << std::endl << std::endl; std::cout << test: growing list does not invalidate iter << std::endl; std::cout << ------------------------------------------- << std::endl; std::cout << empty list << std::endl << std::endl; std::cout << begin addr: << &begin << << std::endl; std::cout << begin t_flag: << begin.target->t_flag << << std::endl; std::cout << end addr: << &end << << std::endl; std::cout << end t_flag: << end.target->t_flag << << std::endl; std::cout << std::endl << add data to list: 33 << std::endl << std::endl; ls.push_back(33); std::cout << begin addr: << &begin << << std::endl; std::cout << begin t_flag: << begin.target->t_flag << << std::endl; std::cout << end addr: << &end << << std::endl; std::cout << end t_flag: << end.target->t_flag << << std::endl; std::cout << std::endl << add data to list: 33 << std::endl << std::endl; ls.push_back(856); std::cout << begin addr: << &begin << << std::endl; std::cout << begin t_flag: << begin.target->t_flag << << std::endl; std::cout << end addr: << &end << << std::endl; std::cout << end t_flag: << end.target->t_flag << << std::endl << std::endl; std::cout << clear() << std::endl << std::endl; ls.clear(); std::cout << std::endl << std::endl; std::cout << add data to list: 0 1 2 3 4 5 6 7 8 9 << std::endl; std::cout << ------------------------------------------------- << std::endl; for (int i = 0; i != 10; i++){ ls.push_back(i); } std::cout << std::endl << std::endl; std::cout << data@ begin+4 << std::endl; std::cout << ------------- << std::endl; std::cout << *(iter + 4) << std::endl; std::cout << std::endl << std::endl; std::cout << data@ begin->end << std::endl; std::cout << ---------------- << std::endl; iter = begin; while (iter++){ std::cout << *iter << ; } std::cout << std::endl << std::endl << std::endl; std::cout << data@ end->begin << std::endl; std::cout << ---------------- << std::endl; iter = end; while (iter--){ std::cout << *iter << ; } std::cout << std::endl << std::endl << std::endl; std::cout << for/iter: begin->end << std::endl; std::cout << ---------------- << std::endl; for (iter = begin; iter++;){ std::cout << *iter << ; } std::cout << std::endl << std::endl << std::endl; std::cout << iter arith: +4 +1 -1 << std::endl; std::cout << -------------------- << std::endl; iter = ls.begin(); iter = iter + 4; std::cout << *iter << ; std::cout << *(iter + 1) << ; std::cout << *(iter - 1) << ; std::cout << std::endl << std::endl << std::endl; std::cout << data@: (0)(1)(2)(3)(4)(5)(6)(7)(8)(9) << std::endl; std::cout << ------------------------------------- << std::endl; for (int i = 0; i != 10; i++){ std::cout << ls.at(i) << ; } ls.clear(); return 0;}",
    "present_kp": [
      "c++",
      "linked list",
      "iterator"
    ],
    "absent_kp": []
  },
  {
    "text": "nginx reverse proxy - no user/password was provided for basic authentication. i've got nginx set up on a rpi (raspbian)as a reverse proxy using ssl between the remote user and the nginx instance. all seems to work well for two services mounted on the rpi (shellinabox and rpi monitor). however i can't get nginx to work with a couch potato instance that is held on another server on the same home network.when on the home network, i can access couch potato from any device on the network without authentication, but when trying to access it externally through the nginx reverse proxy, the nginx error log shows:2015/02/05 10:43:46 [error] 30557#0: *1 no user/password was provided for basic authentication, client: xxx.xxx.xxx.xxx, server: , request: get /couchpotato/ http/1.1, host: xxx.xxx.xxx.xxxand the nginx generated access log for couchpotato shows:xxx.xxx.xxx.xxx - - [05/feb/2015:10:43:46 +0000] get /couchpotato/ http/1.1 401 590 - mozilla/5.0 (compatible; msie 10.0; windows nt 6.1; trident/6.0) the nginx configuration file in sites-available is here: <url> read many of the other questions about this i'm guessing that nginx is trying to pass it's own authentication to couchpotato when i think i don't want anything passed, but i don't know.grateful for any help",
    "present_kp": [
      "nginx",
      "ssl"
    ],
    "absent_kp": []
  },
  {
    "text": "kata: natural sort. i am choosing to learn f# for my own enjoyment. i am getting to the point where concepts of f# seem to be pretty easy, but understanding some of the whys and whens is a bit harder.before i get into the code and the explanation, let me put my question up front. i am asking where can i find better advice on formatting f# code for readability? or can someone give me a few guiding tips based off of the example given below?so what are the best practices for code format and file layout?now to the explanation of the code.i have started practicing coding kata's in f# just to allow me to flex the language a little. the following program is an implementation of a natural sort. this was my first attempt to solving the problem in a tdd fashion in f#, as such i chose to forgo any framework as i did not want to deal with figuring out how to use any of them and not break the functional paradigm.so the code below carries a light weight unit test framework.here is the code for the natural sort:namespace katas open system.linq module naturalsortkata = exception invalidexception of string type comparison = | equal | lesser | greater static member compare x y = if x = y then equal elif x > y then greater else lesser type chuncktype = | numbertype | stringtype | unknown static member gettype (c : char) = if system.char.isdigit(c) then numbertype else stringtype member this.compare other = match other with | ty when ty = this -> equal | unknown -> lesser | numbertype when this = unknown -> greater | numbertype -> lesser | stringtype -> greater let natualcompare (left : string) (right : string) = if left = right then equal else let fix str = new system.string( str |> list.rev |> list.toarray ) let gatherchunck str = let rec gather str acc = match str with | [] -> let (ty, l) = acc (ty, fix(l)) | fistletter::rest -> match acc with | (ty, _) when ty = unknown -> let t = chuncktype.gettype(fistletter) gather rest (t, fistletter :: []) | (ty, l) when ty = chuncktype.gettype(fistletter) -> gather rest (ty, fistletter::l) | (ty, l) -> (ty, fix(l)) gather str (unknown, []) let rec compare (left : string) (right : string) = if (not (left.any())) || (not (right.any())) then match left.length, right.length with | llen, rlen when llen = rlen -> equal | llen, rlen when llen > rlen -> greater | llen, rlen when llen < rlen -> lesser | _ -> raise (invalidexception bad data) else let lt, lchunk = left |> seq.tolist |> gatherchunck let rt, rchunk = right |> seq.tolist |> gatherchunck match lt.compare rt with | equal -> if lchunk = rchunk then let lval = left.replace(lchunk, ) let rval = right.replace(rchunk, ) compare lval rval else match lt with | numbertype -> comparison.compare (system.int64.parse(lchunk)) (system.int64.parse(rchunk)) | _ -> comparison.compare lchunk rchunk | _ -> lt.compare(rt) compare left righthere is the code for the tests:namespace katas.testing open katas.naturalsortkata module tests = let test left right expected title= let testrun x = let result = right |> natualcompare left if result = expected then x |> printfn %d good true else title + fails |> printfn %d %s x result |> sprintf %d actual: %a x |> sprintf %d expected: %a %s x expected |> printfn %s false testrun let testrunner tests= let rec runner x result tests = match tests with | [] -> result | head::tests -> let current = (head x) && result tests |> runner (x + 1) current tests |> runner 1 true let test01 = simple equality |> test one one equal let test02 = left < right |> test left right lesser let test03 = beta > alpha |> test beta alpha greater let test04 = \\9\\ < \\ |> test 9 10 lesser let test05 = lpha9\\ < lpha10\\ |> test alpha9 alpha10 lesser let test06 = lpha9centary9\\ < lpha9centary10\\ |> test alpha9centary9 alpha9centary10 lesser let test07 = \\ > \\9\\ |> test 10 9 greater let test08 = lpha10\\ > lpha9\\ |> test alpha10 alpha9 greater let test09 = lpha9centary9\\ < lpha9centary10\\ |> test alpha9centary10 alpha9centary9 greater let tests = test01 :: test02 :: test03 :: test04 :: test05 :: test06 :: test07 :: test08 :: test09 ::[] let runtests = tests |> testrunner |> printfn %bhere is the code that runs it all:open katas.naturalsortkataopen katas.testing.tests[<entrypoint>]let main argv = //katas.lockers.showlockerresults 300 runtests let _ = system.console.readkey(true) 1",
    "present_kp": [
      "f#"
    ],
    "absent_kp": [
      "unit testing"
    ]
  },
  {
    "text": "regular expression for a language which doesn't look regular. i'm trying to find a regular expression for the following language:$$l=\\{x0y : ext{$x$ contains same number of 0's as $y$ contains 1's}\\}. $$",
    "present_kp": [],
    "absent_kp": [
      "regular languages",
      "regular expressions"
    ]
  },
  {
    "text": "what's wrong about extending a class with prototype methods?. i was at a bar last night with a few of my colleagues. they said that it's a bad idea to extend the functionality of basic javascript objects with a prototype method.for example, let's say you created a method for finding the factorialnumber.prototype.factorial = function(n) { return n == 0 ? 1 : factorial(n - 1)}they said there was some danger to creating prototypes. why would this be a bad practice?",
    "present_kp": [
      "javascript"
    ],
    "absent_kp": [
      "functions",
      "prototyping"
    ]
  },
  {
    "text": "pac learning model definition. the probably approximately correct (pac) learning model is defined as:a concept class $c$ is said to be pac-learnable if there exists an algorithm $a$ and a polynomial function $poly(,,,)$ such that for any $>0$ and $>0$, for all distributions $d$ on $x$ and for any target concept $cc$, the following holds for any sample size $mpoly(1/,1/,n,size(c))$:$pr[r(hs)]1-$where $r(hs)$ is the generalization error over a sample $s$ of size $m$ containing instances of variable $x$ following distribution $d$ and $size(c)$ is the maximal cost of the computational representation of $cc$.i know $poly(1/,1/,n,size(c))$ is a polynomial. but what is the explicit form of $poly(1/,1/,n,size(c))$? what are the variables? what is its degree?",
    "present_kp": [],
    "absent_kp": [
      "machine learning"
    ]
  },
  {
    "text": "safari html for planck constant/reduced planck constant. i want to display the symbols commonly known as h and h-bar. this is for safari and ios. what do i enter into my html?if there is a table of such things somewhere, a reference to it would be great. thanks!",
    "present_kp": [
      "html",
      "safari"
    ],
    "absent_kp": []
  },
  {
    "text": "disable moving cards between lists. i like the way trello on trello lists are locked to the degree where users cannot move cards between lists (only for board owner/admin). is there a setting that controls this feature?",
    "present_kp": [
      "trello"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a way to put todo marker in confluence pages, then find all pages with this marker?. i'm looking for a way to put todo markers on confluence pages. so i could then see todo items in all documents. just the way it's done in visual studio and other ides.",
    "present_kp": [
      "confluence"
    ],
    "absent_kp": []
  },
  {
    "text": "java program to encrypt files using shamir secret sharing. shamir's secret sharing scheme essentially splits a secret into n parts, at least k of which are needed to recover it. i'm using that to encrypt/decrypt arbitrary files (it's part of a college project).here's a rough idea of what i'm doing:take a file, and read n bytes. treat those bytes as an integer, and encrypt it using this implementation of the shamir algorithm. i get n integers, and i write one each to a file. read n more bytes, and so on until i am done.similarly, when decrypting, take n files, read an integer from each (i write a byte to denote the length of an integer before each, so i know how many bytes to read), decrypt the n integers to get the original one, and convert it to bytes to get n bytes, and write them to a file, and then read more integers.this is working, but is rather slow - with encrypting to 3 files a 170 mb file, it takes me 5 minutes to encrypt, 4 minutes to decrypt. how can i speed it up? of course, any other suggestions are also welcome.package crypto;import com.tiemens.secretshare.main.cli.maincombine;import com.tiemens.secretshare.main.cli.mainsplit;import java.io.*;import java.math.biginteger;import java.nio.file.files;import java.nio.file.paths;import java.util.arraylist;import java.util.regex.matcher;import java.util.regex.pattern;import static java.lang.integer.min;import static java.util.arrays.copyofrange;/** * created by hooda on 2/3/2015. */public class shamir { //the encoding that will be used when splitting and combining files. static string encoding = iso-8859-1; //the number of bytes per piece (except maybe the last one)! static int piecesize = 128; //mode 0 for strings, 1 for ints. public static arraylist<string> shamirsplit(string inputstring, int numpieces, int minpieces, int mode) { string type = -ss; if (mode == 1) { type = -sn; } arraylist<string> parts = new arraylist<>(); string[] splitargs = {-n, integer.tostring(numpieces), -k, integer.tostring(minpieces), type, inputstring, -primenone}; mainsplit.splitinput splitinput = mainsplit.splitinput.parse(splitargs); mainsplit.splitoutput splitoutput = splitinput.output(); bytearrayoutputstream baos = new bytearrayoutputstream(); printstream ps = new printstream(baos); splitoutput.print(ps); string content = baos.tostring(); // e.g. iso-8859-1 bufferedreader reader = new bufferedreader(new stringreader(content)); string line; int i = 0; try { while ((line = reader.readline()) != null && i < numpieces) { if (line.startswith(share (x)) { i++; parts.add(line.trim()); } } } catch (exception e) { //todo catch } return parts; } //returns the integer that the decryption represents, but in string format. public static string shamircombineint(arraylist<string> parts, arraylist<integer> partnums, arraylist<string> flags, int k) { arraylist<string> args = new arraylist<>(); args.add(-primenone); args.add(-k); args.add(integer.tostring(k)); for (int i = 0; i < k; i++) { string partsecret = parts.get(i); string partnum = partnums.get(i).tostring(); args.add(-s.concat(partnum)); args.add(partsecret); } bytearrayoutputstream baos = new bytearrayoutputstream(); printstream ps = new printstream(baos); string[] combineargs = args.toarray(new string[args.size()]); maincombine.combineinput combineinput = maincombine.combineinput.parse(combineargs, null, ps); maincombine.combineoutput combineoutput = combineinput.output(); combineoutput.print(ps); string content = baos.tostring(); // e.g. iso-8859-1 pattern pattern = pattern.compile(secret.number = '); matcher matcher = pattern.matcher(content); if (matcher.find()) { int i = matcher.end(); char c = content.charat(matcher.end()); while (c != ''') { i++; c = content.charat(i); } return (content.substring(matcher.end(), i)); } else { return ; } } /** * splits the given file into numpieces, of which at least minpieces are needed to recover the original. * * @param filepath path to the file to be encrypted. * @param numpieces number of files to split into. * @param minpieces minimum splitted files needed to recover original. * @return * @throws ioexception */ public static arraylist<fileoutputstream> filesplit(string filepath, int numpieces, int minpieces) throws ioexception { long starttime = system.currenttimemillis(); //create files to which encrypted pieces will b written. arraylist<fileoutputstream> splitfiles = new arraylist<>(numpieces); for (int i = 0; i < numpieces; i++) { //todo splitfiles.add(i, new fileoutputstream(e://.concat(dummy.txt..concat(integer.tostring(i + 1))))); } //get the file as a byte array. byte[] fileasbytes = files.readallbytes(paths.get(filepath)); system.out.println(file had .concat(integer.tostring(fileasbytes.length))); //do the encryption. for (int i = 0; i < fileasbytes.length; ) { //we want to partition the byte array into pieces of length 4/8/16 whatever, but if length is not multiple (eg there are 15 bytes) //then the last piece should be shorter. j takes care of that. int j = min(fileasbytes.length - i, shamir.piecesize); byte[] piece = copyofrange(fileasbytes, i, i + j); i = i + j; shamir.encryptandwrite(piece, numpieces, minpieces, splitfiles); } for (fileoutputstream f : splitfiles) { f.close(); } long endtime = system.currenttimemillis(); system.out.println(encryption took + (endtime - starttime) / 1000.0 + seconds); //testing code. todo remove starttime = system.currenttimemillis(); system.out.println( testing the decryption ); arraylist<string> files = new arraylist<>(); files.add(e://dummy.txt.1); files.add(e://dummy.txt.2); files.add(e://dummy.txt.3); shamir.filecombine(files, minpieces); endtime = system.currenttimemillis(); system.out.println(decryption took + (endtime - starttime) / 1000.0 + seconds); return splitfiles; } /** * okay, this is a bit hacky. we want to take a piece of a file, encrypt/split it, and write the splits * to the given fileoutputstreams array. we want to treat the piece as an integer (treating it as string => large space overhead). * this is tricky because of two reasons: * 1. if all the bytes are zero, out piece will be zero, and we get an exception! it cannot be encrypted. * 2. if the piece has any zero bytes at start, they get lost in the encrypt/decrypt process. * 3. we cannot predict the length of the encrypted result. a 128 byte piece, when encrypted, can be 128, or 129 or whatever bytes. * * to fix this, we use prefixing and size byte. * we prefix each piece with a one byte - <phone>. this means our piece will never have zero bytes at start. takes care of 1 and 2. * and, when writing the encrypted data to files, we prefix each with one byte containing its size. * * then, when reading, here's what we do - we have n files. from each, we read the first byte. that will give us sizes n1,n2..nn. * from each file, we then read the corresponding number of bytes n1 bytes from 1.. nn bytes from n, and feed them to shamir decryptor. * finally, we convert the recovered number to byte array, and discard the first one - we inserted it ourselves. * * @param piece * @param numpieces * @param minpieces * @param files * @throws ioexception */ public static void encryptandwrite(byte[] piece, int numpieces, int minpieces, arraylist<fileoutputstream> files) throws ioexception {// printbytearray(piece); //prefixing a new 1 at the start of piece == add to 2^(no. of bytes*8). biginteger pieceasint = new biginteger(1, piece); biginteger toadd = (new biginteger(2)).pow(piece.length * 8); pieceasint = pieceasint.add(toadd); assert (pieceasint.tobytearray().length == piece.length + 1); arraylist<string> piecesplit = shamir.shamirsplit(pieceasint.tostring(), numpieces, minpieces, 1); //write to file. for (int i = 0; i < piecesplit.size(); i++) { string secret = piecesplit.get(i).split(=)[1].trim(); byte[] towrite = (new biginteger(secret)).tobytearray(); files.get(i).write((byte) towrite.length);// files.get(i).write(flag); files.get(i).write(towrite); } } public static void writebytestofiles(arraylist<string> shamiroutput, arraylist<fileoutputstream> files) throws ioexception { for (int i = 0; i < shamiroutput.size(); i++) { string partsecret = shamiroutput.get(i).split(=)[1].trim();// system.out.println(shamiroutput.get(i)); byte[] towrite = (new biginteger(partsecret)).tobytearray(); assert (towrite.length <= 255);// system.out.println(towrite.length); system.out.println(towrite.length); files.get(i).write((byte) (towrite.length)); files.get(i).write(towrite); } } public static void filecombine(arraylist<string> files, int k) throws ioexception { //create input streams, and part numbers (needed when decrypting) arraylist<fileinputstream> filestreams = new arraylist<>(files.size()); arraylist<integer> partnums = new arraylist<>(files.size()); for (int i = 0; i < files.size(); i++) { filestreams.add(i, new fileinputstream(files.get(i))); partnums.add(i, integer.parseint(files.get(i).substring(files.get(i).lastindexof(.) + 1, files.get(i).length()))); } arraylist<arraylist<biginteger>> filesasints = new arraylist<>(); for (int i = 0; i < filestreams.size(); i++) { arraylist<biginteger> temp = new arraylist<>(); long size = filestreams.get(i).getchannel().size(); for (int j = 0; j < size; ) { //need to bitmask because java stores integers as two's complement. //if we convert i>128 to a byte and back, we'll end up with negative value without this. int bytestoread = (int) (filestreams.get(i).read() & 0xff); j ++; byte[] intbytes = new byte[bytestoread]; filestreams.get(i).read(intbytes); biginteger biginteger = new biginteger(1, intbytes); j += bytestoread; temp.add(biginteger); } filesasints.add(i, temp); } arraylist<biginteger> decryptedints = new arraylist<>(filesasints.get(0).size()); for (int i = 0; i < filesasints.get(0).size(); i++) { arraylist<string> intsasstrings = new arraylist<>(); for (int j = 0; j < filesasints.size(); j++) { intsasstrings.add(filesasints.get(j).get(i).tostring()); } string decrypted = shamir.shamircombineint(intsasstrings, partnums, null, k); decryptedints.add(i,new biginteger(decrypted)); } fileoutputstream fileoutputstream = new fileoutputstream(files.get(0).substring(0, files.get(0).length() - 2)); for (int i = 0; i < decryptedints.size(); i++) { byte[] intbytes = decryptedints.get(i).tobytearray(); byte[] towrite = copyofrange(intbytes, 1, intbytes.length); fileoutputstream.write(towrite); } fileoutputstream.close(); system.out.println(file decrypted!); for(fileinputstream f : filestreams){ f.close(); } } }",
    "present_kp": [
      "java",
      "io"
    ],
    "absent_kp": [
      "performance",
      "cryptography"
    ]
  },
  {
    "text": "can i use publicly mentioned algorithms for writing programs?. i want to write a program that solves sudoku. so, i found some sudoku algorithms on wikipedia. can i use them or do i need to develop my own algorithm? also, do i need to ask the specific license holder's permission?.. if so, how would i go about obtaining that permission?",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "open source",
      "licensing"
    ]
  },
  {
    "text": "fail2ban is not blocking ips trying to access my server via ssh. i installed fail2ban with the default settings because there's a bunch of bots trying to log in as root to my server. i installed it but nothing has changed, i checked fail2ban jail ip list and there's nothing there.this is how my secure log looks like: may 19 09:11:25 localhost sshd[6080]: failed password for root from 43.255.188.160 port 52111 ssh2may 19 09:11:25 localhost unix_chkpwd[6083]: password check failed for user (root)may 19 09:11:25 localhost sshd[6080]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:28 localhost sshd[6080]: failed password for root from 43.255.188.160 port 52111 ssh2may 19 09:11:28 localhost unix_chkpwd[6084]: password check failed for user (root)may 19 09:11:28 localhost sshd[6080]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:29 localhost sshd[6080]: failed password for root from 43.255.188.160 port 52111 ssh2may 19 09:11:29 localhost sshd[6080]: received disconnect from 43.255.188.160: 11: [preauth]may 19 09:11:29 localhost sshd[6080]: pam 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:30 localhost unix_chkpwd[6087]: password check failed for user (root)may 19 09:11:30 localhost sshd[6085]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:30 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:31 localhost sshd[6085]: failed password for root from 43.255.188.160 port 39053 ssh2may 19 09:11:31 localhost unix_chkpwd[6088]: password check failed for user (root)may 19 09:11:31 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:33 localhost sshd[6085]: failed password for root from 43.255.188.160 port 39053 ssh2may 19 09:11:33 localhost unix_chkpwd[6089]: password check failed for user (root)may 19 09:11:33 localhost sshd[6085]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:36 localhost sshd[6085]: failed password for root from 43.255.188.160 port 39053 ssh2may 19 09:11:36 localhost sshd[6085]: received disconnect from 43.255.188.160: 11: [preauth]may 19 09:11:36 localhost sshd[6085]: pam 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:36 localhost unix_chkpwd[6093]: password check failed for user (root)may 19 09:11:36 localhost sshd[6091]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:36 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:38 localhost sshd[6091]: failed password for root from 43.255.188.160 port 53516 ssh2may 19 09:11:38 localhost unix_chkpwd[6094]: password check failed for user (root)may 19 09:11:38 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:40 localhost sshd[6091]: failed password for root from 43.255.188.160 port 53516 ssh2may 19 09:11:40 localhost unix_chkpwd[6095]: password check failed for user (root)may 19 09:11:40 localhost sshd[6091]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:42 localhost sshd[6091]: failed password for root from 43.255.188.160 port 53516 ssh2may 19 09:11:42 localhost sshd[6091]: received disconnect from 43.255.188.160: 11: [preauth]may 19 09:11:42 localhost sshd[6091]: pam 2 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:43 localhost unix_chkpwd[6098]: password check failed for user (root)may 19 09:11:43 localhost sshd[6096]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=43.255.188.160 user=rootmay 19 09:11:43 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:44 localhost sshd[6096]: failed password for root from 43.255.188.160 port 40323 ssh2may 19 09:11:44 localhost unix_chkpwd[6099]: password check failed for user (root)may 19 09:11:44 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rootmay 19 09:11:46 localhost sshd[6096]: failed password for root from 43.255.188.160 port 40323 ssh2may 19 09:11:46 localhost unix_chkpwd[6100]: password check failed for user (root)may 19 09:11:46 localhost sshd[6096]: pam_succeed_if(sshd:auth): requirement uid >= 1000 not met by user rooti enabled fail2ban, (here says that is already running) fail2ban-client starterror server already runningand the status since yesterday: fail2ban-client statusstatus|- number of jail: 0'- jail list:is there something that i'm not doing which is not enabling fail2ban?",
    "present_kp": [
      "ssh",
      "fail2ban"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i search only the displayed part of concealed text?. if i have syntax highlighting rules setup using conceal to hide or change certain characters in a file, how do i search what is displayed, as opposed to what the buffer actually contains?the concealed part may contain formatting markup, for example, which i wish to ignore.i'd like a method that:doesn't rely on the specific rules used to create the concealed text.provides some level of compatibility with the traditional search operators like n, *, etc.can this be done without re-implementing n, * and the like?related:how can i copy the displayed text, instead of the actual text?",
    "present_kp": [
      "search",
      "conceal"
    ],
    "absent_kp": []
  },
  {
    "text": "read-only file system error on samba share, alternative share with identical options working (linux client). i'm experiencing a very strange problem which i've been trying to solve in the past few days and i already tried various methods of resolution to which i will get to in a moment.my home network consists of a micro server (ubuntu linux server 17.04, kernel 4.10.0-26-generic on x86_64, cli only) and several windows and linux clients. my goal is to set up a samba share with read-only guest access and read-write access for myself (linux mint 18.1, kernel 4.4.0-81-generic).in my smb.conf, there are two identical shares, media and temp (the later is for bug fixing purposes):[media]comment = smb sharepath = /mediabrowsable = yesguest ok = yeswritable = nowrite list = ap[temp]comment = smb sharepath = /tempbrowsable = yesguest ok = yeswritable = nowrite list = ap/media and /temp both are set to chmod -r 775 and chown -r ap:ap.now the strange thing is that i can access both shares from my linux client as ap but i only have write access on [temp]. when i try to create a folder or delete a file on [media], i get a read-only file system error. i also don't have any problems writing when i log onto my server (as root user ap) using ssl.it might also be of interest that i'm mounting three different internal hard drives to /media/*. their fstab entries look like this:uuid=954d122e-ef13-4248-acb3-5c95fb44d2ad /media/misc ext4 defaults 0 0uuid=d213c725-a715-40f3-8278-de890fad1168 /media/cinema ext4 defaults 0 0uuid=6469b3d0-bdb5-4b0c-8559-b9d26f69b332 /media/series ext4 defaults 0 0the following possible solutions didn't work:setting chmod to 777, setting chown back to root:rootfscking all partitions, including the system partitionplaying around with my smb.conf (trying out options like valid users, read list, create mask)adding ap as a samba usertrying to mount the share with mount -t cifs -o username=ap //server /mntpoint (and trying out options like rw,uid,gid,domain,forceuid,forcegid)remounting my internal hard disks with the rw optioni guess that i could switch to nfs but i'm still wondering if i missed something very obvious or what further steps i could take to solve this problem.",
    "present_kp": [
      "ubuntu",
      "samba"
    ],
    "absent_kp": [
      "networking",
      "readonly"
    ]
  },
  {
    "text": "script for getting cpu utilization of particular cores. i am looking for a script for checking cpu utilization of particular cpu cores. we have 80 cores, we need get cpu utilization percentage for particular 4 cores.can you help us on this.thanks.",
    "present_kp": [
      "cpu"
    ],
    "absent_kp": [
      "linux",
      "shell script",
      "shell"
    ]
  },
  {
    "text": "what can be the consequences of using google webmaster tools for my youtube video downloader website?. will it be blocked/spam-listed if google detects that it provides youtube-video downloading ?",
    "present_kp": [
      "youtube"
    ],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "php not working (source file). i do not know why php is not working.i install nginx and php server { listen 80; server_name t.com t.com; location ~ \\.php$ { fastcgi_split_path_info ^(.+\\.php)(/.+)$; root /var/www/t.com/public_html/; index index.html index.htm; try_files $uri $uri/ =404; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }}and php.conf#s# php is an html-embedded scripting language which attempts to make it# easy for developers to write dynamically generated webpages.#<ifmodule prefork.c>loadmodule php5_module /usr/lib64/httpd/modules/libphp5.so</ifmodule><ifmodule worker.c> loadmodule php5_module modules/libphp5-zts.so</ifmodule>## cause the php interpreter to handle files with a .php extension.#addhandler php5-script .phpaddtype text/html .phpaddtype application/x-httpd-php .php## add index.php to the list of files that will be served as directory# indexes.#directoryindex index.php## uncomment the following line to allow php to pretty-print .phps# files as php source code:##addtype application/x-httpd-php-source .phps<filesmatch \\.php$> sethandler application/x-httpd-php</filesmatch>and when browser file , show download file",
    "present_kp": [
      "php"
    ],
    "absent_kp": []
  },
  {
    "text": "paper regarding the complexity of the longest path problem on weighted directed graphs of bounded treewidth. i would like to cite a paper/report/etc that solves the following problem polynomially in $n$:given a weighted directed graph $g=(v,e)$, $|v|=n$, of bounded treewidth $k \\in \\mathbb{n}$ and a source-destination pair $s,t\\in v$, find a longest path (not walk) from $s$ to $t$.the corresponding wikipedia article (<url>) implies that it is possible: the longest path problem is [...] fixed-parameter tractable when parameterized by the treewidth of the graphsadly, my knowledge of treewidth-techniques is rather small.i found the following paper, but it is on undirected (?unweighted?) graphs: confronting hardness using a hybrid approach: cites a paper of bodlaender (in section 2.2.1), where theorem 2.2 states that the longest path problem is solvable in $o(2^k k! n)$ (assuming a treewidth decomposition is given)is it easy to see that this technique also extends to directed weighted graphs? what happens when the weights are encoded in binary, i.e., they can be exponential in $n$?there is also a nice discussion here, but it also seems to rely on undirected (?unweighted?) graphs.thank you!",
    "present_kp": [
      "treewidth"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "graph algorithms",
      "fixed parameter tractable",
      "dynamic programming"
    ]
  },
  {
    "text": "what graphic languages are simpler than svg for database diagrams?. this is png was exported from inkscape. i created it manually and used theconnector tool to link tables.i find the plain svg for this diagram more complicated than i was expecting so would like to know if there are simpler graphic languages or specifications for this task?i would like to write something using python.here's the pastebin: svg for database diagram",
    "present_kp": [
      "diagram"
    ],
    "absent_kp": [
      "2d",
      "vector graphics"
    ]
  },
  {
    "text": "adding a script to google forms to identify incorrect phone numbers. i currently use google forms as a way for applicants to submit their forms. one of the fields that is required is for their contact information. in my country phone numbers have 11 digits.is there a script that i can use that will not accept a number if it does not contain 11 digits and display an error message, like incorrect number, please check and try again?the number format should be 09xxxxxxxxx.",
    "present_kp": [
      "google forms",
      "phone number"
    ],
    "absent_kp": [
      "google apps script"
    ]
  },
  {
    "text": "why does google docs still ask me for permission when people try to view my doc?. i created a doc that i want anyone with a link to see. here are the settings i used:i gave that link to people on my site.for some reason, every week, i get emails from google docs saying that people want to access my document and need my permission.this is what those emails look like.what can i do to keep people who i gave the link to from needing my permission?",
    "present_kp": [],
    "absent_kp": [
      "google drive",
      "google documents",
      "permissions"
    ]
  },
  {
    "text": "live usb version of kali linux grub issues. i have installed kali linux on a 32gb usb drive, and i have a 9gb partition for persistence. also, the macbook pro i am running kali on requires the amd gpu to be disabled, so i am using this guide to disable the amd gpu (step 3). i want to disable it permanently, but the /etc/default/grub file is missing. i reinstalled grub 2.0 and the grub config file was there although there was an error: error: failed to get canonical path of 'overlay'after editing it , i couldn't get the grub-update command to run. it says that there is no such command. and after rebooting, the file disappeared again.please help me with this issue. i appreciate your assistance greatly.",
    "present_kp": [
      "kali linux",
      "live usb"
    ],
    "absent_kp": [
      "grub2"
    ]
  },
  {
    "text": "github pages do not appear. i have added a gh-pages branch to a project on github, but the github pages are not appearing.what could be going wrong?",
    "present_kp": [
      "github"
    ],
    "absent_kp": []
  },
  {
    "text": "using a destructuring assignment on a style object to extract two members. recently, one of my colleague decided to destructure the react-native styles object this way:const { header, headerhint, bodycontainer, body, normaltext, buttonwrapper, button, footer, footerlinks } = styles;and then used the variables in the react code:<view style={header}> <text style={headerhint}hint</text> ...</view>this felt quite wrong to me as it doesn't provide much value to the code, destructuring an object to grab more than 5-6 variables makes the code more difficult to read in my opinion. also, keeping the styles in the styles object let you know your styles comes from the stylesheet. in some cases we might want to create variables to merge several styles, they become much easier to spot.he argues destructuring reduces areas that you need to change - if you need to change them like if the styles object changes to something else, you don't have to remove all the references to styles.i'm wondering what is your opinion on this point and if you follow any style guide about destructuring object like this one?",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "react.js",
      "react native"
    ]
  },
  {
    "text": "working with classes (inheriting), @ properties and initialization. i'm working on this objective c programming assignment i found online. i'm not sure if i have met all the requirements, especially part c. any help or suggestion will be appreciated.part 6a) implement class a with properties a1, a2, and a3 (int, string, int).b) new objects are automatically initialized to 1, hello, 1.c) also provide initializer to any data and constructor (called without alloc) to do the same.d) make sure %@ ob object of a will print all data.e) then implement b inheriting from a. b adds property b (string). f) make sure b works as a, that is new object is initialized to 1, hello, 1, and 3 (the new data). the rest also must work on b. //classa.h file#import <foundation/foundation.h>@interface classa : nsobject// part 6a@property int a1;@property nsstring *a2;@property int a3;-(nsstring *) description;-(id) initwitha1: (int) x anda2: (nsstring *) s anda3: (int) y;-(id) init;@end//classa.m file#import classa.h@implementation classa-(id) initwitha1:(int)x anda2:(nsstring *)s anda3:(int)y { self = [super init]; if (self) { self.a1 = x; self.a2 = s; self.a3 = y; } return self;}// part 6b- (id) init { return [self initwitha1:1 anda2:@hello anda3:1];}// part 6d-(nsstring *) description { return [nsstring stringwithformat:@classa a1 = %d , a2 = %@ , a3 = %d, self.a1, self.a2, self.a3];}@end//classb.h file#import classa.h@interface classb : classa@property int a1;@property nsstring *a2;@property int a3;@property nsstring * b;-(nsstring *) description;-(id) initwitha1:(int)x anda2:(nsstring *)s anda3:(int)y andb: (nsstring *) z;-(id) init;@end//classb.m file#import classb.h@implementation classb-(id) initwitha1:(int)x anda2:(nsstring *)s anda3:(int)y andb:(nsstring *)z { self = [super init]; if (self) { self.a1 = x; self.a2 = s; self.a3 = y; self.b = z; } return self;}-(id) init { return [self initwitha1:1 anda2:@hello anda3:1 andb:@3];}-(nsstring *) description { return [nsstring stringwithformat:@classb a1 = %d , a2 = %@ , a3 = %d , b = %@ , self.a1, self.a2, self.a3, self.b];}@end//viewcontroller.m file#import viewcontroller.h#import classa.h#import classb.h@interface viewcontroller ()@end@implementation viewcontroller- (void)viewdidload{ [super viewdidload]; classa * a = [classa new]; nslog(@%@, a); classb * j = [classb new]; nslog (@%@, j);}- (void)didreceivememorywarning{ [super didreceivememorywarning]; // dispose of any resources that can be recreated.}@end",
    "present_kp": [
      "classes",
      "objective c"
    ],
    "absent_kp": [
      "inheritance"
    ]
  },
  {
    "text": "how can i make a perl script parse blocks more intelligently?. i have a file ~/bigfile.txt that consists of thousands of blocks of text of the formblock number : <block>size : <size1> <size2>extra : <extranumber><block of text>for this example say$ cat ~/bigfile.txtblock number : 1size : 7 6extra : 0john paulgeorge ringoblock number : 2size : 7 3extra : -10i amthewalrusblock number : 3size : 4 3extra : -1024hello worldi am trying to write a script that separates each block into a separate file named <block>-block.txt, nested into subdirectories of ~/data/ indexed by <size1> and <size2>. for instance, running the script should result in $ tree ~/data/~/data/|- 4-size1 |- 3-size2 |- 3-block.txt|- 7-size1 |- 3-size2 |- 2-block.txt |- 6-size2 |- 1-block.txtcurrently i have a script that simply dumps each block to a separate file in ~/data/ but i can't figure out how to alter it. i can post my current script if that would help but i suspect that it's quite inefficient and not suited to tackle this sort of organizational task.i would appreciate any pointers on how to accomplish this task with perl.",
    "present_kp": [
      "perl"
    ],
    "absent_kp": []
  },
  {
    "text": "can the following huffman tree be extended to include more letters?. the following table shows a possible set of huffman codes to be used for lossless compression of a text consisting only of the eight letters shown:e t o h l p w z10 01 111 110 0001 0000 0011 0010the codes will have been chosen by using an algorithm that has as input the frequencies of occurrence of each of the letters in the particular text. the choice of codes can be presented as a huffman tree. the tree is shown below: () / \\ () () / \\ / \\ () t e () / \\ / \\ () () h o / \\ / \\p l z wa) could this tree be extended to include more letters? if not, why not?b) can you suggest a modification of the tree to include two more letters?",
    "present_kp": [],
    "absent_kp": [
      "huffman coding"
    ]
  },
  {
    "text": "unit testing of curl based rest client library. i ran into some issues with unit testing in that getting the response body etc from the curl handle was tricky. i didn't want to necessarily use a mock or abstract the curl functionality.a colleague of mine suggested that i just use the localhost as an endpoint and reflect back the request for unit testing. i thought this was a novel approach.the directories in question are /test/echo/ and /test/unit/i'm also interested in seeing if anyone had any opinions on the assertions.githubthe echo endpoint: <?phpheader('content-type: application/json');$data = array('headers' => getallheaders(),// 'server' => $_server,'request_method' => $_server['request_method'],'get' => $_get,'post' => $_post,'put' => $_post,);//if the request is a put then get the file contents and try to parse the string into an arrayif($data['request_method'] == 'put'){parse_str(file_get_contents(php://input), $put_data);$data['put'] = $put_data;}echo json_encode($data);an example of one of the unit tests:<?phpclass transactiontest extends phpunit_framework_testcase{static $endpoint = '<url> function setup(){$options = array('username' => 'pj-ql-01','password' => 'pj-ql-01p','appkey' => '2489d40d-a74f-474f-9e8e-7b39507f3101');parent::setup();$this->client = new transactionclient($options);$this->client->setendpoint(self::$endpoint);}private function getrequestpath($client = null){if(!isset($client)) $client = $this->client;return str_replace($client->baseurl,'',curl_getinfo($client->curl)['url']);}/*** ensure that the correct verb and path are used for the create method*/public function testcreate(){$data = array('achroutingnumber' => '987654321','achaccountnumber' => '123456789','achaccounttype' => 'checking','foo' => 'bar');$transaction = $this->client->create($data);$this->assertequals($data, get_object_vars($transaction->post),'passed variables are not correct');$this->assertequals('post', $transaction->request_method,'the php verb is incorrect');$this->assertequals('/transactions', $this->getrequestpath(), 'the path is incorrect');}/*** ensure that the correct verb and path are used for the read method*/public function testread(){$transaction = $this->client->read(543);$this->assertequals('get', $transaction->request_method,'the php verb is incorrect');$this->assertequals('/transactions/543', $this->getrequestpath(), 'the path is incorrect');}/*** ensure that the correct verb and path are used for the read method*/public function testupdate(){$data = array('foo' => 'baz');$transaction = $this->client->update(654,$data);$this->assertequals($data, get_object_vars($transaction->put),'passed variables are not correct');$this->assertequals('put', $transaction->request_method,'the php verb is incorrect');$this->assertequals('/transactions/654', $this->getrequestpath(), 'the path is incorrect');}/*** ensure that the correct verb and path are used for the read method*/public function testaddsignature(){$data = array('foo' => 'baa');$transaction = $this->client->addsignature(655,$data);$this->assertequals($data, get_object_vars($transaction->post),'passed variables are not correct');$this->assertequals('post', $transaction->request_method,'the php verb is incorrect');$this->assertequals('/transactions/655/signature/capture', $this->getrequestpath(), 'the path is incorrect');}}the base model from which the various clients extend from: <?phpclass payjunctionclient{public $liveendpoint = '<url>';public $testendpoint = '<url>';public $packageversion = '0.0.1';public $useragent;public function __construct(){$this->useragent = 'payjunctionphpclient/' . $this->packageversion . '(brandedcreate; php/)'; //@todo add process.version$this->baseurl = $this->testendpoint;}public function setendpoint($endpoint){$this->baseurl = $endpoint;}/*** @description initializes the curl handle with default configuration and settings* @param null $handle* @return $this*/public function initcurl($handle = null){$this->curl = curl_init();curl_setopt($this->curl, curlopt_ssl_verifypeer, false); //don't worry about validating ssl @todo talk about security concernscurl_setopt($this->curl, curlopt_returntransfer, true);//if we have a password and username then set it by default to be passed for authenticationif (isset($this->defaults['password']) && isset($this->defaults['username'])) {curl_setopt($this->curl, curlopt_httpauth, curlauth_any);curl_setopt($this->curl, curlopt_userpwd, $this->defaults['username'] . : . $this->defaults['password']);}//if we have default headers to pass then pass themif (isset($this->defaults['headers']) && is_array($this->defaults['headers'])) {$headers = array();foreach ($this->defaults['headers'] as $key => $value) {array_push($headers, $key . ': ' . $value);}curl_setopt($this->curl, curlopt_httpheader, $headers);}return $this;}/*** @description generates a new client* @param null $options* @return $this*/public function generateclient($options = null){$this->baseurl = isset($options['endpoint']) ? $options['endpoint'] : $this->baseurl;$this->defaults['username'] = isset($options['username']) ? $options['username'] : '';$this->defaults['password'] = isset($options['password']) ? $options['password'] : '';$this->defaults['headers']['x-pj-application-key'] = isset($options['appkey']) ? $options['appkey'] : '';$this->defaults['headers']['user-agent'] = $this->useragent;$this->initcurl();return $this;}/*** @description takes the response from our curl request and turns it into an object if necessary* @param $response* @param null $contenttype* @return array|mixed*/public function processresponse($response){$contenttype = curl_getinfo($this->curl, curlinfo_content_type);if ($contenttype == 'text/html' || is_null($contenttype) || !isset($contenttype) || $contenttype = '' || $contenttype == false) {return $response;}try {$object = json_decode($response);return $object;} catch (exception $e) {return array('errors' => array(0 => 'invalid response type, error in processing response from payjunction'));}}/*** @description processes a curl post request* @param $path* @param null $params* @return array|mixed*/public function post($path, $params = null){curl_setopt($this->curl, curlopt_post, true);curl_setopt($this->curl, curlopt_url, $this->baseurl . $path);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, curlopt_postfields, http_build_query($params));}return $this->processresponse(curl_exec($this->curl));}/*** @description processes a curl get request* @param $path* @param null $params* @return array|mixed*/public function get($path, $params = null){//create the query string if there are any parameters that need to be passed$query_string = ;if (!is_null($params)) {$query_string = ? . http_build_query($params,'','&');}curl_setopt($this->curl, curlopt_httpget, true);curl_setopt($this->curl, curlopt_url, $this->baseurl . $path . $query_string);return $this->processresponse(curl_exec($this->curl));}/*** @description processes a curl put request* @param $path* @param null $params* @return array|mixed*/public function put($path, $params = null){curl_setopt($this->curl, curlopt_customrequest, put);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, curlopt_postfields, http_build_query($params));}curl_setopt($this->curl, curlopt_url, $this->baseurl . $path);return $this->processresponse(curl_exec($this->curl));}/*** @description processes a curl delete request* @param $path* @param null $params* @return array|mixed*/public function del($path, $params = null){curl_setopt($this->curl, curlopt_customrequest, delete);if (is_object($params) || is_array($params)) {curl_setopt($this->curl, curlopt_postfields, http_build_query($params));}curl_setopt($this->curl, curlopt_url, $this->baseurl . $path);return $this->processresponse(curl_exec($this->curl));}}the transactionclient related specifically to this unit test:<?phpclass transactionclient extends payjunctionclient{public function __construct($options){parent::__construct();$this->generateclient($options);}/*** @description create a new transaction* @param $params* @return array|mixed*/public function create($params){return $this->post('/transactions',$params);}/*** @description read from an existing transaction* @param $id* @return array|mixed*/public function read($id){return $this->get('/transactions/'.$id);}/*** @description update an existing transaction* @param $id* @param null $params* @return array|mixed*/public function update($id, $params = null){return $this->put('/transactions/'.$id, $params);}/*** @todo this does not appear to be working 405 method not allowed* @description add a signature to an existing transaction* @param $id* @param $params* @return array|mixed*/public function addsignature($id, $params){return $this->post('/transactions/'.$id.'/signature/capture',$params);}}",
    "present_kp": [
      "php",
      "unit testing",
      "phpunit"
    ],
    "absent_kp": []
  },
  {
    "text": "burning a directory structure from a stdin pipe. i'm trying to do something tricky, i want to burn a directory structure onto a cd from a pipe stream. the reason is that it is coming from the network and i don't want it written on the hard drive of the cd-burning machine. i am unsure of how (or if possible) to pipe the output of tar (for example) into genisoimage or mkisofs. i noticed a stream option in genisoimage, but when i tried doing tar -cvf - /home/myuser | genisoimage --stream-media-size 200 -o test.isoi only got a test.iso which contained a stream.img (as specified in genisoimage(1)) which itself was the original tar-archive. this will not do, it needs to be a directory structure on the cd. i know that cdrskin (cli tool for burning) can take data from stdin and burn it. so how can i pipe data into genisoimage, have it create a directory structure of that data for the iso and then have it pipe that data back out to cdrskin to burn? i know also that genisoimage pipes the iso data to stdout by default so my only issue appears to be getting a stream of a directory structure piped into genisoimage and having that directory structure maintained in the iso data. the tags on this post are terrible because i couldn't find genisoimage, cdrskin, not even stdin. edit: this is not about data security, it's about lack of disk space. i don't care if the data is buffered on the hdd but i can't write the full iso. and of course genisoimage is just a suggestion, i'm open to any other method of creating the iso data. for your information it's intended for blu ray discs.",
    "present_kp": [
      "pipe"
    ],
    "absent_kp": [
      "debian"
    ]
  },
  {
    "text": "should we use an outside cms?. i work at a web design/development shop. everything we do is centered around the joomla! cms. i'm a bit worried-if anything goes wrong with joomla (major security flaw revealed, joomla folds and ceases development) we're sunk. i'm meeting with the ceo to plan the next few steps for our company. should i recommend that we create our own in-house cms or am i just being paranoid about a single point of failure?",
    "present_kp": [
      "cms",
      "joomla"
    ],
    "absent_kp": []
  },
  {
    "text": "auto labeling algorithm. i have a set of points (2d space), and for every point there's a label (like city names on a map).i want to find a real-time algorithm that allows labels to avoid overlapping, moving them from their original position if necessary.i've heard about simulated annealing algorithm, but i can't find a good source to learn how to do this. do you have some idea where i can find bibliography and practical examples?thanks in advance for your replies.",
    "present_kp": [],
    "absent_kp": [
      "computational geometry"
    ]
  },
  {
    "text": "on the notion of positive rank of a matrix. the positive rank of a square matrix is defined in theorem $3$ of expressing combinatorial optimization problems by linear programs by mihalis yannakakis as follows: given a $n imes n$ matrix $a$, the positive rank $rank_{\\bbb r}^+(a)$ is the smallest $m$ such that $a=lr$ for a non-negative $n imes m$ matrix $l$, and non-negative $m imes n$ matrix $r$.this concept is valuable in communication complexity, since it was shown that if $rank_{\\bbb r}^+(a)$ and $rank_{\\bbb r}(a)$ could be subexponentially related for a $0/1$ matrix $a$, then the log-rank conjecture holds.is there an exponential separation between $rank_{\\bbb r}^+(a)$ and $rank_{\\bbb r}(a)$ for a general non-negative real matrix $a$ (as opposed to just $0/1$) or is this problem also open?i checked the references in jukna's book, but i am still unable to clarify the above question.",
    "present_kp": [
      "communication complexity"
    ],
    "absent_kp": [
      "definitions"
    ]
  },
  {
    "text": "how to delete the filesytem on a raid device?. how do i delete the filesystem on a raid device?sudo blkid /dev/md1/dev/md1: uuid=9a27b794-12d7-4794-9764-dda623f12e58 type=ext4",
    "present_kp": [],
    "absent_kp": [
      "filesystems",
      "software raid"
    ]
  },
  {
    "text": "powershell to quickly ping a number of machines. i came up with the below code to improve the peformance of pinging a large number of machines.at present it's fairly basic, but thought i should see what people thought before proceeding further.nb: this is my first time playing with workflows, so i've probably committed a few faux-pas there.clsworkflow test-connectionquickly { [cmdletbinding()] param( [parameter(mandatory = $true)] [string[]]$computers ) $computergroups = inlinescript { #group computers to throttle the number of threads [psobject]$itemcounter = [pscustomobject]@{itemno=0;groupsize=10} #alter groupsize per your preference $itemcounter | add-member -membertype scriptmethod -name 'groupno' -value { [math]::floor($this.itemno++ / $this.groupsize) } write-output $using:computers | group-object -property {$itemcounter.groupno()} } foreach -parallel ($computergroup in $computergroups) { $computergroup | select -expandproperty group | %{ $pingable = (test-connection $_ -count 2 -quiet -erroraction silentlycontinue) write-output (new-object -type psobject -property @{name=$_;online=$pingable}) } } }[string[]]$computers = (1..100 | %{(server{0:000} -f $_)}) #here's where we'd read in the computere from filetest-connectionquickly $computers | select name, online #here's where we'd pipe the output to filedesign notes:the inlinescript is used to group servers into small sets (of 10; an arbitrary size) in the hope of balancing serial's performance for small sets against parallel's performance for large sets of computers.the $itemcounter variable's an attempt at making grouping into defined set sizes simpler to read-count 2 is specified on the test-connection so that we have some tolerence for network glitches without too much affect on performance.-quiet is specified because we don't need output / and not having output will help performance.",
    "present_kp": [
      "powershell"
    ],
    "absent_kp": [
      "networking",
      "status monitoring"
    ]
  },
  {
    "text": "how to compile with third party libs properly?. this is a follow up question to confusion about linking boost library while compilation:what is to do, when i generate a makefile by qmake and i have only a third party boost lib installed (i uninstalled all boost libs from dependency management, because it always links to the boost lib from dependency management what i don't want) and i want it to compile only against this manually installed library as well as run against it.these are the important parts of a makefile generated by qmake:cc = gcccxx = g++defines = -dqt_gui -dboost_thread_use_lib -dboost_spirit_threadsafe -dboost_thread_provides_generic_shared_mutex_on_win -d__no_system_includes -duse_upnp=1 -dstaticlib -duse_qrcode -duse_dbus -dhave_build_info -dlinux -dqt_no_debug -dqt_dbus_lib -dqt_gui_lib -dqt_core_lib -dqt_sharedcflags = -m64 -pipe -o2 -wall -w -d_reentrant $(defines)cxxflags = -m64 -pipe -fstack-protector -o2 -fdiagnostics-show-option -wall -wextra -wformat -wformat-security -wno-unused-parameter -d_reentrant $(defines)incpath = -i/usr/share/qt4/mkspecs/linux-g++-64 -i/usr/include/qt4/qtcore -i/usr/include/qt4/qtgui -i/usr/include/qt4/qtdbus -i/usr/include/qt4 -isrc -isrc/json -isrc/qt -ic:/deps/ -ic:/deps/boost -ic:/deps/db/build_unix -ic:/deps/ssl/include -ic:/deps/libqrencode/ -ibuild -ibuildlink = g++lflags = -m64 -fstack-protector -wl,-o1libs = $(sublibs) -l/usr/lib/x86_64-linux-gnu -lc:/deps/miniupnpc -lminiupnpc -lqrencode -lrt -lc:/deps/boost/stage/lib -lc:/deps/db/build_unix -lc:/deps/ssl -lc:/deps/libqrencode/.libs -lssl -lcrypto -ldb_cxx -lboost_system-mgw46-mt-sd-1_54 -lboost_filesystem-mgw46-mt-sd-1_54 -lboost_program_options-mgw46-mt-sd-1_54 -lboost_thread-mgw46-mt-sd-1_54 -lqtdbus -lqtgui -lqtcore -lpthread this is the path to boost:/usr/local/lib/boost1.55/lib# ls -1libboost_atomic.alibboost_atomic.solibboost_atomic.so.1.55.0libboost_chrono.alibboost_chrono.solibboost_chrono.so.1.55.0libboost_context.alibboost_context.solibboost_context.so.1.55.0libboost_coroutine.alibboost_coroutine.solibboost_coroutine.so.1.55.0libboost_date_time.alibboost_date_time.solibboost_date_time.so.1.55.0libboost_exception.alibboost_filesystem.alibboost_filesystem.solibboost_filesystem.so.1.55.0libboost_graph.alibboost_graph.solibboost_graph.so.1.55.0libboost_locale.alibboost_locale.solibboost_locale.so.1.55.0libboost_log.alibboost_log_setup.alibboost_log_setup.solibboost_log_setup.so.1.55.0libboost_log.solibboost_log.so.1.55.0libboost_math_c99.alibboost_math_c99f.alibboost_math_c99f.solibboost_math_c99f.so.1.55.0libboost_math_c99l.alibboost_math_c99l.solibboost_math_c99l.so.1.55.0libboost_math_c99.solibboost_math_c99.so.1.55.0libboost_math_tr1.alibboost_math_tr1f.alibboost_math_tr1f.solibboost_math_tr1f.so.1.55.0libboost_math_tr1l.alibboost_math_tr1l.solibboost_math_tr1l.so.1.55.0libboost_math_tr1.solibboost_math_tr1.so.1.55.0libboost_prg_exec_monitor.alibboost_prg_exec_monitor.solibboost_prg_exec_monitor.so.1.55.0libboost_program_options.alibboost_program_options.solibboost_program_options.so.1.55.0libboost_random.alibboost_random.solibboost_random.so.1.55.0libboost_regex.alibboost_regex.solibboost_regex.so.1.55.0libboost_serialization.alibboost_serialization.solibboost_serialization.so.1.55.0libboost_signals.alibboost_signals.solibboost_signals.so.1.55.0libboost_system.alibboost_system.solibboost_system.so.1.55.0libboost_test_exec_monitor.alibboost_thread.alibboost_thread.solibboost_thread.so.1.55.0libboost_timer.alibboost_timer.solibboost_timer.so.1.55.0libboost_unit_test_framework.alibboost_unit_test_framework.solibboost_unit_test_framework.so.1.55.0libboost_wave.alibboost_wave.solibboost_wave.so.1.55.0libboost_wserialization.alibboost_wserialization.solibboost_wserialization.so.1.55.0this is the output of ldconfig -v concerning boost:# ldconfig -v/sbin/ldconfig.real: path '/lib/x86_64-linux-gnu' given more than once/sbin/ldconfig.real: path '/usr/lib/x86_64-linux-gnu' given more than once/usr/local/lib/boost1.55/lib: libboost_wave.so.1.55.0 -> libboost_wave.so.1.55.0 libboost_thread.so.1.55.0 -> libboost_thread.so.1.55.0 libboost_system.so.1.55.0 -> libboost_system.so.1.55.0 libboost_prg_exec_monitor.so.1.55.0 -> libboost_prg_exec_monitor.so.1.55.0 libboost_context.so.1.55.0 -> libboost_context.so.1.55.0 libboost_atomic.so.1.55.0 -> libboost_atomic.so.1.55.0 libboost_filesystem.so.1.55.0 -> libboost_filesystem.so.1.55.0 libboost_math_c99l.so.1.55.0 -> libboost_math_c99l.so.1.55.0 libboost_math_c99.so.1.55.0 -> libboost_math_c99.so.1.55.0 libboost_timer.so.1.55.0 -> libboost_timer.so.1.55.0 libboost_wserialization.so.1.55.0 -> libboost_wserialization.so.1.55.0 libboost_math_c99f.so.1.55.0 -> libboost_math_c99f.so.1.55.0 libboost_coroutine.so.1.55.0 -> libboost_coroutine.so.1.55.0 libboost_signals.so.1.55.0 -> libboost_signals.so.1.55.0 libboost_random.so.1.55.0 -> libboost_random.so.1.55.0 libboost_chrono.so.1.55.0 -> libboost_chrono.so.1.55.0 libboost_program_options.so.1.55.0 -> libboost_program_options.so.1.55.0 libboost_date_time.so.1.55.0 -> libboost_date_time.so.1.55.0 libboost_locale.so.1.55.0 -> libboost_locale.so.1.55.0 libboost_log.so.1.55.0 -> libboost_log.so.1.55.0 libboost_log_setup.so.1.55.0 -> libboost_log_setup.so.1.55.0 libboost_serialization.so.1.55.0 -> libboost_serialization.so.1.55.0 libboost_math_tr1f.so.1.55.0 -> libboost_math_tr1f.so.1.55.0 libboost_unit_test_framework.so.1.55.0 -> libboost_unit_test_framework.so.1.55.0 libboost_math_tr1l.so.1.55.0 -> libboost_math_tr1l.so.1.55.0 libboost_graph.so.1.55.0 -> libboost_graph.so.1.55.0 libboost_math_tr1.so.1.55.0 -> libboost_math_tr1.so.1.55.0 libboost_regex.so.1.55.0 -> libboost_regex.so.1.55.0what do i have exactly to do to compile and run the code properly? i tried combinations of:-l/usr/local/lib/boost1.55/lib/boost_thread-mgw46-mt-sd-1_54-l/usr/local/lib/boost1.55/lib/boost_thread-i/usr/local/lib/boost1.55/-i/usr/local/lib/boost1.55/lib/-lboost_system-mgw46-mt-sd-1_54-lboost_system-mgw46-mt-sd-1_55-lboost_systemall this never works when there is no boost installed by package manager, but i don't want it to use it from package manager. that means it doesn't compile. sometimes i get something like:/usr/bin/ld: cannot find -lboost_system-mgw46-mt-sd-1_54or /usr/bin/ld: cannot find -lboost_systemor addrman.cpp:(.text.startup+0x23): undefined reference to 'boost::system::generic_category()'...and so on.i don't get it. what's wrong here?[update]it turns out that there seems to be something wrong with boost lib itself.after modifying the important parts of the makefile to:libs = $(sublibs) -l/usr/lib/x86_64-linux-gnu -lminiupnpc -lqrencode -lrt -lssl -lcrypto -ldb_cxx -l/usr/local/lib/boost1.55/ -l/usr/local/lib/boost1.55/include/ -l/usr/local/lib/boost1.55/lib/ -lboost_system -lboost_filesystem -lboost_program_options -lpthread -lboost_thread -lqtdbus -lqtgui -lqtcoremake produced another error:build/json_spirit_reader.o: in function 'void boost::call_once<void (*)()>(boost::once_flag&, void (*)())':json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x14): undefined reference to 'boost::detail::get_once_per_thread_epoch()'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x2c): undefined reference to 'boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x35): undefined reference to 'boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x72): undefined reference to 'boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x77): undefined reference to 'boost::detail::once_epoch_cv'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0xa8): undefined reference to 'boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0xb0): undefined reference to 'boost::detail::once_epoch_mutex'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0xd9): undefined reference to 'boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0xde): undefined reference to 'boost::detail::once_epoch_cv'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0xe9): undefined reference to 'boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x128): undefined reference to 'boost::detail::once_global_epoch'json_spirit_reader.cpp:(.text._zn5boost9call_onceipfvveeevrns_9once_flaget_[_zn5boost9call_onceipfvveeevrns_9once_flaget_]+0x19b): undefined reference to 'boost::detail::once_epoch_cv'collect2: error: ld returned 1 exit statusit seems that there is no such function (in this boost version?):$ objdump -t /usr/local/lib/boost1.55/lib/libboost_thread.so|c++filt|grep once_epochprints nothing as well as $ for i in /usr/local/lib/boost1.55/lib/libboost_*.so ; do if grep once_epoch_mutex <(objdump -t $i|c++filt) ; then echo $i ; fi ; donedoes not.[update 2]after adding -i/usr/local/lib/boost1.55/include/ -i/usr/local/lib/boost1.55/include/boost/to incpath and recompile the whole application within a fresh workspace, the error is different but now, i don't see any error message:/usr/local/lib/boost1.55/include/boost/bind/arg.hpp: in constructor boost::arg<i>::arg(const t&):/usr/local/lib/boost1.55/include/boost/bind/arg.hpp:37:22: warning: typedef t_must_be_placeholder locally defined but not used [-wunused-local-typedefs] typedef char t_must_be_placeholder[ i == is_placeholder<t>::value? 1: -1 ]; ^in file included from /usr/local/lib/boost1.55/include/boost/tuple/tuple.hpp:33:0, from /usr/local/lib/boost1.55/include/boost/thread/detail/async_func.hpp:37, from /usr/local/lib/boost1.55/include/boost/thread/future.hpp:22, from /usr/local/lib/boost1.55/include/boost/thread.hpp:24, from src/util.h:22, from src/bignum.h:13, from src/main.h:9, from src/wallet.h:9, from src/wallet.cpp:7:/usr/local/lib/boost1.55/include/boost/tuple/detail/tuple_basic.hpp: in function typename boost::tuples::access_traits<typename boost::tuples::element<n, boost::tuples::cons<ht, tt> >::type>::const_type boost::tuples::get(const boost::tuples::cons<ht, tt>&):/usr/local/lib/boost1.55/include/boost/tuple/detail/tuple_basic.hpp:228:45: warning: typedef cons_element locally defined but not used [-wunused-local-typedefs] typedef boost_deduced_typename impl::type cons_element; ^src/wallet.cpp: in member function bool cwallet::addtowallet(const cwallettx&):src/wallet.cpp:402:13: error: replace_all is not a member of boost boost::replace_all(strcmd, %s, wtxin.gethash().gethex()); ^in file included from /usr/local/lib/boost1.55/include/boost/system/system_error.hpp:14:0, from /usr/local/lib/boost1.55/include/boost/thread/exceptions.hpp:22, from /usr/local/lib/boost1.55/include/boost/thread/pthread/thread_data.hpp:10, from /usr/local/lib/boost1.55/include/boost/thread/thread_only.hpp:17, from /usr/local/lib/boost1.55/include/boost/thread/thread.hpp:12, from /usr/local/lib/boost1.55/include/boost/thread.hpp:13, from src/util.h:22, from src/bignum.h:13, from src/main.h:9, from src/wallet.h:9, from src/wallet.cpp:7:/usr/local/lib/boost1.55/include/boost/system/error_code.hpp: at global scope:/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:222:36: warning: boost::system::posix_category defined but not used [-wunused-variable] static const error_category & posix_category = generic_category(); ^/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:223:36: warning: boost::system::errno_ecat defined but not used [-wunused-variable] static const error_category & errno_ecat = generic_category(); ^/usr/local/lib/boost1.55/include/boost/system/error_code.hpp:224:36: warning: boost::system::native_ecat defined but not used [-wunused-variable] static const error_category & native_ecat = system_category(); ^make: *** [build/wallet.o] error 1",
    "present_kp": [
      "boost"
    ],
    "absent_kp": [
      "compiling",
      "libraries"
    ]
  },
  {
    "text": "locate a number in an array with ascending even and descending odd entries. below are two examples of arrays i have, with some given length:for some value z, i want to find the column the value is in. matlab code i wrote:if z == 1 column = ceil(length/2); elseif logical(mod(z,2)) column = length - (z-3)/2;else column = z/2;endit is correct i think. but ugly and possibly slow. is there a one-liner in matlab that can do this?",
    "present_kp": [
      "matlab"
    ],
    "absent_kp": []
  },
  {
    "text": "plan variable and call dependencies. i'd like to write down the design of my program to understand the dependencies and calls better. i know there are class diagrams which show inheritance and attribute variables. however i'd also like to document the input parameters to method functions and in particular which calls the methods function executes inside (e.g. on the input parameters).also sometimes it might be useful to show how actual objects are connected (if there is a standard structure).this way i can have a better understanding of the modules and design before starting to program. can you suggest a method to do this software design? it should be one-to-one to programming code structure so that i really notice all quirks beforehand (instead of high-level design where thing are hard to implement without further work).maybe some special diagram or tool or a combination?it is static dependency and call design rather than time dependent execution monitoring.(i use python if you have any specialized recommendations).",
    "present_kp": [
      "design"
    ],
    "absent_kp": [
      "uml"
    ]
  },
  {
    "text": "numerical euler rotation equation. the problem i have may be really simple, but still getting a hard time solving it. so i have the euler rotation equations:$$i_{1}\\dot{\\omega}_{1}+\\left(i_{3}-i_{2} ight)\\omega_{2}\\omega_{3}=\\lambda_{1}$$$$i_{2}\\dot{\\omega}_{2}+\\left(i_{1}-i_{3} ight)\\omega_{3}\\omega_{1}=\\lambda_{2}$$$$i_{3}\\dot{\\omega}_{3}+\\left(i_{2}-i_{1} ight)\\omega_{1}\\omega_{2}=\\lambda_{3}$$where the $i_{i}$ are the moments of inertia about the principal axes of rotation and $\\omega_{i}$ the time dependent angular velocities about each axis. in general $i_{i} eq i_{j}, i eq j$, or don't satisfy any situations in which they can be reduced to easier relations. $\\lambda_{i}$ is a normal distributed random number.i know that these equations are non-linear and, in general, have no analytic solution. the question is:$\\qquad$ is there a good numerical integrator for these equations?i'm using c++ and have looked into the lapack package, but i'm kind of confused on how to use it.i know the reference from skowron and gould (arxiv:<phone> [astro-ph.ep]); however i really don't know how to implement this algorithm.if somebody could help me in finding an open source integrator or a reference where they talk about the implementation of this code, it would be great.",
    "present_kp": [],
    "absent_kp": [
      "computational physics",
      "software"
    ]
  },
  {
    "text": "lu factorization of a 0-1 matrix. i have a rather naive question on lu factorization which probably should be easy to answer. say i have a matrix with entries only from $\\{0,1\\}$. when can we expect to get an lu factorization of such a matrix(whenever it exists) with entries $(a)$ from integers? $(b)$ from $\\{-1,0,+1\\}$?",
    "present_kp": [],
    "absent_kp": [
      "linear algebra",
      "matrices",
      "na.numerical analysis"
    ]
  },
  {
    "text": "why can't subjective utilities take probabilities into account?. if my understanding of expected utility theory is correct, it is rational for a decision maker to have subjective utilities for objective consequences. for example, it can be rational for a decision maker to value 5 dollars twice as much as 4 dollarshowever, it is not rational for a decision maker to value a 100% chance of 5 dollars twice as much as an 80% chance of 5 dollarsthat is, probabilities must be outside of- not taken into account by- subjective utilities. is this understanding correct, and if so, why is the theory structured this way? note: my understanding is based on hastie & dawes (2010), rational choice in an uncertain world.",
    "present_kp": [],
    "absent_kp": [
      "decision making",
      "economics",
      "rationality",
      "behavioral economics"
    ]
  },
  {
    "text": "sed into csv format. i have a file of the formvl-<phone>,30.000,49.000,1.000,21.901,2630.000,428861.000vl-<phone>,1071.000,570.000,35.000,3963.608,632.000,366563.000vl-<phone>,36.000,867.000,24.000,6523.005,3544.000,176054.000vl-<phone>,5:281185.000vl-<phone>,44.000,372.000,67.000,7029.358,293.000,446448.000vl-<phone>,5:48479.000vl-<phone>,0:2.000,2:7.000,3:80.222,4:1153.000it is supposed to be of the formvl-<phone>,1190.000,609.000,28.000,12676.158,1819.000,452813.000but when there are zeros in the file it only shows the column numbers that are nonzero such asvl-<phone>,0:2.000,2:7.000,3:80.222,4:1153.000i would like to write a sed command that makes a 7 length row with zeros included such as vl-<phone>,2.000,0,7.000,80.222,1153.000,0any ideas?",
    "present_kp": [
      "sed"
    ],
    "absent_kp": []
  },
  {
    "text": "open / closed principle. i found this code example explaining open / closed principle.code before application of principle:public class logger{ public void log(string message, logtype logtype) { switch (logtype) { case logtype.console: console.writeline(message); break; case logtype.file: // code to send message to printer break; } }}public enum logtype{ console, file}and refactored code:public class logger{ imessagelogger _messagelogger; public logger(imessagelogger messagelogger) { _messagelogger = messagelogger; } public void log(string message) { _messagelogger.log(message); }}public interface imessagelogger{ void log(string message);} public class consolelogger : imessagelogger{ public void log(string message) { console.writeline(message); }}public class printerlogger : imessagelogger{ public void log(string message) { // code to send message to printer }}can you explain me the reason to still keep logger class with private imessagelogger instance? i would simply avoid it by:public interface ilogger{ public void log(string message);}public class consolelogger : ilogger{ public void log(string message) { console.writeline(message); }} public class printerlogger : ilogger{ public void log(string message) { // code to send message to printer }}the only reason i can think about is, that in suggested solution with logger class, we could still refer to this class in client code, but we still need to modify all log(msg) calls to remove logtype arguments.",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "interfaces",
      "solid",
      "open close"
    ]
  },
  {
    "text": "project euler #48 in c++. this question is similar to project euler #48 but constraints are different:$$n < <phone>$$just in case the link is unavailable, here is the problem statement:we've to print $$\\left( \\sum_{i=1}^n i^i ight) \\mod 10^{10}$$i've tried the following, but i need something faster than that, because the execution time limit is 2s, and this program can only compute values until \\$ n=30000\\$ (approx) in the given time limit.#include <iostream>using namespace std;#define mod 10000000000int main() { int n; cin>>n; long long temp,sum=0; for( int ii=1 ; ii<=n ; ii++ ) { if(ii%10==0) { continue; } temp=1; for( int jj=1 ; jj<=ii ; jj++ ) { temp*=ii; temp=temp%mod; } sum+=temp; sum=sum%mod; } cout<<sum; return 0;}i've added if(n%10==0){ continue;}because numbers of form $$ (k*10)^{k*10}=k^{k*10}*10^{k*10}=k^{k*10}*10^{k}*10^{10} $$ are not at all going to contribute to the answer.note: code is compiled using g++ 4.8.2, c++11 mode",
    "present_kp": [
      "c++",
      "c++11"
    ],
    "absent_kp": [
      "optimization",
      "programming challenge",
      "time limit exceeded"
    ]
  },
  {
    "text": "list all files that end in ball using ls command. i am trying to use ls command to find specific files thathave 4 letters in front of the word ballmust have the ending word balli have been trying to use ls *ball but this shows words with 4 or more words in front of the word ball. is there a specific command that ignores the word that has 4 or more letters before ball?",
    "present_kp": [
      "ls"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "what does chromium net::err_cert_common_name_invalid mean?. i'm trying to figure out why chromium is not happy with a tls certificate, and how to fix it:after upgrading & restarting chromium (now 58.0.3029.81, running on debian testing), i can no longer access our internal gitlab server (installed on debian jessie, via the omnibus package). i get:your connection is not privateattackers might be trying to steal your information from git.ourdomain.net (for example, passwords, messages, or credit cards). net::err_cert_common_name_invalidthe certificate is signed with our internal ca, which is installed in the system store (by putting it in /usr/local/share/ca-certificates). i checked the site with both firefox 52 and openssl s_client -verify 5 -verify_return_error -connect git.ourdomain.net:443; both are happy. openssl shows the chain as:certificate chain 0 s:/c=us/st=virginia/l=sterling/o=us/ou=servers/cn=git.ourdomain.net i:/c=us/st=virginia/l=sterling/o=us/cn=us certification authority/emailaddress=<email> openssl and firefox show strong signing (sha-512) and ciphers (aes-gcm). the certificate (according to openssl x509 -text) is sha512withrsaencryption, with a 4096-bit rsa key. it has a netscape cert type of ssl client, ssl server.note: us and ourdomain.net are redactions; the actual output has our company name for us and our actual domain for ourdomain.net. i carefully checked that all the ourdomain.net actually match.as far as i can tell, there is nothing wrong with the certificate, and the common name (git.ourdomain.net) is perfectly valid and matches the urlso what is chromium complaining about? and, presuming it's not a real issue, is there some way to override it?",
    "present_kp": [
      "ssl"
    ],
    "absent_kp": [
      "chrome",
      "https"
    ]
  },
  {
    "text": "algorithm to project onto line segments. i have the following problem: a large number $n$ of (finite length) line segments in the plane (if it helps, we can assume non-intersecting except at end points, and forming a graph with a small number of components); and a smaller number $n$ of points. for each point, i wish to find the closest line segment.given one line segment, this is easy: orthogonally project onto the line, and if this doesn't fall on the line segment, choose the appropriate end point. this gives a naive $o(nn)$ algorithm.i am wondering if there is a clever data structure which, with some pre-processing on the lines, would give a faster algorithm?",
    "present_kp": [],
    "absent_kp": [
      "computational geometry"
    ]
  },
  {
    "text": "invoking shader in dx. so i am new to the dx12 world. i am currently trying to tweek the nbody_gravity dx12 sample, but appending or calling another compute shader which is to add 2 buffers to produce an output in a different buffer.i have written this code in computeshader.hlsl however when i tried to invoke it using the following, i get an error sayin file not foundwhen i printed the debug error it says the following: d3d12getdebuginterface: this method requires the d3d12 sdk layers for windows 10, but they are not present on the system.i am invoking my shader after the default invocation to the nbodygravity.hlsl is done:comptr<id3dblob> computeshader;comptr<id3dblob> computeshader_m;#if defined(_debug) // enable better shader debugging with the graphics debugging tools. uint compileflags = d3dcompile_debug | d3dcompile_skip_optimization;#else uint compileflags = 0;#endif throwiffailed(d3dcompilefromfile(getassetfullpath(lnbodygravitycs.hlsl).c_str(), nullptr, nullptr, csmain, cs_5_0, compileflags, 0, &computeshader, nullptr));//extra call for my shadercomptr<id3dblob> error_ptr; throwiffailed(d3dcompilefromfile(getassetfullpath(lcomputeshader.hlsl).c_str(), nullptr, nullptr, main, cs_5_0, compileflags, 0, &computeshader_m, &error_ptr));if (error_ptr){ outputdebugstringa((char *)error_ptr->getbufferpointer());}is there somthing amiss?",
    "present_kp": [],
    "absent_kp": [
      "directx"
    ]
  },
  {
    "text": "how to find release date of any .rpm before installing it. is there any way to get the release date (via command line) of an rpm without downloading or installing it?i can get detailed information via the command below but can't find the release date of that particular rpm:[root@connect ~]# yum info kernel-2.6.32-642.6.2.el6.x86_64loaded plugins: fastestmirrorloading mirror speeds from cached hostfile * base: centos.excellmedia.net * epel: ftp.jaist.ac.jp * extras: centos.excellmedia.net * updates: centos.excellmedia.netavailable packagesname : kernelarch : x86_64version : 2.6.32release : 642.6.2.el6size : 32 mrepo : updatessummary : the linux kernelurl : <url> : gplv2description : the kernel package contains the linux kernel (vmlinuz), the core of any : linux operating system. the kernel handles the basic functions : of the operating system: memory allocation, process allocation, device : input and output, etc.",
    "present_kp": [
      "linux",
      "rpm"
    ],
    "absent_kp": []
  },
  {
    "text": "can i disable the download all feature on a shared google photos album?. if i share a google photos album, other people who view it see a download all button at the top of the page, as shown in the screenshot below. you should be able to see it yourself if you visit this album.is there any way to prevent that button from being shown? i've looked in my google+ settings under photos and videos, and the option allow viewers to download my photos and video is already unchecked.",
    "present_kp": [
      "google photos"
    ],
    "absent_kp": []
  },
  {
    "text": "kernel32.basethreadinitthunk without iat. on starting notepad.exe with ollydbg, i see that eax has a value that points at kernel32.basethreadinitthunk.notepad.exe does not seem to import kernel32.dll::basethreadinitthunk.i cannot find that function, by running dependency walker on notepad.exe.how can kernel32.dll::basethreadinitthunk function be executed without importing it ?",
    "present_kp": [
      "dll",
      "iat"
    ],
    "absent_kp": [
      "windows"
    ]
  },
  {
    "text": "ssh over multiple server and save output of multiple commands in file on local server. i want to ssh over multiple server (host 1, host2 and host 3) and save output of multiple commands (cmd1, cmd2 etc) in file (output.properties) on local server. i know there are a few posts similar to this, but i a not sure where i am going wrong. below is the code snippet.folderpath=cd /usr/local/apps/tempdir;echo $folderpath;eval $folderpath;# host 1echo repcard1=$(expr $(grep -r sample text * | wc -l) / 2) >> /usr/local/host1/tempdir/output.properties;# server 2ssh -t user@host2 <<eof >>/usr/local/host1/tempdir/output.properties;#alias getduplicatecardstats=cd /usr/local/apps/tempdirfolderpath=cd /usr/local/apps/tempdir;echo $folderpath;eval $folderpath;echo repcard2=$(expr $(grep -r sample text * | wc -l) / 2);exiteof. /usr/local/host1/tempdir/output.properties;echo host 1echo $repcard1echo host 2echo $repcard2# repcard2 is always executed on host 1 and print value from host 1what is the mistake in the above script?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "time-dependent state machine. i keep having to write state machines that depend on time for various experiments i run and i'd like to know how to write them better. this state machine is for training a neural network by feeding in keys and expected values.import numpy as npdt = 0.001period = 0.1class simpleenv(object): def __init__(self, keys, values, env_period=0.1): self.keys = keys self.values = values self.env_idx = np.arange(len(keys)) self.idx = 0 self.shuffled = false self.i_every = int(round(env_period/dt)) if self.i_every != env_period/dt: raise valueerror(dt (%s) does not divide period (%s) % (dt, period)) def get_key(self): return self.keys[self.idx] def get_val(self): return self.values[self.idx] def step(self, t): i = int(round((t - dt)/dt)) # t starts at dt ix = (i/self.i_every) % len(self.keys) if ix == 0 and not self.shuffled: print(shuffling) np.random.shuffle(self.env_idx) self.shuffled = true elif ix == 1: self.shuffled = false self.idx = self.env_idx[ix] return ix# note the toy keys and values for testing purposess_env = simpleenv(np.arange(4), np.arange(1, 5), env_period=period)key = -1val = -1ix = -1# iterate through keys and values twicerun_time = 4 * period * 2# the event loop# starts at dt because of reasonsfor t in np.arange(dt, run_time, dt): last_ix = ix ix = s_env.step(t) key = s_env.get_key() val = s_env.get_val() assert key + 1 == val if last_ix != ix: print(key: %s, value: %s %(key, val))the results should look something like:shufflingkey: 2, value: 3key: 0, value: 1key: 3, value: 4key: 1, value: 2shufflingkey: 2, value: 3key: 1, value: 2key: 3, value: 4key: 0, value: 1how can i write this better or more efficiently? is there a state machine library in python that would stop me from having to rewrite variations of this class all the time?",
    "present_kp": [
      "python",
      "state machine"
    ],
    "absent_kp": []
  },
  {
    "text": "find the subarray with the max sum. in an interview i was asked to solve the following problem:find a subarray with max sumi have written a piece of code for the same. i need your help in reviewing this code.package com.ankit.rnd;public class maxsubarrsum { int largestsum=0; int previouslargestsum=0; public static void main(string[] args) { // int [] array = {-2,1,-3,4,-1,2,1,-5,4}; int [] array = {-5,1,-3,7,-1,2,1,-4,6}; // int [] array = {-2,-3,-4,2}; maxsubarrsum obj = new maxsubarrsum(); for(int varindex=0;varindex<array.length;varindex++){ // int sumis =new maxsubarrsum().findsum(varindex,array); // system.out.println(sumis:: +sumis); obj.splitcurrentarray(varindex,array); } } private void splitcurrentarray(int in, int[] arr) { int [] temparr = new int[arr.length-in]; for(int i=in;i<arr.length;i++){ if(in ==0){ temparr[i] = arr[i]; } else{ temparr[i-in] = arr[i]; } } int sum =findsum(in, temparr); system.out.println(previous largest sum:: + previouslargestsum); system.out.println(largest sum found: + sum); } @suppresswarnings(unused) private int findsum(int start,int [] array) { int[] currentarray ={}; int [] largestarray = new int[array.length]; int sum=0; /*for(int i=start;i<array.length;i++){*/ for(int i=0;i<array.length;i++){ //a little inefficient here as it always create an array with size more than total number of elements that should be there in the temp array. int psuedoindex=i; if(start==0){ currentarray = new int[i + 1]; for (int j = 0; j <= i; j++) { currentarray[j] = array[j]; psuedoindex=psuedoindex+1; } } else { currentarray = new int[i+1]; for (int j = 0; j <= i; j++) { currentarray[j] = array[j]; /* * if(psuedoindex == array.length){ //needs a fix. as we * have reached the end of the array. //currentarray[j] = * array[psuedoindex-1]; currentarray[j] = 0; break; } else{ * * currentarray[j] = array[psuedoindex]; is commented out * because it missed the element in the previous array. * * * //currentarray[j] = array[psuedoindex]; currentarray[j] = * array[j]; } */ psuedoindex=psuedoindex+1; } } if((sum = calculate(currentarray))>largestsum){ previouslargestsum=largestsum; largestsum=sum; for(int k=0;k<currentarray.length;k++){ system.out.print(currentarray[k] + |); } system.out.println(); } } return largestsum; } private int calculate(int [] currentarr){ int sumofelements =0; for(int index=0;index<currentarr.length;index++){ sumofelements +=currentarr[index]; } //system.out.println(sum is: + sumofelements); return sumofelements; } }",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "java",
      "interview questions"
    ]
  },
  {
    "text": "complex search program. i am working on a fairly complex (at least it feels complex to me at the moment) search program and am looking to possibly increase the performance. everything works exactly how i want it to, but i'm just wondering if there are any slight performance increases i could benefit from. in this code, even minor performance increases are essential. this is due to the extensive amount of operations being performed.// split search into multiple terms and check the {x} longest terms against the cache.string[] word = searchterm.split(' ');array.sort(word, (x, y) => y.length.compareto(x.length));for (int i = 0; i < word.length; i++){ string searchvalue = word[i]; if (i <= max_word_iterations && (xmlsearchresults == blank_search_xml_schema || xmlsearchresults == string.empty)) { xmlsearchresults = getcachedrecord(thissearch, searchvalue); } if (xmlsearchresults != blank_search_xml_schema && xmlsearchresults != string.empty) { thissearch.value = searchvalue; ignorecache = true; break; }}xmlstring.append(string.format(@<{0}>, xmlheader));int objcount = 0;string prevresultname = string.empty;try{ if (searchresults.hitcount > 0) { list<searchitem> searchresults = new list<searchitem>(); foreach (node resultnode in results.nodes) { string code = resultnode.code.tostring(); string result = resultnode.id.tostring(); string name = resultnode.name_l.tostring(); string image = string.empty; if (!code.tolower().contains(ccb) && code.length <= max_code_length && name != prevresultname && objcount < maxresults) { boolean addresult = true; if (thissearch.filterdescription) { if (!name.tolower().contains(thissearch.value.tolower())) { addresult = false; } } if (addresult) { searchitem osearch = new searchitem(name, code); searchresults.add(osearch); prevresultname = name; } } } var sortedsearchresults = searchresults.orderbydescending(s => s.downloads).tolist(); for (int i = 0; i < sortedsearchresults.count(); i++) { if ((objcount < maxresults)) { string te = string.format(<resultname>{0}</resultname>, sortedsearchresults[i].description); if (!xmlstring.tostring().contains(te)) { xmlstring.append(sortedsearchresults[i].getxmlstring()); objcount += 1; } } } }}xmlstring.append(string.format(@</{0}>, xmlheader));return objcount;",
    "present_kp": [
      "performance",
      "xml",
      "search"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "software which will fetch all relevant included files for a web app?. hopefully this is the correct stack exchange site to be asking this question.i've inherited a fairly large web app from the previous it guy at my organisation. it's written in php and there's no documentation. my php is very rusty at best but i've been given the task of looking at the code for the web app, working out what it does, and preparing it so it can definitely be moved to another host with no problems. the directories in which the relevant php, js and css files sit have a whole load of other php, js and css files in them - things like early revisions of files, backups, slight changes etc. all very messy.i'd like to be able to just download locally all the files that are relevant to the app and not all the extra ones so that when i come to look at the code it'll be much easier to untangle. is there such a piece of software which, when given relevant permissions on the server, goes off and fetches an initial php file, looks for any code from includes and downloads them, does the same for css and js files. is there an ide which does something similar for when people need to debug and untangle others' web apps?",
    "present_kp": [
      "php"
    ],
    "absent_kp": []
  },
  {
    "text": "the fastest desktop environment for mint 14. i'm using mint 14 with the cinnamon desktop environments, but some times it get's extremely slow.so i googled about other desktop environments and i found this great article:<url> i don't know which one is faster, i want to install the fastest desktop environment among them, because i have a low performances in my computer.",
    "present_kp": [
      "desktop environment"
    ],
    "absent_kp": [
      "linux mint"
    ]
  },
  {
    "text": "google apps script to check availability. i'm using google form+calendar to create a reservation system for my makers lab. the user fills out the form and an event is created on the calendar so the ta knows when to goto the lab to help the user.currently i'm using this script(which i found online and modified it a bit to fit my usage)+trigger to create events based on the form submissions var calendarid = <email> //below are the column ids of that represents the values used in the spreadsheet (these are non zero indexed) //column containing the start date+time for the event var startdtid = 6; //column containg the end date+time for the event var enddtid = 7; //column containing the first part of the title for the event (in this case, user id) var titleid = 4; //column containing the second part of the title for the event (in this case, user name) var titleid2 = 3; //column containing the user's mobile number var descid = 5; //column containing the time stamp for the event (this will always be 1) var formtimestampid = 1; //column containing the machine selected var mid = 8; function ensubmittocalendar() { //allow access to the spreadsheet var sheet = spreadsheetapp.getactivesheet(); var rows = sheet.getdatarange(); var numrows = rows.getnumrows(); var values = rows.getvalues(); var lr = rows.getlastrow(); var startdt = sheet.getrange(lr,startdtid,1,1).getvalue(); var enddt = sheet.getrange(lr,enddtid,1,1).getvalue(); //create an addition to the description to included when var subon = timestamp :+sheet.getrange(lr,formtimestampid,1,1).getvalue(); //setting the comments as the description, and adding in the time stamp var desc = subon; //create the title var title = sheet.getrange(lr,mid,1,1).getvalue()+-+sheet.getrange(lr,titleid,1,1).getvalue()+ +sheet.getrange(lr,titleid2,1,1).getvalue()+ +sheet.getrange(lr,descid,1,1).getvalue(); //run the crete event function createeventen(calendarid,title,startdt,enddt,desc); }; function createeventen(calendarid,title,startdt,enddt,desc) { var cal = calendarapp.getcalendarbyid(calendarid); var start = new date(startdt); var end = new date(enddt); //set the options, in this case we are only using description and location, as we do not need guests or sendinvites var event = cal.createevent(title, start, end, { description : desc, }); };it works well, and there's really no major problems to it, except when the user doesn't check availabilitysince we only have so many machines(3),if more than 3 users fill in the same time, the calendar will show more than 3 events, and it gets complicated.is there a way to script it so the script checks to see if there's 3 events during that time, and if so, it doesn't create a event?example:event a: 13:30-15:30event b: 13:30-14:30event c: 14:00-15:30user d submits a form that'll create event d: 14:00-15:30but because 14:00-14:30 there's already 3 events, event d isn't created (or is adjusted by the script to start at 14:30 instead)i'm thinking of using getevents(starttime, endtime, options) var checkavail = calendarapp.getdefaultcalendar().getevents(startdtid, enddtid);but i got no idea how to integrate this into my current scriptcan someone give me some pointers/comments? am i even on the right track?(sorry, i'm not at a level where i know how to write scripts, i only know how to modify existing scripts)",
    "present_kp": [
      "google apps script"
    ],
    "absent_kp": [
      "google spreadsheets",
      "google calendar"
    ]
  },
  {
    "text": "single line command to cat last file in ls -lrt output?. system log files are serialized and i use ls -lrt to show me the most recent file. i then cat that file. this requires typing a long serial number each time. how can i cat the last file appearing in my ls -lrt output in one command?i'm using cygwin and the the output from ls -lrt foobar_job* look like this:--rw-r--r-- 1 zundarz domain users 1133 jul 31 16:54 foobar_job4855125.log-rw-r--r-- 1 zundarz domain users 1256 jul 31 17:10 foobar_job4855127.log-rw-r--r-- 1 zundarz domain users 1389 aug 11 10:20 foobar_job4887829.log-rw-r--r-- 1 zundarz domain users 1228 aug 11 10:39 foobar_job4887834.log",
    "present_kp": [
      "ls",
      "cat"
    ],
    "absent_kp": []
  },
  {
    "text": "detecting and joining series of line segments that run along each other. given: several circular series of map gps coordinates for several bus routes. the gps coordinates are not all equal when they run along the same road. the number of gps coordinates for a single bus route runs from 140-600.problem: when the points are downloaded drawn, the raw routes don't follow each other perfectly and especially when zoomed-out you can't see some of the routes. i want to somehow show the multiple routes that run along a road, mostly likely dashed with multiple colors. but in order to do that, i need to detect the segments of the route that run really close to each other.what would be perfect is finding the segments of the routes and mutating their gps coords to be shared among them. once that's done i can easily render it.so my question is: are there any good algorithms for this purpose, or some combination/tweaks of other algorithms i can use? it all has to be done autonomously in an app, not hand-done/hand-checked.if you need any other information please ask.",
    "present_kp": [],
    "absent_kp": [
      "computational geometry",
      "geometry"
    ]
  },
  {
    "text": "how to use google business without showing address. i'm working on a website and my understanding is, by having the place of business listed with google business, it will help with local searches.the problem we have is, this person is a self employed lady and her business is also her home address, and she doesn't want to provide this location to the world. her website shows the town where she lives which appears to be enough for visitors looking for her location, and only after an enquiry is made does she provide her location. the point is, the website does not expose this.is it possible to utilise the localisation for searches (google business) without it exposing the full address?",
    "present_kp": [
      "google"
    ],
    "absent_kp": [
      "local seo"
    ]
  },
  {
    "text": "is it fair to charge again for checking why my code not working on client's server?. so, i was tasked by client to help him convert his wp menu to javascript dropdown. i did on my development server. he did see the change and i was paid. i deliver the code he deploy it. but, no change on his server. so, i have to spent hours debugging it on his server. it turns out, his other plugin is not compatible with my change. that plugin is really custom. i have to change my code to make sure it's compatible with that plugin.my question is, is it fair for me to charge him for the hours i spent on debugging it and actually fixing it? or is it still my responsibility, to make sure my code deployed properly?",
    "present_kp": [],
    "absent_kp": [
      "project management"
    ]
  },
  {
    "text": "booting efi on kvm. i'm on ubuntu 14.04 running kernel 3.19. i'm trying to use virt-manager to start a virtual machine. i have installed ovmf for efi firmware and booted the machine with a gentoo iso in the cd slot.i see the ovmf firmware logo, then some log messages like this:boot failed. efi dvd/cdromboot failed. efi floppy.boot failed. efi floppy 1.it then initializes the network card, presumably for network boot, and then drops to an efi shell:how do i get efi booting working in kvm/libvirt?",
    "present_kp": [
      "virtual machine",
      "kvm"
    ],
    "absent_kp": [
      "uefi"
    ]
  },
  {
    "text": "os x ssh keeps asking for password. i connect from a linux machine to several macs over ssh using public/private keys.the setup is the identical on every ac, different oss from 10.5 to 10.9 and publickey working. only one of them, running os x 10.9.5, keeps asking for user's password instead of using publickey.actually there's no access using publickey from any machinessh -vvv is:...debug1: authentications that can continue: publickey,keyboard-interactivedebug3: start over, passed a different list publickey,keyboard-interactivedebug3: preferred publickey,keyboard-interactive,passworddebug3: authmethod_lookup publickeydebug3: remaining preferred: keyboard-interactive,passworddebug3: authmethod_is_enabled publickeydebug1: next authentication method: publickeydebug1: offering dsa public key: /users/akeeem/.ssh/id_dsadebug3: send_pubkey_testdebug2: we sent a publickey packet, wait for replydebug1: authentications that can continue: publickey,keyboard-interactivedebug1: trying private key: /users/akeeem/.ssh/id_rsadebug3: no such identity: /users/akeeem/.ssh/id_rsa: no such file or directorydebug2: we did not send a packet, disable methoddebug3: authmethod_lookup keyboard-interactivedebug3: remaining preferred: passworddebug3: authmethod_is_enabled keyboard-interactivedebug1: next authentication method: keyboard-interactivedebug2: userauth_kbdintdebug2: we sent a keyboard-interactive packet, wait for replydebug2: input_userauth_info_reqdebug2: input_userauth_info_req: num_prompts 1password:what should i check to make sure publickey is operational?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "osx",
      "macintosh",
      "public key authentication"
    ]
  },
  {
    "text": "update url with new parameter value. i needed a way to update a parameter in the url, or add it if it doesn't exist, but keep any other variables the same value. i built this function to do the task, and while it works, i feel like it's taking longer than it should. does anyone have any suggestion on what i could change or a faster method?function changeurlparameter(svariable, snewvalue){ var aurlparams = []; var aparts; var aparams = (window.location.search).substring(1, (window.location.search).length).split('&'); for (var i = 0; i < aparams.length; i++) { aparts = aparams[i].split('='); aurlparams[aparts[0]] = aparts[1]; } if (aurlparams[svariable] != snewvalue) { if (snewvalue.touppercase() == all) aurlparams[svariable] = null; else aurlparams[svariable] = snewvalue; var snewurl = window.location.origin + window.location.pathname; var bfirst = true; for (var skey in aurlparams) { if (aurlparams[skey]) { if (bfirst) { snewurl += ? + skey + = + aurlparams[skey]; bfirst = false; } else snewurl += & + skey + = + aurlparams[skey]; } } return snewurl; }}",
    "present_kp": [
      "url"
    ],
    "absent_kp": [
      "javascript"
    ]
  },
  {
    "text": "is there a simple way to use underscorejs to achieve this?. i have an object, having key and values. i'd like to pick the object and call the appropriate function from the key:var requireviews = { breadcrumbview: true, headerview: false, footerview: false };var that = this; _.each(requireviews, function(value, key){ if(value){ //if true? if(_.functions(that, key)) that[key](); //checking is that function, and calling the function } })is it ok or can we minimize it further?",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "underscore.js"
    ]
  },
  {
    "text": "algorithm of communication with failures. i am interested in distributed algorithms especially in communication in network with failures.i look for the proof of the following randomized algorithm of communication in network with failures. for me it seems like very general result in the communication, nevertheless i havent found the proof yet. algorithm: initially only vertex $v_0$ has the message, at the end of the algorithm every vertex of the network should have the message. on every round every vertex that has the message choice the neighbour randomly and sends it the message.assumptions: only $f$ failures might happen on the edges between the vertices.$t = o(\\log n)$ - time complexity and the entire network will know the message with high probability, when $f<n/3$, where n - number of vertices.i will appreciate for link or reference to the paper.",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "distributed systems"
    ]
  },
  {
    "text": "iptables: what the difference between filter and mangle. i am using iptables to to mark the package and want to route based on the marks. first i added the ip rule:sudo ip rule add fwmark 1 prohibit(the prohibit is just for test, i will change it to some route table later.)then i began to mark the packages:sudo iptables -a output -d 192.168.1.0/24 -j mark --set-mark 1but the computer can still access the 192.168.1.0/24 networks. after a long time's googling and struggling, i tried:sudo iptables -t mangle -a output -d 192.168.1.0/24 -j mark --set-mark 1it works and the connection was blocked.in the first case, the default table of filter is used. so my question is what is the difference between mangle table and filter table? which one should be used in what cases? as my understanding, all these tables will be consulted before the routing policy, then why the filter table doesn't work properly?",
    "present_kp": [
      "iptables",
      "routing"
    ],
    "absent_kp": [
      "linux",
      "iproute"
    ]
  },
  {
    "text": "debian and centos, why ipv6 prevail over ipv4. every time i am configuring a debian or centos machine with a static ip address, i forget about that behavior of not taking in account my ipv4 configuration. then, i search for the 1000nd time the parameter to put in sysctl.conf to disable ipv6, and finally i reboot the beast.an example to illustrate :linux deb-router 3.2.0-4-amd64 #1 smp debian 3.2.81-2 x86_64 gnu/linuxit has 2 interfaces, eth0 is configured in ipv4 since some time (1 year maybe).eth1 is bridged on my physical network and was addressed by the dhcp, in ipv4. i talk to the vm through this interface.tonight, i lost my internet gateway, this device is also my dhcp server.i realized i cannot reach my vm anymore, so i checked ifconfig result and saw a nice ipv6 instead of the old ipv4 bound to eth1.so, action ! $ sudo vim /etc/network/interfacesallow-hotplug eth1# was dhcp beforeiface eth1 inet static address 192.168.0.15 netmask 255.255.255.0$ sudo ifdown eth1 && ifup eth1deception :(ifconfig output only an ipv6, i cannot reach my vm. i must disable ipv6 (net.ipv6.conf.eth1.disable_ipv6 = 1) and reboot to get the connection back.i don't understand this choice to favor ipv6 over ipv4, most of people are working with ipv4 from what i know.is it technical, or political to influence people to adopt ipv6 ?",
    "present_kp": [
      "debian",
      "centos",
      "ipv6",
      "ipv4"
    ],
    "absent_kp": []
  },
  {
    "text": "trouble with pleskrestore the file you are trying to upload is not a valid backup file. i am having trouble with pleskrestore on plesk 10.4.1, centos 5. i have 6 files i created (also in plesk 10.4.1) with pleskbackup, split into 4gb:here is what i used ...$ /usr/local/psa/bin/pleskbackup --server --output file=<url> --split=4g... to make these files:colossus729_split colossus729_split.001 colossus729_split.002 colossus729_split.003 colossus729_split.004 colossus729_split.005 but plesk restore wouldnt work with those files (contrary to the documentation)# /usr/local/psa/bin/pleskrestore --restore colossus729_split -level server -licenseand get this error:the file you are trying to upload is not a valid backup file",
    "present_kp": [
      "plesk"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "pass snmp trap packet to a php daemon on ubuntu. i have a ubuntu server which is collecting incoming snmp traps. currently these traps are handled and logged using a php script.file /etc/snmp/snmptrapd.conftraphandle default /home/svr/00-vhosts/nagios/scripts/snmptrap.phpthis script is quite long and it contains many database operations. usually the server receives thousands of traps per day and therefore this script is taking too much cpu time. my understand is this is due to high start-up cost of the php script every-time when a trap received.i got a request to re-write this and i was thinking of running this script as a daemon. i can create an ubuntu daemon. my question is how can i pass trap-handler to this daemon using snmptrapd.conf file?thank you in advance.",
    "present_kp": [
      "ubuntu",
      "php",
      "daemon",
      "snmp"
    ],
    "absent_kp": []
  },
  {
    "text": "when is a requirement considered complete?. which elements must a requirement contain that it can be considered complete? or if this works better - which questions should i ask about a requirement to find out if it is complete. i am not talking about the implementation of the requirement but the requirement itself.i am asking this from the perspective of an analyst who wants to make sure that his requirements are complete before passing them on to the design team.",
    "present_kp": [
      "requirements"
    ],
    "absent_kp": []
  },
  {
    "text": "problem with storing an existing triangulation in a dcel. i am new to stackexchange, and i already made the mistake of posting a new question as a response to a previous question. here, i rewrote my question more clearly and separately.i am trying to store an existing 2d triangulation in a dcel data structure, and i have all of the vertices and edges.i was able to store all of the information correctly except the half_edge representative for each triangle. here is the algorithm i used:(taken from constructing of double connected edge list (dcel))algorithm:for each endpoint, create a vertex. for each input segment, create two half-edges and assign their tail vertices and twins. for each endpoint, sort the half-edges whose tail vertex is that endpoint in clockwise order. for every pair of half-edges e1, e2 in clockwise order, assign e1->twin->next = e2 and e2->prev = e1->twin. pick one of the half-edges and assign it as the representative for the endpoint. (degenerate case: if there's only one half-edge e in the sorted list, set e->twin->next = e and e->prev = e->twin.) the next pointers are a permutation on half-edges. for every cycle, allocate and assign a face structure.the last sentence seems to be easier said than done. how can i ensure that every triangle will have a representative, and that a representative will be assigned only once for each triangle? furthermore, which cycle is it referring to? if you have any other ideas, please share.thank you very much for your help. i've been struggling with this for a while.ps- i am working in c++. also, i am using the same structure as provided in the link above.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "data structures",
      "computational geometry"
    ]
  },
  {
    "text": "find adsense earning from different websites. i am going to add my adsense code to one new website i've created recently.the problem is how to find out which site earned what in final earning. i need to share the earning of second site with my partner. i can setup different channel to see what each site earned but the final earning may not be the same.so how can i find out which site earned what in final earning page.thanks in advance.",
    "present_kp": [],
    "absent_kp": [
      "google adsense"
    ]
  },
  {
    "text": "custom user input function. the program consists of 3 files: demo.c, mylib.c and mylib.h. the code is heavily commented.demo.c:/*********************************************************************** * * this is a program that prompts the user for an input string using a * custom input function. * ***********************************************************************/#include <stdio.h> /* printf */#include <stdlib.h> /* exit */#include mylib.h/* for testing purposes, let's make the length of the string 4 */#define string_length 4int main(int argc, char* argv[]) { char* s = udf_get_input(prompt: , string_length); printf(you entered: \\%s\\n, s); /* i put quotes around the string to better see what has actually been entered */ free(s); s = null; /* this is not really necessary */ exit(exit_success);}mylib.h:#ifndef mylib_h_#define mylib_h_size_t udf_strlen(const char* s);char* udf_get_input(const char* const prmpt, int str_len);#endif /* mylib_h_ */mylib.c:#include <stdio.h> /* printf, getchar */#include <stdlib.h> /* malloc, realloc, free, exit */#define error_msg error: could not allocate enough memory/*********************************************************************** * * this is just my own implementation of the c standard library's * strlen function. we're going to need it later. * ***********************************************************************/size_t udf_strlen(const char* s) { size_t i = 0; while (*s++) { i++; } return i;}/*********************************************************************** * * this is a function that takes in as arguments a pointer to a string * that represents the prompt the user sees when typing things at the * keyboard and the length of the string. the function returns a pointer * to the string that has been entered. * * how it works: * we are going to allocate a certain number of bytes on the heap. this * is going to be our buffer. then we will read whatever the user types * in into that buffer. after that, we will check if we need to tweak * the amount of memory that the string takes up so that no memory is * wasted unnecessarily. if the number of characters entered by the user * exceeds the buffer size, the rest of the string is discarded. * ***********************************************************************/char* udf_get_input(const char* const prmpt, int str_len) { int buffer_size = str_len + 1; /* number of characters allowed to be entered plus one to accommodate the null character */ char* buffer; /* temporary storage for the user's string */ if (!(buffer = malloc(buffer_size * sizeof(char)))) { printf(%s , error_msg); exit(exit_failure); } printf(%s, prmpt); /* display the prompt */ int ch; /* stores characters retrieved from stdin */ char* p = buffer; /* temporary pointer to traverse the buffer */ while ((ch = getc(stdin)) != eof) { /* if the character read is a newline character or buffer_size - 1 characters have been already entered, terminate the string with a null character and bail out of the loop */ if (ch == ' ' || !--buffer_size) { *p = ''; break; } *p++ = ch; } /* if buffer_size is more than zero, that means there are unused bytes in the buffer. so, we will reallocate memory to shirk it so that the string occupies as much memory as exactly necessary. otherwise no memory reallocation is needed and we can skip this step. */ if (buffer_size) { buffer = realloc(buffer, (udf_strlen(buffer) + 1) * sizeof(char)); if (!buffer) { printf(%s , error_msg); exit(exit_failure); } } return buffer; /* return the pointer to the string stored on the heap */}to test the program, make a separate directory and create these three files in it:touch demo.c mylib.c mylib.hto run the program, execute this command:gcc -c demo.c mylib.c && \\gcc demo.o mylib.o -o a.out && \\./a.out",
    "present_kp": [
      "c",
      "io"
    ],
    "absent_kp": [
      "strings"
    ]
  },
  {
    "text": "how to make multipage book in calameo?. if i upload a pdf binder i get the correct amount of pages but with the content of the first page on each. if i upload a number of pdfs separately its just creates a new publication for each pdf.would anyone know how to correctly publish a multi page book with calameo from pdfs?",
    "present_kp": [
      "pdf"
    ],
    "absent_kp": [
      "books"
    ]
  },
  {
    "text": "are derivative works a subset of combined works?. this question stems from discussion of a question on programmers.stackexchange.com.in the lgpl 3.0 section 4 combined works it states:you may convey a combined work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the library contained in the combined work and reverse engineering for debugging such modifications, if you also do each of the following:generally, it seems the lgpl license is concerned with open source libraries and software that uses these libraries where a combined work would be a piece of software that includes a library.if one were to open source a standalone single file program and someone modified that and redistributed it, it would technically be a derivative work. would the statements regarding combined works map to derivative works?or more simply: are derivative works a subset of combined works?",
    "present_kp": [
      "derivative works",
      "lgpl"
    ],
    "absent_kp": []
  },
  {
    "text": "need an example of convection-dominated problem to test on freefem++. can you all give me (at least) one example about convection-dominated problem in order that i can test it (them) on freefem++. if possible, please give me specific examples (it/they contain(s) full equations, boundary condition, initial condition, value of parameters, code in freefem++,...)",
    "present_kp": [],
    "absent_kp": [
      "finite element",
      "numerical analysis"
    ]
  },
  {
    "text": "self join exercise. have i over-complicated it?. this my 3rd question on the same exercise, but by no means a duplicate. the two previous questions were posted on stackoverflow here and here.now i'm posting my oracle solution (below) that works. i wonder if the same could've been simpler and/or much more efficient. not in terms of cte or analytic expressions but with basic simple logic.data:create table readings ( user_id varchar(10), reading_time int , x decimal(10,2), y decimal(10,2));insert all into readings (user_id, reading_time, x, y) values ('u1', 60, 345, 400) into readings (user_id, reading_time, x, y) values ('u1', 100, 560, 300) into readings (user_id, reading_time, x, y) values ('u2', 35, 1024, 250) into readings (user_id, reading_time, x, y) values ('u1', 90, 450, 450) into readings (user_id, reading_time, x, y) values ('u3', 150, 600, 100) into readings (user_id, reading_time, x, y) values ('u3', 100, 500, 125)select * from dual;intermediate script:select r.user_id, rm.reading_time start_time, r.reading_time end_time, (r.reading_time-rm.reading_time) time_spent, (to_char(rm.x)||' ; '||to_char(rm.y)) start_point, (to_char(r.x)||' ; '||to_char(r.y)) end_point, sqrt(power(r.x-rm.x, 2)+power(r.x-rm.y, 2)) distance from readings r join readings rm on (r.user_id = rm.user_id and rm.reading_time = (select max(r2.reading_time) from readings r2 where r2.reading_time < r.reading_time))order by 1,2; final script:select rr.user_id, sum(rr.distance) total distance, sum(rr.time_spent) total time, sum(rr.distance)/sum(rr.time_spent) average speed from (select r.user_id, (r.reading_time-rm.reading_time) time_spent, sqrt(power(r.x-rm.x, 2)+power(r.x-rm.y, 2)) distance from readings r join readings rm on (r.user_id = rm.user_id and rm.reading_time = (select max(r2.reading_time) from readings r2 where r2.reading_time < r.reading_time))) rrgroup by rr.user_idorder by 1;exercise description multiple users roam a plain and at irregular time intervals report their coordinates (x, y). this information (user id, time-stamp and the coordinates) populate table readings. for each user that reported more than one set of coordinates we need to find total distance traveled, total time spent, and their average speed.for the sake of simplicity coordinates are cartesian and time-stamps are integers.",
    "present_kp": [
      "oracle"
    ],
    "absent_kp": [
      "sql"
    ]
  },
  {
    "text": "converting cartesian pixels to polar pixels. (i've largely revamped this entire question, though the motivation remains the same.)revised questioni want to convert a raster of cartesian pixels into polar pixels. is there a sensible algorithm for doing this? for example, how do i compute the value of the shaded (polar) pixel in the image below, given the value of the three (cartesian) pixels that it overlaps? original questionis there a reasonable way to compute the area of the intersection of a square and an annular section, as shown in the orange section below?the motivation: i have a raster of square pixels, and i'm converting it to polar pixels -- i want to find out the contribution of each cartesian pixel to each polar pixel.",
    "present_kp": [],
    "absent_kp": [
      "polygon",
      "2d graphics"
    ]
  },
  {
    "text": "function to log arguments and return value of any function in clojure. i have implemented a function, which logs the inputs and outputs of any function, indenting the log based on the depth of the call stack:(def depth (atom 0))(defn logfun [fun] (fn [& args] (do (swap! depth inc) (println (str (apply str (repeat @depth )) >>> ( fun args ))) (let [result (apply fun args)] (do (swap! depth dec) (println (str (apply str (repeat @depth )) <<< result)) result)))))usage example:(defn fact [n] (if (> n 1) (* n (fact (dec n))) n))(def fact (logfun fact))(fact 5)output: >>> (lang.core$fact@5eb14bce (5)) >>> (lang.core$fact@5eb14bce (4)) >>> (lang.core$fact@5eb14bce (3)) >>> (lang.core$fact@5eb14bce (2)) >>> (lang.core$fact@5eb14bce (1)) <<< 1 <<< 2 <<< 6 <<< 24 <<< 120main questions:is there a way to improve this function so that it is not dependent on global variables? (i have already attempted a solution based on with-local-vars / var-set -- see below, but it seems to me that they do not work as i wish they did).are there any edge cases, for which the above function does not work?are there any modifications by which this function can be made better adhering to clojure best practices (besides somehow getting rid of the global state)?is there a way to improve the output of the function names (e.g., instead of lang.core$fact@5eb14bce i would like to get lang) in a way that satisfies both conditions below:it must be available in the clojure core language (no third-party libs, no usage of repl utilities)it must not use string manipulation (e.g. find the @ and $ characters via regexp and then strip away the parts before/after them).in other words, i'm looking for something like: (get-pretty-printed-function-name fun). (i already did some research, and found only solutions which do not satisfy the criteria above. still asking, just in case ;) )the attempted, not working solution using var-set/with-local-vars:(defn logfun [fun] (with-local-vars [depth 0] (fn [& args] (do (var-set [depth (inc @depth)]) (println (str (apply str (repeat @depth )) >>> ( fun args ))) (let [result (apply fun args)] (do (println (str (apply str (repeat @depth )) <<< result)) (var-set [depth (dec @depth)]) result))))))edit: using bound-fn, i get one step further, but unluckily it still does not do what is expected, as it seems that the variable depth in the closure is reset to zero upon every invocation of the returned function:(defn logfun [fun] (with-local-vars [depth 0] (bound-fn [& args] (do (var-set depth (inc @depth)) (println (str (apply str (repeat @depth )) >>> ( fun args ))) (let [result (apply fun args)] (do (var-set depth (dec @depth)) (println (str (apply str (repeat @depth )) <<< result)) result))))))result: >>> (lang.core$fact@510da75f (5)) >>> (lang.core$fact@510da75f (4)) >>> (lang.core$fact@510da75f (3)) >>> (lang.core$fact@510da75f (2)) >>> (lang.core$fact@510da75f (1)) <<< 1 <<< 2 <<< 6 <<< 24 <<< 120",
    "present_kp": [
      "clojure"
    ],
    "absent_kp": [
      "logging"
    ]
  },
  {
    "text": "is it required to disclose source code for custom qt software?. i was hired to develop a custom qt application for a customer, but i'm concerned about the licensing.my software will not be publicly distributed and it is going to be used exclusively by this customer.do i need to disclose my source code for this customer, if i link my application with qt libraries, such as qtcore and qwebkit that can be installed from a linux distribution repository?",
    "present_kp": [
      "licensing",
      "qt"
    ],
    "absent_kp": [
      "open source",
      "closed source"
    ]
  },
  {
    "text": "can a long option be shortened arbitrarily?. is that a long option can be shortened arbitrarily part of gnu conventions for options, or some other conventions/standards, or just provided by some special c function? for example, why do python and awk behave differently?$ python --versionpython 2.7.12$ python --versiounknown option: --usage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...try 'python -h' for more information.$ awk --versiongnu awk 4.1.3, api: 1.1 (gnu mpfr 3.1.4, gnu mp 6.1.0)$ awk --versignu awk 4.1.3, api: 1.1 (gnu mpfr 3.1.4, gnu mp 6.1.0)thanks.",
    "present_kp": [
      "options"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "google analytics not recording 99%+ of traffic. i have google analytics on a rails web app.lately traffic has picked up, and i get about 1000 page views per hour as seen from rails. but ga only picks up 25-100 per day, and i need help understanding this.i know ga doesn't pick up some kinds of traffic, like web crawlers, and my own traffic. what else does it deliberately ignore?is there a way i can recognize these categories in my rails code?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "discovering functionality from parallel class hierarchy. i have an abstract syntax tree which i want to compile down to different representations. i am now struggling to arrange the classes in a way that new representations can be added easily.the easiest way to achieve this is to add a method for each representation, e.g. compile_to_foo, compile_to_bar. additional representations can be added by monkey patching. the problem with this is that the compilation implementations are spread all over the place, and that it violates the single responsibility principle. the advantage is that compilation can be inherited.now, i could also define a compilation function containing a giant switch which dispatches on argument type. but this looses advantages of polymorphism, and makes inheriting behavior of the compilation more difficult. this is not a viable option.an interesting solution would use an abstract factory:this design looks fairly promising, but has some disadvantages:the ast node hierarchy cannot be extended without also extending the abstractcompiler, and in turn all concrete compilers and their parallel hierarchies of concrete nodes.the subtyping information of the ast nodes is spead across the whole system. it has to be specified between the abstractnodes in order to share behaviour (i will be using roles), between the concretenodes in order to share compile implementations, and in at least in the abstractcompiler to provide default implementations (e.g. method nodea() { return node() }). this could be partially solved via metaprogramming.when an ast is built, this can only compile down to one representation. if i want to have multiple outputs, i need to rebuild the ast with a different concretecompiler.ideally, i would just pass a concrete compiler instance as a parameter to the compile method: but i have no idea how the compile method could obtain the actual implementation from a parallel class hierarchy (without again using a giant switch on the node type).i also investigated the bridge pattern, but the solution does not seem applicable to my problem without creating a thousand little bridges.i carefully read through this previous question: designing a robust architecture for multiple export types?. the key difference is that the input data (there: equivalent, standalone data represenations) are now hierarchical ast nodes, so that inheritance between the compilation implementations is crucial.the system will be implemented in perl, so i'm not restricted to classic oop, but can also use metaprogramming, roles (aka. traits), and functional programming.what am i missing? is there an architecture i could use to elegantly structure this system? how can i make the corresponding class from the parallel class hierarchy discoverable to the node classes, without sacrificing polymorphism?",
    "present_kp": [
      "architecture",
      "perl",
      "single responsibility"
    ],
    "absent_kp": [
      "design patterns"
    ]
  },
  {
    "text": "using qt in open source app that communicates with closed source hardware. prefacei'm having trouble determining if i can use the qt framework for developing a cross platform desktop app.situationthe app is open source, and the libraries it uses are also open source.so i can provide the source code for the whole app without issue.however, the app will be communicating with hardware that has closed source firmware. the app will read and write data from the device. read data will be used to visualize what the hardware is doing. it will also update the hardware by feeding the device an encrypted firmware file, which its boot-loader (also closed source) will encrypt and commit to flash. lgpl and gpl licensed code will in no way be used in the firmware or boot-loader. questionsdoes the free lgpl version of the qt framework allow me to keep my firmware as closed source? if so, does the gpl license allow for this use-case as well? editi read something interesting on a similar question involving the lgpl and gpl licenses: as a rule of thumb, the gpl reaches as far as the address space of the licensed code.if i am reading this correctly, my qt app should have no licensing issues.",
    "present_kp": [
      "licensing",
      "gpl",
      "lgpl",
      "qt"
    ],
    "absent_kp": []
  },
  {
    "text": "best free blogging site that allows adsense and other advertising?. i'm looking to start my own blog. under the incredibly vain assumption that anyone cares what i think, i'd like to put up some ads to fund my, um, habits, yeah. i don't want to have to pay anything, nor do i want to host it myself (if possible).what blogging platform fits this bill?",
    "present_kp": [
      "advertising",
      "blog",
      "free"
    ],
    "absent_kp": [
      "google adwords"
    ]
  },
  {
    "text": "parsing odataqueryoptions to expression>. i am following up on this answer for a scenario that i am currently working on. like the op, i am too concerned about the longevity of the code.public iqueryable<tentity> emptyenumerable(){ return enumerable.empty<tentity>().asqueryable();}private expression<func<tentity, bool>> getfilterexpression(filterqueryoption filter){ var enumerable = this.emptyenumerable(); var param = expression.parameter(typeof(tentity)); if(filter != null) { enumerable = (iqueryable<tentity>)filter.applyto(enumerable, new odataquerysettings()); var mce = enumerable.expression as methodcallexpression; if(mce != null) { var quote = mce.arguments[1] as unaryexpression; if(quote != null) { return quote.operand as expression<func<tentity, bool>>; } } } return expression.lambda<func<tentity, bool>>(expression.constant(true), param);}my questions are:is there anything that i should be checking, which i am not already checking?is returning a truth expression a sensible default?any refactorings/improvements are welcome.",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "api"
    ]
  },
  {
    "text": "what is the state-of-the-art in machine translation on chinese/cjk?. sorry for my unfamiliarity with the field. hopefully this question is on-topic here.currently the machine translation from western european languages to english is arguably quite robust, with google translate able to quite accurately translate articles on wikipedia or news site. however, it seems to me that the translation between chinese/japanese and english is still quite off: google translate is frequently unable to produce a reasonably coherent/meaningful translation for even just one chinese/japanese sentence.it gets me wondering, is the state-of-the-art in cjk machine translation still much off the pace compared with european languages? or is it just that some research advances haven't been applied to the industry yet? what is the current status of the cutting-edge researches on this field, e.g. novel translation models/improvements on precision rate. where should i go to look for more information?",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "natural language processing"
    ]
  },
  {
    "text": "setting .conf files for nginx. i use nginx as a server, and i currently use this for configuration of each my sites. basically, i have multiple files like this located in /etc/nginx/conf.d/.#example.confserver { listen 80; server_name <url> my-site.com; root /var/www/html/my-site.com; location / { rewrite ^/category/(.*)$ /category.php?id=$1 last; rewrite ^/profile/(.*)$ /profile.php?id=$1 last; try_files $uri $uri/ /index.php?$query_string; } index index.html index.htm index.php; error_page 404 /404.html; location = /var/www/html/nginx/error/404.html { root /var/www/html/nginx/error/; } error_page 500 502 503 504 /50x.html; location = /var/www/html/nginx/error/50x.html { root /var/www/html/nginx/error/error/; } location ~ \\.php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param script_filename $document_root$fastcgi_script_name; include fastcgi_params; }}so, i have 6 sites with their own file like this, and since i am about to do a complete re-install of my server, i would like to know how i can improve this configuration, both security and optimization wise.",
    "present_kp": [
      "server",
      "nginx"
    ],
    "absent_kp": []
  },
  {
    "text": "top for web browsers. this is a bit off the unix road, but i believe most people interested in the answer are linux or unix users so here goes.for a long time it seems that the number one process chewing up cpu time and memory is my web browser ( mainly firefox, but others too ). it is true that i have a lot of pages open at once, so i generally don't mind, but recently it's gotten to the point where the browser just bogs down the system, and when i close some pages some sanity is restored.what would be nice is if there were some tool or plugin that would tell me exactly what web pages/sites are using the most resources.",
    "present_kp": [
      "browser"
    ],
    "absent_kp": []
  },
  {
    "text": "openvpn: routing by destination name or port, not ip. on a dd-wrt router, openvpn uses policy based routing for 192.168.1.128/25. if the vpn goes down, the firewall denies access to clients in the range.i would like to add exceptions to the vpn routing.is it possible to specify that connection to certain fqdns will be sourced from the wan address not the vpn address (and of course be unencrypted)? if not possible as above, at least have connections to a certain port (587) be routed off vpn, across the board?",
    "present_kp": [
      "routing",
      "openvpn",
      "router",
      "route"
    ],
    "absent_kp": [
      "dd wrt"
    ]
  },
  {
    "text": "complexity of knapsack-type problem with applications to computational workflows. consider the following problem:let there be a set a of $n$ items $a=\\{z_1, ..., z_n\\}$, and let $w$ be a strictly positive integer. each item $z_i$ has a value $v_i$ and a weight $w_i$. finding a subset $as$ of $a$ so that the weight of $as$ is less than $w$ and the value of $as$ (the sum of the value of its items) is maximized is the 0/1 knapsack problemnow, consider a deviation from it where the items in $a$ have certain dependency relationships between each other, and these dependencies can be captured by a directed acyclic graph $g(a, e)$. the value of the set $as$ is no longer the sum of the value of the items in $as$. for each item in $as$, its value depends on which other items are also in $as$. more formally, this is how we calculate the value of an item $v$ in $as$. let $a$ be the a closest ancestor of $v$ in $g$ that is also in $as$. then the contribution of $v$ to the value of $as$ would be its own value, plus the value of all the ancestors in the path between $v$ and $a$. (since this is a dag, there could be many of these ancestors. see formalization below).this problem has important applications in computational workflow systems where you have limited storage, and you want to optimize the computational time of running a workflow (represented by a dag) by storing some of the intermediate datasets for future use.my questionsthe problem is obviously np-hard because the knapsack problem can be reduced to it. i have a feeling that it is likely that no pseudo-polynomial algorithm exists for it. do you know of a problem that i could use to reduce to my problem to confirm those feelings? or do you think that it is possible to produce a pseudo-polynomial algorithm for this?edit: formalization on how to compute value of $as$to succinctly define the value of $as$ i will add to the notation from above a little bit. let $v(z_i)$ be equivalent to $v_i$ from above. then $v(z_i|as)$ reads: value of node $z_i$ given answer set $as$.if $z_i \\in as$, then $v(z_i|as)=0$. otherwise, if $z_i ot\\in as$, $v(z_i|as) = v(z_i) + \\sum_{z_j \\in parents(z_i)}{v(z_j|as)}$those two definitions are enough to then say that:$value(as) = \\sum_{z_i \\in as}{v(z_i|as-\\{z_i\\})}$end of edit",
    "present_kp": [],
    "absent_kp": [
      "np hardness",
      "time complexity",
      "reductions"
    ]
  },
  {
    "text": "sending files over twitter. i want to be able to send a file to my followers. how do i do this?",
    "present_kp": [
      "twitter"
    ],
    "absent_kp": [
      "file send"
    ]
  },
  {
    "text": "does sitting idle for one month without work leads to depression?. does sitting idle for one month without work leads to depression?following case is an example:if a human do 8 hours job before computer. because of no work or a few work; generally sitting idle for one month. and when work came after a month; then that human do not want to do it because:symptoms which generally such human is facing:1) that humans head remain heavy; always feel like outing. even if that human go to outing and come back to office feel like go out again.2) it is like nothing is in that human head. just sounds shaaan shaaaan.3) sometimes it is like that human need to get my ear clean from ent; may be due to that head is heavy. but nothing is there in that human's ear , because that human use to clean my ears during bathing.4) life becoming dull. now work came after 1 month; that human being lazy not to attempt that work. that human do not want work now.5) not agreeing to any external motivation and self motivation is becoming zero.6) just looking at facebook, amazon and doing nothing. not a like on facebook; but looking just. it is like nothing new.7) if reading news forget the story after 15 minutes. forget the work that human's family member says.8) that human feel like that human is blunder; that human do mistakes; you all leave that human; throw that human out of computer company.could anyone please figure out situation of that human's mind!!! is that human getting mad or depressed?",
    "present_kp": [
      "depression"
    ],
    "absent_kp": []
  },
  {
    "text": "importance of the empty string. in the sense of a string distinct from a null reference string, what is the importance of an empty string in cs (and specially in formal languages)? why do you need a separate concept, that of 'empty string', which even has it's own greek letter ()?couldn't just an eol character replace it?",
    "present_kp": [
      "formal languages"
    ],
    "absent_kp": [
      "terminology"
    ]
  },
  {
    "text": "best sources on data stream algorithms. i recently got interested in data stream algorithms to the point that i'd like to study the topic and then teach it to someone.i'd be thus grateful for pointers to really good sources on the topic, t.i. papers presenting major ideas in a particularly articulate way, papers with clever proofs of clever theorems, just good overviews of the state of the art, whatever.my two cents:lecture notes from the dartmouth university, 2009. this is the best source i've found so far.distributing frequency-dependent data stream computations, described in my answer to a different (also mine) question.the book data streams: algorithms and applications (i haven't read it yet)",
    "present_kp": [
      "data streams"
    ],
    "absent_kp": [
      "reference request",
      "big list"
    ]
  },
  {
    "text": "autostart bash script, debian 8. bash script#!/bin/shxflux -l 55 -g 37how autoboot it precisely in debian 8? i.e via startap application commandgnome-terminal -e /path_to_script/script.shdoesn't work",
    "present_kp": [
      "debian"
    ],
    "absent_kp": []
  },
  {
    "text": "numerical solution of fractional integro-diffrential equ. using collocation method?. problem comes from numerical solution of fractional integro-differential , equations by collocation method , e.a. rawashdeh, department of mathematics, yarmouk university, irbid 21110, jordan$d^qy(t)=p(t)y(t)+f(t)+\\int_{0}^{1}{k(t,s)y(s)\\,ds} , t\\in i=[0,1]$i want to create a maple code to check if the results in given article is valid or not but i do not have any idea about collocation method!any reference to collocation method solution are welcome!",
    "present_kp": [
      "collocation"
    ],
    "absent_kp": [
      "finite difference",
      "matlab",
      "mathematica",
      "integral equations"
    ]
  },
  {
    "text": "how to install osqa using xampp on windows 7 32bit?. i want to install osqa using xampp on windows 7 32bit. i've followed the instructions on this tutorial until the install the database server section. in this section, to create a database, i've used phpmyadmin and created a database (name: osqa; password: 1234). now my problem is the next step, edit settings. in this step i don't know how to fill in the settings_local.py's fields. i know that apache needs mod_wsgi.so so, i've placed mod_wsgi.so into my apache modules directory and then added loadmodule wsgi_module modules/mod_wsgi.so to the file httpd.conf. then i restarted the apache with no errors. then i followed the next steps, but after entering <url> in my browser, i just see a blank page! can someone please provide me with an instruction in full details? please note that i don't like to use bitnami osqa for some reasons.unfortunately, the official support for osqa is not very active in these days. p.s.: i'm using python 2.7.5 and django 1.6.2. also my osqa source files are in c:\\xampp\\htdocs\\osqa.",
    "present_kp": [
      "xampp",
      "django",
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "how to place / store a file in memory on linux?. i have read somewhere that one can put a file on a linux system into memory, and loading it will be superfast.how do i do this? how do i verify the file is loaded from memory?",
    "present_kp": [
      "linux",
      "memory"
    ],
    "absent_kp": [
      "files"
    ]
  },
  {
    "text": "undecidability of the language with its elements(tm) having empty language. we can write a decider for the language:$e=\\{a\\; |\\; a \\mbox{ is a dfa and } l(a)=\\emptyset\\}$by marking method. why we cannot use the same method to write a decider for the language with tm as follows?$a = \\{ m \\;|\\; m \\mbox{ is a tm and } l(m)=\\emptyset\\}$",
    "present_kp": [],
    "absent_kp": [
      "turing machines"
    ]
  },
  {
    "text": "table - replace values of a column. i have several tables (tab separated) in which the first column is as follow:month0.000.000.000.000.000.000.000.000.000.000.000.00i would like to replace those values by the actual month value, as follow:month123456789101112",
    "present_kp": [
      "table"
    ],
    "absent_kp": []
  },
  {
    "text": "using a singleton for a collection of discounts to calculate?. i'm wondering if using a singleton for a storage of discounts is the right way to go. this is because i will be looping over all added discounts in another class.client code// dynamically add new discounts$collection = discountcollection::getinstance();$collection->add(new tenpercentdiscount());$collection->add(new twentypercentdiscount());discountcollection<?php namespace notflip\\discount;use notflip\\discount\\discounts\\discount;class discountcollection { private static $instance; private static $discounts; final static function getinstance() { if(static::$instance === null) { static::$instance = new static(); } return static::$instance; } public function add(discount $discount) { static::$discounts[] = $discount; } public function count() { return count(static::$discounts); } public function show() { return static::$discounts; }}",
    "present_kp": [
      "php",
      "singleton"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "given a string, return a string where every character in the original is doubled. for example, given the string xyz, return the string xxyyzz.i was given this as a part of a test. i would really appreciate if you can help me to find a better way of doing it.i came up with two methods to do the same thing but one was an extension method.i have a couple more questions which i will post in separate posts.public class repeatcharactersinstring{ public string repeatastring(string sinputstring, int repeatcount) { stringbuilder soutputstring = new stringbuilder(); if (string.isnullorempty(sinputstring)) { console.writeline(empty string !); } else { foreach (char c in sinputstring) { soutputstring.append(new string(c, repeatcount)); } } return soutputstring.tostring(); }}// method 2 using extension methodspublic static class repeatcharactersinstingextensions{ public static string repeatallcharactersinthisstring(this string sinputstring, int repeatcount) { stringbuilder soutputstring = new stringbuilder(); if (string.isnullorempty(sinputstring)) { console.writeline(empty string !); } else { foreach (char c in sinputstring) { soutputstring.append(new string(c, repeatcount)); } } return soutputstring.tostring(); }}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "strings"
    ]
  },
  {
    "text": "linux software center cannot run anymore. i am using linux mint 18 cinnamon.linux mint has software center, just like ubuntu software center in ubuntu. after linuxmint installation, i could run the software center in my system. but someday, may be after some operation like remove openjdk, install oracle jdk,...the software center doesn't run anymore. when i click the software center icon or run from terminal, the os ask for super user password too, after entered the password, the round-spin (waiting) cursor appear for some seconds. after all, nothing happen. the software center doesn't run. something i tried:reinstall default jre (openjre)remove software-manager and reinstall software-managerthis is the output when i try to run sudo mintinstall$ sudo mintinstallvector smash protection is enabled.add_categories took 13.497 msbuild_matched_packages took 0.298 msadd_packages took 3828.769 msfirst run detected, initial set of reviews usedadd_reviews took 1022.018 mstraceback (most recent call last): file /usr/lib/linuxmint/mintinstall/mintinstall.py, line 1920, in <module> application() file /usr/lib/linuxmint/mintinstall/mintinstall.py, line 59, in wrapper res = func(*arg) file /usr/lib/linuxmint/mintinstall/mintinstall.py, line 617, in __init__ sans26 = imagefont.truetype(self.font, 26) file /usr/local/lib/python2.7/dist-packages/pil/imagefont.py, line 239, in truetype return freetypefont(font, size, index, encoding) file /usr/local/lib/python2.7/dist-packages/pil/imagefont.py, line 128, in __init__ self.font = core.getfont(font, size, index, encoding) file /usr/local/lib/python2.7/dist-packages/pil/imagefont.py, line 37, in __getattr__ raise importerror(the _imagingft c module is not installed)importerror: the _imagingft c module is not installed",
    "present_kp": [
      "linux mint"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "colordiff - how to retain color while saving to file. is it possible to retain the color while storing the diff output in a file?this is working and showing the colors in terminalcolordiff -yw 1000 --suppress-common-lines file1 file2 > tempfilebut when i redirect the output to a file its not showing the colors. colordiff -yw 1000 --suppress-common-lines file1 file2 > tempfile",
    "present_kp": [
      "diff",
      "colordiff"
    ],
    "absent_kp": []
  },
  {
    "text": "backing up messages in s3 within a storm topology. in my project we are trying to build up a kind-of-a-lambda storm based architecture. the component would be responsible for indexing the site usage events so we expect a quite massive random load. the solution for real-time processing of the messages seems fine, but in parallel to the speed layer we want to back up the messages in a raw form (just as they are coming down from the queue) in amazon s3. since writing a file per message is obviously out of the question, we need to somehow buffer/aggregate the messages before posting to s3 - and here is where the problems begin. we have two concurrent approaches and none seems perfect:we used redis as a buffer. basically messages coming down from a queue (rabbitmq) are buffered in redis and once some preconfigured batch size (say 1000) is reached the buffer is flushed and stored to s3. the whole message proccesing cycle is not transactional. once message is stored to redis it is acknowledged in the queue. this means that if redis dies the whole batch gets lost and this is not acceptable. we can think of redis cluster to make the thing more bullet proof but... doesn't it seem like going in a wrong direction?the second approach would be to use trident topology. changing the input queue to kafka makes things looking more or less straightforward. the message processing cycle can be transactional. however, there is this one annoying keyword that keeps beeing repeated in the trident documentation - small batches - that trident assumes small batches. for example the transactionaltridentkafkaspout batches the messages into 2 seconds chunks. this is much too little for us. i'm not sure why the batches should be small, but if it's really required maybe the first approach is better?which one from above is better? maybe somoeone would come up with a third idea?",
    "present_kp": [
      "architecture",
      "redis"
    ],
    "absent_kp": [
      "real time",
      "aws",
      "apache kafka"
    ]
  },
  {
    "text": "how to remap keys using xkb/symbols/us file in ubuntu?. i have dropped some water on my keyboard and only one key is not working which is the down key. i want now to use some other keys such as right alt or menu key between right-alt and right-ctrl keys as i do not use them very often. i have open the us file in ...xkb/sybmols/us file, however, i am very confused and could not find the up, down, left and right keys. can anyone help me to remap the down key to the menu key on the keyboard? thanks",
    "present_kp": [
      "ubuntu",
      "xkb"
    ],
    "absent_kp": [
      "keyboard shortcuts",
      "keyboard layout"
    ]
  },
  {
    "text": "why is mediawiki auto-linking the word files. our mediawiki installation is auto-linking the word files. sohere are some files: a, b, cwould result in the word files being linked to http://ourhost/mediawiki/files.why is that happening and how do i make it stop? i can use the nowiki tag, but perhaps it does not surprise you that the word files appears often, and it is aggravating to use that tag all the time.here is some info on our mediawiki installation from special:version. yes, it's old.installed softwareproduct versionmediawiki 1.16.5php 5.2.14-pl0-gentoo (apache2handler)mysql 5.0.84installed extensionsparser hooks googledocs4mw (version 1.1) adds tag for google docs' spreadsheets display jack phoenix syntaxhighlight (version 1.0.8.6) provides syntax highlighting using geshi highlighter brion vibber, tim starling, rob church and niklas laxstrmwebservicesequencediagram(version 1.0) render inline sequence diagrams using websequencediagrams.com eddie olsson other mwsearch mwsearch plugin kate turner and brion vibberextension functions efluceneprefixsetupparser extension tags gallery, googlespreadsheet, html, nowiki, pre, sequencediagram, source and syntaxhighlightparser function hooks anchorencode, basepagename, basepagenamee, defaultsort, displaytitle, filepath, formatdate, formatnum, fullpagename, fullpagenamee, fullurl, fullurle, gender, grammar, int, language, lc, lcfirst, localurl, localurle, namespace, namespacee, ns, nse, numberingroup, numberofactiveusers, numberofadmins, numberofarticles, numberofedits, numberoffiles, numberofpages, numberofusers, numberofviews, padleft, padright, pagename, pagenamee, pagesincategory, pagesize, plural, protectionlevel, special, subjectpagename, subjectpagenamee, subjectspace, subjectspacee, subpagename, subpagenamee, tag, talkpagename, talkpagenamee, talkspace, talkspacee, uc, ucfirst and urlencode",
    "present_kp": [
      "mediawiki"
    ],
    "absent_kp": []
  },
  {
    "text": "tensorflow rnn not learning when output included in training variables. i have been attempting to train a rnn on a set of time series data. the goal is to predict one of six categorical outputs. the input is given as 5 time steps of 14 inputs, six of which at one-hot attributes for the output. there is an output at each time step, but the goal is to use previous recorded time spots and their human-assigned outputs to assign an output to the most recent event. confusingly the rnn is unable to learn that one of the inputs is in fact the output of the classification. this is simply a sanity check for me, but it seems that it may indicate a larger underlying problem.the data is heavily imbalanced, 91%, 4%, 2%, 1%,<1%,<1%, but a cost function is being use to weight mis-classification inversely to it's make-up in the data set. could the imbalance cause this issue? i'm using 60,000 training examples right now, is this not enough?i'm working off of this dynamic rnn model: <url> the additional matrix multiplication for a hidden layer. is this done correctly?def dynamicrnn(x, seqlen, weights, biases):# prepare data shape to match 'rnn' function requirements# current data input shape: (batch_size, n_steps, n_input)# required shape: 'n_steps' tensors list of shape (batch_size, n_input)# permuting batch_size and n_stepsx = tf.transpose(x, [1, 0, 2])# reshaping to (n_steps*batch_size, n_input)x = tf.reshape(x, [-1,n_input])x = tf.matmul(x, weights['hidden'])+ biases['hidden']# split to get a list of 'n_steps' tensors of shape (batch_size, n_input)x = tf.split(0, n_steps, x)# define a lstm cell with tensorflowlstm_cell = rnn_cell.basiclstmcell(n_hidden, forget_bias=1.0)# get lstm cell output, providing 'sequence_length' will perform dynamic# calculation.outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32, sequence_length=seqlen)# when performing dynamic calculation, we must retrieve the last# dynamically computed output, i.e, if a sequence length is 10, we need# to retrieve the 10th output.# however tensorflow doesn't support advanced indexing yet, so we build# a custom op that for each sample in batch size, get its length and# get the corresponding relevant output.# 'outputs' is a list of output at every timestep, we pack them in a tensor# and change back dimension to [batch_size, n_step, n_input]outputs = tf.pack(outputs)outputs = tf.transpose(outputs, [1, 0, 2])# hack to build the indexing and retrieve the right output.batch_size = tf.shape(outputs)[0]# start indices for each sampleindex = tf.range(0, batch_size) * n_steps + (seqlen - 1)# indexingoutputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)# linear activation, using outputs computed abovereturn tf.matmul(outputs, weights['out']) + biases['out']",
    "present_kp": [
      "tensorflow"
    ],
    "absent_kp": []
  },
  {
    "text": "making a header row in a google spreadsheet. is there a way to put text in a row at the top of a spreadsheet, like a header? so it is separate and fixed from the columns below it? in other words, i want a header row at the top and the columns below it in different widths from the columns in the header row.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "variant of subset sum problem with changing bound. given a sequence of decreasing integers, i.e., $a_1 \\geq a_2 \\geq \\cdots \\geq a_t $ and a positive real $k\\geq 1$, find a subset $s$ such that$$\\max_{s\\subseteq \\{1,\\ldots,t\\}} \\sum_{i\\in s} a_i$$$$s.t., \\sum_{i\\in s/\\{t\\}} a_i \\leq k \\cdot a_t,$$where $a_t$ represents the smallest one of subset $s$. note that $a_t$ is the smallest of set $s$ and may be different for different set $s$. i am wondering whether this problem is still np-complete. any comments or suggestions will be very appreciated.",
    "present_kp": [
      "subset sum"
    ],
    "absent_kp": [
      "np hardness",
      "partition problem"
    ]
  },
  {
    "text": "port numbers for ssl. we have an existing web site with http on port 80 and https on port 443. i'm adding a second site to that now, and from what i understand, i cannot host two sites on the same ssl port. so my question is: which port number range is appropriate for me to use as my ssl port on the second site?",
    "present_kp": [
      "https"
    ],
    "absent_kp": [
      "server",
      "iis7",
      "iis",
      "configuration"
    ]
  },
  {
    "text": "best practice for ensuring name uniqueness/correctness in message queues in a microservice architecture/distributed system. i was wondering what a good solution would be for ensuring that queue-names are entered correctly and are only used by the correct applications in a large system which uses message queues to exchange messages.we have a large system written in java and apache camel. it is split into several microservices where they use message queues to communicate with each other. the queue names are as of now strings, which tend to get pretty simple, like incupdate or inccreate. when the system continues to grow and we continue to add more services i am worried that someone is going to reuse a queue-name that already exists, which would create bugs that would not show up in local testing and would be hard to debug. an easy solution to this is to simply add the service name as a prefix to the queue-name, this would ensure uniqueness between the services.but i was thinking, why not take it a little further?what if i created a reference, that all services had access to, for example an enum, where each service would only use entries in the reference as the queue-names? this way it would not only ensure uniqueness, but it would also ensure correctness (for example typos in queue-names). and it would also provide code-highlighting for wherever each queue-name is used.do you have any solutions or suggestions for a problem like this? is the reference-solution viable at all? i can see one problem with it, and it's that each service actually has to have access to the enum, which means injecting it from somewhere. i think we could use maven or spring for this, but i am not sure.",
    "present_kp": [
      "java",
      "spring",
      "message queue",
      "microservices"
    ],
    "absent_kp": []
  },
  {
    "text": "saving a pointer to the n/4 node in avl tree. i have an avl tree which every node has a filed with a key which is an integer. i need to save a pointer to the minimum , maximum and the $\\left \\lfloor rac{n}{4} ight floor $ nodes. the first and the second were pretty easy i just saved a pointer between each node and its follow and back nodes. but i couldn't find a way to save the $\\left \\lfloor rac{n}{4} ight floor$ one. any ideas? thank you.",
    "present_kp": [],
    "absent_kp": [
      "data structures",
      "trees",
      "search trees",
      "balanced search trees"
    ]
  },
  {
    "text": "kvm - how to use a usb as storage. i'm on debian testing.i'm trying to install a vm on a storage which is located on a ext4 formated usb stick. however i'm getting a permission error before the os can be installed. i'm using virtual machine manager:unable to complete install: 'cannot access storage file '/media/user/mnt/generic.qcow2' (as uid:121, gid:131): permission denied'traceback (most recent call last): file /usr/share/virt-manager/virtmanager/asyncjob.py, line 88, in cb_wrapper callback(asyncjob, *args, **kwargs) file /usr/share/virt-manager/virtmanager/create.py, line 2288, in _do_async_install guest.start_install(meter=meter) file /usr/share/virt-manager/virtinst/guest.py, line 461, in start_install doboot, transient) file /usr/share/virt-manager/virtinst/guest.py, line 396, in _create_guest self.domain = self.conn.createxml(install_xml or final_xml, 0) file /usr/lib/python2.7/dist-packages/libvirt.py, line 3777, in createxml if ret is none:raise libvirterror('virdomaincreatexml() failed', conn=self)libvirterror: cannot access storage file '/media/user/mnt/generic.qcow2' (as uid:121, gid:131): permission deniedi mounted the usb using the following command:sudo mount -t ext4 /dev/sdb1 /media/user/mnt -o rwi have also tried to chmod 777 on the mount point while the usb was mounted as well as on the storage file itself (generic.qcow2).further i changed the owner of the mount point to libvirt-qemu (uid=121) however the error still persists.how can i provide the appropriate permissions to be able to install the os?",
    "present_kp": [
      "permissions",
      "virtual machine",
      "kvm"
    ],
    "absent_kp": []
  },
  {
    "text": "limiting number of processes by name. is it possible to limit number of processes for a given group or user using the process name? eg. i'd like to groups remotes have only 5 simultaneous ssh processes that are run on my server.i don't see any options in pam_limit (i can only limit number of process per user or group, regardless of process name) and i don't see ability in cgroups.do you have any ideas how to accomplish this? (script in cron is not an answer for me :))",
    "present_kp": [
      "process",
      "limit"
    ],
    "absent_kp": []
  },
  {
    "text": "iptables nat on debian openvz. so i want to create a nat rule for an openvpn server.after getting trouble with the tap/tun devices, it's finally working i think.now i have to make a nat rule like so : >iptables -t nat -a postrouting -s 172.16.0.0/24 -o venet0:1 -j masquerade iptables v1.4.14: can't initialize iptables table 'nat': table does not exist (do you need to insmod?)perhaps iptables or your kernel needs to be upgraded.but it doesn't work. i searched a lot and found another commandiptables -t nat -a prerouting -i tun0 -j dnat --to-destination 5.135.###.###this command does the same result as the previous one.don't know what to do.i ask the host to enable nat but he tell me that i have to do it on my own.",
    "present_kp": [
      "debian",
      "iptables",
      "nat",
      "openvz"
    ],
    "absent_kp": []
  },
  {
    "text": "switching to a virtual terminal is slow. when switching to a virtual terminal using e.g. ctrl+alt+f2, it takes about a second to switch. not too horrible for something that's typically rarely used, but i would like to use it more and it's substantially slower than, say, alt+tab. it's particularly weird since switching back to the desktop environment (alt+f7 for me) is instant.i've noticed it before, but currently i'm running debian testing (stretch) with cinnamon 2.8.7 on x 1.18.3. the resolution of the virtual terminal is the same as x's resolution.what is this delay caused by and how can i improve it?",
    "present_kp": [],
    "absent_kp": [
      "console"
    ]
  },
  {
    "text": "reference for dudley's chaining integral. dudley's chaining integral is commonly used to bound rademacher complexities. i recall seeing several papers give this as the reference@article{mr512411, author = {dudley, r. m.}, title = {central limit theorems for empirical measures}, journal = {ann. probab.}, year = {1978}, volume = {6}, pages = {899--929 (1979)}, number = {6}, coden = {apbyae}, fjournal = {the annals of probability}, issn = {<phone>}, mrclass = {60f05 (28c20 60b10 60f17)}, mrnumber = {mr512411 (81k:60029a)}, mrreviewer = {p. r{'e}v{'e}sz}}but i don't think the result in question actually appears in that paper. could anyone point me to the definitive reference?",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "machine learning",
      "lg.learning"
    ]
  },
  {
    "text": "requesting user input while reading file line by line. for class i need to write a bash script that will take the output from ispell and when i try and request user input inside the while loop it just saves the next line of the file as the user input.how could i go about requesting user input in the while loop?#!/bin/bash#returns the misspelled words#ispell -l < file#define varsispell_output_file=output.tmp;input_file=$1ispell -l < $input_file > $ispell_output_file;#echo a new line for give space between command#and the output generatedecho ;while read line;do echo '$line' is misspelled. press enter to keep; read -p this spelling, or type a correction here: user_input; if [ $user_input != ] then echo input: $user_input; fi echo ; #echo a new linedone < $ispell_output_file;rm $ispell_output_file;",
    "present_kp": [
      "bash",
      "user input"
    ],
    "absent_kp": [
      "shell script",
      "control flow"
    ]
  },
  {
    "text": "is there any good/fundamental reason that python classvars, and javascript prototype inheritance, don't mutate the parent on assignment?. in python, if you have a classvar, it's accessible from an instance, but if you set the variable on the instance it doesn't actually change the classvar, rather it assigns a new name which shadows the parent value:>>> class foo:... classvar = 10...>>> f = foo()>>> (foo.classvar, f.classvar)(10, 10)>>> f.classvar = 30>>> (foo.classvar, f.classvar)(10, 30)>>> foo.classvar = 9>>> (foo.classvar, f.classvar, foo().classvar)(9, 30, 9)this is exactly akin to prototype inheritance in javascript:> var proto = {x: 10};> function bar() { }> bar.prototype = proto;> var b = new bar(); > [proto.x, b.x][10, 10]> b.x = 30> [proto.x, b.x][10, 30]> proto.x = 9> [proto.x, b.x, (new bar()).x][9, 30, 9]of course, if the child mutates the value, then it is seen in the parent, because the variable was not re-assigned and so no shadowing occurred:>>> class foo:... classvar = [10]...>>> f = foo(); f.classvar[10]>>> f.classvar[0] = 30>>> (foo.classvar, f.classvar)([30], [30])my question is: is there any good reason for this? it seems like it would be less of a gotcha if the assign semantics were assign on any parent if the value exists there, otherwise create the new value.i ask because i'm designing my own language and, as i get to choose what the semantics are, i'm wondering if i should break from the herd and do what seems like less of a gotcha.",
    "present_kp": [
      "design",
      "javascript",
      "python",
      "semantics"
    ],
    "absent_kp": [
      "programming languages"
    ]
  },
  {
    "text": "easier way to dig into docs. i would to know a way to dig into vim and plugin doc easily. i saw mentions about doc ctrlp documentation or commandt.i would like easier documentation discovery for functions, motions, commands i don't know.thanks",
    "present_kp": [],
    "absent_kp": [
      "help system",
      "plugin ctrlp"
    ]
  },
  {
    "text": "hg:command not found. i am trying to clone a repository from bitbucket, and i installed mercurial, and copied the https command. when i run this command i still get hg: command not found, why is this?",
    "present_kp": [
      "mercurial"
    ],
    "absent_kp": []
  },
  {
    "text": "can't log out of facebook. for two days, we have not been able to log out of our facebook account. if we cannot log out the normal way, how can we do this?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": [
      "security"
    ]
  },
  {
    "text": "how do you encode algebraic data types in a c#- or java-like language?. there are some problems which are easily solved by algebraic data types, for example a list type can be very succinctly expressed as:data conslist a = empty | conscell a (conslist a)consmap f empty = emptyconsmap f (conscell a b) = conscell (f a) (consmap f b)l = conscell 1 (conscell 2 (conscell 3 empty))consmap (+1) lthis particular example is in haskell, but it would be similar in other languages with native support for algebraic data types.it turns out that there is an obvious mapping to oo-style subtyping: the datatype becomes an abstract base class and every data constructor becomes a concrete subclass. here's an example in scala:sealed abstract class conslist[+t] { def map[u](f: t => u): conslist[u]}object empty extends conslist[nothing] { override def map[u](f: nothing => u) = this}final class conscell[t](first: t, rest: conslist[t]) extends conslist[t] { override def map[u](f: t => u) = new conscell(f(first), rest.map(f))}val l = (new conscell(1, new conscell(2, new conscell(3, empty)))l.map(1+)the only thing needed beyond naive subclassing is a way to seal classes, i.e. a way to make it impossible to add subclasses to a hierarchy.how would you approach this problem in a language like c# or java? the two stumbling blocks i found when trying to use algebraic data types in c# were:i couldn't figure out what the bottom type is called in c# (i.e. i couldn't figure out what to put into class empty : conslist< ??? >)i couldn't figure out a way to seal conslist so that no subclasses can be added to the hierarchywhat would be the most idiomatic way to implement algebraic data types in c# and/or java? or, if it isn't possible, what would be the idiomatic replacement?",
    "present_kp": [
      "java",
      "c#",
      "scala",
      "haskell",
      "algebraic data type"
    ],
    "absent_kp": []
  },
  {
    "text": "how to represent oop concepts in algorithms in a standard way?. i have usually been using the cormen algorithm format to teach some introductory courses in programming. i mean something like this:treesearch(k,n)1. if x==nil or k==x.key2. return x3. if k<x.key4. return treesearch(k.left,n)5. else return treesearch(k.right,n)actually i have not agree with a couple of lecturers in my institution that they insist to put the type of the variable that they are using in the algorithm. i mean, to do that, will it not be to make a bias toward the programming language and not to focus on the algorithm? for example what would happen if the student grab other programming language, like r or python, that really do not care about the type of variable.the other issue that i have is how to represent oop algorithms in a nice algorithmic way. for example when i make a constructor should i put something like:class: carattributes: wheelsconstructor car()or something likeclass: carfunction car()also when i come to the part of inheritance, one of my colleages put the word super() to define inheritance in an algorithmic way, but again i think that is too java-way to do this part. usually they teach in that way because the practical part is made in java, but again i think that the algorithm should be more freely, directly towards the logic, and not to an specific programming language.does anybody knows some standard to represent algorithms for oop?",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "terminology",
      "education",
      "object oriented",
      "didactics"
    ]
  },
  {
    "text": "filter output of command by color. i am running a utility that doesn't offer a way to filter its output. nothing in the text of the output indicates that a particular function failed but it does show in red. the output is so long that at the end when it reports some # of errors i can't always scroll to see the output where the error occurred.how can i filter out non-red text?pseudo code:dolongtask | grep -color rededitthe command outputs other colors as well and i need to be able to filter out all text that isn't red. also the text coloring is multiline.",
    "present_kp": [
      "grep",
      "colors",
      "text",
      "filter"
    ],
    "absent_kp": []
  },
  {
    "text": "bash globbing variable substitution?. possible duplicate:batch renaming files i want to rename files using their existing name as a base for the new one.so if i can ls these files withls blue*+(.png)i'd want to rename them something likemv blue$(*)+(.png) $(1).pngexcept that doesn't work obviously. is there syntax for these kind of variables in bash globbing or is there an easier way?",
    "present_kp": [
      "bash",
      "rename",
      "variable substitution"
    ],
    "absent_kp": [
      "shell",
      "wildcards"
    ]
  },
  {
    "text": "warshall's algorithm for transitive closure. i was going through this code for implementing warshall's algorithm. i think the time complexity for this simple problem is huge because there are too many loops running here. the time complexity for this code should be \\$o(n^3)\\$. is there a way to optimize this code so that the time complexity can be reduced a bit?#include<stdio.h>#include<unistd.h>#include<math.h>int maximum(int,int);void warshal(int p[10][10],int n){int i,j,k;for(i=1;i<=n;i++) for(j=1;j<=n;j++) for(k=1;k<=n;k++) p[i][j]=maximum(p[i][j],p[i][k]&&p[k][j]);}int maximum(int a,int b){ ;if(a>b)return(a);elsereturn(b);}void main(){int p[10][10]={0},n,e,u,v,i,j; printf( enter the number of vertices:); scanf(%d,&n); printf( input values now ); for(i=1;i<=n;i++) for(j=1;j<=n;j++) scanf(%d,&p[i][j]); printf( matrix of input data: ); for(i=1;i<=n;i++) { for(j=1;j<=n;j++) printf(%d ,p[i][j]); printf( ); } warshal(p,n); printf( transitive closure: ); for(i=1;i<=n;i++) { for(j=1;j<=n;j++) printf(%d ,p[i][j]); printf( ); } }",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "performance",
      "beginner"
    ]
  },
  {
    "text": "what makes a large and complex software product slow?. for a reason that is largely irrelevant, i installed delphi 7 once again in such a long time. i have to say, i was completely blown away - in a way i haven't been for rather a while. this is not how i remember things at all. the installation took around 30 seconds. launching it took 2 seconds, and it was immediately usable. i can press run the second after it started, and less than a second later the blank program is already visible and running. hurray for computers getting so much faster!but the reason i've been blown away like this is because usually i use visual studio 2010, that doesn't feel snappy like this at all. granted, delphi 7 is a much smaller system than visual studio 2010, but it does have the appearance of having all the really necessary things there: a control palette, a form designer, a code editor with code completion. i realise that the language might be simpler, and the code completion might be a lot less powerful, and the ide might not be nearly as extensible and feature-rich, but still: i do not understand how (i.e. through what mechanism) does having a lot of extra features (that i might not have even triggered yet) cause a system like visual studio to always feel sluggish in comparison.i would like to ask people experienced in working with systems the scale of visual studio: what is it that makes them slow? is it the layers upon layers of abstractions required to keep the codebase within the human comprehension capabilities? is it the sheer amount of code that needs to be run through? is it the modern tendency towards programmer-time-saving approaches at the (mindbogglingly huge) expense in the clock cycles / memory usage department?",
    "present_kp": [],
    "absent_kp": [
      "architecture",
      "performance"
    ]
  },
  {
    "text": "how iconify xterm when it loses focus?. i am attempting iconify a xterm terminal when it loses focus in fluxbox.i am following this wiki:<url> so far, i've got it appending this linecontrol t : if {matches (xterm)} {delay {iconify} 1}to ~/.fluxbox/keys file, which iconify the terminal when i press control t shortcut.how can i get that behavior when xterm loses the focus?",
    "present_kp": [
      "xterm",
      "fluxbox"
    ],
    "absent_kp": [
      "linux",
      "slackware"
    ]
  },
  {
    "text": "not mounting nfs shared folders with vagrant libvirt provider in debian jessie. i have a problem with vm virtualization and vagrant libvirt provider for mounting nfa shared folders.with the help of @infernix in github, i was able to properly install the instance of libvirt but the problem now is to mount the shared directory with the vm.references to installation:<url> never see error in mount nfs with vagrant before. :o==> default: exporting nfs shared folders...==> default: preparing to edit /etc/exports. administrator privileges will be required... nfs-kernel-server.service - lsb: kernel nfs server supportloaded: loaded (/etc/init.d/nfs-kernel-server)active: active (exited) since sun 2016-12-18 20:21:10 brst; 15h ago=> default: mounting nfs shared folders...the following ssh command responded with a non-zero exit status.vagrant assumes that this means the command failed!mount -o vers=3,udp 192.168.121.1:/home/tosystems/documents/projects /home/vagrant/vagrant_projectsresult=$?if test $result -eq 0; thenif test -x /sbin/initctl && command -v /sbin/init && /sbin/init 2>/dev/null --version | grep upstart; then /sbin/initctl emit --no-wait vagrant-mounted mountpoint=/home/vagrant/vagrant_rojectsfielse exit $resultfistdout from the command:stderr from the command:stdin: is not a ttymount.nfs: rpc.statd is not running but is required for remote locking.mount.nfs: either use '-o nolock' to keep locks local, or start statd.mount.nfs: an incorrect mount option was specified.i follow the @halosghost hints in link below, but i not succeeded.mount linux nfs. rpc.statd is not runningi changed the synced_folders parameter in vagrant file and added:config.vm.synced_folder ~/documents/projects, /home/vagrant/vagrant_projects, type: nfs, nfs_version: 4, nfs_udp: false, mount_options: [rw, vers=4, tcp]but output here yet:==> default: preparing to edit /etc/exports. administrator privileges will be required... nfs-kernel-server.service - lsb: kernel nfs server support loaded: loaded (/etc/init.d/nfs-kernel-server) active: active (exited) since sun 2016-12-18 20:21:10 brst; 19h ago==> default: mounting nfs shared folders...the following ssh command responded with a non-zero exit status.vagrant assumes that this means the command failed!mount -o vers=4,rw,vers=4,tcp 192.168.121.1:/home/tosystems/documents/projects /home/vagrant/vagrant_projectsresult=$?if test $result -eq 0; thenif test -x /sbin/initctl && command -v /sbin/init && /sbin/init 2>/dev/null --version | grep upstart; then/sbin/initctl emit --no-wait vagrant-mounted mountpoint=/home/vagrant/vagrant_projectsfielseexit $resultfistdout from the command:stderr from the command:stdin: is not a ttymount.nfs: connection timed outour efforts did not help in the end.. edit: uzing rsync: ==> default: rsyncing folder: /home/tosystems/ => /vagrantthere was an error when attempting to rsync a synced folder.please inspect the error message below for more info.host path: /home/tosystems/guest path: /vagrantcommand: rsync --verbose --archive --delete -z --copy-links --no-owner --no-group --rsync-path sudo rsync -e ssh -p 22 -o loglevel=fatal -o controlmaster=auto -o controlpath=/tmp/ssh.661 -o controlpersist=10m -o identitiesonly=yes -o stricthostkeychecking=no -o userknownhostsfile=/dev/null -i '/home/tosystems/.vagrant/machines/default/libvirt/private_key' --exclude .vagrant/ /home/tosystems/ <email>/vagranterror: symlink has no referent: /home/tosystems/.config/google-chrome/singletoncookiesymlink has no referent: /home/tosystems/.config/google-chrome/singletonlockrsync: write failed on /vagrant/.vagrant.d/boxes/ubuntu-amd64/0/libvirt/box.img: no space left on device (28)rsync error: error in file io (code 11) at receiver.c(393) [receiver=3.1.1]rsync: [sender] write error: broken pipe (32)please, i need you help.",
    "present_kp": [
      "debian",
      "nfs",
      "vagrant",
      "libvirt"
    ],
    "absent_kp": []
  },
  {
    "text": "installing video driver on arch linux. i have arch linux installed in console mode on an intel-pc machine. my task is to write and run an opengl display program on the machine to check whether it meets the following conditions:it would take at most 10% of total cpu usageit would take at most 20% of total ramhere are more info about the device:uname -a3.6.5-1-arch #1 smp preempt wed oct 31 .. x86_64 gnu/linuxcpu mhz: 1866.717ram: 2gbpreemptible: yeslspci -v | grep -i graphic*vga compatible controller: intel corporation mobile 4 series chipset integrated graphics controller (rev 07) (prog-if 00 [vga controller])(same for subsystem and graphics controller)now, what i want if to install the relevant graphics driver. however, i cannot do anything as it is run in console mode. it has no x window. i try alt+f8 but it does not start x window. also tried startx,but i get -bash:startx: command not foundcould anyone guide me how to install the graphics driver please. considering that i think the kernel is compiled in preemptive mode.",
    "present_kp": [
      "arch linux",
      "console",
      "graphics"
    ],
    "absent_kp": [
      "drivers"
    ]
  },
  {
    "text": "bash - reading user variable into bash script grep. i've tried every possible combination to get this bash script working. it's part of a larger script, and it basically prompts for a username (to check if it exists) and returns the appropriate response:#! /bin/bash# script to see if user existsclearecho -n enter user to check: read $uzergrep -c '^${uzer}:' /etc/passwdif [ $? -eq 0 ]; then echo user does exist :)else echo no such userfiin terminal the following works fine:grep -c '^devuser1:' /etc/passwdreturns: 1grep -c '^devuser1234:' /etc/passwdreturns: 0i've tried many combinations of passing the read variable into '^${uzer}:' with no joy. any ideas what else i can try?",
    "present_kp": [
      "bash",
      "variable"
    ],
    "absent_kp": [
      "regular expression"
    ]
  },
  {
    "text": "filtering the colored output of grep. i'm on osx, but i suspect this doesn't make a big difference for this question.in my .bash_profile, i aliased grep to get color outputs by default:alias grep='grep --color=always'i commonly run searches for content within files in my repositories in ways similar to:grep --include=*.cpp -ern . -e (foo|bar)but i often want to further refine the results, typically piping with say grep -v colorbar.the problem is that the second grep command then runs on the colored ouput, and doesn't seem to be able to match the exclusion patterns because of this.obviously i could run the first search without colors and then everything would work fine, but i would prefer to keep them if there is a way to work around this?",
    "present_kp": [
      "grep",
      "colors"
    ],
    "absent_kp": []
  },
  {
    "text": "merge lines between keywords into one-line comma separated values. between first occurrence of cat to next occurrence of cat, it should create a separate line with delimiter as ,.file input as below.cataabbcccataa-1bb-1cc-1output expected:cat,aa,bb,cccat,aa-1,bb-1,cc-1",
    "present_kp": [],
    "absent_kp": [
      "text processing",
      "awk",
      "sed",
      "perl"
    ]
  },
  {
    "text": "does duplicate content on another site affect my ranking?. a competitors set up a new site and copy and pasted some copy from our home page.when doing a comparison with a duplicate content tool the result was that the pages where 21% similiar.does the fact they have copied our content affect our site?their site has seen an increase in their ranking recently and ours ahs dropped slightly",
    "present_kp": [
      "content",
      "ranking"
    ],
    "absent_kp": [
      "seo",
      "google"
    ]
  },
  {
    "text": "is there a google docs (or -spreadsheets) api to scroll the view?. if i want to scroll to a particular paragraph in google docs, or a particular cell in google spreadsheets, is there a way to do that via google apps script?",
    "present_kp": [
      "google spreadsheets"
    ],
    "absent_kp": [
      "google drive"
    ]
  },
  {
    "text": "faster way to perform function calculation in python?. i'm interested in whether there is a way to further improve a fast version of a function used in a homework assignment i received recently (i've already submitted the completed work).from math import logdef func_fast(mass, density): return sum(map((log(mass * density)).__truediv__, range(1,10001)))def func_slow(mass, density): total = 0.0 for i in range(10000): masslog = log(mass * density) total += masslog/(i+1) return totalmass = 2.5 density = 12.0the fast version times in around 2-2.5ish seconds while the slow version nets 6-7 seconds.",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "performance",
      "python 3.x"
    ]
  },
  {
    "text": "how to achieve root privilege in metasploitable 2 linux?. suppose, i have just entered the metasploitable 2 linux like the following command:username : msfadminpassword : msfadminnow, i need to gain 'root' privilege so that i do not need to use 'sudo' - command again and again. for example, in order to shutdown the machine i just want to type:shutdown -h 1not,sudo shutdown -h 1how to do that?",
    "present_kp": [
      "metasploit"
    ],
    "absent_kp": []
  },
  {
    "text": "pf blocks all in/out traffic instead of just the one port i wanted to block. i need to block one incoming port with pf. i'm new to pf, and i can't figure out what i'm doing wrong here.here is my entire rule file, made to block incoming port 22:set block-policy droppass in all keep statepass out all keep stateblock in proto tcp to port 22after i start pf with sudo /sbin/pfctl -e -f /path/to/my/rule/file, all my network traffic is blocked. i try to load a webpage, and it won't load until i do sudo /sbin/pfctl -d to disable pf.if i remove the fourth line (block in proto tcp to port 22) from my rule list, nothing is blocked. so what did i do wrong on the fourth line that is causing it to block everything instead of just incoming tcp port 22? all the examples did this similarly.if it matters, my os is os x 10.8.5.",
    "present_kp": [
      "pf"
    ],
    "absent_kp": [
      "osx",
      "firewall"
    ]
  },
  {
    "text": "show only weekends in google calendar. is there a way to only display weekends in google calendar and not the week days?",
    "present_kp": [
      "google calendar"
    ],
    "absent_kp": []
  },
  {
    "text": "installing jre-8u51-linux-x64.rpm on sles 11 sp3: failed dependencies. i tried to update my java installation on a sles 11 sp3 system usingrpm -i jre-8u51-linux-x64.rpm(for some reasons i want to run the original java and not the ibm java provided by suse) and i got the following error message:error: failed dependencies: /usr/sbin/alternatives is needed by jre1.8.0_51-1.8.0_51-fcs.x86_64i see that sles 11 has /usr/sbin/update-alternatives in place of /usr/sbin/alternatives. i am not versed with the details of rpm packaging, how can i fix the rpm package to install on my box? please give the details, not only the greater picture.p.s. the java installation is meant for a servlet container (apache tomcat) running some services including a fedora commons repository.edit (update): with jre-8u65-linux-x64.rpm the dependencies are no longer needed, but the rpm still needs /usr/sbin/alternatives to complete sucessfully (so either provide it as a softlink or edit the rpm file as described in the accepted answer).",
    "present_kp": [
      "rpm",
      "java",
      "dependencies",
      "sles",
      "alternatives"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i exit or cancel a bad bash command?. i expect to get some flak for this, but i can't find the answer anywhere. it seems like it should be so obvious. sometimes, when i type a bad command in a bash terminal, the cursor just jumps down to the next line without any error or anything. i can't tell what i did wrong. it's like i'm stuck in the program. reenactment:$ tidyme: oops! that's not what i meant to type...:qme: that didn't work...:exit:quitexitquit/exit/quit-exit-quit-wtf???i know i screwed up but how do i get back to the prompt without closing the terminal?",
    "present_kp": [
      "terminal"
    ],
    "absent_kp": [
      "shell",
      "command line",
      "kill"
    ]
  },
  {
    "text": "concurrency in hierarchical filesystem databases. i am writing a small program that is a client of some protocol. i wanted this program to have a filesystem database. the main directory would contain one directory for a server that is configured, and the server directory would contain things like server settings in json and other data, this time those are certificates, not sure if certificates would be stored in separate dirs.the question is: if it is possible, even though rare, that multiple instances of this app could access the database, and also this program can run in daemon mode multithreaded, what kinds of locks may be needed for thread and for jvm?for example, should i use a read/write lock for inter thread synchronization + a shared or exclusive file lock? should i lock the whole database, or only the directory near the set of files i want to change, like the server directory?",
    "present_kp": [
      "database"
    ],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "google sites: code block - how to disable wrapping. i'm using google sites to host the wiki-like website. i noticed that code blocks have text wrapped in them. instead, i would like to have the code non-wrapped and with horizontal scrollbar when needed. has anyone accomplished this?i would like to do this without html-markup editing of each post that contains a code block.",
    "present_kp": [
      "google sites",
      "code"
    ],
    "absent_kp": []
  },
  {
    "text": "debian 8 - run scripts after boot. i've tried run some scripts after boot via /etc/rc.local./etc/rc.local#!/bin/sh -e## rc.local## this script is executed at the end of each multiuser runlevel.# make sure that the script will exit 0 on success or any other# value on error.## in order to enable or disable this script just change the execution# bits.## by default this script does nothing./home/startup.shexit 0/home/startup.shmount -t vboxsf test /home/testhere is the result on boothere is the output of systemctl status rc-local.servicerc-local.service - /etc/rc.local compatibility loaded: loaded (/lib/systemd/system/rc-local.service; static) active: failed (result: exit-code) since sun 2016-02-07 22:48:23 ict; 18min ago process: 432 execstart=/etc/rc.local start (code=exited, status=1/failure)feb 07 22:48:23 debian rc.local[432]: /sbin/mount.vboxsf: mounting failed with the error: no such devicefeb 07 22:48:23 debian systemd[1]: rc-local.service: control process exited, code=exited status=1feb 07 22:48:23 debian systemd[1]: failed to start /etc/rc.local compatibility.feb 07 22:48:23 debian systemd[1]: unit rc-local.service entered failed state.i've tried manually running sudo bash /home/startup.sh and it works fine. i've also applied this method on ubuntu 14.04 and no errors occurr.what is the reason behind this failure? how can i fix it?",
    "present_kp": [
      "debian",
      "ubuntu"
    ],
    "absent_kp": [
      "virtualbox"
    ]
  },
  {
    "text": "sitemap file linked from another sitemap file. i currently have a site setup that, in addition to regular static pages, also has a wordpress blog. this results in my main site having a sitemap.xml file listing the basic pages and then a sitemap for the wordpress blog posts. i understand that i could create a sitemap_index file and point to each of the sitemap files, but would it be possible to just link to the wordpress sitemap from my regular sitemap file?for instance:<urlset xmlns=<url> xmlns:video=<url> <loc><url> <changefreq>weekly</changefreq> <lastmod>2013-04-30t14:10:03+00:00</lastmod> <priority>1.0</priority></url>",
    "present_kp": [
      "wordpress",
      "sitemap"
    ],
    "absent_kp": []
  },
  {
    "text": "how to execute a file without execute permissions. let's say user wants to execute a script test.sh but ls -l test.sh gives -rwxrwxr-- 1 root root 96 feb 25 21:44 test.shnow if user doesn't want to make a copy of test.sh (on which he does chmod +x), he can simply dosh test.shto execute test.sh.is there an analogue way to execute binary programs which one doesn't have execute permissions?",
    "present_kp": [
      "permissions"
    ],
    "absent_kp": []
  },
  {
    "text": "which bash will expand {1..$var} in the same way that zsh does. in response to a comment of mine to this question on sf the op asserts that the for i in {1..$num}expands correctly in bash. i have access to bash 4.0.33 (ubuntu), 3.2.25 (centos) and 3.00.16(1) (solaris 10). none of these will expand the {1..$num}. does anyone know which versions of bash do the expansion? if it's not bash what is it ? i know zsh will do the expansion but in the op's script the shebang should remove the possibility of an alias ?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": []
  },
  {
    "text": "write bash function which operates on list of filenames. i want to define the function cpfromserver in bash so that when i run$ cpfromserver xxx yyy zzzthe result is the same as if i had typed$ scp <email>/some/location/xxx/xxx.txt /some/location/xxx/xxx.pdf /some/location/yyy/yyy.txt /some/location/yyy/yyy.pdf /some/location/zzz/zzz.txt /some/location/zzz/zzz.pdf /somewhere/else/where it works for any number of arguments.(that is, the function should copy filename.txt and filename.pdf from the directory /some/location/filename/ on the remote.server to the local directory /somewhere/else/ for every filename i specify as an argument to the function. and do it all in a single ssh connection.)currently, i have written a function that works for a single argument, and i just loop over it, but this establishes separate ssh connections for each argument, which is undesirable.my difficulty is that i only know how to use function arguments individually by their position ($1, $2, etc.) not how to manipulate the whole list.[note that i am writing this function as a convenience tool for my own use only, and so i would prioritize my own ease of understanding over handling pathological cases like filenames with quotation marks or linebreaks in them and whatnot. i know that the filenames i will be using this with are well-behaved.]",
    "present_kp": [
      "bash",
      "scp",
      "function",
      "for"
    ],
    "absent_kp": []
  },
  {
    "text": "showing a list of plugins to filter. how can i refactor this function? i show a list of plugins in jsf, and i should filter them. i added function filterplugins but i have some questions:should we simplify block with conditional expression?i reassign global variable plugins to introduce my filter function (is it not bad practice?)load()@notnull@datamodel(plugins)list<plugin> plugins;public void load() { plugins = pluginmanager.getplugins(); plugins = filterplugins(searchparam); sortingutil.sort(plugins, sortingutil.sorttype.id_asc); if (plugins.size() > 0) { if (plugin != null && plugins.contains(plugin)) { selectplugin(plugin); } else { selectplugin(plugins.get(0)); } } else { plugin = null; }}@suppresswarnings(unchecked)private list<plugin> filterplugins(final string searchparam ){ return (list)iterables.filter(plugins, new predicate<plugin>() { @override public boolean apply(@nullable plugin plugin) { return plugin.getname().contains(searchparam) || plugin.getnetworkclasses().contains(searchparam) || plugin.getclassname().contains(searchparam); } });}@overridepublic void selectplugin(plugin p) { plugin = p; }plugin.javapublic class plugin { private static final long serialversionuid = -8424575107726996696l; @notnull private long id; @notnull private string name; @notnull private string networkclasses; + setters and getters}i want to pay your attention this code interacts with jsf page:<a:support event=onrowclick action=#{configplugins.selectplugin(p)} rerender=pluginlist/><a:commandlink action=#{configplugins.removeplugin(true)} rerender=pluginlist/>",
    "present_kp": [
      "java",
      "plugin"
    ],
    "absent_kp": []
  },
  {
    "text": "when does anchoring improve our judgement?. anchoring is the behavioral pattern where the first piece of information we receive about a situation is what all other data points are compared to. for example, the price of the first menu item we see at dinner, the degree of physical pain experienced when exercising, or perceived positivity or negativity in an interaction with a person -- whatever our first experience of these contexts might be, we're likely to view all information received afterward as being either worse or better than those initial impressions. when ive read about anchoring, its been discussed as a cognitive bias, and it appears to be viewed as a huge blind spot in human reasoning. but if this is such a strong tendency, it must serve us in some contexts (or have served us at one point in time).so, does anchoring ever improves our judgement, instead of deprecating it?",
    "present_kp": [],
    "absent_kp": [
      "perception",
      "behaviorism"
    ]
  },
  {
    "text": "scala as a language for generic programming. i posted the same q at programmers.se, but nobody really helps.in the paper an extended comparative study of language support for generic programming by garcia et al. an interesting comparison of programming languages features for generic programming is given:with the brief explanation of terminology:can anyone assess scala programming language support for generic programming in a view of this framework? i.e. add a column in the first table with explanations and examples if possible.",
    "present_kp": [
      "programming languages"
    ],
    "absent_kp": [
      "typing"
    ]
  },
  {
    "text": "how to design restful uri to get all unread messages?. i'm developing an asp.net mvc web api 2 with .net framework 4.5.1 and c#.i have these entities in database:users, which are members of groups.groups.messages. users can sent messages to a groups.i have this route:config.routes.maphttproute( name: groupmessagesapiroute, routetemplate: api/groups/{groupid}/messages/{messageid}, defaults: new { controller = groupmessages, messageid = routeparameter.optional });with this route i can get all group's messages and one message, with {messageid}, sent to {goupid}.but now i want to get all messages with an id greater than {messageid}. how can i do that?i've thought to create another route like this one:config.routes.maphttproute( name: groupmessagesapiroute, routetemplate: api/groups/{groupid}/messages/{messageid}/unread, defaults: new { controller = groupunreadmessages });i will need another controller, 'groupunreadmessages, to get all unread messages. but i don't know if this is the better approach.",
    "present_kp": [
      "asp.net",
      "rest"
    ],
    "absent_kp": []
  },
  {
    "text": "what is inode for, in freebsd or solaris. i know a little about linux kernel. but for freebsd, the vnode actually is similar to the inode in linux kernel.and there is a inode concept in freebsd or solaris.so my question is: what is inode in freebsd for?below is good to read.thank you.http://hub.opensolaris.org/bin/view/community+group+advocacy/solaris-linux-freebsdall three operating systems use a data abstraction layer to hide file system implementation details from applications. in all three oses, you use open, close, read, write, stat, etc. system calls to access files, regardless of the underlying implementation and organization of file data. solaris and freebsd call this mechanism vfs (virtual file system) and the principle data structure is the vnode, or virtual node. every file being accessed in solaris or freebsd has a vnode assigned to it. in addition to generic file information, the vnode contains pointers to file-system-specific information. linux also uses a similar mechanism, also called vfs (for virtual file switch). in linux, the file-system-independent data structure is an inode. this structure is similar to the vnode on solaris/freebsd. (note that there is an inode structure in solaris/freebsd, but this is file-system-dependent data for ufs file systems). linux has two different structures, one for file operations and the other for inode operations. solaris and freebsd combine these as vnode operations.",
    "present_kp": [
      "freebsd",
      "solaris",
      "inode"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "how can i find the approximate daily traffic of a site which i don't own?. possible duplicate:is there any way to discover the traffic of a site i dont control? i want to find the approximate daily traffic of a site which isn't ours, and the site is located in other country than us (in greece - hence no quantcast or compete.com afaik) and it doesn't use google ads (hence no google ad planner).i know about alexa but the site(s) has/have relatively low traffic and the alexa's rank isn't very useful (same stands to google trends). or perhaps i should look more at alexa's data?any other ideas?ps: i looked before posting here and here. no luck.",
    "present_kp": [
      "traffic"
    ],
    "absent_kp": [
      "statistics",
      "suggestions"
    ]
  },
  {
    "text": "how can we delete a card in trello?. possible duplicate:how do i delete a list or card in trello? i've added some test cards on this project, i wish not to have them anywhere.i've archived them but that's absurd. trying to find a trash can or delete text, no luck so far.how can we delete cards ?",
    "present_kp": [
      "trello"
    ],
    "absent_kp": []
  },
  {
    "text": "how to allow apache to serve a file written by rsyslogd (selinux). i have a an application which is run as a systemd service on rhel7 that makes use of the system journal for logging. to ease monitoring of this application i have configured rsyslogd to write logs from this service (only) to a dedicated log file.i would now like to serve this log file using httpd so that users can easily monitor the application.the problem i am facing is that no matter how i setup the file contexts it seems selinux will prevent me from doing what i want:rsyslog is allowed to write to var_log_thttpd is allowed to read from httpd_sys_content_tas far as i can tell there is no context that will allow writing by rsyslogd and reading from httpd.what can i do to get around this problem? will i end up needing to create a custom policy module?",
    "present_kp": [
      "selinux",
      "rsyslog"
    ],
    "absent_kp": [
      "apache httpd"
    ]
  },
  {
    "text": "ideas how to get my usb audio interface to work with linux?. pulseaudio does not appear to recognize the focusrite scarlett 6i6 usb audio interface. the 2i2, however, is properly recognized and it works as expected. i can't seem to get the 6i6 to work on the same system where the 2i2 worked. both are said to be class compliant usb devices. i also tried the 6i6 on another computer with a fresh system installation (kubuntu 12.04) and the result is the same -- pulseaudio doesn't see the 6i6.here's the only official info i found:linux and focusrite / novation products | focusrite developmenthttp://focusritedevelopmentteam.wordpress.com/2012/04/23/linux-and-focusrite-novation-products/should work: scarlett 2i2, 2i4, 8i6, 18i6, 6i6, 18i8, 18i20, saffire 6 usb mkii (usb audio class 2.0 compatible), forte and itrack solo.my experience is that the 6i6 does not work (while the 2i2 does). i'm hoping someone here has figured it out or can tell me the steps i need to figure it out.$ lsusb[snip other h/w]bus 001 device 006: id 1235:8012 novation ems $ cat /proc/asound/cards[snip other h/w] 1 [usb ]: usb-audio - scarlett 6i6 usb focusrite scarlett 6i6 usb at usb-0000:00:1a.0-1.2, high speed$ pacmd list-cardswelcome to pulseaudio! use help for usage information.>>> 1 card(s) available.[the 6i6 is not shown, only the built-in sound card is shown]i'm running kubuntu 12.04 lts (kde) and system settings -> multimedia -> phonon does not show the 6i6 at all.previously the 2i2 was recognized like this:#lsusb[snip other h/w]bus 003 device 002: id 1235:8006 novation ems $ cat /proc/asound/cards1 [usb ]: usb-audio - scarlett 2i2 usb focusrite scarlett 2i2 usb at usb-0000:04:00.0-1, high speed$ pacmd list-cards welcome to pulseaudio! use help for usage information. >>> 3 card(s) available. [snip other cards] index: 2 name: <alsa_card.usb-focusrite_scarlett_2i2_usb-00-usb>thanks",
    "present_kp": [
      "kde",
      "audio",
      "pulseaudio",
      "kubuntu"
    ],
    "absent_kp": [
      "drivers"
    ]
  },
  {
    "text": "iis sub-domain reverse proxy based on host name. i have a virtual machine in azure running three self hosted applications (not hosted in iis) on three different ports.i can access them at the urls below:my-server.cloudapp.azure.com:8080 my-server.cloudapp.azure.com:8081my-server.cloudapp.azure.com:8082i've purchased a domain name (my-server.company.com) and want to create three subdomains pointing to each respective applicationsapplication-1.my-server.company.comapplication-2.my-server.company.comapplication-3.my-server.company.commy first thought is to install iis on the virtual machine and setup a reverse proxy using url rewrite on the default website as mentioned in this article (<url>).so in this scenario, i would setup cname records for each of the sub-domains to point to my-server.cloudapp.azure.com and then configure the reverse proxy to forward to the different ports (8080, 8081, 8082) based on the host header.is this possible / the best way to go about this?the second question is once i get this working, how can i add ssl? would each sub-domain need its own ssl certificate, in which case how can this work with the setup above (there are no iis websites to bind each certificate to). or could i just use a certificate for my-server.company.com and then offload at the reverse proxy?",
    "present_kp": [
      "subdomain",
      "iis"
    ],
    "absent_kp": [
      "dns"
    ]
  },
  {
    "text": "cqrs + event sourcing - event groups and event propagation. this is my current cqrs use-case setup:command dto is received in application layer handler where we map command dto to appropriate domain objects if needed, re-hydrate aggregate root from repo and call some method on ar class commandhandler{ handle(command command){ dom1 dom1 = new dom1(command.d1); dom2 dom2 = new dom2(command.d2); aggregateroot ar = repo.rehydrate(command.arid); ar.dosmth(dom1, dom2, command.int1); }}inside dosmth method in ar, i don't have immediately event to apply, but i have to pass some args to entity that is part of this ar. so inside dosmth method i have class aggregateroot{ void dosmth(dom1 dom1, dom2 dom2, integer int1){ subent = new orhersubentity(); subent.dosmth(int1); }}now i have sub entity that is activated and generates one domainevent. this domain event should be part of event stream that is saved in eventstore and at same time, it is propagated to any listener in this aggregate root. class subentity{ void dosmth(integer int1){ //validate int1 apply(new subentityevent(int1)); } void when(subentityevent event){ //just modify local fields //used also in event sourcing rehydration }}since second sub entity that is listening to subentityevent is now activated, it performs cpu intense operation and generates somecpuintensecalchappened domainevent. this event should also be part of the event stream that is saved in eventstore. it is also propagated to other sub-entities in same ar but since nobody else listens to it then we have no further processing.class othersubentity{ void listen(subentityevent event){ data = somecpuintensecalc(); apply(somecpuintensecalchappened(data)); } void when(somecpuintensecalchappened event){ //just modify local fields //used also in event sourcing rehydration }}questions:since aggreagateroot is responsible for saving all of the events to event store, how can it know for existence of all of this sub events that happened in it's tree.in this transaction we generated 2 events. should we store them inside event store as array of events, or we should store them simply one event after another. in order for ar to be in consistent state, both events must be applied in single transaction.in othersubentity we have listen method that is listening to subentityevent. since on re-hydration from event store we will call subentity.when(subentityevent event), how to prevent othersubentity.listen to be called at the same time?since aggregate root needs to send 1 resulting message down the pipeline (in my case amqp message), i suppose that this message will actually be projection of this 2 domain events - basically a read model dto. where should i create this model? something similar as read model just with propagation?",
    "present_kp": [
      "cqrs",
      "event sourcing"
    ],
    "absent_kp": [
      "domain driven design"
    ]
  },
  {
    "text": "how can i search for gmail messages on a particular date?. i'm searching for a message on or about a particular date and rather than scrolling through my emails to go back about a year, i'd like to know a search method to only find emails from a particular date or date range. how can i do this with gmail?",
    "present_kp": [
      "gmail",
      "search",
      "date"
    ],
    "absent_kp": []
  },
  {
    "text": "err_ssl_protocol_error apache hosting gitlab. i am hosting gitlab on digital ocean and i have setup gitlab to use apache. when i create a virtualhost for gitlab i get ssl. it works when virtualhost is set to <virtualhost *:80> but then when i change it to my domain i get an error in chrome saying err_ssl_protocol_error. below is my configuration, i don't understand why it doesn't work. i'm no expert in apache and this is the configuration that i got on the gitlab website for apache. <virtualhost example.com:80> servername example.com serversignature off rewriteengine on rewritecond %{https} !=on rewriterule .* https://%{server_name}%{request_uri} [ne,r,l]</virtualhost><virtualhost example.com:443> sslengine on sslhonorcipherorder on sslciphersuite ecdh+aesgcm:dh+aesgcm:ecdh+aes256:dh+aes256:ecdh+aes128:dh+aes:ecdh+3des:dh+3des:rsa+aesgcm:rsa+aes:rsa+3des:!anull:!md5:!dss header add strict-transport-security: max-age=<phone>;includesubdomains sslcompression off sslcertificatefile /etc/letsencrypt/live/example.com/cert.pem sslcertificatekeyfile /etc/letsencrypt/live/example.com/privkey.pem sslcacertificatefile /etc/letsencrypt/live/example.com/chain.pem servername example.com serversignature off proxypreservehost on allowencodedslashes nodecode <location /> require all granted proxypassreverse <url> proxypassreverse <url> </location> rewriteengine on rewritecond %{document_root}/%{request_filename} !-f [or] rewritecond %{request_uri} ^/uploads/.* rewriterule .* <url>%{request_uri} [p,qsa,ne] requestheader set x_forwarded_proto 'https' requestheader set x-forwarded-ssl on documentroot /opt/gitlab/embedded/service/gitlab-rails/public</virtualhost>i want to set multiple sites up on the same server and i only want to get to my gitlab server with a certain domain, which is why i am setting this up in apache",
    "present_kp": [
      "gitlab"
    ],
    "absent_kp": [
      "apache httpd",
      "apache virtualhost"
    ]
  },
  {
    "text": "searching word or phrase among files. i've written a program:import java.io.file;import java.io.filenamefilter;import java.io.ioexception;import java.util.arraylist;import org.apache.commons.io.fileutils;/** * * @author mohammad faisal */public class filecontentmatcher {public static void main(string[] args) throws ioexception { string texttomatch = quick styles gallery on; arraylist<string> paths = new arraylist<string>(); string content; int found = 0; int notfound = 0; filenamefilter filter = new filenamefilter() { public boolean accept(file dir, string name) { return name.endswith(.txt); } }; file path = new file(e:\\anchit\\temp); file[] listoffiles = path.listfiles(filter); for (file file : listoffiles) { content = fileutils.readfiletostring(file); if (content.contains(texttomatch)) { //system.out.println(found in: + file.getabsolutepath()); paths.add(file.getabsolutepath()); found++; } else { //system.out.println(no found + content); notfound++; } } for (string pth : paths) { system.out.println(pth); } system.out.println(found in + found + files. not found in + notfound + files.);}}in which i've used apache commons io api.my actual requirement is to list all the files in the given directory which contains the search phrase texttomatch in minimum amount of time about 4-5 seconds, where number of files could be upto 100000. but this program takes much more time than that.so i need to optimize this code but not getting how?is there any api which can help me? i've heard of lucene but not getting how to work with it.",
    "present_kp": [
      "java",
      "search"
    ],
    "absent_kp": [
      "optimization"
    ]
  },
  {
    "text": "how can i copy the subject title in inbox by gmail to clipboard?. is there a way to access the subject title of an email in inbox by gmail to copy it to clipboard?figure 1. example subject title in inbox by gmail",
    "present_kp": [
      "inbox by gmail"
    ],
    "absent_kp": []
  },
  {
    "text": "what type of hmm-gmm i need. context: i have 100 speech sentences that i asked my friend to speak. the vocabulary in the sentences are same but only the order of words are changed. my friend says that he spoke exactly what was asked for each sentence. but i don't know whether he spoke exactly that sentence or something else. what i have here is those 100 reference sentences against which i need to match his speech samples. as i want to do it by computer and not by listening manually therefore i am seeking your guidance.data: i have been able to segment the words in each speech sample of my friend. so i have 100 sentences each segmented into individual words with sequence of each word preserved for each sentence. i have extracted required features from each word (mfcc + delta and delta delta).what i am looking for: i need your guidance and help in informing how can i recognize these words with over 95% accuracy. as i read many papers and articles, gmm + hmm is the reasonably good way to do this. but i have a confusion, when i have already segmented every sentence, why should i try to match the entire speech sentence by transitioning state to state using hmm? i can simply match each word and see if the sequence is same with respect to the reference sentence word sequence. is gmm + hmm the way to go for this? can i use dtw or neural network or svm to classify (matching or not matching) each word and get high accuracy?",
    "present_kp": [],
    "absent_kp": [
      "hidden markov models",
      "speech recognition"
    ]
  },
  {
    "text": "tree search for path finding - algorithm critiques. so, i'm pretty new to ai in general, and am trying to implement a tree-based search from a textfile input (a maze). an example would be:||||||||||||||||||||||| || | | | \\| |||||| | |||||| | \\|||||| | p | \\| .| |||||| || ||||| \\ p = start| |||| | | | / . = goal| ||| ||| | | /|||||||||| |||||| | /| || | /||||||||||||||||||||||i understand the basic algorithms in general (bfs, dfs, a*, etc.), but i want to make sure i'm implementing them correctly, and not somehow cutting corners because i know where the best path is. my basic idea is:parse the file into a 2d arraywhile parsing, if i encounter p, note the start indexwhile parsing, if i encounter ., note the goal indexbegin at index(start), and evaluate surrounding [blank] spacescreate nodes for these, and add the appropriate actions to the current node's available actions --- add these nodes to my frontier que[continue whichever algorithm from here]so i guess my main question is, am i generating my world correctly? is it right to not really create nodes until i encounter them during the search? it seems wasteful to get to a [blank] space, scan the surrounding 4 directions for other [blank] spaces, and if they exist add them to the available actions and create nodes for all possible actions.another alternative would be to generate nodes as i encounter the [blank] spaces, but this would be hard (since i wouldn't be aware of the upcoming blanks) ... should i parse the file completely, and the traverse the stored array to create all possible nodes/links/actions? or is that considered cheating somehow...",
    "present_kp": [
      "search"
    ],
    "absent_kp": [
      "python",
      "artificial intelligence"
    ]
  },
  {
    "text": "getting input from a usb device listed with lsusb. i have a cf-1kb barcode reader connected to an rs232 to ps/2 adaptor and a ps/2 to usb adaptor. i'm not sure how the device works so i'm trying to figure it out by looking at what information i'm getting from the device.when connected to my computer, it gives me[ <phone>] usb 4-1: new low speed usb device using uhci_hcd and address 3[ <phone>] input: generic usb k/b as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.0/input/input16[ <phone>] generic-usb 0003:13ba:<phone>: input,hidraw0: usb hid v1.10 keyboard [generic usb k/b] on usb-0000:00:1a.1-1/input0[ <phone>] input: generic usb k/b as /devices/pci0000:00/0000:00:1a.1/usb4/4-1/4-1:1.1/input/input17[ <phone>] generic-usb 0003:13ba:<phone>: input,hidraw1: usb hid v1.10 mouse [generic usb k/b] on usb-0000:00:1a.1-1/input1output from sudo cat /dev/hidraw0 and sudo cat /dev/hidraw1 gives me either unreproducible gibberish each time i scan something or nothing at all.where can i look to find useful data from the device?",
    "present_kp": [
      "usb"
    ],
    "absent_kp": [
      "hardware"
    ]
  },
  {
    "text": "magento not responding to payment gateway notifications fast enough or at all?. some of our customers are getting to the confirmation of payment step in purchasing from our magento store, and then they are getting a timeout error, where the sagepay payment gateway is trying to contact our server to tell it that a payment was successful (or not) but it cannot contact our server, or cannot get a response from our server in a timely manner, and then the payment/order is being cancelled.i've raised this question to my hosting company, but all they told me was:this is down to the way the software is configured on your serverthis is currently a magento 1.4.0.1 standard installation as far as payment gateways are concerned. what on earth could this statement mean?is there some configuration that i need to do to make magento listen to these requests and respond properly?",
    "present_kp": [
      "magento"
    ],
    "absent_kp": []
  },
  {
    "text": "how to check if currently running linux kernel has been loaded with kexec?. by checking i mean something quite rock-solid, i. e., trying to analyse loader's configuration or available kernel files and matching to uname's output clearly isn't an option.",
    "present_kp": [
      "linux",
      "kexec"
    ],
    "absent_kp": []
  },
  {
    "text": "installing cppman. i've tried to install cppman in fedora 19 or linux mint 15 and it installs successfully. but when i try to use it i get the error:python ioerror: [errno 13] permission deniedi've installed it in ubuntu 12.04 and had no problem. can you help me?update: i fixed this problem, but i have a new problem. when for example i enter cppman cout the output shown is not in right format:1mname0m std::cout - standard output stream1mtype0m object <iostream>1msynopsis0m extern ostream cout;1mdescription0m object of class ostream that represents the standard output stream oriented to narrow characters (of type char ). it corresponds to the c stream stdout.it seems that i need to install or configure something. can you help me?",
    "present_kp": [
      "fedora",
      "linux mint",
      "python"
    ],
    "absent_kp": [
      "vim",
      "software installation"
    ]
  },
  {
    "text": "superscalar processors and complex instructions. i read that a supercalar processor has redundant functional units. one can read this e.g. on wikipedia.how do such redundant units work? is a complex instruction (for accelerating heavy process, for example instructions used in intel ipp, integrated performance primitives) decomposed in micro operations befaure being dispatched among these redudant functional units?what about hardware instructions? like aes-ni?i also read the wikipedia article smt and did not understand the following sentence:superscalar means executing multiple instructions at the same time while thread-level parallelism (tlp) executes instructions from multiple threads within one processor chip at the same time.i don't understand very well the distinction between these two things. can somebody explain the subtleties?",
    "present_kp": [],
    "absent_kp": [
      "computer architecture",
      "parallel computing",
      "concurrency"
    ]
  },
  {
    "text": "mocking the class under test with private method calls. consider the scenario below. it covers multiple methods of my unit under test.public class originalsample{ public bool foo(isomeentity entity) { return entity.isthatso ? entity.isthatso : bar(entity); } public bool bar(isomeentity entity) { return entity.isthataswell; }}[testclass]public class originalsampletest{ [testmethod] public void foo_entitywithso_returnstrue { // arrange mock<isomeentity> someentitymock = new mock<isomeentity>(); mock.setupget(m => m.isthatso).returns( false ); mock.setupget(m => m.isthataswell).returns( true ); // act private bool result = _originalsample.foo( someentitymock.object ); // assert assert.istrue(result); }}however, in my production code there is a lot that i need to mock away that is then used in more method calls. i need to find a way to test the foo method without hitting the bar method.i came up with the scenario as below. however the disadvantage is that i need a interface and pass the instance in each method. i do not like this design. any feedback?public interface inewsample{ bool foo(isomeentity entity, inewsample sample); bool bar(isomeentity entity);}public class newsample : inewsample{ public bool foo(isomeentity entity, inewsample sample) { return entity.isthatso ? entity.isthatso : sample.bar(entity); } public bool bar(isomeentity entity) { return entity.isthataswell; }}[testclass]public class newsampletest{ [testmethod] public void foo_entitywithso_returnstrue { // arrange mock<isomeentity> someentitymock = new mock<isomeentity>(); mock.setupget(m => m.isthatso).returns( false ); mock<inewsample> samplemock = new mock<inewsample>(); samplemock.setup(m => m.bar).returns(false).verify(); // act private bool result = _originalsample.foo( someentitymock.object, samplemock.object ); // assert (that the logic tried to use the 'bar' method samplemock.verify(); }}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "unit testing",
      "moq"
    ]
  },
  {
    "text": "can i set a different reply-to address from the from address for a mailchimp campaign?. as the title indicates, i'd like replies to my mailchimp campaign to go to a different email address from the from address appearing as the sender. is this possible? i couldn't see an obvious way to do it when i created a test campaign, but i thought it might be worth asking anyway.",
    "present_kp": [
      "mailchimp"
    ],
    "absent_kp": []
  },
  {
    "text": "load plaintext output without write files. i have a program (than i run from terminal) that generates 4 plaintext files.for example./myproggenerates file1.dat, file2.dat, file3.dat, file4.dat.i want to create a script that allows me run myprog and load (read) this four file outputs but without write the physical files (may be, load that files only in ram). is this possible?the reason is that i need about 70000 of this files, so i don't want to lose time saving extra files, i just need to use the information.=============================================specific example that was asked me in commentstriangle software (free software to generate meshes for numerical calculus, written in c) read the file mesh.poly::4 2 0 11 0 0 202 1 0 203 1 1 104 0 1 104 11 1 2 20 # bottom side2 2 3 20 # right side3 3 4 10 # top side4 4 1 20 # left side011 0.5 0.5 1 0.0005the commandtriangle mesh.poly generate the following files:mesh.node:4 2 0 1 1 0 0 20 2 1 0 20 3 1 1 10 4 0 1 10and mesh.ele2 3 0 1 4 1 2 2 2 3 4and other two files, in total: four output files.after generate this files i need to use the information in other program, written by me on fortran, that need the *.node and *.ele information. i'm thinking to write a .sh file to do this automatically, but i can use python or any language that allows me to run executable programs.to load (read) the mesh.node and mesh.ele is easy. but i need to generate thousands physical files as output of triangle and input of my fortran code. for that reason, i'm looking for a way to write virtual files thinking that will be more efficient and clean.my problem is that i have about 70000 mesh.poly generating 70000x4 output (and little) files.",
    "present_kp": [],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "repository wrapper. the following implementation is of a repository proxy.i will post only the code for nhibernate repository here. everything else (including configurers and tests) can be found on the pastebin.p.s. : i changed all the xml-like comments to their more readable representation, so the actual code still has nice xml documentation.public interface irepository{ // retrieves every entity of the specified type stored in the repository. iqueryable<t> retrieveentities<t>() where t : irepositoryentity; // retrieves every entity filtered by the supplied expression. // as long as the result is models 'iqueryable', it implies on the lazy result // evaluation and therefore doesn't have significant performance impact. iqueryable<t> retrieveentities<t>(expression<func<t, bool>> expression) where t : irepositoryentity; // new items are added to the repository and existing are updated. void addentities<t>(iqueryable<t> sequence) where t : irepositoryentity; void addentities<t>(params t[] entities) where t : irepositoryentity; // removes every entity of the specified type stored in the repository. void removeentities<t>() where t : irepositoryentity; // removes entities of the specified type which fit under the specified expression. void removeentities<t>(expression<func<t, bool>> expression) where t : irepositoryentity; // removes every entity in the sequence from the repository. throws if at least one entity // from the sequence doesn't belong to the database. void removeentities<t>(iqueryable<t> sequence) where t : irepositoryentity; void removeentities<t>(params t[] entities) where t : irepositoryentity;}public class nhibernaterepository : irepository{ private readonly configuration configuration; private readonly isessionfactory sessionfactory; private readonly isession session; public nhibernaterepository(nhibernaterepositoryconfigurer repositoryconfigurer) { // build and store the nhibernate-specific configuration. configuration = repositoryconfigurer.configuration.buildconfiguration(); // build the corresponding session factory and open the session. sessionfactory = repositoryconfigurer.sessionfactory; session = sessionfactory.opensession(); } public iqueryable<t> retrieveentities<t>() where t : irepositoryentity { checktypemappings(typeof(t)); return session.query<t>(); } public iqueryable<t> retrieveentities<t>(expression<func<t, bool>> expression) where t : irepositoryentity { checktypemappings(typeof(t)); return session.query<t>().where(expression); } public void addentities<t>(iqueryable<t> sequence) where t : irepositoryentity { checktypemappings(typeof(t)); withintransaction(() => { foreach (var entity in sequence) { session.merge(entity); } }); } public void addentities<t>(params t[] entities) where t : irepositoryentity { checktypemappings(typeof(t)); addentities(entities.asqueryable()); } public void removeentities<t>() where t : irepositoryentity { checktypemappings(typeof(t)); withintransaction(() => { foreach (var entity in session.query<t>()) { session.delete(entity); } }); } public void removeentities<t>(expression<func<t, bool>> expression) where t : irepositoryentity { checktypemappings(typeof(t)); withintransaction(() => { foreach (var entity in session.query<t>().where(expression)) { session.delete(entity); } }); } public void removeentities<t>(iqueryable<t> sequence) where t : irepositoryentity { checktypemappings(typeof(t)); withintransaction(() => { foreach (var entity in sequence) { session.delete(entity); } }); } public void removeentities<t>(params t[] entities) where t : irepositoryentity { checktypemappings(typeof(t)); removeentities(entities.asqueryable()); } // performs the entire specified action within a single unit of work. private void withintransaction(action action) { var transaction = session.begintransaction(); try { action(); transaction.commit(); } catch (exception) { transaction.rollback(); throw; } finally { transaction.dispose(); } } // throws if the type is not mapped to the database. private void checktypemappings(type type) { if (type.isinterface) return; if (configuration.classmappings.any(x => x.mappedclass == type)) return; // the 'type' is definitely doesn't have an appropriate persister. throw new mappingexception(type + type.fullname + doesn't have an appropriate persister); }",
    "present_kp": [
      "repository"
    ],
    "absent_kp": [
      "c#",
      "beginner"
    ]
  },
  {
    "text": "can i copy a kernel changes to a new machine?. in order to install oracle database on fedora, i had to make a lot of changes in fedora... how can i copy all those changes and install them on my new fedora installation ?or is it even possible to copy the whole partition (os and software included) and install that partition on a new hdd and launch it ?",
    "present_kp": [
      "fedora",
      "kernel"
    ],
    "absent_kp": [
      "migration"
    ]
  },
  {
    "text": "what is the meaning of the data inside wave_format_ieee_float?. i made a program that connected to the microphone and captured wave_format_ieee_float data from it. i noticed that if i made a really loud noise the data seems to fluctuate between -1 and 1 (when i cast the buffer pointer into float*). what is the significance of this? how do i connect this to decibel sound pressure level, pascals from ambient pressure or the voltage being sent through the microphone cable? i know the microphone has -38db sensitivity. any explanation or further reading tips that casts light on what the numbers inside the wave represents in real life are welcome.",
    "present_kp": [],
    "absent_kp": [
      "specifications"
    ]
  },
  {
    "text": "how to document rest api before coding. my team is working on a web application using micro service architecture and angular + spring mvc. we follow agile development. for each story, we create few implementation and test tasks. documenting rest api is the first task to be done in the story.we currently document it in confluence so that developers and testers can work on implementation and test cases respectively. we are looking to generate rest api documentation with swagger automatically using codegen. it looks like documenting in confluence and generating with swagger is redundant. however, swagger generates accurate documentation. what is the best way to document rest api before coding ? are there any other tools ?",
    "present_kp": [
      "rest",
      "documentation",
      "swagger"
    ],
    "absent_kp": [
      "api design"
    ]
  },
  {
    "text": "how to highlight a search range?. i'd like to test the range pattern, same as vim highlights the text while searching (e.g. :/), but for the range command instead.so in other words, instead of executing::/<head/,/\\/head>/di'd like to test only /<head/,/\\/head>/ range pattern in form of highlight to check whether the pattern is correct, before i'm going to run any command on that range.sample text to play with can be retrieved by: vim <url>",
    "present_kp": [
      "search",
      "highlight",
      "range"
    ],
    "absent_kp": []
  },
  {
    "text": "assigning variables as lines of code. i know in lua you can do something along the lines ofprint=system.out.printlnprint(hello)but is there something similar in java?",
    "present_kp": [
      "java",
      "lua"
    ],
    "absent_kp": []
  },
  {
    "text": "is it possible to stop emacs from down translating my key chords?. emacs has the default behaviour of double-guessing which key-combo (chord) i've pressed. it automatically down-translates to a lesser chord when the key-combo i pressed is unassigned, eg. <c-m-up> (translated from <c-m-s-up>) how can i turn this off? i really can't see any value in it, but it must be for some users. i'd also like to know what advantage this (dubious) feature offers...",
    "present_kp": [
      "emacs"
    ],
    "absent_kp": [
      "keyboard shortcuts"
    ]
  },
  {
    "text": "languages that lack contraction, weakening or exchange. when learning about generalized arrows, a question arised to me: are there any languages (or potential languages) that lack one or more of the structural rules: contraction, weakeing and exchange?under curry-howard isomorphism, these rules, used frequently in logic, map into programming concepts. if we denote $a, b, c dash d$ a program (corresponding to a natural deduction proof) that computes a value of type $d$ from inputs of types $a$, $b$ and $c$, we get:contraction: $\\gamma, a, adash b$ can be transformed into $\\gamma, adash b$.that is, a single input can be used twice.weakening: $\\gammadash b$ can be transformed into $\\gamma, adash b$.that is, it's possible to add arbitrary, unused inputs.exchange: $\\gamma_1, a, b, \\gamma_2 dash c$ can be transformed into $\\gamma_1, b, a, \\gamma_2 dash c$.that is, the order of inputs doesn't matter.an example for language lacking contraction would be quantum computing. there the allowed operations can be described with unitary matrices, and duplicating a value can't be expressed as such.it also seems to me that weakening isn't an admissible rule for quantum computing, at least in the above form, as we can't forget a value with a unitary matrix. but we could have a weaker rule such as $\\gammadash b$ can be transformed into $\\gamma, adash a\\otimes b$, and the $a$ in the output can be dropped when extracting the results of such a computation.the exchange rule is clearly permissible in quantum computing.are there any other examples, in particular a language that doesn't allow exchange, or where weakening isn't allowed even in such a weaker form?",
    "present_kp": [],
    "absent_kp": [
      "lo.logic",
      "pl.programming languages",
      "curry howard"
    ]
  },
  {
    "text": "new created custom list shape doesn't work in microsoft visio 2013 x64. objective:first, i should say what i want to do, and then i'll describe what i've done to achieve to my goal in the next (descriptions) part.i want to create a custom list master shape from the plain container of the diagram parts section in the insert tab of the ribbon. then, i want to create another master shape that can use as the member shape for the created custom list master shape.in other words, i want to add my created master shape to my custom list master shape like attaching the member and separator master shapes to the class master shape of the uml stencil.so, i've faced with some problems in achieving to my goal that i've described them in the next parts.descriptions:i've created some new master shapes in a visio stencil (.vssx) file as follows:figure 1 - new created master shapes with used master shapeproperty master shape (green box): that is created from the member master shape of the uml class stencil (blue box).object master shape (red box): that is created from the plain container of the diagram parts section in the insert tab of the ribbon.the property master shape is created to use as the member shape in the object master shape like the member master shape to use in the class master shape of the uml stencil.figure 2 - class master shape with its initial membersthe property master shape that is created from member master shape has changed as follows:i added one shape data to it (figure 3).figure 3 - shape data dialogue box of the property master shapei added one data graphic item to it (figure 4).figure 4 - data graphic and data graphic item dialogue boxes of the property master shapei changed the user.membername formula in the user-defined cells' section of the shapesheet window as follows (figure 5):=mid(substitute(trim(shapetext(thetext)),[,),1,find( ,substitute(trim(shapetext(thetext)),[,))-1)instead of:=shapetext(thetext)figure 5 - shapesheet window of the property master shapethe object master shape that is created from the plain container has changed as follows:i changed the contents of the cells in the user-defined cells' and events sections of the shapesheet window as figure 6:figure 6 - cells in the user-defined cells' and events sections of the shapesheet window after changing their contentsinstead of:figure 7 - cells in the user-defined cells' and events sections of the shapesheet window before changing their contentsquestions:1st question:why isn't/aren't instance(s) of the property master shape arranged and placed correctly after adding it/them to the instance(s) of the object master shape like adding instance(s) of the member master shape to the instance(s) of the class master shape of the uml stencil (figure 8)?figure 8 - comparing an instance of the object master shape and one instance of the property master shape with an instance of the class master shape of the uml stencil and its initial members2nd question:why do(es)n't instance(s) of the object master shape add its initial members after attaching it/them to the page like adding initial members after adding instance(s) of the class master shape of the uml stencil to the page (figure 9)?figure 9 - comparing an instance of the object master shape with an instance of the class master shape of the uml stencili've added the following formula for achieving to this objective; however, i think that it doesn't work:=if(listmembercount()=0,docmd(2270),0)3rd question:why isn't displayed a bar in the instance(s) of the object master shape to insert instance(s) of the property master shape like displaying the bar in the instance(s) of the class master shape of the uml stencil to insert its members (figure 10)?figure 10 - comparing an instance of the object master shape with an instance of the class master shape of the uml stencil for displaying the bar to insert related members4th question:why do(es) instance(s) of the object master shape accept instance(s) of all master shapes except than only instance(s) of the property master shape, instead of the instance(s) of the class master shape of the uml stencil that only accept(s) the instance(s) of the member and separator master shapes of the uml stencil (figure 11)?figure 11 - comparing an instance of the object master shape that accepts instance(s) of all master shapes with an instance of the class master shape of the uml stencil that only accepts the instance(s) of the member and separator master shapes of the uml stencili've set =use(property) for the user.msvsdlistitemmaster in the user-defined cells' section of the shapesheet window; however, i think that it doesn't work.5th question:why isn't/aren't displayed options for inserting members on the added instance(s) of the property master shape to the instance(s) of the object master shape like attached instance(s) of the member and separator master shapes of the uml stencil to the instance(s) of the class master shape of the uml stencil (figure 12)?figure 12 - comparing an instance of the object master shape and one instance of the property master shape with an instance of the class master shape of the uml stencil and its members for displaying options of the inserting members on the added members6th (final) question:why do(es) instance(s) of the object master shape behave and act like the container while i've changed its/their master object to a list?",
    "present_kp": [
      "visio"
    ],
    "absent_kp": []
  },
  {
    "text": "vim paste string with non-ascii characters. i am trying to paste a string from a register in vim which contains non-ascii characters such as ctrlr, how can i paste this string into a file, but escape the non-ascii characters automatically?essentially, what i am trying to achieve is recording a macro which has some (non-ascii) characters, such as ctrlw which vim will show as ^w. i want to be able to take the macro (by examining the registers and taking the macro string (i.e @a=^w)) and copying it into a .vimrc file as a key-map, so that when i press the key it will run that macro. i want to do this automatically (or as fast as possible) without having to change ^w into ctrlw in the .vimrc file, or wherever i paste it too.",
    "present_kp": [
      "vim",
      "paste"
    ],
    "absent_kp": []
  },
  {
    "text": "view stdout for another pts. here is the situation. i left my pc at home doing an rsync from a 2tb hard drive to another 2tb hard drive (it's going to take a while since they are both usb 2.0). i am now at work and i have ssh-ed into my home pc. if i do ps aux | grep rsync i can see the following:1000 7214 18.8 0.1 30636 1368 pts/0 s+ 00:52 134:00 rsync -vr /media/master /media/slavehowever i want to see exactly what rsync is doing. when i was at home, the standard output was shown in my terminal and the verbose mode of rsync showed which files were currently being copied. is there any way to read stdout for another pts?$ ps -t pts/07214 pts/0 02:14:42 rsynci did a little bit of googling and it seems that /proc/pid/fd may hold the answer but i'm not sure about this...p.s. i have sudo privileges of course.",
    "present_kp": [
      "terminal",
      "rsync"
    ],
    "absent_kp": [
      "process",
      "io redirection"
    ]
  },
  {
    "text": "can't connect to tomcat on port 8080 (port 80 works). we have a bunch of centos 6 dedicated servers hosting our web applications that are set up behind a reverse proxy. the reverse proxy is running haproxy and forwards web requests to the backend servers. we periodically have to add a new server which we configure using puppet (software, users, firewall), so they should theoretically be set up the same.i have an issue with the latest server i've added where for some reason i can't connect when running tomcat on port 8080 (our default puppet setup), however it connects fine if i manually amend server.xml and haproxy.cfg to use port 80.i initially thought i'd made a mistake in iptables but i've tried temporarily allowing all traffic, with no luck. my rules were initially port specific and i've tried expanding them to all ports, although the original rule included port 80 and 8080 together along with 443 and 8443, so this was unlikely to be the issue.i can connect locally on the server via localhost (<url>), but i can't connect remotely, either by domain name through the proxy, or directly by hostname or ip address.i've tried monitoring port 8080 on eth0 using sudo tcpdump -i eth0 port 8080 and got nothing.not sure what to try next. any advice/help would be appreciated, thanks.edit: netstat output looks like this...tcp 0 0 :::8080 :::* listen 29875/jsvc.execedit2: regarding iptables, i've tried temporarily setting the default policy to accept (it's normally drop) on both the reverse proxy and the backend server. also the rules all come from the same file that puppet uses to set iptables on all our backend servers.",
    "present_kp": [
      "centos",
      "tomcat"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "getting spam by gmail filter match. i recently noticed some spam messages getting labeled by some of my filters. for example:i have a filter that labels any message coming from @domain but if a message come from @xxxxx-domain the filter is getting triggered labeling the message too.does anyone know how to fix my filter?",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "gmail filters",
      "spam prevention"
    ]
  },
  {
    "text": "occi for non-web application. i am writing a non-web application (written in java) which will allocate cloud resources. i want to make it compatible with as many providers as possible. is it wise to use occi interface? will it be too complicated?",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "cloud computing",
      "rest"
    ]
  },
  {
    "text": "why can i add members to fb groups instead of just inviting them?. i was under the impression group membership is voluntary - that you can't add someone to a group, but rather you can invite them.i want to create a facebook entity that:is open to everyone - everyone can leave or join at willthe only one that can make use x be in the group is an action by user xwill be accessible to users that aren't signed to facebooka group doesn't seem to follow rules 2 and 3. should i use a fan page ? or ... what is the best facebook entity to capture this?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "multisets of a given set. a multiset is an unordered collection of elements where elements may repeat anynumber of times. the size of a multiset is the number of elements in it countingrepetitions.(a) what is the number of multisets of size $4$ that can be constructed from $n$distinct elements so that at least one element occurs exactly twice?(b) how many multisets can be constructed from $n$ distinct elements?for part b, infinite is correct.for part a, taking $n=3$ and elements $\\{1,2,3\\}$ we have multisets as:$\\{1,1,2,2\\}, \\{1,1,3,3\\}, \\{1,1,2,3\\}, \\{2,2,3,3\\}, \\{2,2,1,3\\}, \\{3,3,1,2\\}$, for a total of $6$.similarly for $n=4$ and using elements $\\{1,2,3,4\\}$, we have $18$ multisets. there must be some formula, or we have to develop one!i am in particular looking for a formula when there is a restriction on the number occurrences in the multiset.",
    "present_kp": [
      "sets"
    ],
    "absent_kp": [
      "combinatorics"
    ]
  },
  {
    "text": "iptables - why do i get table does not exist (do you need to insmod?). i need to install some iptable ruels to block traffic that originates from a certain country, i found this script example on <url> it works great on another host i have but on this one (an embedded box) i get: ./iptable_rules.sh modprobe: module ip_tables not found in modules.depiptables v1.4.16.3: can't initialize iptables table 'filter': table does not exist (do you need to insmod?)perhaps iptables or your kernel needs to be upgraded.now upgrading the kernel due to the nature of the device, is not an option. does anyone know a way i can get around this? this system running on kernel 3.2.34",
    "present_kp": [
      "kernel",
      "iptables"
    ],
    "absent_kp": [
      "firewall"
    ]
  },
  {
    "text": "what does gmail really mean when the login page offers me an option to stay signed in?. gmail's sign in page offers the checkbox stay signed in. does this mean that it will stay signed in indefinitely? if not, then for how long?the need help? link is not immediately helpful.",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": []
  },
  {
    "text": "how to remove page/menu from page title in joomla 2.5 and 3+ on front page only. i have a joomla 2.5 website and i would like to remove the page/menu name from appearing in the title so it does not display in google or the browser tab. currently the homepage is appending 'home' to the page title i.e:<title>example sitename - page/menu name</title>i know that the browser page title can be found within page display options, but if i leave it empty, it uses the menu item title.please note that i only want to remove the page/menu name on the front page of site, also the solution should be working for bilingual (or multilingual) websites, that means my website - home will be my website and other languages will follow the same rule, i.e. mon website - accueil will be mon website.",
    "present_kp": [
      "joomla",
      "title",
      "page"
    ],
    "absent_kp": []
  },
  {
    "text": "how to differentiate 2 nics with the same pci address. i am running fedora 22, and have a gpu that i passthrough to a kvm guest. i accomplished this by adding pci-stub.ids=<pci id 2>,<pci id 2> to my grub boot option. the two pci ids i'm using now are for the same gpu, but the ids are different. i recently purchased a tp-link nic, and the manual says it is using a realtek 8xxx chipset. apparently this is the same chipset used by my integrated nic, as lspci -nn shows the same output, except the pci bus id is 08:00 instead of 06:00 for my integrated nic. given that the pci-stub.ids line uses the 8 hexadecimal values for the pci id, how do i attach only one of my nics to the pci stub driver?edit: here is some of the lshw output:*-pci:5 description: pci bridge product: sb700/sb800/sb900 pci to pci bridge (pcie port 0) vendor: advanced micro devices, inc. [amd/ati] physical id: 15 bus info: pci@0000:00:15.0 capabilities: pci pm pciexpress msi ht normal_decode bus_master cap_list configuration: driver=pcieport *-network description: ethernet interface product: rtl8111/8168/8411 pci express gigabit ethernet controller vendor: realtek semiconductor co., ltd. physical id: 0 bus info: pci@0000:06:00.0 logical name: enp6s0 version: 06 serial: 90:2b:34:xx:xx:xx size: 1gbit/s capabilities: pm msi pciexpress msix vpd bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3lk-napi duplex=full firmware=rtl8168e-3_0.0.4 03/27/12 ip=192.168.1.10 latency=0 link=yes multicast=yes port=mii speed=1gbit/s*-pci:7 description: pci bridge product: sb900 pci to pci bridge (pcie port 2) vendor: advanced micro devices, inc. [amd/ati] physical id: 15.2 bus info: pci@0000:00:15.2 configuration: driver=pcieport *-network description: ethernet interface product: rtl8111/8168/8411 pci express gigabit ethernet controller vendor: realtek semiconductor co., ltd. physical id: 0 bus info: pci@0000:08:00.0 logical name: enp8s0 version: 06 serial: c4:e9:84:xx:xx:xx size: 1gbit/s capabilities: pm msi pciexpress msix vpd bus_master cap_list ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3lk-napi duplex=full firmware=rtl_nic/rtl8168e-2.fw ip=192.168.1.142 latency=0 link=yes multicas",
    "present_kp": [
      "kvm",
      "pci"
    ],
    "absent_kp": [
      "virtual machine"
    ]
  },
  {
    "text": "why doesn't my udev rule work?. i created a file /etc/udev/rules.d/60.alsa.rules with the following content:kernel==0000:00:1b.0, subsystem==pci, attr{label}==realtek high definition audio device, attr{vendor}==0x8086, symlink+=jumanjithen i restarted udev using init.d but the symbolic link /dev/jumanji was not created.what should i do?additional information:udevadm info -a -n /dev/snd/by-path/pci-0000\\:00\\:1b.0looking at device '/devices/pci0000:00/0000:00:1b.0/sound/card0/controlc0': kernel==controlc0 subsystem==sound driver== looking at parent device '/devices/pci0000:00/0000:00:1b.0/sound/card0': kernels==card0 subsystems==sound drivers== attrs{id}==pch attrs{number}==0 looking at parent device '/devices/pci0000:00/0000:00:1b.0': kernels==0000:00:1b.0 subsystems==pci drivers==snd_hda_intel attrs{irq}==45 attrs{subsystem_vendor}==0x8086 attrs{broken_parity_status}==0 attrs{class}==0x040300 attrs{index}==1 attrs{label}==realtek high definition audio device attrs{consistent_dma_mask_bits}==64 attrs{dma_mask_bits}==64 attrs{local_cpus}==ff attrs{device}==0x1c20 attrs{msi_bus}== attrs{local_cpulist}==0-7 attrs{vendor}==0x8086 attrs{subsystem_device}==0x2042 attrs{d3cold_allowed}==1 looking at parent device '/devices/pci0000:00': kernels==pci0000:00 subsystems== drivers==",
    "present_kp": [
      "audio",
      "udev",
      "pci"
    ],
    "absent_kp": [
      "ubuntu"
    ]
  },
  {
    "text": "proper use of timer in windows service. i have following code to use timer (system.timers.timer) in windows service. the goal is that new time handler should not occur if previous one didn't finish its job. here is how i achieve this:protected override void onstart(string[] args){ try { // // create and start a timer. // m_maintimer = new system.timers.timer(); m_maintimer.interval = 60000; // every one min m_maintimer.elapsed += new system.timers.elapsedeventhandler(this.timer1_tick); m_maintimer.autoreset = false; // makes it fire only once m_maintimer.enabled = true; } catch (exception ex) { // omitted }}and:protected override void onstop() { try { // service stopped. also stop the timer. m_maintimer.enabled = false; m_maintimer = null; } catch (exception ex) { } }also in handler:private void timer1_tick(object sender, elapsedeventargs e) { try { }catch(exceptione x) { } finally { if (null != m_maintimer) { m_maintimer.start(); // re - enable the timer } }}it works but my question is is this approach safe? maybe i should make m_maintimer volatile? because of the null check inside finally?",
    "present_kp": [
      "timer"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "how to create a tar.gz file from a folder excluding a folder. how do i exclude a file or folder while creating a tar.gz file with tar command?",
    "present_kp": [
      "tar"
    ],
    "absent_kp": [
      "compression"
    ]
  },
  {
    "text": "how to make visits count on google analytics if someone visits my own jsfiddle on my website?. i'm a developer and i often write jsfiddles for example. i use google analytics on my personal website to monitor traffic. jsfiddle.net is not my own domain, but in a way, snippets i'm publishing on belongs to me.how can i make traffic my own jsfiddles' generate counts for my own domain's one? in other words, when someone visits a jsfiddle i have written, i'd like it counts for one visits on google analytics.",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": [
      "visitors"
    ]
  },
  {
    "text": "what are the standards for dealing with pluralia tantum in your code?. when using variables of which their plural and singular are both the same, how do you name them? are there any standards out there?for example:series[] series // pluralseries series // singularindepth:to be specific, my collection of series needs to be called series (due to json formatting), would you consider naming the singular form of series that gets added to the collection series s?as in:list<series> series = new list<series>();series s;while (somebool){ s = new series(); s.name = name; while (anotherbool) { s.addvalue(somevalue); } series.add(s);}",
    "present_kp": [
      "naming"
    ],
    "absent_kp": [
      "c#",
      "naming standards",
      "language discussion"
    ]
  },
  {
    "text": "solution to google code jam 2008 round 1c problem b. this is my solution to google code jam 2008 round 1c problem b (ugly numbers). i think it's very elegant. however, i wonder if it's too concise. what could i improve here?the problem:once upon a time in a strange situation, people called a number ugly if it was divisible by any of the one-digit primes (2, 3, 5 or 7). thus, 14 is ugly, but 13 is fine. 39 is ugly, but 121 is not. note that 0 is ugly. also note that negative numbers can also be ugly; -14 and -39 are examples of such numbers.one day on your free time, you are gazing at a string of digits, something like:123456you are amused by how many possibilities there are if you are allowed to insert plus or minus signs between the digits. for example you can make1 + 234 - 5 + 6 = 236which is ugly. or123 + 4 - 56 = 71which is not ugly.it is easy to count the number of different ways you can play with the digits: between each two adjacent digits you may choose put a plus sign, a minus sign, or nothing. therefore, if you start with d digits there are 3^d-1 expressions you can make.note that it is fine to have leading zeros for a number. if the string is 01023, then 01023, 0+1-02+3 and 01-023 are legal expressions.your task is simple: among the 3^d-1 expressions, count how many of them evaluate to an ugly number.inputthe first line of the input file contains the number of cases, n. each test case will be a single line containing a non-empty string of decimal digits.outputfor each test case, you should output a linecase #x: ywhere x is the case number, starting from 1, and y is the number of expressions that evaluate to an ugly number.code:from functools import lru_cachem = 2*3*5*7uglies = list(filter(lambda n: (int(n)%2 == 0 or int(n)%3 == 0 or int(n)%5 == 0 or int(n)%7 == 0), range(m)))@lru_cache(maxsize=none)def f(line, k=none): if k == none: return sum([f(line, k) for k in uglies]) return sum([ (1 if (int(line) % m) == k else 0), sum([f(line[:p], (k-int(line[p:])) % m) for p in range(1, len(line))]), sum([f(line[:p], (k+int(line[p:])) % m) for p in range(1, len(line))]), ])if __name__ == '__main__': import sys data = sys.stdin.read().splitlines()[1:] case = 1 for line in data: print('{:.0%}'.format(case/len(data)), file=sys.stderr) print('case #{}: {}'.format(case, f(line))) case += 1",
    "present_kp": [],
    "absent_kp": [
      "python",
      "programming challenge",
      "python 3.x",
      "dynamic programming"
    ]
  },
  {
    "text": "switching disks. we currently have two servers with sata disks. the box load on the box every so often jumps. we see a direct correlation between the io wait and the system usage going up. when ever the io is high the system cpu usage jumps as well. the server has hardware raid with the drive showing as /dev/sda. we re running centos. we want to install two ssd's in a raid 1 as well, boot from a usb key and then use dd to copy from the sata disks over to the ssd's. once we copy everything over we will remove the original array and leave just the second. will this work? how does linux assign which disk is /dev/sda or /dev/sdb?",
    "present_kp": [
      "centos",
      "dd"
    ],
    "absent_kp": [
      "hard disk"
    ]
  },
  {
    "text": "how to reduce size of swap after a system is already installed?. i'm running debian squeeze 6.0.5. does the use of swap memory make my computer run slower? if so, how can i reduce the size of the swap memory after the system is already installed?",
    "present_kp": [
      "debian",
      "swap"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "network unreachable: robots.txt unreachable. i am trying to add a valid sitemap to google webmaster. yet, it says: network unreachable: robots.txt unreachablewe were unable to crawl your sitemap because we found a robots.txt file at the root of your site but were unable to download it. please ensure that it is accessible or remove it completely.and network unreachable: robots.txt unreachablewe were unable to crawl your sitemap because we found a robots.txt file at the root of your site but were unable to download it. please ensure that it is accessible or remove it completely.yet, i can access both my robots.txt and sitemap.xml. i have reading other posts here and there, but could not solve/understand what is causing this issue. anyone knows?",
    "present_kp": [
      "sitemap",
      "robots.txt"
    ],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "how can i delete my youtube account?. my school email address is not @gmail.com, however, it is managed by gmail, so i log into a special school log-in and it takes me to my email with the familiar gmail tools and gmail inbox. unfortunately, it linked itself to a youtube account. i want to either delete this youtube account or unlink it.however, as you can see, there is no unlink button nor are there delete account options. i also tried this question : how do i unlink my youtube account from my gmail account? and followed the link to unlink youtube and google accounts, but it doesn't do anything and simply redirects me back to my manage account page.",
    "present_kp": [
      "youtube"
    ],
    "absent_kp": [
      "account management"
    ]
  },
  {
    "text": "how do you prove two languages are equivalent using the definition of acceptance?. i need to prove that $l(f(m)) = l(m)\\cup \\{arepsilon\\}$where $m$ is a dfa and $f$ is the function $f(m) := (q\\cup \\{q_f\\}, \\sigma, \\delta', q_f, f\\cup\\{q_f\\})$ and $q_f$ is a new state not in $q$ and $\\delta'(q,a) = egin{cases} \\delta (q,a) & ext{if }q\\in q\\ \\delta (q_0,a) & ext{if }q= q_f. \\end{cases}$i'm assuming i need to use induction but i'm not sure how to go about it",
    "present_kp": [
      "induction"
    ],
    "absent_kp": [
      "formal languages",
      "regular languages",
      "finite automata",
      "proof techniques"
    ]
  },
  {
    "text": "mirror for fedora core 4 still available?. i'm trying to rebuild eldk 4.0, which uses fedora core 4 as its base. can anyone direct me to a mirror that still hosts the files?",
    "present_kp": [
      "fedora"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "validating only attributes that are present in a form. i want to skip validations based on attributes. if certain attributes are not in form so i do not want to validate them.currently, if i post them from one form which has 1 field, it still validates other 9 fields and show me errors that it cant be blank.if i check from big form which has 10 fields, it passes successfully.the below code did trick for me but my main intention is to refactor so it will fullfil its purpose as i stated above.code is:validates :teacher_number, presence: true, if: teacher_number && teacher_number.blank? validates :title, presence: true, if: title && title.blank? validates :name, presence: true, if: name && name.blank? validates :gender, presence: true, if: gender && gender.blank? validates :location, presence: true, if: location && location.blank? validates :dob, presence: true, if: dob && dob.blank? validates :contact_mobile, presence: true, if: contact_mobile && contact_mobile.blank? validates :contact_home, presence: true, if: contact_home && contact_home.blank? validates :street, presence: true, if: street && street.blank? validates :city, presence: true, if: city && city.blank? validates :state, presence: true, if: state && state.blank? validates :zip_code, presence: true, if: zip_code && zip_code.blank? validates :country, presence: true, if: country && country.blank? validates :teacher_number, uniqueness: {scope: :school_id}, if: teacher_number && teacher_number.blank? validate :teacher_number_existance, :on => :create, if: self.teacher_number && self.teacher_number.blank? validate :school_existance, :on => :create, if: self.teacher_number && self.teacher_number.blank?i simply wants to do something like:before_validation :skip_validationsdef strip_validations [:teacher_number, :title, :name, :gender, :location, :dob, :contact_mobile, :contact_home, :street, :city, :state, :zip_code, :country].each do |attr| errors.add(teacher, #{attr} can't be blank) if attr && attr.blank? end endbut above code does not work for my cases. any good work around?",
    "present_kp": [
      "validation"
    ],
    "absent_kp": [
      "ruby",
      "ruby on rails"
    ]
  },
  {
    "text": "cp won't work on current bash script's directory. i'm trying to copy some files from current directory in a bash script but the problem is that the cp command doesn't work with the current directory. i can use the following command without any problem on backtrack 5 (based on ubuntu) but not in kali linux (based on debian):cp -f -v *.{html,txt,php} /var/www/i can execute this command directly from the terminal by first changing directory to the directory where these files are. but using script i get the following error:cp -f -v *.{html,txt,php} /var/www/cp: cannot stat '*.{html,txt,php}': no such file or directoryagain i have no problem with this command in the script when i use ubuntu.",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "file copy"
    ]
  },
  {
    "text": "calculating shopping cart discounts. i have a method that checks to see if a hash of given items should have discounts applied and if so, determines and returns the discount:def get_discounts @items.each do |name, attr| @specials.each do |special| while name == special.sale_item && attr[:quantity] >= special.quantity @discounts << special.discount attr[:quantity] = attr[:quantity] - special.quantity end end end determine_discountenddef determine_discount if @discounts.empty? @discounts = 0 else @discounts = @discounts.inject(:+) end endthis works perfectly, but is there a more concise way to write it? i'm looking especially at the two each loops. i'm also a bit iffy about the while loop - it was an if statement (if name == special.sale_item) but it felt like too much so i combined it into the while loop.",
    "present_kp": [],
    "absent_kp": [
      "ruby",
      "e commerce"
    ]
  },
  {
    "text": "setting up custom bash script to run only as sudo. i made a script (name of the file is update) to update and upgrade in one command. all it is is:#! /bin/bashsudo /usr/bin/apt-get updatesudo /usr/bin/apt-get upgradei used the full paths, as well putting this in its own directory, /home/user_name/custom_scripts. i also made sure to designate this directory as root, the permissions are listed as drwxr-xr-x. 2 root root 4096 aug 23 00:12 custom_scriptsand the executable script is:-rwx------. 1 root root 73 aug 23 00:12 updatei edited my path to look like this /home/user_name/custom_scripts:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games yet for some reason this won't execute if i type sudo update. the weirdest thing is if i just try update, i get a permission denied exception. i'm not really sure what's wrong.",
    "present_kp": [
      "permissions",
      "path"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "subdomain redirect to website.com/wp-signup.php?new=example after multisite - wordpress. i have a question and i hope that someone can help me! i have a website powered by wordpress with some articles and i wanted to make a network, so a multisite installation.i followed the steps that are present on the wordpress codex, inserting first the function to enable multisite in wp-config.php and then i went in my wp-admin to and followed the instruction to complete the procedure.this is my code added in wp-config.php:define('multisite', true);define('subdomain_install', true);define('domain_current_site', 'website.com');define('path_current_site', '/');define('site_id_current_site', 1);define('blog_id_current_site', 1);while this is the code in my .htaccess:rewriteengine onrewritebase /rewriterule ^index\\.php$ - [l]# add a trailing slash to /wp-adminrewriterule ^wp-admin$ wp-admin/ [r=301,l]rewritecond %{request_filename} -f [or]rewritecond %{request_filename} -drewriterule ^ - [l]rewriterule ^(wp-(content|admin|includes).*) $1 [l]rewriterule ^(.*\\.php)$ $1 [l]rewriterule . index.php [l]when i did this, then i realized that even creating a new site in the network it couldn't be loaded: in fact, when i was going to the site test.website.com, the server didn't responded, giving a chrome error that now i don't remember: it was something to do with dns.so i've searched online and i read that i needed to create a wildcard.as how i understood, i needed to create a new dns record of a type and redirect it to the ip of my website, with the * as subdomain.i did this, but i created a subdomain with cpanel too: i named it *.website.com and its folder was the root of my website, then i did a redirect to my website ip for this subdomain.for some hours anything happened: this is i guess because i had to wait for the dns change, and in fact, this morning, i saw that test.website.com was loading!but there's a strange thing: if i type a non existing subdomain like wp.website.com, it redirect to my principal website (the domain in itself) with this on the link:/wp-signup.php?new=wpthe wp after the = is because the subdomain is wp in itself.in the page there appears like a registration module: what i mean is that if i'm not logged in my website, a page like this (that could be asd.website.com or java.website.com and redirects to website.com/wp-signup.php=?new=ads), shows up a registration requiement and if i proceed, it seems like if a new user could register a new subdomain or something like that. because appears a username box and a password box, then i can click on next in the bottom of the page. it feels like a registration form for my network... but it's right that this appears when an user writes an not existent subdomain of my website?anyway in the very bottom of the page, there comes out (i translate from italian, so maybe isn't the real english wordpress text): the website you were looking for, hello.website.com doesn't exists. oh, i forgot to say: this page comes with the layout of my wordpress theme, but it's sovrasting it: infact buttons and text box aren't of my wp theme, but of wordpress itself.that's all!what i would know is: it's a normal thing or i messed up with something?and if it's normal, how could i make this not to happen?thank you anyone will help me!",
    "present_kp": [
      "wordpress",
      "dns",
      "cpanel"
    ],
    "absent_kp": []
  },
  {
    "text": "django api design. i recently followed the django api tutorial. <url> i initiate a post request my intent is that after inserting the record into database, launch a process. example:post server/will insert a new server record, return 201 to api client and behind the scenes i want to launch a process that will install and discover the server via some ssh/icmp.where is the best place to put this code any tutorial or advise?how can i return a 201 and after that execute my discovery process. is it better to monitor the db for new records and have a different process doing it? @csrf_exemptdef snippet_list(request): list all code snippets, or create a new snippet. if request.method == 'get': snippets = snippet.objects.all() serializer = snippetserializer(snippets, many=true) return jsonresponse(serializer.data) elif request.method == 'post': data = jsonparser().parse(request) serializer = snippetserializer(data=data) if serializer.is_valid(): serializer.save() <? is here?> return jsonresponse(serializer.data, status=201) return jsonresponse(serializer.errors, status=400)",
    "present_kp": [
      "api design",
      "django"
    ],
    "absent_kp": []
  },
  {
    "text": "what is user agent issbot. i am seeing a lot of traffic to my website from user agent issbot. this certainly looks like a bot, but is not listed in the <url> listing, and i have not been able to find anything useful on google. does anyone know what or who this is?",
    "present_kp": [
      "user agent"
    ],
    "absent_kp": [
      "web crawlers"
    ]
  },
  {
    "text": "can synapse launcher be installed in debian?. i am thinking of changing from linux mint cinnamon to linux mint debian cinnamon, but synapse launcher is something i can't work without. it doesn't seem to be available in debian.does anyone know if it is possible to install it and use all the features it offers?",
    "present_kp": [
      "debian",
      "synapse"
    ],
    "absent_kp": []
  },
  {
    "text": "slicing time spans into calendar months. i have apparently correct code that still runs for weeks on my data (tens of millions of rows). i show the entire code for reference (and maybe other gains to be made), but the key operation is in the loop between lines 66 and 79. basically, if a spell (spent in hospital) extended over a single calendar month, i wanted to have separate lines counting the number of days spent in hospital for each of those calendar months.i thought things won't be this bad iterating over rows if i allocate space for all the new rows in a single step (the concatenation before the loop) and only reset values row by row in the loop. # -*- coding: utf-8 -*-import numpy as npimport pandas as pdall_treatments = list()filelist = ['slutenvard1997','slutenvard2011','slutenvard2012','slutenvard19982004','slutenvard20052010']tobacco_codes = '|'.join([c{}.format(i) for i in range(30, 40)] + [f17])nutrition_codes = '|'.join([d{}.format(i) for i in range(50, 54)] + [e{}.format(i) for i in range(10, 15)] + [e{}.format(i) for i in range(40, 47)] + [e{}.format(i) for i in range(50, 69)])mental_codes = 'f'alcohol_codes = '|'.join([k70] + [f0])circulatory_codes = 'i'dental_codes = '|'.join([k0{}.format(i) for i in range(2, 4)])accident_codes = '|'.join([x{}.format(i) for i in range(10, 60)] + [v] + [x0])selfharm_codes = '|'.join([x{}.format(i) for i in range(60, 85)])cancer_codes = 'c'endonutrimetab_codes = 'e'pregnancy_codes = 'o'other_stress_codes = '|'.join([j{}.format(i) for i in range(11, 48)] + [l{}.format(i) for i in range(20, 66)] + [k{}.format(i) for i in range(20, 60)] + [x{}.format(i) for i in range(86, 99)] + [z{}.format(i) for i in range(10, 77)] + [r] + [j0] + [z0])items = {}conds = ['tobacco','nutrition','mental','alcohol','circulatory','dental','accident','selfharm','cancer','endonutrimetab','pregnancy','other_stress']for c in conds: items[c] = eval(c + '_codes')treatment_summaries = {item: list() for item in items.keys()}for file in filelist: filename = '/path/' + file +'.txt' treatments = pd.read_table(filename,usecols=[0,8,9,11]) if file == 'slutenvard20052010': treatments.loc[treatments['indatuma']==20060230,'indatuma'] = 20060203 treatments.loc[treatments['indatuma']==20108024,'indatuma'] = 20100824 if file == 'slutenvard19982004': treatments.loc[treatments['utdatuma']==<phone>,'utdatuma'] = 20030701 treatments.loc[treatments['utdatuma']==<phone>,'utdatuma'] = 20030901 treatments = treatments[(treatments['indatuma'] !='.') & (treatments['utdatuma'] > <phone>)] treatments['indatuma'] = treatments['indatuma'].astype(float) all_treatments.append(treatments) del treatmentsall_treatments = pd.concat(all_treatments, ignore_index=true)print remember datatypes for future use:print all_treatments.dtypesall_treatments['indate'] = pd.to_datetime(all_treatments['indatuma'], errors='coerce',format='%y%m%d')all_treatments['outdate'] = pd.to_datetime(all_treatments['utdatuma'], errors='coerce',format='%y%m%d')# separating months:all_treatments['monthlyindate'] = all_treatments['indate']all_treatments['monthlyoutdate'] = all_treatments['outdate']micolix = all_treatments.columns.get_loc('monthlyindate')mocolix = all_treatments.columns.get_loc('monthlyoutdate')ocolix = all_treatments.columns.get_loc('outdate')all_treatments['extramonths'] = 12*(all_treatments['outdate'].dt.year-all_treatments['indate'].dt.year)+(all_treatments['outdate'].dt.month-all_treatments['indate'].dt.month)emcolix = all_treatments.columns.get_loc('extramonths')originaln = len(all_treatments)newrowcount = int(all_treatments['extramonths'].sum())newn = int(originaln+newrowcount)all_treatments = pd.concat([all_treatments,all_treatments.iloc[:newrowcount,:]],ignore_index=true) # this fills the new rows with the wrong data instead of nans, but will be overwrittenbomoffset = pd.tseries.offsets.monthbegin()newrowix = originalnfor i in range(0,originaln): monthstoadd = all_treatments.iloc[i,emcolix].astype('int') for x in range(0,monthstoadd): all_treatments.iloc[newrowix,:] = all_treatments.iloc[i,:] if x==0: all_treatments.iloc[i,mocolix] = bomoffset.rollforward(all_treatments.iloc[i,micolix]) all_treatments.iloc[newrowix,micolix] = bomoffset.rollforward(all_treatments.iloc[i,micolix] + pd.tseries.offsets.dateoffset(months = x)) if x < monthstoadd-1: all_treatments.iloc[newrowix,mocolix] = bomoffset.rollforward(all_treatments.iloc[newrowix,micolix]+ pd.tseries.offsets.dateoffset(months = 1)) else: all_treatments.iloc[newrowix,mocolix] = all_treatments.iloc[newrowix,ocolix] newrowix += 1all_treatments['monthlyyear'] = all_treatments['monthlyindate'].dt.yearall_treatments['monthlymonth'] = all_treatments['monthlyindate'].dt.monthall_treatments['monthlystay'] = (all_treatments['monthlyoutdate']-all_treatments['monthlyindate']).astype('timedelta64[d]')# cleaning up:all_treatments = all_treatments.drop(['indatuma','indate','utdatuma','outdate','extramonths'], axis=1)print non-missing values across columns (missing will be dropped):print all_treatments.count(axis=0)all_treatments = all_treatments.dropna()treatment_summaries = {name: all_treatments[(all_treatments.diagnos.str.contains('{0}'.format(code)))].groupby(by=['lopnr','monthlyyear','monthlymonth'],as_index=false,sort=false).sum().astype(int, copy=false,raise_on_error=false) for name, code in items.iteritems()}del all_treatments# finally, save the aggregated results to files.[treatment_summaries[name].to_csv('path/inpatient_treatments_monthly_sliced_{0}.csv'.format(name)) for name in items.keys()]i haven't done extensive profiling of where the memory or processing bottlenecks are with the current model.",
    "present_kp": [
      "numpy",
      "pandas"
    ],
    "absent_kp": [
      "python",
      "performance"
    ]
  },
  {
    "text": "is order of bits in byte really not of concern?. what i can't wrap my head around is sentence repeated everywhere i look, that order of bits in byte is not important(not of my, as a programmer, concern).my question then is if there is possibility that it makes difference?for example, i crate a binary file with just 0x1 in it (represented on my machine as <phone>). what keeps other machine to read the same byte as 128(<phone>) ?is there standard for msb placement in file, memory that guarantees compability or am i missing something trivial/obvious along?edit:thanks to dirk5959's answer i found out that my machine is little-endian for bytes and the same is for bits in byte. additional question is, if it is a rule or there is some architecture that behaves different?",
    "present_kp": [],
    "absent_kp": [
      "computer architecture",
      "memory access"
    ]
  },
  {
    "text": "summing up an array inside of awk?. i have the following piece of code:sum1=sum2= declare -a aecho $temp | awk '{split($0,a,,); name=a[1] ; for(i=2;i<=4;i++) sum1+=a[i] ; for(i=5;i<=7;i++) sum2+=a[i] }'this code is not working. here temp is a string of type:abc,1,2,3,4,5,6i am beginner and need some suggestions. actually i am parsing data from a file.the input file is like:abc,1,2,3,4,5,6de,3,5,7,8,4,2xyz,6,5,3,7,8,2i am reading it usingwhile read tempdo #do somethingdone < sample.csvand expected output is of the form:name sum1 sum2abc 6 15de 15 14xyz 14 17",
    "present_kp": [
      "awk"
    ],
    "absent_kp": [
      "bash",
      "shell",
      "shell script",
      "scripting"
    ]
  },
  {
    "text": "radare2 search first occurrence before. is it possible to use radare2 to perform a search like the following:first occurence of ldr r1 before address 0x000048b4in the following example it should return:0x000048b2 ldr r1, [pc, 0x20]radare2 is able to guess the value of [pc, 0x20] (511). would it be possible to retrieve that separately ?",
    "present_kp": [
      "radare2"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a philosophical counterpart question to p != np?. gdels motivation to prove his incompleteness theorems was the philosophical statement this sentence is wrong.. is there a philosophical counterpart to the statement p != np? for example such statement might be this theorem is practically unprovable. the consequences of an existence of such theorem would be: if the sentence is true, than there is no practical way to prove it. if it is not true, then there is a practical way to prove it, hence it must be true, which is a contradiction. since p!=np is such a deep question, i wonder if philosophist have a counterpart question in the sense given above.",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "p vs np"
    ]
  },
  {
    "text": "best semantic structure & seo optimised approach for image replacement for badges?. in the past, i extensively used css image replacement techniques for seo purposes and to separate presentation from content. but from my reading of the google webmaster guidelines and other comments recently, i'm starting to question whether it is better to use <img> with alt attributes in most cases, reserving css image replacement for cases where there isn't an alternative.for example, i'm trying to display a 'badge' image showing the iso9001 certification of a client. am i right in concluding that the best approach would be to mark up something like...html:<div class=accreditationitem> <h4>iso9001 accreditation</h4> <p>quality iso 9001 certified system</p> <p>fm 999999</p> <img alt=quality iso 9001 certification - fm 999999 src=iso9001-badge.jpg/></div>css:div.accreditationitem h4, div.accreditationitem p { display: none;}",
    "present_kp": [
      "seo",
      "google",
      "css"
    ],
    "absent_kp": [
      "images"
    ]
  },
  {
    "text": "how to create / find static targeted ads. i'm not sure how to ask the right question but i noticed on this website, each post has very specific targeted ads that fit the overall theme of the blog post.www.ma-petite-chou.comi'm only familiar with google adsense, in which a text box just displays dynamic ads.i just don't understand how this blog is displaying permanent very specific ads. any pointers will be helpful.",
    "present_kp": [],
    "absent_kp": [
      "advertising",
      "static content",
      "ad targeting"
    ]
  },
  {
    "text": "how to add friends on ultranet?. my government primary school where i am a student, has just given us ultranet and i was wondering how do i add friends on it so that i can see their blog posts and their wall or just at least see their blog.",
    "present_kp": [
      "blog",
      "friends"
    ],
    "absent_kp": []
  },
  {
    "text": "$np$-complete problems on cubic hamiltonian graphs. the class of cubic hamiltonian graphs is well studied class. i came across the fact that independent set problem is $np$-complete when restricting input to cubic hamiltonian graphs. i am interested in other hard problems on this class.which $np$-complete problems on cubic graphs remain hard when restricted to cubic hamiltonian graphs?a survey of such hard problems would be very nice.motivationgiven two np-complete problems on a restricted graph class, i would like to understand the intractability boarderline when we further restrict input instances.update: i am not interested in decision version of optimization problem such as clique problem (or maximum independent set). however, dominating clique problem is the kind of $np$-complete problem that would interest me if it was hard on cubic hamiltonian graphs. dominating clique in graph $g(v,e)$ is a dominating set of $v$ and a clique of $g$. dominating clique problem is interesting for me because the problem definition does not contain a parameter ( unlike clique or mis for which we must specify the size of the required solution).",
    "present_kp": [],
    "absent_kp": [
      "cc.complexity theory",
      "graph theory"
    ]
  },
  {
    "text": "converting web.config from iis6 to iis7 format. i'm a bit stuck, kinda been lumbered with a website developed over a year ago. the company that designed it and the company that own it dont now speak so i have been lumbered with trying to get it to work. bought the web space and have loaded it on to one of our sub domains while i get it working. problem is that the hosting provider is running iss7 and the web.config was designed in iis6 so am getting an error500 cause the tags are wrong. could anyone give me some pointers on how to migrate the current web.config file over to iis7.",
    "present_kp": [
      "iis7",
      "iis6"
    ],
    "absent_kp": []
  },
  {
    "text": "parallelising processing of users. update i updated my question to reflect the fact i'm working with a database.i need to process user actions:the actions for each user change the user's balance which is then persisted to a database.a user's action must be processed sequentially. otherwise, we might corrupt the balance in the database.some actions are associated with 2 users in which case they can't run in parallel with either user's actions. the volume of actions per user varies considerably during the day.update the processes are going to be distributed over several machines. i am trying to find a way to distribute the actions between processes so that the above requirements are met.is there a known paradigm, architecture or algorithm that solves such a problem?i'm looking for a solution that does not involve processes talking to each other except through a message queue or some other scalable mediator.",
    "present_kp": [],
    "absent_kp": [
      "distributed computing",
      "parallelism",
      "load balancing"
    ]
  },
  {
    "text": "what is the difference between nss and pam?. from my readings, nss seems to be a superset of pam. pam on the other hand are just limited to authentication/authorization. am i correct ?",
    "present_kp": [
      "authentication",
      "pam"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i convince a team member to use a web framework?. the question is this and the detail follows: is there anything i can say/bring up, as a programmer, to bring him to my side? i'd love to hear valid arguments for both sides on this one, but mostly suggestions for how to talk him around.my situation is this: i'm working on a team project on my degree course, building a mid-sized website as a prototype for the university. all are considered equals in the group and there is no one appointed leader so the answer to this problem can't be pull rank. all are equals, however there is a huge gap in knowledge between members. the team member in question and i are both capable developers, though he holds no industry experience. the other three members are less capable, and two have opted out of development entirely. all three have declined to comment on the situation due to lack of knowledge.as as a group, we are coming to decide on what technologies to use in the implementation of the website; specifically, whether to use a php framework (code igniter) or not. i am arguing in favour, citing:not reinventing the wheelwell written and tested code base to work fromgetting going (the deadline is closer than we'd like)speed of developmentsound and maintainable design patterns and good practiceshe is arguing in favour of working in the way he's used to: writing bespoke, one-time functions in to a library file as when he needs them functions for data access and rendering that data the page, getting/setting to and from session and get/post data etchaving 1 file per page (resulting in no separation of concerns amongst control, presentation and data)his reasons against using are framework are mostly based on him not being able to see the point: he can do all those things already. the framework doesn't change that, it just makes it harder because he has to learn the framework; he doesn't want to use code he hasn't personally written. he has also said that it doesn't matter the quality of the code base, since the project is only a prototype and will never be maintained. for me, that is no excuse to write unmaintainable code.i can see why he makes those arguments, but i hold issue with his lack of concern over maintainability and his disregard for good design, or even separation of concerns. however, i suspect he has never studied design patterns, so i don't know how effective demonstrating why his method could prove unmaintainable would be.i want to get going on this project, but i don't want to do it without regard for everything i've learnt over the years. as i said before, there is no possibility of pulling rank here, nor are other team members willing to pitch in. should i just back down and do things his way? is he too stubborn and inexperienced to know better? or am i being the stubborn one here?tl;drinexperienced team member is being stubborn, how can i win him over?",
    "present_kp": [],
    "absent_kp": [
      "professionalism"
    ]
  },
  {
    "text": "adding kill to a sudoers group. how can i give permissions in sudoers such that each member of a group is able to kill the process owned by another member of the group?scenario: i have two users -- bill and dev-cron -- who are members of the group tech. i'd like bill to be able to kill processes started by dev-cron.",
    "present_kp": [
      "sudo",
      "kill",
      "group"
    ],
    "absent_kp": []
  },
  {
    "text": "install linux to ssd or hdd for virtualizing windows with qemu?. in my pc i have 1 tb slow hdd and 120 gb fast ssd. i am curious which one of my drives should be used for ubuntu installation.i plan to use windows without dual-boot - by virtualizing it with qemu (iommu, vt-d). e.g. i am going to use qemu virtual hdd files as hdd in guest windows.i wonder if there is any difference if the virtual hdd file will be on clean ssd, or it will share same drive with ubuntu installation. can i improve windows guest performance by keeping host os on another hdd than guests's hdd, or it is completely irrelevant for qemu?",
    "present_kp": [
      "performance",
      "qemu",
      "ssd"
    ],
    "absent_kp": [
      "virtual machine"
    ]
  },
  {
    "text": "how to revert a test account to a normal account on facebook. i want to start developing some facebook applications and i came across this page that allows me to create a test account.please do not click the make [your name] test accountbecome a platform app test accounti went against my urge to click and decided to google a bit and it seems this option converts your actual facebook account into a test account.how can one revert this change ?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "how to specify memory region for ramdrive. we are setting up a linux based benchmarking cluster. each node is going to be a headless, diskless machine, booted via tftp, the os copied to a local ramdrive, and the same ramdrive is used as local drive by the benchmarked application. my problem is the following: the machines have 2 cpus, each has its own memory banks and have 4 memory channels to those banks (so the banks are populated with multiples of 4 memory chips to get maximum memory throughput). if i can't control which memory regions are used for the ramdisk, then it may be possible that it will be created in a region that is on one single channel, and uses all memory on that chip. which means that when my application is running then the threads running on the cpu from whose memory bank the ramdisk was taken would have 25% less memory bandwidth to their local memory than the threads on the other cpu. that would be bad. hence the desire to control which memory regions are used by the ramdisk.or is this a non-issue and i can just trust the memory controller to lay out contiguous memory addresses in a strided fashion among the chips on the 4 channels? that would make sense, since that would maximize the memory bandwidth when pulling in large chunks of memory into cache.i just don't know how these things work and would appreciate some enlightment...",
    "present_kp": [
      "linux",
      "memory",
      "ramdisk"
    ],
    "absent_kp": []
  },
  {
    "text": "need to configure network card manually after each reboot. i am using suse linux enterprise server 11 (x86_64) as vm ware virtual machine (that was cloned). not sure why but network card cannot be configured via yast2. if i go to edit and hit enter yast will go back to control center. also in yast2 i can see that the card is not connected. no idea what it means though.but if i go command line and issue these two commands the network is up and running.ifconfig eth1 10.0.0.xxx netmask 255.255.255.0 broadcast 10.0.0.255route add default gw 10.0.0.1 eth1from /var/log/messagesjun 18 14:20:19 edumate kernel: [ 221.986998] e1000: eth1 nic link is up 1000 mbps full duplex, flow control: nonejun 18 14:20:19 edumate kernel: [ 221.988366] addrconf(netdev_up): eth1: link is not readyjun 18 14:20:19 edumate kernel: [ 221.988482] addrconf(netdev_change): eth1: link becomes readyjun 18 14:20:29 edumate kernel: [ 232.399704] eth1: no ipv6 routers presentq1: would anybody know how to fix the network configuration orq2: what files i update with above two commands so i can have network up and running after each reboot?editsremoving /etc/udev/rules.d/70-persistent-net.rules and rebooting didn't helpcontent of /etc/sysconfig/networkedu:/var/lib/edu/bdrs # cd /etc/sysconfig/networkedu:/etc/sysconfig/network # lltotal 108-rw-r--r-- 1 root root 13192 jun 5 16:30 config-rw-rw-rw- 1 root root 13181 jun 5 15:42 config.backup.by.convert_to_netconfig-rw-r--r-- 1 root root 7482 jun 18 14:10 dhcp-rw-r--r-- 1 root root 7686 jun 5 15:42 dhcp.backup.by.convert_to_netconfigdrwxr-xr-x 2 root root 4096 jun 5 15:42 if-down.ddrwxr-xr-x 2 root root 4096 jun 5 15:42 if-up.d-rw------- 1 root root 172 jan 31 23:45 ifcfg-lo-rw-r--r-- 1 root root 29333 jan 31 23:45 ifcfg.template-rw-r--r-- 1 root root 239 jan 31 23:45 ifroute-lodrwx------ 2 root root 4096 may 6 2010 providers-rw-r--r-- 1 root root 22 jun 18 14:07 routes-rw-r--r-- 1 root root 0 jun 18 14:07 routes.yast2savedrwxr-xr-x 2 root root 4096 jun 5 15:42 scripts",
    "present_kp": [
      "virtual machine",
      "suse"
    ],
    "absent_kp": [
      "init script",
      "networkcard"
    ]
  },
  {
    "text": "how to fix error: symbol lookup error: /usr/local/lib/libqt5dbus.so.5: undefined symbol?. i was using gns3 network simulator fine for a while & then after few dayswhen i start gns3 network simulator, it is giving out following error, not sure what caused this.$ sudo gns3 gns3 gui version 1.5.2copyright (c) 2007-2016 gns3 technologies inc.your locale en_in.iso8859-1 encoding is not utf-8, switching to the utf-8 version...2016-12-23 22:57:53 info logger.py:107 log level: info/usr/share/gns3/gns3-gui/bin/python: symbol lookup error: /usr/local/lib/libqt5dbus.so.5: undefined symbol: _z28qenvironmentvariableintvaluepkcpbi tried reinstalling gns3 but the error persisted.while un-installing, i got the following warnings:dpkg: warning: while removing gns3-gui, directory '/usr/share/gns3/gns3-gui/lib/python3.4/__pycache__' not empty so not removeddpkg: warning: while removing gns3-gui, directory '/usr/share/gns3/gns3-gui/bin' not empty so not removedremoving gns3-server (1.5.2~trusty1) ...dpkg: warning: while removing gns3-server, directory '/usr/share/gns3/gns3-server/lib/python3.4/__pycache__' not empty so not removeddpkg: warning: while removing gns3-server, directory '/usr/share/gns3/gns3-server/bin' not empty so not removedso i removed /usr/share/gns3* and then tried installing gns3 no luck.tried the following suggestions made in this answercommented the line /usr/local/lib in the file /etc/ld.so.conf.d/libc.conf but no use.also when i tried installing gns3 through ubuntu software center",
    "present_kp": [
      "ubuntu",
      "python",
      "python3"
    ],
    "absent_kp": [
      "libraries"
    ]
  },
  {
    "text": "tar - transform stdin without extracting. i am attempting to transform the paths of a tar file coming from standard input without having to extract the tar first.this is an apparent duplicate of this question, i am looking for a solution that can be accomplished without having to extract in order to simplify my script, so i do not care if the performance is the same as extracting.use case:i am creating a tar from git archive, and piping the result to an ssh process that will run on another machine that does not have the --transform option for tar. i will therefore need to transform before sending it over to ssh. i could always extract to a temporary directory, and then recreate another tar with the transform, but i am looking for a one-line solution to temporarily pop into an existing script.",
    "present_kp": [
      "tar",
      "git"
    ],
    "absent_kp": []
  },
  {
    "text": "dcvs and bug database. i am considering implementing the following policy and would like to run it by the community before implementing it:all mercurial commits must have a bug id corresponding to our bug reporting database.all commits immediately preceding a push for a new feature must have a bug id (it's a new feature but the id is still a bug id in the database)this will do several things. first, it will ensure that an entry is always put into the bug database for all code changes. second, it will provide a diff of each change made for each bug fix. this would also simplify commenting in the mercurial commits and put most details about the commit into the bug report.do you know of any reasons why this would be a bad idea? also, do you think i should make some additions to this policy?",
    "present_kp": [],
    "absent_kp": [
      "project management",
      "version control",
      "issue tracking"
    ]
  },
  {
    "text": "parseable windows api documentation. for a project i'm in need of a parseable version of the windows api (i.e. the functions described in msdn).i tried to crawl it myself, but there seem to be more than 5 formats for signatures and parameters used. the msdnapiextractor project does not seem to work anymore.i've seen some projects using help files, but i can't seem anything to parse .hlp files. sadly, using the header files is no alternative, since it lacks argument names.i'm mainly interested in the high-level api (e.g. readfile, closehandle etc.)edit:seems i've been looking at the wrong header files",
    "present_kp": [
      "windows",
      "api",
      "documentation"
    ],
    "absent_kp": []
  },
  {
    "text": "in general, is it ethical to make a copy of work source code and take it home as reference?. is it ethical to make a copy of my work's source code, for the sole purpose of my own reference? by reference, i mean as reference where i can refer to it about how i (and my teammates) implemented various design patterns, architecture, etc. it does not contain any trade secret, product, secret algorithm or anything like that.note that i wrote many parts of the source code, and also the added value from me studying the code will also indirectly benefit the company i am working on.",
    "present_kp": [
      "source code"
    ],
    "absent_kp": [
      "copyright",
      "ethics"
    ]
  },
  {
    "text": "disproving euler proposition by brute force in c. i wrote a little bit of code to brute force disprove the euler proposition that states:$$a^4 + b^4 + c^4 = d^4$$has no solution when \\$a\\$, \\$b\\$, \\$c\\$, \\$d\\$ are positive integers.i'm no mathematician, but reading around this, at least one solution was found by noam elkies in 1987 (a = 95800; b = 217519; c = 414560; d = 422481). i wanted to get an idea of how much firepower it would take to solve by brute force, so i wrote the following in c:#include <stdio.h>#include <time.h>#include <math.h>int prop(long int a, long int b, long int c, long int d) { return (pow(a, 4) + pow(b, 4) + pow(c, 4) == pow(d, 4));}int main() { long int a, b, c, d; clock_t t; t = clock(); for (a = 1; a < 100000; a++) { for (b = 1; b < 300000; b++) { for (c = 1; c < 500000; c++) { for (d = 1; d < 500000; d++) { if (prop(a, b, c, d)) printf(found it! a = %ld b = %ld c = %ld d = %ld , a, b, c, d); } if (!(c%1000)) printf(a = %ld, b = %ld, c = %ld, time = %fs , a, b, c, ((double)(clock() - t))/clocks_per_sec); } printf(a = %ld, b = %ld, time = %fs , a, b, ((double)(clock() - t))/clocks_per_sec); } printf(a = %ld, time = %fs , a, ((double)(clock() - t))/clocks_per_sec); }}i ran it for a while, and worked out that it would take roughly \\$85 imes 10^6\\$ years for it to get to the answer above on my current machine.i mean, maybe if i waited a few thousand years, i'd have a slightly better machine, but my question is (and i am new to c and computer science in general - so please be gentle); what strategies could i take to make the above code run faster? i thought about threading, and using some sort of bit shifting in place of the pow() calls.would there be any way (on my current machine) to get this to run in my lifetime?",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "beginner",
      "multithreading",
      "time limit exceeded",
      "mathematics"
    ]
  },
  {
    "text": "how to list users without a strong password?. i would like to list the username of the users which do not have a strong password in a lan.how can i do it?i do not want to force the password of the users, i want to force the users that have no password or not strong one to change it and use a stronger one.",
    "present_kp": [
      "password"
    ],
    "absent_kp": [
      "linux",
      "security"
    ]
  },
  {
    "text": "alsa capturing mono microphone as right channel of stereo. the laptop microphone is mono but audio seems to get captured as stereo.the resulting recording has the sounds captured by the mic in the right channel and for some reason whatever sound is currently playing (speaker or headphones) is recorded as the left channel.telling arecord to use one channel doesn't seem to have any effectarecord -c 1 -d 3 -f dat foo.wavand setting audacity to capture mono instead of stereo results in nothing getting recorded.what could be causing this and how do i get capture to work properly?amixer output: <url>",
    "present_kp": [
      "alsa",
      "recording"
    ],
    "absent_kp": []
  },
  {
    "text": "why can't i use an operator like plus sign to concatenate strings?. why in objective-c we should be typing explicit references to methods like stringbyappendingstring to concatenate strings, when in some other languages we can use operators for that?for example, java and c++ let us just concatenate strings in a similar fashion to the way we make our programs add two numbers.",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "language design",
      "history",
      "objective c"
    ]
  },
  {
    "text": "will using google's pagespeed module help to speed up a site with magento?. i'm considering installing google's pagespeed module on a debian linux / apache 2.4 web server to speed up a magento ce website. will using google's pagespeed module help to speed up a website using magento?",
    "present_kp": [
      "magento",
      "debian"
    ],
    "absent_kp": [
      "apache2",
      "performance",
      "google pagespeed"
    ]
  },
  {
    "text": "two sitemap.xml with wordpress in subfolder. i have a site at example.com which also hosts a wordpress blog at example.com/blog/i am generating a sitemap.xml at my main site which also includes urls from my wordpress blog. what is the proper way to do this? should i let wordpress generate its own sitemap.xml under /blog/ and only include urls from my main website in the root sitemap.xml?is it hurting anything if they both exist?",
    "present_kp": [
      "sitemap"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "use bash for irssi. alright i am writing a shell script to open irssi and then automatically connect to freenode. should i edit the file at ~/.irssi/config or is there a way to simulate me typing /connect irc.freenode.net? i have used echo, send, and expect but it hasn't worked. here is the code i have so far.irssiecho /connect irc.freenode.net",
    "present_kp": [
      "bash",
      "irssi"
    ],
    "absent_kp": []
  },
  {
    "text": "ddrescue - avoiding sectors that shut the controller down. i have a problem with my ssd drive it would appear that the controller started acting up. what happens is that if requested to read specific sectors, it will completely shut down the access to disk. at this point not even restarting or acpi power off helps i actually need to physically unplug and plug the cord back to make it work again.i naturally want to rescue as much as possible, but its extremely time consuming with ddrescue, given the way it works. i played with i option, trying to force it to skip specific areas of the disk, but either i do not fully understand the way it works, or the tool ignores the option most of the times. mind that i do understand that i by design may be ignored depending on the direction ddrescue attempts to read sectors from, yet many times it was ignored despite the right order of reading - e.g. in case my i byte was x+1000 but ddrescue upon starting still attempted to read byte x in forward direction.my question here is whether there is a way to mark some byte untouchable, so that ddrescue avoids reading it altogether - possibly by manually editing the log file? if not, do you have any other tips on how to recover the data efficiently?edit: just found mapfile (logfile) documentation and based on what i see there, it should be fairly easy to prepare it to make ddrescue do what i want it to.",
    "present_kp": [
      "ssd",
      "ddrescue"
    ],
    "absent_kp": []
  },
  {
    "text": "what part of your project should be in source code control?. a fellow developer has started work on a new drupal project, and the sysadmin has suggested that they should only put the sites/default subdirectory in source control, because it will make updates easily scriptable. setting aside that somewhat dubious claim, it raises another question -- what files should be under source control? and is there a situation where some large chunk of files should be excluded?my opinion is that the entire tree for the project should be under control, and this would be true for a drupal project, rails, or anything else. this seems like a no-brainer -- you clearly need versioning for your framework as much as you do for any custom code you write.that said, i would love to get other opinions on this. are there any arguments for not having everything under control?",
    "present_kp": [
      "drupal"
    ],
    "absent_kp": [
      "version control"
    ]
  },
  {
    "text": "running the double tree heuristic in a given graph - some slight confusion. i'm working on an exam question that asks me to run the double-tree heuristic algorithm on the following graph:this algorithm starts by finding a minimum cost spanning tree. my solution: minimum spanning tree contains edges ec, cb, dc, dadoubling these edges to find an euler tour: a, d, c, b, c, e, c, d, aremoving duplicate edges: a, d, c, b, e, aactual solution:minimum spanning tree contains edges ed, ec, cb, dadoubling these edges to find the euler tour: a d e c b c e d aremoving duplicate edges: a d e c b a (cost: 51)i want to know if i have used the algorithm correctly. can there be more than 1 specific solution to this problem?",
    "present_kp": [],
    "absent_kp": [
      "graphs"
    ]
  },
  {
    "text": "what is faster? using rest api or querying a database directly?. what is faster performance wise? creating a rest api and having your web app use the rest api to do all interactions with your database or querying your database directly (i.e. using whatever typical object your language uses to query a database such as jdbc for java)?the way i see it with rest:you make an object in your code to call the rest methodcall http methodcode inside your rest api queries the databasedatabase returns some data rest api code packs up the data into json and sends it to your clientclient receives json/xml response map response to an object in your codeon the other hand, querying a database directly:you make an object with query string to query the databasedatabase returns some datamap response to an object in your codeso wouldn't this mean that using a rest api would be slower? maybe it depends on the type of database (sql vs nosql)?",
    "present_kp": [
      "database",
      "rest",
      "sql"
    ],
    "absent_kp": []
  },
  {
    "text": "how-to convince company to start documenting for legacy software. it has been less than a year since i joined my current company. their majority of sales have come from a single product that has been alive since the last 10 years. however, there is minimal (if at all) documentation. not only do the developers in the company struggle with the lack of documentation but also there is a high amount of turnover, causing everyone to lose their time. this is because experienced developers have left the company and there is less and less resources to communicate/brain storm with.without getting into too much detail, i have suggested to the previous manager that there needs to be some sort of documentation (at least an architecture document) that outlines the product. i also suggested using javadoc and other automatic documentation tools. these suggestions were responded to by slight smiles and statements of the sort we do not have enough time, we need short-term improvements right now and even the code itself should be the documentation from the programmers themselves.i have already wasted enough time trying to find out if what i needed per requirement/bug had existed in this big (really) code base. i am looking for any suggestions that you might give regarding the need of documentation. or, rather, if this is a lost case for this legacy system or organization.",
    "present_kp": [
      "documentation",
      "legacy"
    ],
    "absent_kp": [
      "source code",
      "documentation generation"
    ]
  },
  {
    "text": "how to develop complex applications. i want to know the approach in developing big complex application regardless of which programming language to use. i want to know how developers make such big applications such as internet banking, api's and big database management application. how should one approach to make such applications. i have only 1 year programming experience so far and i work as a freelancer so when i saw such applications lots of questions came in my mind. how to understand the basic need of information technology. what actually it is? how it can be useful for common people of small towns. i want everyone to make use of technology no matter they are educated or not, rich or not. please post some suggestions.",
    "present_kp": [
      "database"
    ],
    "absent_kp": [
      "programming languages"
    ]
  },
  {
    "text": "meta description showing other content other than specified in meta tag when inspected. please see the link as given.https://bhetincha.com/gurkha-technologieswhen searched for in google the meta description is different.but when i view page source it the meta description is different.why is google not showing the coded meta description ?",
    "present_kp": [
      "meta description"
    ],
    "absent_kp": [
      "seo",
      "local seo"
    ]
  },
  {
    "text": "is this a good structure for my website?. i have been building a site using php and would like advice to improve the structure of my site and the best way to lay out my code for seo. i'm also a little concerned about echoing large chunks of html and how seo will work with my structure.ok here's my structure...my site contains many pages with only the body content changing for each page. so i have created template functions in php for echoing html. i use $_get['page_id'] in a switch statement to determine what page content to load. .my pages look something like this....header(); //echo header html switch ($_get['page_id']) //echo body content { default: homepage(); break; case 1: servicespage(); break; case 2: gallerypage(); break; case 3: contactpage(); break; } footer(); //echo footer htmland my php functions look like this function header() { echo <div> <h1>header</h1> </div>; } function footer() { echo <div> <h1>header</h1> </div>;} function homepage() { echo <div> <h1> home </h1> <ul> <li> home1 </li> <li> home1 </li> </ul> <p>this is home page</p> </div>; }i'm really looking for any pointers to improve my code but my main concerns are...is it ok to echo large chucks of html like that from php? especially with my site growing?does google crawler bot still crawl my site ok using $_get['page_id'] for all my pages?p.s i'm new here, so sorry if any code formatting is a little off!",
    "present_kp": [
      "php",
      "html"
    ],
    "absent_kp": []
  },
  {
    "text": "fft - function only in sine series? can be done with mkl / lapack?. please can i ask, how one can make from function sine series (fourier transform) with mkl? i can do normal exponential fft with mkl (lapack of course), how can i say that i want only sine series?many thanks",
    "present_kp": [
      "lapack"
    ],
    "absent_kp": [
      "fftw"
    ]
  },
  {
    "text": "how to get the glfw_context_version_major value?. this code snippet:glint versionmajor;glfwwindowhint(glfw_context_version_major, 2);glgetintegerv(glfw_context_version_major, &versionmajor);std::cout << version major: << version << std::endl;prints 3 in my screen, but in the first line i set the the glfw_context_version_major to 2. how i can get back that value?",
    "present_kp": [],
    "absent_kp": [
      "opengl",
      "c++"
    ]
  },
  {
    "text": "pandas data frame: calculating custom moving average. i have a time series containing stock price data.i would like to calculate the money flow index (mfi) for each row.given that the mfi, uses the previous approx. 14 rows to calculate the current mfi, what would be the best approach to doing this?the below calculates the current mfi (<url>) for a given dataframe, but i would like to implement this for each row in the data frame# typical price =(high price + low price + closing price) / 3tp=(hst['high']+hst['low']+hst['close'])/3 tp=tp.to_frame(name='price')# raw money flow = typical price x volumetp['raw']=tp['price'] * hst['volume']# identify flow (upwards or downwards)tp['direction'] = np.where(np.nan_to_num(tp['raw'].shift(1))>tp['raw'], 'up', 'down')mfr=0# money flow ratio = (14-day positive money flow) / (14-day negative money flow)if tp.loc[tp['direction']=='down']['price'].sum(axis=0) != 0: mfr=tp.loc[tp['direction']=='up']['price'].sum(axis=0) / tp.loc[tp['direction']=='down']['price'].sum(axis=0)# mfi = 100 - 100 / (1 + money flow ratio)100-(100/(1+ mfr))i managed to work this using the 'apply' function, but this function only allows for 1 argument, whilst i would need to pass more than 1 argument to compute the above.",
    "present_kp": [
      "time series",
      "pandas"
    ],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "displaying the calenday day. i have this (working) code:class calendarday attr_accessor :from_month, :to_month, :year def self.line_of_day_numbers(month,year,start,offset) @line='' @offset=offset finish = (start+6)-@offset self.first_line_padding(start) start-= @offset self.day_numbers(month,year,start,finish) end private def self.first_line_padding(start) if start < 7 @line=' ' * (@offset * 3) @offset=0 end end ...but the methods are tangled and there's a mix of instance and local variables.tests include:it shows the day numbers do expect(calendarday.line_of_day_numbers(2,2000,1,2)).to eq ' 1 2 3 4 5'endit shows the day numbers do expect(calendarday.line_of_day_numbers(10,2000,1,0)).to eq ' 1 2 3 4 5 6 7'endit shows the day numbers do expect(calendarday.line_of_day_numbers(1,2000,8,6)).to eq ' 2 3 4 5 6 7 8'end",
    "present_kp": [],
    "absent_kp": [
      "ruby",
      "datetime",
      "rspec"
    ]
  },
  {
    "text": "any way to send gmail auto-response at certain times every week?. i have a gmail account that it is only monitored monday through thursday. i would like to set something up to automatically send a canned reply for emails received between thursday afternoon and monday morning informing the sender that the email will not be seen until monday morning, and giving emergency contact information. i don't think this can be done directly in gmail right now. (vacation replies need to be manually turned on and off, and filters for canned email do not include any date/time options.) can i set gmail out of office replies for every week recurring? also suggests that this is was possible in gmail, at least at the time of that question. is there any work-around or way to do some simple coding to accomplish this? i have a software development background, but i'm not aware of what (if any) options are available to the general public to extend gmail.",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "automation"
    ]
  },
  {
    "text": "implement java/javafx on arm. i am working on arm linux.i have found this link that says that javafx could work on arm.i am confused about embedded java se and javafx arm. do i need to setup a jvm for those or not?i have compiled my own kernel and built a functional root file system with busybox, glibc library and arm cross compiler toolchains.should i need to implement a jvm to get the j2se and javafx platform?i just want to build a small java based os especially using javafx. i have the glibc-2.9 library to run the framework as said by the requirement to run embedded j2se. but there is no tutorial about how to install or set it up to work. can anyone help me?",
    "present_kp": [
      "linux",
      "java",
      "embedded",
      "arm"
    ],
    "absent_kp": []
  },
  {
    "text": "multiple enumerations of ienumerable. i have a snippet of code here that uses c# and linq. the ganttdata variable i have has 12 warnings stating:possible multiple enumerations of ienumerableshould i change it to a list or leave it the way it is?private ienumerable<productlinedto> filterathighestlevel(ienumerable<productlinedto> ganttdata, ganttfilterdto ganttfilterdatamodel) { if (ganttfilterdatamodel.projectid == null) return ganttdata; //check if it's a productline, project, or subproject that was selected from the project filter productline productline = unitofwork.productlinerepository.getall().singleordefault(x => x.productlineid == ganttfilterdatamodel.projectid.value); project project = unitofwork.projectrepository.getall().singleordefault(x => x.projectid == ganttfilterdatamodel.projectid.value); subproject subproject = unitofwork.subprojectrepository.getall().singleordefault(x => x.subprojectid == ganttfilterdatamodel.projectid.value); if (productline != null) ganttdata = getprouctlinesfromdto(ganttdata, ganttfilterdatamodel.projectid.value); else if (project != null) { ganttdata = getprouctlinesfromdto(ganttdata, project.productlineid); //its always the first one ganttdata.elementat(0).projects = ganttdata.elementat(0).projects.where(x => x.projectid == ganttfilterdatamodel.projectid.value); } else if (subproject != null) { ganttdata = getprouctlinesfromdto(ganttdata, subproject.project.productlineid); /// don't just filter for the subproject get the project and show the entire project tree /// what's the point of this filter then? var rootproject = subprojectservice.entityrepo.getall().firstordefault(x => x.subprojectid == ganttfilterdatamodel.projectid.value); ganttdata.elementat(0).projects = ganttdata.elementat(0).projects = ganttdata.elementat(0).projects.where(x => x.projectid == rootproject.projectid); } return ganttdata; } private ienumerable<productlinedto> getprouctlinesfromdto(ienumerable<productlinedto> ganttdata, guid id) { return ganttdata.where(x => x.productlineid == id); }",
    "present_kp": [
      "c#",
      "linq"
    ],
    "absent_kp": []
  },
  {
    "text": "script for backup each db on server but omit system databases. i have read a lot of post around this topic but i didn't found the one to fit my needs. so, basically i want to make two backups: one at mid day (12 pm) and the other at midnight (12 am) for each database on a mysql server but i want to leave out system databases: mysql and information_schema (as far as i know is there is another one please let me know). after read a lot of topics i come with this bash script:#!/bin/shnow=$(date +'%d_%m_%y_%h_%m_%s')filename=db_backup_$now.gzbackupfolder=/home/backupsfullpathbackupfile=$backupfolder/$filenamelogfile=$backupfolder/backup_log_$(date +'%y_%m').txtecho mysqldump started at $(date +'%d-%m-%y %h:%m:%s') >> $logfilemysqldump --user=userbackup --password=***** --default-character-set=utf8 database | gzip > $fullpathbackupfileecho mysqldump finished at $(date +'%d-%m-%y %h:%m:%s') >> $logfilefind $backupfolder -name db_backup_* -mtime +7 -exec rm {} \\;echo old files deleted >> $logfileecho operation finished at $(date +'%d-%m-%y %h:%m:%s') >> $logfileecho ***************** >> $logfileexit 0this script made a backup for database database and keep 7 last .tar.gz files. can any help me to improve this script so i can backup each database other than system ones and keep 7 last copies for each?",
    "present_kp": [
      "bash",
      "backup"
    ],
    "absent_kp": [
      "shell script",
      "scripting",
      "cron"
    ]
  },
  {
    "text": "algorithm to find a polyhedral embedding. a polyhedral embedding of a graph on a surface is an embedding without edge crossings such that all the faces are bounded by simple cycles, and any two faces share a common vertex, share a common edge, or do not intersect at all.i need an algorithm that, given a graph, finds a polyhedral embedding if the graph admits it. i have been looking around but haven't found it. i also need to know the time order of the algorithm.deciding whether a graph admits a polyhedral embedding is np-complete (proved here: b. mohar, existence of polyhedral embeddings of graphs, combinatorica 21 (2001), 395401, <url>). i don't expect an efficient algorithm, just something that works.note: i should mention that i am only interested in the combinatorial aspect of this problem. an embedding of a graph can be described by specifying the cyclic orderings of the edges incident on any vertex, and a signature for each edge, which is +1 or -1 according to whether the cyclic orderings of the two vertices on this edge are consistent along this edge. a face-walk is a walk in the graph where at all vertices the next edge is the leftmost edge according to the cyclic ordering on the vertex. a polyhedral embedding is an embedding where all the face-walks are simple cycles. the problem is then to find a circular ordering of edges around each edge and a signature for each edge such that all face-walks are simple cycles.",
    "present_kp": [],
    "absent_kp": [
      "ds.algorithms",
      "reference request",
      "co.combinatorics",
      "topological graph theory"
    ]
  },
  {
    "text": "how can i prevent abandoning a project due to a lack of time?. i have a somewhat popular open source project. it's used by enough people to get a good number of bug reports and some pull requests per month, but not popular enough to have a development team or steady project managers or contributors.due to a lack of time, i haven't had the time to properly maintain the project. even though i currently have some spare time that i can spend on the project, the time that's needed to get the project up to quality looks beyond my reach.how do i salvage this project, instead of it coming abandoned?edit: i'm looking for a specific solution, preferably someone who has experienced the same issue and managed to overcome it. answers like 'trying asking for help' without more detail are not useful.",
    "present_kp": [],
    "absent_kp": [
      "project management"
    ]
  },
  {
    "text": "uncomment multiple lines. in vim i can use for instance 10j to go 10 lines down. and i can use . to repeat the last deletion.now, in bash script i have many commented lines like this:# ...# ...# ...# ...# ...# ...# ...# ...# ...etc...say, there are 52 such lines. is there a way to combine moving 52j and repeating the deletion of the # via x and delete 52 lines at once?",
    "present_kp": [],
    "absent_kp": [
      "normal mode",
      "comments"
    ]
  },
  {
    "text": "simple maze game with four rooms. i'm starting to learn lua and in one part of the book i need to convert a maze game that uses goto to another one that doesn't use goto.the maze is the simplest ever made, starting from room #1:---------| 1 | 2 |---------| 3 | 4 |---------this is the original version using goto from the book:goto room1 -- initial room::room1:: do local move = io.read() if move == south then goto room3 elseif move == east then goto room2 else print(invalid move) goto room1 -- stay in the same room endend::room2:: do local move = io.read() if move == south then goto room4 elseif move == west then goto room1 else print(invalid move) goto room2 endend::room3:: do local move = io.read() if move == north then goto room1 elseif move == east then goto room4 else print(invalid move) goto room3 endend::room4:: do print(congratulations, you won!)endand this is my attempt:local rooms = {}rooms[1] = { south=3, east=2}rooms[2] = { south=4, west=1}rooms[3] = { north=1, east=4}currentroom = 1repeat local move = io.read() local room = rooms[currentroom][move] if room == nil then room = currentroom print(invalid move) elseif room == 4 then print(congratulations, you won!) end currentroom = room or currentroomuntil currentroom == 4 the above code is working but i was wondering if there is something i need to change to improve it somehow.",
    "present_kp": [
      "lua"
    ],
    "absent_kp": [
      "adventure game"
    ]
  },
  {
    "text": "the warren buffett problem. here is an abstraction of an online learning / bandit problem that i've been working on in the summer. i haven't seen a problem like this before, and it looks quite interesting. if you know of any related work, i would appreciate references. the problemthe setting is that of multi-armed bandits. you have n arms. each arm i has an unknown but fixed probability distribution over rewards that can be earned by playing it. for concreteness, let's assume that each arm i pays reward $10 with probability p[i] and reward $0 with prob. 1-p[i]. in every round t you select a set s[t] of arms to play. for each arm you select, you pay a fee of $1 up front. for each selected arm, you collect a reward that is drawn from the (unknown) reward probability distribution of that arm. all rewards are credited to your bank account, and all fees are deducted from that account. in addition, you get a credit of $1 at the beginning of every iteration. the problem is to develop a policy to select a subset of arms to play in each iteration to maximize profit (i.e. rewards minus fees for playing) over a long enough horizon, subject to the constraint that it must maintain a non-negative account balance at all times.i did not specify whether the per-arm reward distributions are chosen from a prior distribution or chosen by an adversary. both choices make sense. the adversary formulation is more appealing to me, but probably harder to make progress on. here, the adversary chooses a vector (d1, d2, .., dn) of distributions. given the distributions, the optimal budget balanced policy is to play all arms whose expected reward is greater than $1. let p be the per-step profit of this optimal omniscient policy. i want my online policy to minimize regret (i.e. loss of profit over a time window t) wrt this omniscient policy.",
    "present_kp": [
      "online learning"
    ],
    "absent_kp": [
      "machine learning",
      "lg.learning"
    ]
  },
  {
    "text": "extracting the last component (basename) of a filesystem path. fn basename<'a>(path: &'a str, sep: char) -> cow<'a, str> { let pieces = path.split(sep); match pieces.last() { some(p) => p.into(), none => path.into(), }}usage:println!('{}', basename(foo, '/')); // outputs 'foo'println!('{}', basename(bob/, '/')); // outputs ''println!('{}', basename(/usr/local/bin/rustc, '/')); // outputs 'rustc'i think the split() into a match on last() is kind of elegant.i know there is some work needed to handle both str and string, i am not sold on the use of cow and needing to define a lifetime for the string.i am not sold on cow because later on i need to extract from it.let prog = basename(&args[0], '/').into_owned();it feels like i am working too hard.",
    "present_kp": [
      "rust"
    ],
    "absent_kp": [
      "strings",
      "memory management",
      "url"
    ]
  },
  {
    "text": "a function for block allocation. during jonathan blow's video where he muses about a games-focused programming language, he presents c++ code that allocates a single big block of memory and has n pointers into that block. the purpose being to avoid heap allocating n blocks of memory for n arrays.that code looked to me like it could use some genericity... so i first came up with the following where we would allocate three arrays into a single block of memory:using memory_block = std::unique_ptr<char[]>;template<typename a, typename b, typename c>memory_block block_allocate(a*& p, size_t a, b*& q, size_t b, c*& r, size_t c){ memory_block z = std::make_unique<char[]>(a * sizeof(a) + b * sizeof(b) + c * sizeof(c)); p = reinterpret_cast<a*>(z.get()); q = reinterpret_cast<b*>(p + a); r = reinterpret_cast<c*>(q + c); return z;}improving for any number of arrays gives us:using memory_block = std::unique_ptr<char[]>;namespace detail{ template<typename t> size_t block_size(t* const, size_t const n) { return sizeof(t) * n; } template<typename t, typename u, typename... args> size_t block_size(t* const t, size_t const m, u* const u, size_t const n, args&&... args) { return block_size(t, m) + block_size(u, n, args...); } template<typename t, typename u> void block_assign(t* const p, size_t const offset, u*& u, size_t const) { u = reinterpret_cast<u*>(p + offset); } template<typename t, typename u, typename... args> void block_assign(t* const p, size_t const offset, u*& u, size_t const n, args&&... args) { block_assign(p, offset, u, n); block_assign(u, n, args...); }}template<typename t, typename... args>memory_block block_allocate(t*& t, size_t const n, args&&... args){ memory_block b = std::make_unique<char[]>(detail::block_size(t, n, args...)); detail::block_assign(b.get(), 0, t, n, args...); return b;}it's understood that jonathan's blow's desire is for a language solution to this problem and not the library solution that i present but i had fun coming up with it nonetheless.so, after simple testing the code appears to behave as expected but do you see something missing that would make production-ready?",
    "present_kp": [
      "c++"
    ],
    "absent_kp": [
      "memory management"
    ]
  },
  {
    "text": "optimization of sieve of erathosthenes. #include <iostream> #include <conio.h> #include <windows.h> #include <math.h> using namespace std; #define runs 1000 char z[100000]; int i,j,k,c; void main(void) { dword starttime,endtime; float totaltime; starttime = gettickcount();//get start time for(k=0;k<runs;k++) { c=0; //for (i=0;i<10000;i++) z[i]=0; //clear array memset(z,0,100000); z[0]=1; // 0 is not a prime z[1]=1; // 1 is not a prime //now remove all evens from 4 up for(i=4;i<100000;i=i+2) z[i]=1; //remove evens //now loop through remaing up to square root of max number for(i=3;i<316;i=i+2) { if(z[i]==0) for(j=2*i;j<100000;j=j+i) z[j]=1; } } endtime=gettickcount();//get finish time //calc time for(i=0;i<100000;i++) { if(z[i]==0) {cout<<i<< ;c++;} } cout<<primes found=<<c<<endl; totaltime=((float)endtime-(float)starttime)/(1000.0*runs);//calculate total time in secs cout<<totaltime=<<totaltime<< sec ; printf(press any key to end); getch(); }i'm trying to find any optimization for my sieve of eratosthenes code for counting first 100000 prime numbers.the program first mark all even numbers, than square root of max number.the program already does take fraction of the seconds to count these prime numbers, but i'm looking for any optimization to make it even quicker.",
    "present_kp": [
      "c++",
      "optimization",
      "primes",
      "sieve of eratosthenes"
    ],
    "absent_kp": []
  },
  {
    "text": "bash tab completion stop searching. when i am typing into bash and i press the tab key to auto complete, sometimes it takes a significant time. e.g., file io to read directories takes >5 seconds, and thus i am hung waiting for io to complete before i can continue typing. i get frustrated and ctrl-c so that i can redo what i was typing.ctrl-c is unfortunate, since i must retype everything again. how can i tell bash to stop trying to fulfill my auto complete request.$ /long/path/to/some/d # once i've typed this, i press <tab>. i now will be # stuck waiting for perhaps 10 seconds. the only thing i # know to do is ctrl-c. when i press ctrl-c, i am forced # to retype the original command string.$",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "autocomplete"
    ]
  },
  {
    "text": "transcoding mjpeg stream to flv or mp4. i want to transcode mjpeg stream that comes from ip camera (<url>) to flv or mp4 stream under linux os so that users can play the file using a web based flash player such as flowplayer.i discovered vlc for that purpose but i cannot figure out the exact command line string. i also need http authentication feature since ip camera access is password protected.i also interested in any non-vlc solution if any (ffmpeg?).",
    "present_kp": [
      "ffmpeg",
      "vlc"
    ],
    "absent_kp": [
      "video",
      "conversion"
    ]
  },
  {
    "text": "bing gives net::err_cert_common_name_invalid on my website. i have added my site <url> on bing webmaster. but when i search greymeter on bing.com, it gives <url> as the result, and navigating to it, gives a crossed https with error net::err_cert_common_name_invalid, and this message is displayed:your connection is not privateattackers might be trying to steal your information from <url> (for example, passwords, messages, or credit cards). net::err_cert_common_name_invalidit works perfectly with google.com though. can you please give me any idea, what i am missing, or what needs to be done here?",
    "present_kp": [
      "https",
      "bing"
    ],
    "absent_kp": [
      "security certificate"
    ]
  },
  {
    "text": "how do i cause a watchdog reset of my embedded linux device. is there a command likevi > outvi | outthat i could use to cause a watchdog reset of my embedded linux device?",
    "present_kp": [
      "linux",
      "embedded",
      "watchdog"
    ],
    "absent_kp": [
      "bash",
      "kernel"
    ]
  },
  {
    "text": "samba prompts for a password twice. i have a relatively new samba install configured to give windows users access to some log files on a syslog server (littleengineer). however it's prompting for a password to just get a share listing by accessing \\littleengineer\\, is there a way to disable this behavior so that it will only prompt for a password if the user tries to access a secured share?this is my testparm output:root@littleengineer /var/log/samba $ testparmload smb config files from /etc/samba/smb.confrlimit_max: increasing rlimit_max (1024) to minimum windows limit (16384)warning: the idmap uid option is deprecatedwarning: the idmap gid option is deprecatedprocessing section [aviationlogs]warning: the security=share option is deprecatedloaded services file ok.server role: role_standalonepress enter to see a dump of your service definitions[global] workgroup = bizco realm = bizco.com server string = samba server version %v security = share password server = bizco.com log file = /var/log/samba/log.%m max log size = 50 utmp = yes template shell = /bin/bash winbind use default domain = yes idmap config * : range = <phone>-33554431 idmap config * : backend = tdb cups options = raw[aviationlogs] comment = apache httpd log files (access and error) path = /var/log/central-logs/aviation force user = root guest ok = yesedit:client: windows 7 sp1client machine is vpn'd into the customer's local network but is not part of their ad domain. samba is configured for bizco.com (our client), let's say my laptop is part of the fuzzypants.com domain.from log.%m when i pull the share up and click cancel on the prompt:[2014/08/13 21:56:28.812088, 3] lib/access.c:338(allow_access) allowed connection from xxx.xxx.28.194 (xxx.xxx.28.194)[2014/08/13 21:56:28.812201, 3] smbd/oplock.c:922(init_oplocks) init_oplocks: initializing messages.[2014/08/13 21:56:28.812372, 3] smbd/oplock_linux.c:226(linux_init_kernel_oplocks) linux kernel oplocks enabled[2014/08/13 21:56:28.812519, 3] smbd/process.c:1662(process_smb) transaction 0 of length 159 (0 toread)[2014/08/13 21:56:28.812569, 3] smbd/process.c:1467(switch_message) switch message smbnegprot (pid 2467) conn 0x0[2014/08/13 21:56:28.813049, 3] smbd/negprot.c:598(reply_negprot) requested protocol [pc network program 1.0][2014/08/13 21:56:28.813104, 3] smbd/negprot.c:598(reply_negprot) requested protocol [lanman1.0][2014/08/13 21:56:28.813143, 3] smbd/negprot.c:598(reply_negprot) requested protocol [windows for workgroups 3.1a][2014/08/13 21:56:28.813177, 3] smbd/negprot.c:598(reply_negprot) requested protocol [lm1.2x002][2014/08/13 21:56:28.813212, 3] smbd/negprot.c:598(reply_negprot) requested protocol [lanman2.1][2014/08/13 21:56:28.813247, 3] smbd/negprot.c:598(reply_negprot) requested protocol [nt lm 0.12][2014/08/13 21:56:28.813315, 3] smbd/negprot.c:598(reply_negprot) requested protocol [smb 2.002][2014/08/13 21:56:28.813350, 3] smbd/negprot.c:598(reply_negprot) requested protocol [smb 2.???][2014/08/13 21:56:28.813514, 3] smbd/negprot.c:401(reply_nt1) not using spnego[2014/08/13 21:56:28.813553, 3] smbd/negprot.c:704(reply_negprot) selected protocol nt lm 0.12[2014/08/13 21:56:46.975628, 1] smbd/process.c:457(receive_smb_talloc) receive_smb_raw_talloc failed for client xxx.xxx.28.194 read error = nt_status_connection_reset.[2014/08/13 21:56:46.975865, 3] smbd/server_exit.c:181(exit_server_common) server exit (failed to receive smb request)i can give the log output from a successful authentication but it's probably not as informative.edit #2since the last log didn't have anything telling i went through with the login prompt and began to see check_ntlm_password in log.%m:[2014/08/14 12:33:59.988239, 3] auth/auth.c:219(check_ntlm_password) check_ntlm_password: checking password for unmapped user []\\[]@[] with the new password interface[2014/08/14 12:33:59.988274, 3] auth/auth.c:222(check_ntlm_password) check_ntlm_password: mapped user is: []\\[]@[][2014/08/14 12:33:59.988328, 3] auth/auth.c:268(check_ntlm_password) check_ntlm_password: guest authentication for user [] succeeded[2014/08/14 12:33:59.988379, 3] smbd/process.c:1467(switch_message) switch message smbtconx (pid 6290) conn 0x0[2014/08/14 12:33:59.988450, 3] lib/access.c:338(allow_access) allowed connection from xxx.xxx.29.76 (xxx.xxx.29.76)[2014/08/14 12:33:59.988613, 3] auth/auth.c:219(check_ntlm_password) check_ntlm_password: checking password for unmapped user [bizco]\\[davisja5]@[xxx.xxx.29.76] with the new password interface[2014/08/14 12:33:59.988651, 3] auth/auth.c:222(check_ntlm_password) check_ntlm_password: mapped user is: [xxxxxxvlp01]\\[davisja5]@[xxx.xxx.29.76][2014/08/14 12:33:59.988735, 3] auth/check_samsec.c:399(check_sam_security) check_sam_security: couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.988772, 2] auth/auth.c:319(check_ntlm_password) check_ntlm_password: authentication for user [davisja5] -> [davisja5] failed with error nt_status_no_such_user[2014/08/14 12:33:59.988819, 3] auth/auth.c:219(check_ntlm_password) check_ntlm_password: checking password for unmapped user [bizco]\\[davisja5]@[xxx.xxx.29.76] with the new password interface[2014/08/14 12:33:59.988853, 3] auth/auth.c:222(check_ntlm_password) check_ntlm_password: mapped user is: [xxxxxxvlp01]\\[davisja5]@[xxx.xxx.29.76][2014/08/14 12:33:59.988927, 3] auth/check_samsec.c:399(check_sam_security) check_sam_security: couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.988964, 2] auth/auth.c:319(check_ntlm_password) check_ntlm_password: authentication for user [davisja5] -> [davisja5] failed with error nt_status_no_such_user[2014/08/14 12:33:59.989005, 3] auth/auth.c:219(check_ntlm_password) check_ntlm_password: checking password for unmapped user [bizco]\\[davisja5]@[xxx.xxx.29.76] with the new password interface[2014/08/14 12:33:59.989039, 3] auth/auth.c:222(check_ntlm_password) check_ntlm_password: mapped user is: [xxxxxxvlp01]\\[davisja5]@[xxx.xxx.29.76][2014/08/14 12:33:59.989092, 3] auth/check_samsec.c:399(check_sam_security) check_sam_security: couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.989126, 2] auth/auth.c:319(check_ntlm_password) check_ntlm_password: authentication for user [davisja5] -> [davisja5] failed with error nt_status_no_such_user[2014/08/14 12:33:59.989167, 3] auth/auth.c:219(check_ntlm_password) check_ntlm_password: checking password for unmapped user [bizco]\\[davisja5]@[xxx.xxx.29.76] with the new password interface[2014/08/14 12:33:59.989201, 3] auth/auth.c:222(check_ntlm_password) check_ntlm_password: mapped user is: [xxxxxxvlp01]\\[davisja5]@[xxx.xxx.29.76][2014/08/14 12:33:59.989253, 3] auth/check_samsec.c:399(check_sam_security) check_sam_security: couldn't find user 'davisja5' in passdb.[2014/08/14 12:33:59.989286, 2] auth/auth.c:319(check_ntlm_password) check_ntlm_password: authentication for user [davisja5] -> [davisja5] failed with error nt_status_no_such_user[2014/08/14 12:33:59.989359, 3] smbd/password.c:721(authorise_login) authorise_login: accepted: guest account and guest ok (root)[2014/08/14 12:33:59.989566, 3] passdb/lookup_sid.c:1754(get_primary_group_sid) forcing primary group to 'domain users' for root[2014/08/14 12:33:59.989752, 3] smbd/service.c:872(make_connection_snum) connect path is '/tmp' for service [ipc$]",
    "present_kp": [
      "samba",
      "authentication"
    ],
    "absent_kp": []
  },
  {
    "text": "how to unninstall linux distro in trialboot?. i have ubuntu, fedora and windows installed in my laptop. i installed ubuntu after windows and then i installed fedora. how can i unninstall fedora without messing up the grub, which was reinstalled during the fedora installation?",
    "present_kp": [
      "grub"
    ],
    "absent_kp": []
  },
  {
    "text": "how would i implement a self-destruct feature into the free trial version of my software?. there is the ongoing argument of free trial versus a freemium model (that is, a free-for-life version of their software with restricted and/or stripped down features) for allowing potential customers and users to test run their product. upon my research, i can conclude that the free trial is the way to go on both for the benefit of the user experience of the individual using the software and for the benefit of the vendor in both aspect of sales and maximizing usage. there are many factors for a free trial software that can greatly maximize user usage like the length of the free trial.one keyword that reoccurs on my research for freemium is frustrating. many individuals chose to uninstall the software instead of having to use a piece of software where some features were unavailable to them. at the same time, these users never had the chance to use the paid features. unbeknownst to them, and hidden by the very own vendors who are selling the software, they don't know and cannot know what benefits the pro features will bring. without first having to use them, a user will not know they have the feeling of needing something. which brings me onto my next point of a free trial model.some opinions of a free trial user is i cannot imagine using this software without the pro features. this goes back to the point of the user not knowing they need something until they first understanding the feeling of have. those that have had 14 days to use a the full version features said they cannot imagine not having or using the features provided there. so when fourteen days were over, they were more likely to dish out money than someone who's never experienced the full features. the length of the free trial is also an important factor is creating a lasting impression on users. in an experiment conducted by visual website optimizer, they noticed that for a 14 day free trial versus a 30 day free trial, while the number of sign ups and installs were the same, the usage for the 14 day trial increased 102%. this, of course, in turn increased their revenue as well.another very important point to mention is that offering a useful and fully functional free version of the product is very important. fully functional free trials are effective in getting media coverage, and this publicity for new software and/or software vendors are fairly crucial.one other relevant aspect is the importance for users to give feedback. consider, in the fully functional time-limited free trial, the ability for users to give feedback.one other feature important for our software is the need for telemetric data, that is, quantitative and comprehensive data on how a user uses our software. some of usage statistics may fall into a legal grey area, as laws are different depending on the location in the united states, and the world. one way to combat this legal issue is to have an opt-in feature for gathering anonymous usage statistics. an opt-in feature would mean giving the user an option to turn off statistics gathering and at the same time, the user must be very well aware of what the gathering of anonymous usage information does. it is important to make it clear to the user what data will be collected, what we will be doing with it, and make it easy to turn off any time, including allowing them to change their mind for turning it on or off. for more detailed statistics, like tracking individual activities of users, it could lead to legal issues. the eclipse ide logs detailed usage statistics, but it does it by the full consent of the user. we may have to potentially prepare a consent form with our legal team. the eclipse usage information collection collects this information:1. plug-ins that are started by the system.2. commands accessed via the keyboard shortcuts and actions invoked via menus or toolbars.3. when the view of the editor is given focus.4. system information like the version of the software being used, the operating system being used.5. description of internal errors.kill switcha kill switch for our software can be managed logging the initial data, encrypting it with a salt, and whenever it's an invalid date, that is, the user tried to change it, it would disable the software. another option is to have internet authentication on install, log that date to a central web database, and check the date every time the application is opened.on disabling the software, we can delete vital dlls. the option of having to pay to generate a report cannot be considered.i am interested in implementing a free trial version to my existing software. i plan on having the trial last 14 days. upon the 14th day, my software would prompt the user to either pay for the paid version, or have the consequence of not being able to use it. the free trial version is entirely unlocked, meaning all paid features are there.however, my dilemma is about the best way to implement what to do for an end-of-trial solution. do i delete vital dlls? have a user authentication system upon installation or use? encrypt the initial time and date of use with a salt, and if it's an invalid date (aka they try to change their initial date), disable the software?i am interested in knowing what are some effective measures of disabling software.",
    "present_kp": [
      "software"
    ],
    "absent_kp": [
      "development"
    ]
  },
  {
    "text": "inheritance in test classes. i have an interface serializer with methods serialize and isserializerfor. i created a first implementation of this using tdd, and ended up with a nice clean test case fully covering a nice clean implementation. to get a more concrete idea, here is one relevant commit.now someone else (who is not used to doing tdd) started with writing the second implementation of this serializer interface. this person figured the test needed for the second implementation would have some overlap with my initial test. so an abstract base class for serializer tests was created, holding the methods that are suspected to be common to all serializer test cases.i'm not happy with this for two main reasons. first of all, the only reason inheritance is used here is for code reuse, which is a big code smell. secondly, this breaks the tdd cycle. if i now want to create another implementation of serializer, and create a derivative of the base test class, i end up having to implement all production code in one step.on the other hand, simply duplicating the common code in the test classes seems rather odd as well. i'm hoping composition can be used here in a sane way to avoid these problems.this seems like a reasonably common situation. how would you solve this? what would you do differently?",
    "present_kp": [
      "tdd",
      "inheritance",
      "composition"
    ],
    "absent_kp": [
      "design",
      "unit testing"
    ]
  },
  {
    "text": "any serious risk if mint 17 thinks it is ubuntu?. running mint 17, just ran apt-get upgrade for the first time in a while, with 350mb download. it stops halfway to tell me /etc/issue is not the package maintainers versions. ditto for issue.net and lsb-release, where the diff looks like:-distrib_id=linuxmint-distrib_release=17-distrib_codename=qiana-distrib_description=linux mint 17 qiana+distrib_id=ubuntu+distrib_release=14.04+distrib_codename=trusty+distrib_description=ubuntu 14.04.2 ltsok, i've said no to each of those three file updates (i.e. keep it as mint). now i'm just wondering if this is a symptom of a more serious problem? could apt-get be corrupted? is there some simple check i can do to tell myself everything is ok? google, so far, tells me no-one else has this problem, which seems strange if it is a mess-up in mint packaging.sorry, that is a bit of a wishy-washy question. i guess it boils down to: is it fine to shrug and think nothing about those three files?updatehere is the output of apt-cache policy base-files:base-files: installed: 7.2ubuntu5.2 candidate: 7.2ubuntu5.2 version table: *** 7.2ubuntu5.2 0 500 <url> trusty-updates/main amd64 packages 100 /var/lib/dpkg/status 7.2ubuntu5 0 500 <url> trusty/main amd64 packages 500 <url> trusty/main amd64 packageshowever there are some mint packages still, here is apt-cache policy | grep -i mint: 700 <url> qiana/main i386 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main origin extra.linuxmint.com 700 <url> qiana/main amd64 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main origin extra.linuxmint.com 700 <url> qiana/import i386 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=import origin packages.linuxmint.com 700 <url> qiana/upstream i386 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=upstream origin packages.linuxmint.com 700 <url> qiana/main i386 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main origin packages.linuxmint.com 700 <url> qiana/import amd64 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=import origin packages.linuxmint.com 700 <url> qiana/upstream amd64 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=upstream origin packages.linuxmint.com 700 <url> qiana/main amd64 packages release v=17,o=linuxmint,a=qiana,n=qiana,l=linuxmint,c=main origin packages.linuxmint.com",
    "present_kp": [
      "linux mint",
      "apt"
    ],
    "absent_kp": []
  },
  {
    "text": "health check of web page using curl. i'd like to do a health check of a service by calling a specific url on it. feels like the simplest solution would be to use cron to do the check every minute or so. in case of errors, cron sends me an email. i tried using curl for this but i can't get it to output messages only on errors. if i try to direct output to /dev/null, it prints out progress report. % total % received % xferd average speed time time time current dload upload total spent left speed100 5559 100 5559 0 0 100k 0 --:--:-- --:--:-- --:--:-- 106ki tried looking through the curl options but i just can't find anything to suit the situation where you want it to be silent on success but make noise on errors.is there a way to make curl do what i want or is there some other tool i should be looking at?",
    "present_kp": [
      "curl"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "is it a good idea to use twitter bootstrap 3 for production?. so in the past few weeks i was introduced to bootstrap 3-rc1. i made some web sites using it, and i actually enjoyed it. then, recently, i discovered twitter bootstrap has already released version 3-rc2. it makes me wonder if it's okay for me to use bootstrap rc2 for production now? is it wise if i used it considering it still in rc phase or should i just wait for the official, completed version 3?",
    "present_kp": [],
    "absent_kp": [
      "web development"
    ]
  },
  {
    "text": "ls command: what does the first line mean?. when i do ls -l i get this:calico@a000505:~/documentos$ ls -ltotal 2020-rwxr-xr-x 1 calico calico 8559 2010-11-16 11:12 a.out-rwxrw-rw- 1 smt smt <phone>-14 10:40 java2.pdf-rwxrw-rw- 1 ocv ocv <phone>-16 11:11 test.cbut what does the total 2020 mean? i only have 3 files so it's not the number of files or directories, and i guess it's not the size either. so what is it?",
    "present_kp": [
      "ls"
    ],
    "absent_kp": [
      "shell"
    ]
  },
  {
    "text": "will google crawl a news/rss aggregator site?. i know how to code. i know how to set up a news/rss aggregator site. but i don't know if google will crawl it. will google crawl such a site?the site will have a listing of all the aggregated news with the title, a short snippet of the news, and an image (not all will have an image) of the original news article.when a user clicks the article the user will get redirected to the source.something like drudgereport. i haven't seen a drudgereport link when i search so i can't tell. (maybe because it has something to do with my location i don't know.)anyway any ideas?",
    "present_kp": [],
    "absent_kp": [
      "googlebot",
      "aggregators"
    ]
  },
  {
    "text": "what's the best lesson you have learned in your career?. i think mine is there's no such thing as a five minute job - that programmers tend to be overly optimistic about development and that we should really think through a the implications before promising a quick solution to a problem and then diving in to code",
    "present_kp": [],
    "absent_kp": [
      "interview",
      "career development",
      "experience"
    ]
  },
  {
    "text": "checking opcode values. what troubles me are the empty /**/ brackets. is there a cleaner way of handling this logic?if (opcode == op_0) { /* continue */} else if (opcode == op_1negate) { /* continue */} else if (opcode >= op_1 && opcode <= op_16) { /* continue */} else { throw new exception(decodefromopn called on non op_n opcode); }",
    "present_kp": [],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "aes-ni not passed to guest in virtualbox. i'm trying to use encryption inside a virtual machine. the problem is that the aes-ni doesn't seem to be passed to the guest virtual machine.i have vt-x enabled.this is my host cpuinfo:processor : 0vendor_id : genuineintelcpu family : 6model : 42model name : intel(r) core(tm) i7-2600 cpu @ 3.40ghzstepping : 7cpu mhz : 1600.000cache size : 8192 kbphysical id : 0siblings : 8core id : 0cpu cores : 4apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 x2apic popcnt aes xsave avx lahf_lm ida arat epb xsaveopt pln pts dts tpr_shadow vnmi flexpriority ept vpidbogomips : 6801.03clflush size : 64cache_alignment : 64address sizes : 36 bits physical, 48 bits virtualpower management:this is my guest cpuinfo:processor : 0vendor_id : genuineintelcpu family : 6model : 42model name : intel(r) core(tm) i7-2600 cpu @ 3.40ghzstepping : 7cpu mhz : 3399.615cache size : 6144 kbphysical id : 0siblings : 2core id : 0cpu cores : 2apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 5wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx lm constant_tsc rep_good nopl pni ssse3 lahf_lmbogomips : 6799.23clflush size : 64cache_alignment : 64address sizes : 36 bits physical, 48 bits virtualpower management:am i missing some configuration option? or is this a problem of virtualbox?",
    "present_kp": [
      "virtual machine",
      "virtualbox",
      "encryption"
    ],
    "absent_kp": [
      "i386"
    ]
  },
  {
    "text": "how can i check the first process that is run? i can see both init and linuxrc in root folder. i get a modified linux installation on qnap x86 based nas. in the initrd image file, i noticed there are both a init script /initand a symbolic link that points to a different program(busybox): linuxrc ->/bin/busybox.how can i figure out which one is the init process that is run every time the system is booted?",
    "present_kp": [
      "linux",
      "boot",
      "busybox"
    ],
    "absent_kp": []
  },
  {
    "text": "ldconfig not following user-created symbolic link. i'm attempting to run inkscape 0.48.4-15 (armv7) which is installed via pacman from arch linux arm. $ inkscapeinkscape: error while loading shared libraries: libmagick++-6.q16hdri.so.3: cannot open shared object file: no such file or directoryas expected, the shared object is not available in /usr/lib:$ ll /usr/lib | grep libmagick+lrwxrwxrwx 1 root root 30 jun 5 03:04 libmagick++-6.q16hdri.so -> libmagick++-6.q16hdri.so.4.0.0lrwxrwxrwx 1 root root 30 jun 5 03:04 libmagick++-6.q16hdri.so.4 -> libmagick++-6.q16hdri.so.4.0.0-rwxr-xr-x 1 root root 379428 jun 5 03:06 libmagick++-6.q16hdri.so.4.0.0so i make a symbolic link linking *.so.3 to *.so.4.0.0:$ sudo ln -s libmagick++-6.q16hdri.so.4.0.0 libmagick++-6.q16hd.so.3lrwxrwxrwx 1 root root 30 jun 5 03:04 libmagick++-6.q16hdri.so -> libmagick++-6.q16hdri.so.4.0.0lrwxrwxrwx 1 root root 30 jun 6 15:15 libmagick++-6.q16hdri.so.3 -> libmagick++-6.q16hdri.so.4.0.0lrwxrwxrwx 1 root root 30 jun 5 03:04 libmagick++-6.q16hdri.so.4 -> libmagick++-6.q16hdri.so.4.0.0-rwxr-xr-x 1 root root 379428 jun 5 03:06 libmagick++-6.q16hdri.so.4.0.0and verify that *.so.3 is indeed linked to *.so.4.0.0.$ readlink -f libmagick++-6.q16hdri.so.3/usr/lib/libmagick++-6.q16hdri.so.4.0.0now i reconfigure the dynamic linker run time bindings and rerun inkscape:$ sudo ldconfig $ ldd $(which inkscape) | grep libmagick++libmagick++-6.q16hdri.so.3 => /usr/lib/libmagick++-6.q16hdri.so.3 (0x75cf9000)why is *.so.3 linking to itself and not following the symbolic link created earlier?",
    "present_kp": [],
    "absent_kp": [
      "symlink",
      "dynamic linking"
    ]
  },
  {
    "text": "windows phone 7 app development - is it worth it?. i've written a windows phone 7 application to display the ordnance survey maps that are loved so much in the uk (i am amazed that no-one else has done this yet). however i was about to shell out the 65 to pay for the app hub and get my app to the marketplace when i started investigating how you actually get paid for the apps that people buy. apparently if you are not a us developer then you have to start sending over forms e.g. w8ben form? and even after this the irs takes another 30% (after ms have taken their 30% share). it also mentions vat so maybe there is more money taken off after this as well???has anyone from outside the us actually got all the paperwork sorted so they got paid? did you get tax taken off as well? what percentage of the sales do you actually end up with? is it all worth it? i don't expect to make much from the app but i would like to think i could recoup my 65 and have enough to buy a couple of beers as well.",
    "present_kp": [
      "windows phone 7"
    ],
    "absent_kp": []
  },
  {
    "text": "sort files by highest number in filename. i've got a bunch of files all named like this:name_file-1.txtname_file-2.txtname_file-3.txtsome_other_file-1.txtsome_other_file-2.txtthere are thousands of different filenames, some with just one -1.txt at the end, some with -1.txt, -2.txt ... -60.txti need to copy the highest numbers of each file, so name_file-3.txt, some_other_file-2.txt. how do i do that on a linux command line?",
    "present_kp": [
      "files"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "what tools do php developers use?. possible duplicate:what would you consider best practice workflow tools for web application (php) development? i start my new job next week as a php developer which is my dream job but it's going to be object-orientated which i've only done in java whilst at university.my question is regarding php tools - what are the best ide's (i use notepad++), what versioning packages work best and bug trackers etc, so i was just wondering what tools the php developers out there use in their working lives.",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "self improvement"
    ]
  },
  {
    "text": "is it possible to run fc without showing my inputted commands?. if i'm in bash and i type fc, write echo hello world and save it, it will double print:echo hello worldhello worldinstead of justhello worldis there any way of avoiding it printing my own commands?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": []
  },
  {
    "text": "how to diagnose ssh connection timeout issue?. i am debain and linux beginner so please bare with me.i have a vps running debian 7, that i connect to using putty from my windows machine. most of the time, putty connects fine and i can log in fine. however, occasionally, putty will report that connection timeout.when this happened last time, i attempted to telnet to the port that is running ssh and it could not connect. i then attempted to telnet to another port on the vps that i knew was running a service and it connected fine.when it starts to play up, if i try 5-10 times to connect, i can successfully connect. i checked the syslog and i could not see anything interesting in there that could help with this problem. if it is worth anything, when i do connect to the server when it is playing up, it appears to be slow (i will type a command and it will take a second or two to appear in the ssh window).i don't believe this to be a firewall issue as it will work most of time, then sometimes just not work. maybe my host is doing some maintenance? as i said, i am a beginner so any help would be appreciated.edit: tcpkeepalive is enabled. it played up again just now and when attempting to telnet to the ssh port, it could in fact connect. weird.",
    "present_kp": [
      "debian",
      "ssh"
    ],
    "absent_kp": [
      "openssh"
    ]
  },
  {
    "text": "(ethernet cables): can a straight wire work (slightly) where a crossover-wire is necessary (without mdx)?. if i connect a straight ethernet cable where a crossover cable should be used. can i get the behaviour that it works occassionally, once in a while? too me it seems it would either work or not, not occassionaly -is this correct?i have a situation where ethernet sometimes work, and sometimes after reboot it stops working. the question is then -can crossover wiring be the culprit or not? one end is not auto mdi-x but the other probably is.it would seem it would rather have something to do with speed negotiation or so but i don't know.",
    "present_kp": [
      "ethernet"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i redirect only stderr?. i am having a bit of trouble doing this. i am required to run a compiled .java file and redirect only stderr to a file called error. so the .java file is named javaprogram.java.this is what i have tried:java javaprogram 2> errorhowever when icat errorit appears that there is stuff in there, even when i know for a fact that the specific .java file has no errors. am i doing something wrong? all i want this error file to display is errors, not anything else.",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "compiling",
      "io redirection"
    ]
  },
  {
    "text": "does algorithm design belong to software engineering?. in academic meaning, it seems to me that algorithm design is studied in a high/abstract level of computation (computability, complexity), although software engineering is also studied in high/abstract level in academia.software engineering is about the process of creating a software program for solving a problem. that seems to make algorithm design part of the process.but from the limited references on software engineering that i have taken a glanced at, algorithm design isn't discussed (but i may miss something).instead, pattern design (or is it called design pattern instead?) is discussed in software engineering.my questions are:does algorithm design belong to software engineering? is algorithm design a step in the process of software engineering?what are the differences and relations between algorithm design, pattern design, program design, and system design? these words can be heard often from industry as buzzwords. can you share the definitions of these various kinds of designs?",
    "present_kp": [
      "design",
      "software",
      "system"
    ],
    "absent_kp": [
      "design patterns",
      "algorithms"
    ]
  },
  {
    "text": "why does a usb drive only mount as read-only after copying a disk image to it?. i was preparing a usb thumb drive for installing debian 8.3. per the installation instructions, it suggests:cp debian.iso /dev/sdx # e.g. /dev/sdb, no /dev/sdb1syncso i gave this a try. i noticed after doing this that if i try to mount /dev/sdb1, it does mount, however it always mounts as read-only, regardless of whatever options i pass. i tried with a few usb drives, with the same result.why will the drive only mount as read-only after doing the above? is there a way to still mount it as rw?",
    "present_kp": [
      "mount"
    ],
    "absent_kp": []
  },
  {
    "text": "f2fs vs ext3/ext4. we are using beaglebone black based custom board,we are planning to use emmc in our board.we are in the process of checking different filesystem options,what are the different file system we can use for emmc ?usage of ext3/ext4 is very famous, but is it worth investing in evaluating btrfs or f2fs.we are bit worried when we think of using f2fs file system, because it is being developed by samsung, we are worried about roadmap of f2fs file system and further update of the same.what approach should we use to evaluate different filesystems? any suggestions/pointers for the same ?",
    "present_kp": [
      "filesystems"
    ],
    "absent_kp": [
      "linux",
      "embedded"
    ]
  },
  {
    "text": "find duplicity files after using photorec. i've partly formatted a disc where my duplicity files was stored. i have used photorec to recover the files but now they're all unsorted and without the correct filename. i have the files separated by extension. is there a way to discover the duplicity files and recover my backup?",
    "present_kp": [
      "duplicity"
    ],
    "absent_kp": [
      "ext4"
    ]
  },
  {
    "text": "synchronize access to an instance method using a static serial queue. in my current project i have a number of data services classes, each one dedicated to a specific source of data so that it's responsible of downloading data from its api, checking for local database and doing inserts or updates as necessary. i needed to synchronize access to the entry point method for each of these classes as they may be consumed by other classes (like view models in the project architecture). my first thought was to use @synchronized, but it uses locks under the hood and apple's advice was to avoid that and use serial queues instead.i ended up creating a static shared serial queue for every data service class to be used by its instance entry point method as those classes are not singletons.i also used dispatch_suspend and dispatch_resume to control the flow of blocks being executed by this serial queue.it's working, and now for a specific data service class (ds), if we have 2 instances of it ds1 and ds2 then called ds1.loaddata() and ds2.loaddata successively, ds2.loaddata would be executed after ds1.loaddata() has finished. this also has the benefit of other instances of the other data services classes working concurrently.could this approach impose any risks or issues?data service class:// userdataservice.m@interface userdataservice () @property (strong, nonatomic) dispatch_queue_t serialqueue;@end@implementation userdataservice- (instancetype)init { self = [super init]; if (self) { _serialqueue = [self sharedqueue]; } return self;}// private method- (dispatch_queue_t)sharedqueue{ static dispatch_queue_t sharedqueue; static dispatch_once_t oncetoken; dispatch_once(&oncetoken, ^{ sharedqueue = dispatch_queue_create(com.userdataservice.queue, dispatch_queue_serial); }); return sharedqueue;}// public method// this is the entry point method for this data service class- (void)loaddatawithsuccess:(datasuccessblock)success failure:(datafailureblock)failure { // check for data in database (realm database), if not download from server dispatch_async(self.serialqueue, ^{ nsarray *results = [user allobjects]; // user is rlmobject (realm object) if (results && results.count > 0) { dispatch_async(dispatch_get_main_queue(), ^{ success([user allobjects]); }); } else { dispatch_suspend(self.serialqueue); // start to download data and persist it into local database [self downloadandpersistdatawithsuccess:^(rlmresults *result) { dispatch_async(dispatch_get_main_queue(), ^{ dispatch_resume(self.serialqueue); success(result); }); } failure:^(nsstring *errormsg) { dispatch_resume(self.serialqueue); failure(errormsg); }]; } });}- (void)downloadandpersistdatawithsuccess:(datasuccessblock)success failure:(datafailureblock)failure { // download data from server and persist it in local database apiservice *apiservice = [apiservice new]; //apiservice class wraps afnetworking get methods [apiservice getuserswithsuccess:^(nsdictionary *result) { //persist data [self persistdata:result withsuccess:^(rlmresults *persistedobjects) { success(persistedobjects); } failure:^(nsstring *errormsg) { failure(errormsg); }]; } failure:^(nsstring *errormsg) { failure(errormsg); }];}- (void)persistdata:(nsdictionary *)data withsuccess:(datasuccessblock)success failure:(datafailureblock)failure { if (data) { nsarray *users = [data valueforkey:@users]; rlmrealm *realm; @try { realm = [rlmrealm defaultrealm]; [realm beginwritetransaction]; for (nsdictionary *userdata in users) { // create user realm object user *user = [[user alloc] initwithdictionary:userdata]; [realm addorupdateobject:user]; } [realm commitwritetransaction]; success([user allobjects]); } @catch (nsexception *exception) { if ([realm inwritetransaction]) { [realm cancelwritetransaction]; } failure([nsstring stringwithformat:@%@ - %@, exception.name, exception.reason]); } }}@end",
    "present_kp": [],
    "absent_kp": [
      "objective c",
      "synchronization",
      "grand central dispatch"
    ]
  },
  {
    "text": "black screen when i move from x session to tty session. i've the ati proprietary drivers. when i power on the computer and i do the login all works well, but when i run xorg i can't change tty or exit from xorg because if i try i see only a black screen (the monitor backlight stays on).if i change tty (ctrl alt f2) i've the black screen, if then ireturn to xorg (ctrl alt f1) it works.if i close or kill xorg i've the black screen and i must reset thecomputer.this is the xorg log when i go to tty2 and during the blackscreen[ 312.470] (**) option fd 24[ 312.470] (**) option fd 17[ 312.470] (**) option fd 23[ 312.470] (**) option fd 33[ 312.470] (**) option fd 20[ 312.471] (**) option fd 22[ 312.471] (**) option fd 21[ 312.471] (ii) aiglx: suspending aiglx clients for vt switch[ 312.471] (ii) fglrx(0): backup framebuffer data.[ 312.560] (ii) fglrx(0): backup complete.[ 312.596] (ii) systemd-logind: got pause for 13:68[ 312.596] (ii) systemd-logind: got pause for 13:67[ 312.596] (ii) systemd-logind: got pause for 13:69[ 312.596] (ii) systemd-logind: got pause for 13:65[ 312.596] (ii) systemd-logind: got pause for 13:64[ 312.596] (ii) systemd-logind: got pause for 13:66[ 312.596] (ii) systemd-logind: got pause for 13:70what can i do?",
    "present_kp": [
      "xorg",
      "tty",
      "ati",
      "fglrx"
    ],
    "absent_kp": [
      "arch linux"
    ]
  },
  {
    "text": "what is the role of abstract machines in the curry-howard isomorphism?. by abstract machines i mean things like the secd machine, krivine's machine or more generally machines with states/memory/registers/stack/accumulator...according to wikipedia page of the curry-howard isomorphism, we have a correspondence with the sequent calculus where the left/right introductions rule matches with the constructors of codes and evaluation stacks. and the priority of rules application is related to call-by-value and call-by name reduction.so i'm looking for more information than what we can find in wikipedia.",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "logic",
      "computation models",
      "curry howard"
    ]
  },
  {
    "text": "populating a combobox from a range. i recently had quite a lot of fun answering a stack overflow question, and i think i've gone a bit overboard and ended up with a fairly decent way of populating a combobox from a range.given a simple userform featuring some combobox1 control that i'd want to populate from a listobject on sheet1, the calling/client code looks like this:option explicitsub test() with new userform1 .populatefromlist sheet1.listobjects(1) .show vbmodal end withend sub(thanks to thomas inzina for helping with the column headings)...the change handler in the form's code is just to illustrate that the hidden id column is effectively being used as the combobox.value:private sub combobox1_change() if not isnull(combobox1.value) then debug.print combobox1.value, combobox1.textend suband it works! 3 star wars 1 lord of the ringshere's the rest of the form's code-behind, the actual code under review - i'm wondering what's the best way to reuse it, i haven't decided whether it's best to extract it into a class module as a utility; with a withevents foo as combobox field i could be having a dynamic control there... it's certainly not practical in the code-behind of some random form though.i'm not very happy with getcolumnwidths, i'm sure there's a better way to do this. as for the populatefromxxxx methods, ...they're perfect, aren't they? ;-)option explicitpublic sub populatefromlist(byval source as listobject, optional byval valuecolumn as long = 1, optional byval hasheader as boolean = true) with me.combobox1 .columncount = source.range.columns.count .columnwidths = getcolumnwidths(source.range) .listwidth = iif(combobox1.width > source.range.width, combobox1.width, source.range.width) .rowsource = source.name & [#data] .boundcolumn = valuecolumn .columnheads = hasheader end withend subpublic sub populatefromarray(byval source as range, optional byval valuecolumn as long = 1, optional byval hasheader as boolean = true) with me.combobox1 .columncount = source.columns.count .columnwidths = getcolumnwidths(source) .listwidth = iif(combobox1.width > source.width, combobox1.width, source.width) .list = source.range(source.rows(iif(hasheader, 2, 1)).entirerow, source.rows(source.rows.count).entirerow).value .boundcolumn = valuecolumn end withend subprivate function getcolumnwidths(byval source as range) as string dim cols as long cols = source.columns.count dim widths() redim widths(1 to cols) dim col as long for col = 1 to cols widths(col) = source(, col).width next getcolumnwidths = join(widths, ,)end functionis there any way to clean this up? the .list assignment in populatefromarray seems particularly painful.",
    "present_kp": [],
    "absent_kp": [
      "vba",
      "excel"
    ]
  },
  {
    "text": "does google always downrank pages with hidden texts. i'm creating a faq for my page. to help the user to get a better overview i want to hide all answers and only display the questions. if the user clicks on a question the answer is set to display:block.i know that google also reads and indexes hidden content, but i also know that hiding text is a common technique for spammers and thus probably discredited by google, resulting in getting wiped from search results.but i'm wondering; does google always downrank pages that have large amounts of hidden text? i mean an faq like this is not that uncommon. should i not use this kind of faq?",
    "present_kp": [
      "google",
      "hidden text"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "wheel of fortune -- the es6 version. i have taken my original code from here and turned it into an es6 version of the same game.any code review and critiques are useful.side note: bankrupt and lose a turn do not do anything right now as it is a non-multiplayer game right now and i do not think it adds anything to the dynamic, but the wheel i have has those values. here is a jsfiddle link to play with <url> onlistener { constructor() { this.events = {}; } on(event, callback) { this.events[event] = callback.bind(this); } trigger(event, ...value) { if (object.keys(this.events).includes('all')) { return this.events['all'](event, ...value); } for (let _event in this.events) { if (event.indexof(_event) > -1 || _event.indexof(event) > 1) { this.events[_event](event, ...value); } } }}class wheel extends onlistener { constructor({ element, button, values = [] }) { super(); this.element = element; this.values = values; this.modifier = wheel.spinmodifier(); this.slowdownspeed = 0.5; this.currentrotation = 0; this.spintimeout = null; const clickfn = this.click.bind(this); element.addeventlistener('click', clickfn, false); button.addeventlistener('click', clickfn, false); } static spinmodifier() { return math.random() * 10 + 20; } stop() { cleartimeout(this.spintimeout); } click() { this.trigger('spin:start'); return this.spin().then((value) => { this.trigger('spin:end', value); return value; }); } rotate(degrees) { this.element.style.transform = 'rotate(-${degrees}deg)'; this.currentrotation = degrees; return this; } spin(amount = this.currentrotation, modifier = this.modifier) { this.stop(); modifier -= this.slowdownspeed; this.rotate(amount); return new promise((res, rej) => { if (modifier > 0) { this.spintimeout = settimeout(() => { res(this.spin(amount + modifier, modifier)); }, 1000 / 5) } else { const datarotation = this.currentrotation; const divider = 360 / this.values.length; const offset = divider / 2; // half division const wheelvalue = this.values[math.floor(math.ceil((datarotation + offset) % 360) / divider)]; this.modifier = wheel.spinmodifier(); switch (wheelvalue) { case 0: return res(0); case -1: return res(free spin); case -2: return res(lose a turn); default: return res(wheelvalue); } } }) }}class board extends onlistener { static randomize(arr) { //fisher yates from <url> let i = arr.length; if (i === 0) return []; while (--i) { const j = math.floor(math.random() * (i + 1)); const tempi = arr[i]; const tempj = arr[j]; arr[i] = tempj; arr[j] = tempi; } return arr; } constructor({ answers = [], element, button }) { super(); this.element = element; this.answers = board.randomize(answers); this.currentboard = -1; button.addeventlistener('click', () => this.next(), false); } clear() { const displayarea = this.element; while (displayarea.haschildnodes()) { //remove old puzzle displayarea.removechild(displayarea.firstchild); } } solve(solution) { return (this.answers[this.currentboard].touppercase() === solution.touppercase()); } getnextboard() { try { const board = this.answers[++this.currentboard].touppercase(); const boardarray = board.split(''); this.trigger('new:puzzle', board); return boardarray; } catch (e) { throw new error('no more levels!'); } } inputletter(_letter) { let count = 0; this.letters.foreach((obj) => { const { letter, element } = obj; if (!obj.seen && _letter === letter) { element.textcontent = letter; obj.seen = true; count += 1; } }); return count; } next() { const boardarray = this.getnextboard(); const displayarea = this.element; this.clear(); this.letters = []; let word = document.createelement('div'); word.classlist.add('word'); const words = boardarray.reduce((words, currentletter, index) => { const letter = document.createelement('div'); letter.classlist.add('wordletter'); letter.id = 'letter_${index}'; if (currentletter !== ' ') { letter.classlist.add('letter'); this.letters.push({ letter: currentletter, element: letter }); word.appendchild(letter); } else { words.push(word); word = document.createelement('div'); word.classlist.add('word'); } return words; }, []); // push the last one words.push(word); words.foreach((wordelement) => { displayarea.appendchild(wordelement); }); }}class game { constructor({ wheel, board, vowelbutton, solvebutton, moneyelement }) { this.wheel = wheel; this.board = board; this.vowels = ['a', 'e', 'i', 'o', 'u']; this.totalscore = 0; this.moneyelement = moneyelement; vowelbutton.addeventlistener('click', () => { if (this.totalscore >= 100) { this.totalscore -= 100; this.guessletter(0, true); } else { // @todo an else case } }, false); solvebutton.addeventlistener('click', () => { const solution = prompt('what is the solution?'); if (board.solve(solution)) { solution.split('').foreach((letter) => { this.board.inputletter(letter.touppercase()) }); settimeout(() => alert('puzzle solved!'), 10); } else { alert('puzzle not solved!'); } }, false); } start() { this.listen(); this.board.next(); } guessletter(value, asvowel = false) { const letter = prompt('guess a ${asvowel ? 'vowel' : 'letter'}'); try { if (!(/^[a-za-z]$/.test(letter))) { throw new error('must input an actual letter a-z'); } const capitalletter = letter.touppercase(); const letterisvowel = this.vowels.includes(capitalletter); if (asvowel && !letterisvowel) { throw new error('must input a vowel: [${this.vowels.join(', ')}]'); } else if (!asvowel && letterisvowel) { throw new error('cannot input a vowel: [${this.vowels.join(', ')}]'); } const count = this.board.inputletter(capitalletter); console.log('found ${letter} ${count} times worth $${value * count}'); if (!asvowel) { this.totalscore += (value * count); } this.moneyelement.textcontent = this.totalscore; } catch (error) { alert(error.message); this.guessletter(...arguments); } } listen() { this.wheel.on('spin:end', (event, value) => { if (isnan(value) || value === 0) { console.log('spun something bad', value); } else { console.log('can guess a letter', value); this.guessletter(value); } }); this.board.on('new:puzzle', (event, ...value) => { console.log('${event} ${value}'); this.wheel.stop(); }); }}const wheel = new wheel({ element: document.getelementbyid('wheel'), values: [5000, 600, 500, 300, 500, 800, 550, 400, 300, 900, 500, 300, 900, 0, 600, 400, 300, -2, 800, 350, 450, 700, 300, 600], button: document.getelementbyid('spin'),});const board = new board({ element: document.getelementbyid('display'), answers: [ doctor who, the dark knight rises, wheel of fortune, facebook, twitter, google plus, sea world, pastrami on rye, i am sparta, whose line is it anyway, google chrome ], button: document.getelementbyid('newpuzzle')});const game = new game({ wheel, board, vowelbutton: document.getelementbyid('vowel'), solvebutton: document.getelementbyid('solve'), moneyelement: document.getelementbyid('money')});game.start();console.log(game);@import url(//fonts.googleapis.com/css?family=changa+one);#game { font-family: 'changa one' serif;}#wheel { top: 0; left: 0; width: 500px; -moz-border-radius: 250px; -webkit-border-radius: 250px; border-radius: 250px; -webkit-transition: -webkit-transform 0.5s linear; -moz-transition: -moz-transform 0.5s linear; -opera-transition: -opera-transform 0.5s linear; -ms-transition: transform 0.5s linear;}#tick { margin-left: 244px; font-family: arial; font-size: 14pt;}#display { background-color: #43759f; padding: 1em 2em; text-align: center; border-radius: 40px; border: 4px double #fff;}#display div.word { display: inline-block;}#display div.word:not(:first-child) { padding: 0 30px;}#display div.wordletter { display: block; width: 50px; height: 65px; margin: 2px; border: 2px solid #43759f; float: left; line-height: 65px; font-size: 40px;}#display div.wordletter.letter { border-color: #eee;}#playarea { clear: both;}#playarea button { text-transform: uppercase; z-index: 1000; border: 4px double #fff; background-color: #43759f; padding: 6px 14px; color: white; font-family: inherit; font-size: 12pt;}#playarea #moneyarea { float: right; position: relative; padding: 10px; border: 2px black solid; width: 200px; margin: 5px; font-size: 14pt;}.clear { clear: both;}<div id=game> <div id=display></div> <div id=playarea> <button id=spin>spin wheel</button> <button id=vowel>buy vowel</button> <button id=solve>solve puzzle</button> <button id=newpuzzle>new puzzle</button> <div id=moneyarea> score: $<span id=money>0</span> </div> </div> <div class=clear></div> <div id=tick></div> <img id=wheel src=//i.imgur.com/r7jyazp.png data-rotation=0 /></div>",
    "present_kp": [
      "game"
    ],
    "absent_kp": [
      "javascript",
      "ecmascript 6"
    ]
  },
  {
    "text": "how can i resolve duplicates in yum?. in a moment of confusion and impatience, i severely damaged my os. here's the deal...system: centos 7problem: essential packages like samba do not work, and yum will not do anything.how it started: i installed kmod-xpad, which required a kernel update. this new kernel never worked, but i could boot from the old kernel on the boot loader. i did a routine package update via yum. later on, i tried to remove kmod-xpad, but that failed. now the system permanently tells me that i need to restart in order to install updates. even worse, i cannot mount a network drive via samba. i get an error message like.../sbin/mount.cifs: /usr/lib64/samba/libreplace.so: version samba_4.1.1' not found (required by /lib64/libwbclient.so.0)/sbin/mount.cifs: /usr/lib64/samba/libwinbind-client.so: version 'samba_4.1.1' not found (required by /lib64/libwbclient.so.0)while trying to fix samba, i found that yum is completely confused, and had unfinished transactions. i searched around for solutions without luck (e.g. such as why does yum update fails with many duplicates, after many months of no upgrades?)yum error messages:when i run yum clean all and yum update i run into an error with dependency resolution, and am then told that there are 374 pre-existing rpmdb problems, which are basically a bunch of duplicate packages. here is a snippet:--> finished dependency resolutionerror: package: avahi-libs-0.6.31-13.el7.x86_64 (@anaconda) requires: avahi = 0.6.31-13.el7 removing: avahi-0.6.31-13.el7.x86_64 (@anaconda) avahi = 0.6.31-13.el7 updated by: avahi-0.6.31-14.el7.x86_64 (base) avahi = 0.6.31-14.el7error: avahi-libs conflicts with avahi-0.6.31-14.el7.x86_64error: avahi-autoipd conflicts with avahi-0.6.31-14.el7.x86_64...you could try using --skip-broken to work around the problem ** found 374 pre-existing rpmdb problem(s), 'yum check' output follows: 1:networkmanager-1.0.0-14.git20150121.b4ea599c.el7.x86_64 is a duplicate with 1:networkmanager-0.9.9.1-29.git20140326.4dba720.el7_0.x86_64...avahi-libs-0.6.31-14.el7.x86_64 is a duplicate with avahi-libs-0.6.31-13.el7.x86_64avahi-ui-gtk3-0.6.31-14.el7.x86_64 has installed conflicts avahi < ('0', '0.6.31', '14.el7'): avahi-0.6.31-13.el7.x86_64avahi-ui-gtk3-0.6.31-14.el7.x86_64 is a duplicate with avahi-ui-gtk3-0.6.31-13.el7.x86_64bash-4.2.46-12.el7.x86_64 is a duplicate with bash-4.2.45-5.el7_0.4.x86_64...yum logand here are the main events from my yum.log:apr 24 11:34:08 updated: linux-firmware-20140911-0.1.git365e80c.el7.noarchapr 24 11:34:13 installed: kernel-3.10.0-229.1.2.el7.x86_64apr 24 11:34:14 installed: kmod-xpad-0.0.6-3.el7.elrepo.x86_64may 08 13:38:28 updated: libgcc-4.8.3-9.el7.x86_64may 08 13:38:28 updated: centos-release-7-1.1503.el7.centos.2.8.x86_64may 08 13:38:28 updated: python-urlgrabber-3.10-6.el7.noarchmay 08 13:38:28 updated: 1:control-center-filesystem-3.8.6-18.el7.x86_64may 08 13:38:28 updated: hyperv-daemons-license-0-0.25.20141008git.el7.noarch... (a bunch of packages)...may 08 13:40:31 updated: xorg-x11-server-common-1.15.0-33.el7_1.x86_64may 08 13:40:31 updated: xorg-x11-server-xorg-1.15.0-33.el7_1.x86_64may 08 14:02:03 erased: kmod-xpad-0.0.6-3.el7.elrepo.x86_64is this a good solution?right now, i'm considering removing the duplicates by following the advice on the centos forum: rpm -e --justdb <package-version>this sounds tedious, and i'm not confident that it will really resolve my problem. is this a situation that calls for reinstallation?any advice will be appreciated.",
    "present_kp": [
      "centos",
      "yum"
    ],
    "absent_kp": []
  },
  {
    "text": "how to manage 2 vm using upstart?. i use an upstart script to monitor a vm and respawn it when it gets killed. i would like to simulate a failover by doing the following. create a clone of the vm1 say vm2. when either of them is running , i have the other vm in saved state. as soon as one gets killed , i resume the other and start the killed vm but keep it paused.how should i modify this single vm script to work for 2 vms or maybe multiple vms even?start on (local-filesystems and net-device-up iface=eth0)stop on runlevel [016]console outputrespawnrespawn limit 5 10pre-stop scriptsu pankajm -c vboxmanage controlvm ubuntu-server savestateend scriptexec su pankajm -c vboxheadless startvm ubuntu-server",
    "present_kp": [
      "upstart"
    ],
    "absent_kp": [
      "virtualbox",
      "virtualization"
    ]
  },
  {
    "text": "can i start a microdata after and end the same just before ?. i want to use itemscope website. can i start it just after <head> and end it just before </body>?for website itemscope, which itemprop should i use to define the logo for the website?",
    "present_kp": [
      "microdata"
    ],
    "absent_kp": [
      "schema.org"
    ]
  },
  {
    "text": "keyboard issue with ctrl button in x11. i've an issue. i think it started several month ago, suspiciously near the update to newest fedora version. i've used to blame this on hardware, however when i've attached usb keyboard to my laptop (which i've only managed couple of days ago), issues still prevailed, so i think it might be somehow a software issue.issue:when i press ctrl button, nothing happens. e.g., it is not being sent to windows. however, if i chain-press buttons (e.g. ctrl-t, etc), it works. also if i first press alt, and then press ctrl, and then release alt, ctrl keypress is being sent to the applications.xev log for the issue:with only ctrl, only this happens: (doesn't matter left or right ctrl)<url> you can see, there is no keypress event, nor keyrelease event.with alt-ctrl-release alt sequence, this happens:<url> you can see, everything is as expected. what can be the issue behind this? more importantly, what are my options to fix that?software details: fedora desktop stable latest, gnome flavor. all system configs are default.",
    "present_kp": [
      "x11",
      "keyboard"
    ],
    "absent_kp": []
  },
  {
    "text": "converting and rescaling a lot of png images to jpeg. i have a lot of .png images in a folder. is there a command (or software) that can convert all them to .jpg and (simultaneously) rescale the created .jpg files to 25% of their original size?",
    "present_kp": [
      "images"
    ],
    "absent_kp": [
      "scripting",
      "conversion"
    ]
  },
  {
    "text": "iterative counting change implementation in mit-scheme. here is my iterative implementation of the counting change example in sicp. please note that i'm a beginner, which means i only know the basic syntax for the time being.requirement:how many different ways can we make change of $ 1.00, given half-dollars, quarters, dimes, nickels, and pennies? more generally, can we write a procedure to compute the number of ways to change any given amount of money?code:(define (count-change-iterative amount) ;; penny is not in the signiture, bacause it equals (- amount ;; (* half-dollar 50) ;; (* quarter 25) ;; (* dime 10) ;; (* nickeli 5)) (define (count-iter half-dollar quarter dime nickeli) (cond ((> (* half-dollar 50) amount) 0) ((> (+ (* half-dollar 50) (* quarter 25)) amount) (count-iter (+ half-dollar 1) 0 0 0)) ((> (+ (* half-dollar 50) (* quarter 25) (* dime 10)) amount) (count-iter half-dollar (+ quarter 1) 0 0)) ((> (+ (* half-dollar 50) (* quarter 25) (* dime 10) (* nickeli 5)) amount) (count-iter half-dollar quarter (+ dime 1) 0)) (else (+ 1 (count-iter half-dollar quarter dime (+ nickeli 1)))))) (count-iter 0 0 0 0))if you run (count-change-iterative 100), it would tell you 292.i think this is the best scheme code i've written by now. how can i improve it?",
    "present_kp": [
      "beginner",
      "scheme",
      "sicp"
    ],
    "absent_kp": [
      "combinatorics",
      "iteration"
    ]
  },
  {
    "text": "feeding data to xgboost for recomender system. i am using xgboost for a recommender system. there are 3-4 recommended content on each page. my data consists of columns like page_id and advertisement_id. currently for every page_id, there are 3-4 rows of advertisement_id in data. xgboost then gives me the probability of likelihood of an ad being clicked.it is known that one content(advertisement_id) from each page(page_id) is definitely clicked. i want to leverage this fact while training xgboost. how can i tell xgboost that one ad_id from each page_id is definitely clicked?can this be done somehow by using a vector of advertisement_id for each row of page_id?",
    "present_kp": [
      "xgboost",
      "recommender system"
    ],
    "absent_kp": []
  },
  {
    "text": "best choice of sdlc. i am studying sdlc models from a book. while attempting the exercise questions, i found these questions:what is the best choice among process models to address tight schedules and cost of the software precisely?what should be the best choice among different process models for development of any general software, such as library information system or inventory management system?what are the best best areas of application of v-shape model?based on what i've learned, i think the answers are:spiral model. in this model risk analysis is done repeatedly at the start of any iteration.i am not sure if we can have a generalized model for a general software. the most generalized model according to my learning is waterfall as it has phases applicable to almost all types of software. but again it has its own limitations.i can't think of applications where v-model is the best as it too is an extension of waterfall model and is not considered to be practical.please correct me if i am wrong in answering these questions.",
    "present_kp": [
      "sdlc"
    ],
    "absent_kp": [
      "development process"
    ]
  },
  {
    "text": "ensuring non conflicting components in a modular system. so lets say we are creating a simple modular system framework.the bare bones might be the user management. but we want things like the page manager, the blog, the image gallery to all be optional components.so a developer could install the page manager to allow their client to add a static home page and about page with content they can easily edit with a wysiwyg editor.the developer could then also install the blog component to allow the client to add blog entries.the developer could then also install the gallery component to allow the client to show off a bunch of images.the thing is, all these components are designed to be independent, so how do we go about ensuring they don't clash? e.g. ensuring the client doesn't create a /gallery page with the page manager and then wonder why the gallery stopped working, or the same issue with the blog component, assuming we allow the users to customize the url structure of the blog (because remember, the page manager doesn't necessarily have to be there, so we might not wan't our blog posts to be date/title formatted), likewise our clients aren't always going to be happy to have their pages under pages/title formatting.my core question here is, when building a modular system how to we ensure that the modules don't conflict without restricting functionality?do we just leave it up to the clients/developer using the modules to ensure they get setup in a way that does not conflict?",
    "present_kp": [
      "design",
      "modules"
    ],
    "absent_kp": [
      "php",
      "architecture",
      "cms"
    ]
  },
  {
    "text": "find and delete. i want to find and delete first 10 largest files. below is the command to find out 10 largest files.du -a * | sort -n -r | head -n 10",
    "present_kp": [
      "files"
    ],
    "absent_kp": [
      "command line",
      "rm"
    ]
  },
  {
    "text": "color configuration in xterm. i have been using nvim on ubuntu machine for about 3 month now, and like most noobs started with gnome terminal, i would like to graduate to plain xterm, but having trouble with the color in xterm. below, on the left is the gnome terminal and on the right is the xterm:below is my xterm configuration:file ~/.xinitrc contents[[ -f ~/.xresources ]] && xrdb -merge -i$home ~/.xresourcesfile ~/.xresources contentsxterm*facename: ubuntu mono for powerlinexterm*facesize: 11xterm*loginshell: truexterm*savelines: 16384! double-click to select whole urls :dxterm*charclass: 33:48,36-47:48,58-59:48,61:48,63-64:48,95:48,126:48*customization: -colorxterm*termname: xterm-256colorxterm*rightscrollbar: falsexterm*scrollbar: falsexterm*selecttoclipboard: true! hard contrast: *background: #1d2021*background: #282828! soft contrast: *background: #32302f*foreground: #ebdbb2! black + darkgrey*color0: #282828*color8: #928374! darkred + red*color1: #cc241d*color9: #fb4934! darkgreen + green*color2: #98971a*color10: #b8bb26! darkyellow + yellow*color3: #d79921*color11: #fabd2f! darkblue + blue*color4: #458588*color12: #83a598! darkmagenta + magenta*color5: #b16286*color13: #d3869b! darkcyan + cyan*color6: #689d6a*color14: #8ec07c! lightgrey + white*color7: #a89984*color15: #ebdbb2in the xterm running the 256color.pl script show following:it seems like this is all that i need. am i missing something? also my configs can be found at:<url> i use nvim, so for configuration look at the .nvimrc, but doing some testing the colours are the same for nvim and vim.",
    "present_kp": [],
    "absent_kp": [
      "colorscheme"
    ]
  },
  {
    "text": "syntactic complexity class ${f x}$ such that ${f pp} \\subseteq {f x} \\subseteq {f pspace}$. it is known that some (non-relativized) syntactic complexity classes between ${f p}$ and ${f pspace}$ have the following property, ${f p} \\subseteq {f conp} \\subseteq {f us} \\subseteq {f c_=p} \\subseteq {f pp} \\subseteq {f pspace}$. i am wondering if there exists a (non-relativized) syntactic complexity class ${f x}$ such that ${f pp} \\subseteq {f x} \\subseteq {f pspace}$? what are the implications of existence or non-existence of complexity class ${f x}$ ?",
    "present_kp": [
      "complexity classes"
    ],
    "absent_kp": [
      "cc.complexity theory"
    ]
  },
  {
    "text": "what are the proper tools to setup a remote compilation and running (something like ideone)?. i'm trying to achieve similar functionality in a server for community programming and i've drafted this to wrap up another take on oneide's functions:from a perl cgi i build a script like this (not even pseudocode):compiler_response = timeout (params) compiler (params)result = timeout compiledprogram (params)save result in databasei think timeout is the tool i need to restrain the program from executing or compiling more than x seconds, the problem i have is that i need to limit the compiled program from writing to anything other than stdout or reading from anything other than stdin. also i need to limit the size of the program to a certain limit, 128kb for example, and the ammount of ram it can use, 64 mb for example.what are the proper tools to do this from bash? thanks in advance.",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "scripting",
      "process management"
    ]
  },
  {
    "text": "how to update steam from command line?. is there a quick way to update steam from the command line? i would prefer to update steam without a gui running so it can be done in the background (headless).",
    "present_kp": [
      "steam"
    ],
    "absent_kp": []
  },
  {
    "text": "gnome: disable sleep on lid close. is it possible to stop my laptop going to sleep when i close the lid?gnome 3.20, fedora 24.my laptop does not reliably wake from sleep. (it happens to be a hardware issue... i think i basically killed it while trying to replace a wifi card. but i want to keep using it for a while longer).",
    "present_kp": [
      "gnome",
      "laptop"
    ],
    "absent_kp": [
      "suspend"
    ]
  },
  {
    "text": "impact of blogger's country level redirect on traffic and ranking. as many of you know blogger displays different url for the same blog in the different country. apart from so many domains, do you see any impact on traffic and ranking? i read that it does affect that as link juice, social counts are lost, but there is no official word on this. please share if you have any experience.",
    "present_kp": [
      "blogger"
    ],
    "absent_kp": []
  },
  {
    "text": "does the license of jaxb apply to the java class files it autogenerated?. each generated java file has this header comments// this file was generated by the javatm architecture for xml binding(jaxb) reference implementation, v2.2.8-b130911.1802 // see <a href=<url> // any modifications to this file will be lost upon recompilation of the source schema. whole scenario: xml schema(input) -> jaxb library -> java class(output) jaxb generates java class files based out of the input given to them via xml schema file.the generated class file has the above mentioned comments on the top. rest of the lines contains normal java code that is generated as per the inputs defined in the xml schema.there is no comments related to license apart from the above mentioned.jaxb has dual license cddl + lgpli am wondering whether the license of jaxb applies to my generated files as well?",
    "present_kp": [
      "java"
    ],
    "absent_kp": []
  },
  {
    "text": "function that check's file type based on certain keywords. i have a function that breaks up a source file and checks each token against a keyword list to determine whether its a particular file type. how can i improve this function? tokenization is a class that contains a function to break up the source code.public static boolean validationtypeofsql(string sourcefile, tokenization tokenization,arraylist<string> uniquekeywordlist) { arraylist<token> createsourcecodetokens = tokenization.createsourcecodetokens(sourcefile); for (token x : createsourcecodetokens) { string smallertokens[] = tokenization.tokentosmallertoken(x.gettoken()); for (string smallertokenvalue : smallertokens) { boolean result = smallertokenvalue.contains(,); if (result == true) { string[] tokensplit = smallertokenvalue.split(,); for (string ts : tokensplit) { for (string t : uniquekeywordlist) { if (t.tolowercase().equals(ts.tolowercase().replace((, ).replace(,, ).replace(), ).replace( , ))) { // system.out.println(this is a mysql file mysql); return true; } } } } else { for (string uniquekeyword : uniquekeywordlist) { if (uniquekeyword.tolowercase().equals(smallertokenvalue.tolowercase().replace((, ).replace(,, ).replace(), ))) { return true; } } } } } return false;}",
    "present_kp": [],
    "absent_kp": [
      "java",
      "performance",
      "strings",
      "parsing"
    ]
  },
  {
    "text": "need metrics for expectations/targets. after our relaunch, we are wanting to find some standard metrics for our first year of performance. we can compare our numbers to last year and set our targets and expectations, but we would like to find an industry standard for b2b websites in year 1 - whether as a new site or a relaunch. is there a way to find that information?",
    "present_kp": [
      "metrics"
    ],
    "absent_kp": []
  },
  {
    "text": "amplify quiet passages in an mp3 file. i have an mp3 file where is a dialog with two voices and oneof the voices is very quiet.is there a command or application that is able the detect thequiet passages and amplify them? the two voices are alternating.i already tried to do it manually with audacity but this is verytime-consuming job.",
    "present_kp": [
      "application"
    ],
    "absent_kp": [
      "command line",
      "audio"
    ]
  },
  {
    "text": "use both libinput clickmethod options : two fingers and right button. i'm using ubuntu gnome 17.04 (gnome 24), with libinput drivers for touchpad, and i want to be able to right click using both methods : two fingers click, and click on the bottom right of the touchpad.my touchpad id is elan1300:00 04f3:3028 touchpadthe command xinput list-props 12 | grep click gives me libinput click methods available (294): 1, 1libinput click method enabled (295): 0, 1the 0, 1 option corresponds to the two fingers click, and the 1, 0 corresponds to the bottom right click. but i can set only those two options : when i try xinput set-prop 12 295 1, 1, i get x error of failed request: badvalue (integer parameter out of range for operation) major opcode of failed request: 131 (xinputextension) minor opcode of failed request: 57 () value in failed request: 0x127 serial number of failed request: 19 current serial number in output stream: 20is it possible to use the two options with my touchpad?",
    "present_kp": [
      "drivers",
      "touchpad",
      "xinput",
      "libinput"
    ],
    "absent_kp": []
  },
  {
    "text": "make a flowchart to demonstrate closure behavior. i saw below test question the other day in which the authors used a flowchart to represent the logic of loops, and i got to thinking it would be interesting to do this with some more complex logic. for example, the closure in this immediately-invoked function expression (iife) sort of boggles me:while (i <= qty_of_gets) { // needs an iife (function(i) { promise = promise.then(function(){ return $.get(queries/html/ + product_id + i + .php); }); }(i++)); }i wonder if seeing a flowchart representation of what happens in it could be more elucidating. could such a thing be done? would it be helpful, or just messy? i haven't the foggiest clue where to start, but thought maybe someone would like to take a stab. probably all the ajax could go and it could just be a simple return within the iife.",
    "present_kp": [
      "flowchart"
    ],
    "absent_kp": [
      "javascript",
      "programming practices",
      "closures"
    ]
  },
  {
    "text": "how to dynamically load address of user32.dll in shellcode?. assuming i'm injecting a shellcode into a windows gui application, i know i could: gets kernel32.dll base address through the peb (process environment block); finds address of loadlibrary; call loadlibrary(user32.dll); finally call getprocaddress.this is the classic way and that's what i would do, however i'd like to know if there's a better/improved/faster/clever/different/smaller or simpler way to do this.any ideas?",
    "present_kp": [
      "windows",
      "shellcode"
    ],
    "absent_kp": []
  },
  {
    "text": "weighted hamming distance. basically my question is, what kind of geometry do we get if we use a weighted hamming distance. this is not necessarily theoretical computer science but i think similar things come up sometimes, for instance in randomness extraction. define:$d(x,y)=$ the hamming distance between binary strings $x$ and $y$ of length $n$, $=$ the cardinality of $\\{k: x(k) e y(k)\\}$. for a set of strings $a$, $d(x,a)=\\min \\{ d(x,y): y\\in a\\}$.the $r$-fold boundary of $a\\subseteq \\{0,1\\}^n$ is$$\\{x\\in\\{0,1\\}^n: 0 < d(x,a)\\le r\\}.$$balls centered at $0$ are given by$$ b(p)=\\{x: d(x,0)\\le p\\}, $$where $0$ is the string of $n$ many zeroes.a hamming-sphere is a set $h$ with $b(p)\\subseteq h\\subseteq b(p+1)$. (so it's more like a ball than a sphere, but this is the standard terminology...)now, harper in 1966 showed that for each $k$, $n$, $r$, one can find a hamming-sphere that has minimal $r$-fold boundary among sets of cardinality $k$ in $\\{0,1\\}^n$. so a ball is a set having minimal boundary -- just like in euclidean space.the cardinality of $b(p)$ is ${n\\choose 0}+\\cdots {n\\choose p}$. the $r$-fold boundary of $b(p)$ is just the set $b(p+r)\\setminus b(p)$, which then has cardinality ${n\\choose p+1}+\\cdots+{n\\choose p+r}$.so far, so good. but now suppose we replace $d$ by a different metric $d$: first let $d_j(x,y)$ be the hamming distance between the prefixes of $x$ and $y$ of length $j$, and then$$ d(x,y)=\\max_{j\\le n}\\ rac{d_j(x,y)}{f(j) }$$where $0\\le f(j)\\le j$. (for example we could have $f(j)=\\sqrt{j}$, or $f(j)=j/\\log j$.) this is supposed to make $d(x,y)$ small if the differences of $x$ and $y$ do not clump together at small values of $j$. questionsis the minimum $r$-fold boundary (under $d$) realized by a $d$-ball? is there a better definition of $d$?under the metric $d$, what's the minimum size of the $r$-fold boundary of a subset of $\\{0,1\\}^n$ having cardinality $k$? (a reasonable lower bound would be nice.)(cross-posted on mathoverflow).",
    "present_kp": [
      "randomness"
    ],
    "absent_kp": [
      "co.combinatorics"
    ]
  },
  {
    "text": "how important is multithreading in the current software industry?. i have close to 3 years experience writing web applications in java using mvc frameworks (like struts). i have never written multithreaded code till now though i have written code for major retail chains.i get a few questions on multithreading during interviews and i answer them usually (mostly simple questions). this left me wondering how important is multithreading in the current industry scenario ?",
    "present_kp": [
      "multithreading"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i maintain a database record of an entity that belongs to several categories of another entity, per year, per season, etc. i am building a kind of school management system.i want to be managing the database records of things like assessment, term/season, academic years. every info must belong to a particular academic year so at anytime the admin can query for info pertaining to a particular year. assessment too can belong not only to an academic year, but term, class, subject, student too.i have been figuring out on how to develop a scalable database schema for this. i thought of having separate databases for each year, or combine them each on a very different table but how to properly reference each assessment down to a particular student, subject, class, term and year is still my confusion over the whole matter.",
    "present_kp": [],
    "absent_kp": [
      "php",
      "web development",
      "database design",
      "relational database",
      "scalability"
    ]
  },
  {
    "text": "controlling users' default printer as an administrator. what are the necessary steps to change the default printer for individual users on a reasonably recent linux system using cups? (i.e. not the system-wide default)the cups lpr manpage indicates that setting the printer environment variable is looked to first by the printing system. but does this also affect the default printer for gnome & kde applications?does this also override whatever the user has changed by going to, for instance, the 'printing' setup application in ubuntu? or the equivalent in rhed?how can i cover all my bases?",
    "present_kp": [
      "linux",
      "printing",
      "cups"
    ],
    "absent_kp": []
  },
  {
    "text": "how could a web developer go about offering free hosting to clients that buy a website?. lots of web design companies offer a year free hosting service when purchasing a website. how do they offer this service? do these companies use their own server to host sites or do they buy a years hosting from somewhere and use that?i understand that not all companies would use the same method, but in general, how would it be done?thanks for any answers :)",
    "present_kp": [
      "server"
    ],
    "absent_kp": [
      "web hosting",
      "web development"
    ]
  },
  {
    "text": "feature scoring. i am preparing my data to be training data so that i woud bbe able too use it with some algorithms of classifications and i have to score some fetures depending on its value, what is the best way to do it with python",
    "present_kp": [
      "python",
      "scoring"
    ],
    "absent_kp": [
      "machine learning",
      "feature engineering"
    ]
  },
  {
    "text": "help interpreting this deadlock question. i have this assignment question but i am a bit unsure how to go about answering it. the question is as follows and accompanied by the image below: three processes are competing for six resources labelled a to f as shownbelow.using a resource allocation graph, show the possibility of a deadlock inthe implementation above.i know how to do the graph but what i am struggling to understand is, do i take the release(); methods into consideration or only the get(); methods. and also, would p0() access resources a, b and c first or will each process run simultaneously meaning p0() access resource a, p1() access resource d and p2() access resource c, and then the second set of get() methods are requested simultaneously? lastly it does not specify how many instances (dots) are in each resource, is there any indication as to how to determine/go about working with this? as soon as i can clear up these misunderstandings i can draw the diagram",
    "present_kp": [
      "resource allocation"
    ],
    "absent_kp": [
      "deadlocks"
    ]
  },
  {
    "text": "backup and synchronization. i want to synchronize my personal document repository between my different computers in my home. today this folder is under a dedicated partition of the hard drive of a dual boot workstation.my configuration is the following one:dual boot workstation running ubuntu 11 and windows xp (the documents are simply shared using the dedicated partition)laptop running ubuntu 12.04 (today no access to the documents)a freebox with an external hard drive pluged to itwhat i want is to be able to synchronize this document folder also with the laptop and in addition to have a backup of this on the hard drive attached to the freebox.what tools should i use for this (rsync, unison, others?)",
    "present_kp": [
      "rsync",
      "synchronization",
      "unison"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "htaccess redirect a page with a query string hosted on a temporary ip address?. i have a site that was temporarily set up as 111.222.333.444/~mysite because the real url was not ready. 111.222.333.444/~mysite/?page_id=123 was a valid page on that site. my site is live now. i no longer want or need to use 111.222.333.444/~mysite to access the site.however google has indexed a search for a term on page ?page_id=123 as 111.222.333.444/~mysite/?page_id=123. but ?page_id=123 no longer exists. it's now on a new page, and i want to redirect google's link to <url> closest i have come to implemeting this redirect is:rewritecond %{http_host} ^111'\\.333\\.444$ [nc]rewritecond %{query_string} ^\\?page_id=123$ [nc]rewriterule ^~mysite/$ //www.example.com/newpage [r=301,ne,nc,l]but this doesn't work, and gives me an internal server error.i have also tried:redirect 301 /?page_id=195 /newpagebut that had no effect. can anyone suggest how to do this? i don't have a problem redirecting single pages, but the temporary/alternate url with the ip address is throwing me.",
    "present_kp": [
      "htaccess"
    ],
    "absent_kp": [
      "url rewriting"
    ]
  },
  {
    "text": "how to get gcc-4.7 to /usr/bin/gcc-4.7 as second gcc in debian jessie?. i would like to keep my gcc 4.9 but let matlab use gcc 4.7 because stable debian does not support 4.7, as observed in the thread debian jessie: why gcc-4.7 conflicts with gcc-4.8? i do the following but nothing in jessie because matlab 2016 wants gcc 4.7.x# <url> search gcc-4.7 however, i think apt-get is not the way to go because i just want to get gcc-4.7 in my system for matlab, not for any other purpose. example of the warning when using wrong gcc in matlabmex completed successfully.building with 'gcc'.warning: you are using gcc version '4.9.2'. the version of gcc is not supported. the versioncurrently supported with mex is '4.7.x'. for a list of currently supported compilers see:<url> os: debian 8.5 64 bitlinux kernel: 4.6 of backportshardware: asus zenbook ux303ua",
    "present_kp": [
      "debian",
      "gcc",
      "matlab"
    ],
    "absent_kp": []
  },
  {
    "text": "reversing dlink dir100 firmware. i'm trying to extract this firmware but i'm running into some issues. the first lecture of the firmware with binwalk shows this:decimal hex description-------------------------------------------------------------------------------------------------------------------48 0x30 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 992240 bytes275832 0x43578 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 65011 bytes312165 0x4c365 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 6425 bytes314338 0x4cbe2 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 6198 bytes316542 0x4d47e lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 11645 bytes319496 0x4e008 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9923 bytes322366 0x4eb3e lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 3981 bytes323721 0x4f089 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1269 bytes324228 0x4f284 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9785 bytes327024 0x4fd70 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9717 bytes329754 0x5081a lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9957 bytes332630 0x51356 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 4544 bytes334066 0x518f2 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 378 bytes334305 0x519e1 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1019 bytes334787 0x51bc3 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 12756 bytes338395 0x529db lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 16497 bytes343482 0x53dba lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 11019 bytes347416 0x54d18 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 39577 bytes358366 0x577de jpeg image data, jfif standard 1.<phone> 0x579fb jpeg image data, jfif standard 1.<phone> 0x57c12 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1787 bytes361070 0x5826e lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 893 bytes361902 0x585ae lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 637 bytes362528 0x58820 jpeg image data, jfif standard 1.<phone> 0x58c02 jpeg image data, jfif standard 1.<phone> 0x591a3 jpeg image data, jfif standard 1.<phone> 0x5bcf1 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 683 bytes376714 0x5bf8a lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 761 bytes377462 0x5c276 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 225 bytes377638 0x5c326 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 4146 bytes378953 0x5c849 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1487 bytes379723 0x5cb4b lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 2240 bytes380729 0x5cf39 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1527 bytes381510 0x5d246 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 8294 bytes384148 0x5dc94 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 10412 bytes385299 0x5e113 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 16812 bytes389806 0x5f2ae lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9294 bytes391417 0x5f8f9 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 9108 bytes392764 0x5fe3c lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 4796 bytes393633 0x601a1 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 3710 bytes394440 0x604c8 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 7870 bytes395948 0x60aac lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 10764 bytes398896 0x61630 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 6804 bytes400960 0x61e40 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 2135 bytes401785 0x62179 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 2864 bytes402878 0x625be lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 3747 bytes404192 0x62ae0 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 2776 bytes405196 0x62ecc lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 6761 bytes407148 0x6366c lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1582 bytes407859 0x63933 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 6849 bytes409864 0x64108 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 4678 bytes411440 0x64730 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 11297 bytes414011 0x6513b lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 3990 bytes415534 0x6572e lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 12540 bytes418894 0x6644e lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 3623 bytes420239 0x6698f lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 13366 bytes423782 0x67766 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 5498 bytes425717 0x67ef5 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1524 bytes426450 0x681d2 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 28728 bytes434580 0x6a194 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 18125 bytes439538 0x6b4f2 lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 36719 bytes445116 0x6cabc lzma compressed data, properties: 0x5d, dictionary size: 33554432 bytes, uncompressed size: 1940 byteschecking the hexdump code i found that binwalk detects the lzma magic number '5d 00' but i think that this is inconsistent and a false positive:root@kali:~/desktop/firmwares/dlink# cat hexdump.txt | grep '5d 00'<phone> 5d 00 00 00 02 f0 23 0f 00 00 00 00 00 00 20 20 |].....#....... |0000c7b0 f9 5d 00 0e e6 e7 55 ca 16 5f d1 c9 67 67 30 c7 |.]....u.._..gg0.|<phone> ac 00 5d 00 00 00 02 c9 1d 00 00 00 00 00 00 00 |..].............|0004a2c0 6e 93 3d d1 e8 e3 96 5a f9 17 38 b1 28 5d 00 00 |n.=....z..8.(]..|0004bb30 25 14 f9 96 26 85 58 20 18 07 b9 fa e3 5d 00 00 |%...&.x .....]..|0004c360 9f f6 e9 d8 28 5d 00 00 00 02 19 19 00 00 00 00 |....(]..........|0004cbe0 f6 20 5d 00 00 00 02 36 18 00 00 00 00 00 00 00 |. ]....6........|0004d470 3f 38 df 6f 97 98 4b 41 0d 83 14 d8 4d 00 5d 00 |?8.o..ka....m.].|0004e000 78 c4 bc c4 11 98 56 00 5d 00 00 00 02 c3 26 00 |x.....v.].....&.|0004eb30 e6 73 64 e2 bc fa 37 7a 11 0d 3c b1 d2 af 5d 00 |.sd...7z..<...].|0004f080 57 ad 80 5f 20 ef 40 0e 7c 5d 00 00 00 02 f5 04 |w.._ .@.|]......|0004f280 1a 1c ab 00 5d 00 00 00 02 39 26 00 00 00 00 00 |....]....9&.....|0004fd70 5d 00 00 00 02 f5 25 00 00 00 00 00 00 00 1e 12 |].....%.........|after this i browsed the hexdump and found some strings in <phone> and 00042fa0:<phone> 41 49 48 30 4c 0f c1 fb 80 00 01 00 00 04 2f 74 |aih0l........./t|00042fa0 6e 23 00 00 41 49 48 30 4c 0f c1 fb 00 00 00 00 |n#..aih0l.......|googling for aih0l i did not find anything useful and now i'm stuck.other things i tried was to search bin img sqsh sq sh and other strings in the hexdump without result.also the entropy analysis seems weird for me. did anyone faced this issues or can figure out how to extract this?regards.edit:searching for filesystems 'fs' in the hexdump file i found a zfs header:t@kali:~/desktop/firmwares/dlink# cat hexdump.txt | grep zfs0000b990 65 a7 0c aa 7a 66 73 24 1e bc b6 e8 d7 c4 29 1a |e...zfs$......).|i'm not sure wether this points to a real zfs or it's just a coincidence. i copied the firmware from that position to the end but the new file is not recognized and the binwalk lecture is the same as above.",
    "present_kp": [
      "firmware"
    ],
    "absent_kp": []
  },
  {
    "text": "simulation of a mechanical arm. the code that i am doing is to simulate a scenario where a mechanical arm search pieces closer and these pieces selected the mechanical arm leaves in a position defined closer.clear[global'*]beziercirclearc[{x_,y_},r_,{1_,2_}]:= module[{,p0,p1,p2,p3}, =4/3tan[(2-1)/4]; p0={x,y}+r{cos[1],sin[1]}; p3={x,y}+r{cos[2],sin[2]}; p1=p0+ r{-sin[1],cos[1]}; p2=p3+ r{sin[2],-cos[2]};beziercurve[{p0,p1,p2,p3}]]initial positionpinitial={106.8,0};armlenghtinitialarm=90;arm={beziercirclearc[{lenghtinitialarm+16.8,0},20,{2.57,3.72}],line[{{0,12.5},{lenghtinitialarm,12.5},{lenghtinitialarm,12.5},{lenghtinitialarm,10.87}}],line[{{0,-12.5},{lenghtinitialarm,-12.5},{lenghtinitialarm,-12.5},{lenghtinitialarm,-10.87}}],{edgeform[black],graylevel[0.84],disk[armcenter={0,0},18]},{edgeform[black],graylevel[0.50],disk[armcenter={0,0},6]}};clawsclaws={edgeform[black],graylevel[.84],filledcurve[{beziercirclearc[{lenghtinitialarm+16.8,0},rclaws=20,claw1a={0.8,2.9}],beziercirclearc[{lenghtinitialarm-5,5.6},2.5,claw1b={6.03-2,2.9-2}][[;;,2;;]],beziercirclearc[{lenghtinitialarm+16.8,0},25,reverse@claw1a-2][[;;,2;;]],beziercirclearc[{lenghtinitialarm+32.54,16.07},2.5,claw1c={0.8,-2.35}][[;;,2;;]]}]};arm + clawsrobot={geometrictransformation[{arm,u=geometrictransformation[claws,{rotationtransform[0degree,{85,5.6}]}],geometrictransformation[u,reflectiontransform[{0,1},{85,0}]]},rotationtransform[initialposition=0degree,{0,0}]]};boxespbox=6;recx1=160;recy1=-80;recx2=recx1+6rclaws+4espbox;recy2=-30;pospieces={{150,105},{32,220},{320,175}};pospiecesfinal={{recx1+espbox+rclaws,(recy1 + recy2)/2},{recx1+3 rclaws+espbox+5,(recy1 + recy2)/2},{recx1+5 rclaws+espbox+10,(recy1 + recy2)/2}};boxgoal={edgeform[{thickness[0.005],black}],white,rectangle[{recx1,recy1},{recx2,recy2}]};pieces={edgeform[black],rgbcolor[0.35,0.30,0.25],disk[pospieces[[1]],20],disk[pospieces[[2]],20],disk[pospieces[[3]],20]};piecesfinal={dashed,edgeform[red],white,disk[pospiecesfinal[[1]],20],disk[pospiecesfinal[[2]],20],disk[pospiecesfinal[[3]],20]};the function below determines the shortest route that the arm mechanism must follow to perform this procedure.route logicf[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospieces, pinitial]] // n;p1 = pospieces[[first[sol]]];pospieces = drop[pospieces, {first[sol]}];f[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospiecesfinal, p1]] // n;p2 = pospiecesfinal[[first[sol]]];pospiecesfinal = drop[pospiecesfinal, {first[sol]}];f[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospieces, p2]] // n;p3 = pospieces[[first[sol]]];pospieces = drop[pospieces, {first[sol]}];f[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospiecesfinal, p3]] // n;p4 = pospiecesfinal[[first[sol]]];pospiecesfinal = drop[pospiecesfinal, {first[sol]}];f[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospieces, p4]] // n;p5 = pospieces[[first[sol]]];pospieces = drop[pospieces, {first[sol]}];f[pg_, pi_] := {pos = position[ euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]], min[euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]]], extract[(euclideandistance[pi, evaluate@pg[[#]]] & /@ range[length[pg]]), first@pos]};sol = flatten[f[pospiecesfinal, p5]] // n;p6 = pospiecesfinal[[first[sol]]];pospiecesfinal = drop[pospiecesfinal, {first[sol]}];positions = {pinitial, p1, p2, p3, p4, p5, p6};this graphic serves basically to illustrate the route to be coveredgarrow = {red, arrowheads[0.05], thickness[0.008], arrow[positions]};graphics[{boxgoal, pieces, robot, piecesfinal, garrow}, axes -> true, imagesize -> 500, background -> white];with the function below i determine the angles needed to perform the routeanglist[p_] := (p - armcenter)anglist = arctan @@ anglist[#] & /@ positions/degree // n;numbertotalframes = 300;framesclaws = 4;numberframesstopped = framesclaws*(length[anglist] - 1);framesstoppedang = transpose[table[rest@anglist, framesclaws]];restframes = numbertotalframes - numberframesstopped;diffang = differences[anglist];accdiffang = accumulate@abs@diffang;sumallang = last@accdiffang;quantrestframes = round[n[abs@diffang[[#]]/last@accdiffang]*restframes] & /@ range[length[accdiffang]];sublistsang = map[most, subdivide @@@ transpose@{most@anglist, rest@anglist, quantrestframes}];anglistanim = flatten[riffle[sublistsang, framesstoppedang]];listlineplot[anglistanim, plottheme -> monochrome, imagesize -> {1200, 800}, axeslabel -> {holdform[frames], holdform[angles]}, plotlabel -> holdform[angles x frames], labelstyle -> {fontfamily -> arial, 12, graylevel[0]}]with the function below i determine the lenghts needed to perform the routeplenghtarm = euclideandistance[ positions[[#]], {0, 0}] - (106.8 - (lenghtinitialarm = 90)) & /@ range[length[positions]] // n;quantframeslenghtarm = quantrestframes;sublistslenghtarm = map[most, subdivide @@@ transpose@{most@plenghtarm, rest@plenghtarm, quantframeslenghtarm}];framesstoppedlenghtarm = transpose[table[rest@plenghtarm, framesclaws]];plenghtarmanim = flatten[riffle[sublistslenghtarm, framesstoppedlenghtarm]];listlineplot[plenghtarmanim, plottheme -> monochrome, imagesize -> {1200, 800}, axeslabel -> {holdform[frames], holdform[length]}, plotlabel -> holdform[length x frames], labelstyle -> {fontfamily -> arial, 12, graylevel[0]}]here i present my solution for the arm mechanic collection the pieces and can put this pieces in place appropriateflatten @@ table[graphics[{boxgoal, pieces, piecesfinal, {geometrictransformation[{{beziercirclearc[{plenghtarmanim[[#]] + 16.8, 0}, 20, {2.57, 3.72}], line[{{0, 12.5}, {plenghtarmanim[[#]], 12.5}, {plenghtarmanim[[#]], 12.5}, {plenghtarmanim[[#]], 10.87}}], line[{{0, -12.5}, {plenghtarmanim[[#]], -12.5}, {plenghtarmanim[[#]], -12.5}, {plenghtarmanim[[#]], -10.87}}], {edgeform[black], graylevel[0.84], disk[armcenter = {0, 0}, 18]}, {edgeform[black], graylevel[0.50], disk[armcenter = {0, 0}, 6]}}, u = geometrictransformation[{edgeform[black], graylevel[0.84], filledcurve[{beziercirclearc[{plenghtarmanim[[#]] + 16.8, 0}, rclaws = 20, claw1a = {0.8, 2.9}], beziercirclearc[{plenghtarmanim[[#]] - 5, 5.6}, 2.5, claw1b = {6.03 - 2*pi, 2.9 - 2*pi}][[1 ;; all, 2 ;; all]], beziercirclearc[{plenghtarmanim[[#]] + 16.8, 0}, 25, reverse[claw1a] - 2*pi][[1 ;; all, 2 ;; all]], beziercirclearc[{plenghtarmanim[[#]] + 32.54, 16.07}, 2.5, claw1c = {0.8, -2.35}][[1 ;; all, 2 ;; all]]}]}, {rotationtransform[ 0 degree, {85, 5.6}]}], geometrictransformation[u, reflectiontransform[{0, 1}, {85, 0}]]}, rotationtransform[ initialposition = anglistanim[[#]] degree, {0, 0}]]}}, axes -> true, imagesize -> 500, background -> white, plotrange -> {{400, -40}, {-90, 250}}], 1] & /@ range[300];the question would be as follows:could someone propose some improvement to shorten this code?",
    "present_kp": [],
    "absent_kp": [
      "performance",
      "wolfram mathematica"
    ]
  },
  {
    "text": "will google remove the old caches if noarchive is added to robots.txt. if you want google's cache of your site to remain unchanged is it a good idea to add noarchive to robots.txt? or will this wipe out your caches?",
    "present_kp": [
      "google",
      "robots.txt"
    ],
    "absent_kp": []
  },
  {
    "text": "choosing the language to build an app in based on hiring market vs performance and maintainability. i'm facing a choice of whether to start building haskell components for a certain production app that is all done in ruby.i'm leaning toward haskell for several reasons, primarily speed (compiled haskell is like 4-8x faster), greater transparency (via haskell type system), and safer refactorability (type system). i've written a few open source and production programs in haskell already and enjoy writing it very much.feasibility is not an issue. i've played around with the haskell snap web framework and database libraries like postgresql.simple and am satisfied that rewriting a rails app and various backend programs with haskell is feasible.the real issue is hiring programmers when we need to scale the dev team, or eventually handing off the programming responsibilities altogether. it's a lot easier to find programmers in ruby than in haskell. on the other hand, the haskell community seems to be growing, and it's not too hard to train programmers to modify parts of a haskell program if you approach it as a dsl (much like ruby on rails). the haskell type system also seems to promise much safer collaboration than dynamic ruby does.in his essay beating the averages (<url>), paul graham argues that using a superior language can be a decisive advantage. but when does it make sense to forgo using a superior language in order to make it easier to add programmers to your team?",
    "present_kp": [
      "hiring",
      "haskell"
    ],
    "absent_kp": [
      "programming languages",
      "teamwork"
    ]
  },
  {
    "text": "how do i read the output of 'dmesg' to determine how much memory a process is using when oom-killer is invoked?. i asked this question:running 'sudo /sbin/service mysqld start' causes system to crashin the comments of one of the answers, a very helpful individual is asking for more information regarding how much memory processes were using when oom-killer is invoked.the output of dmesg is ~9000 lines, and hundreds of thousands of characters, though.an example of the output that i see multiple times throughout the output is this:out of memory: killed process 21000, uid 48, (httpd).mysqld invoked oom-killer: gfp_mask=0x201d2, order=0, oomkilladj=0call trace: [<ffffffff802c1b64>] out_of_memory+0x8b/0x203 [<ffffffff8020fa5d>] __alloc_pages+0x27f/0x308 [<ffffffff802139dd>] __do_page_cache_readahead+0xc8/0x1af [<ffffffff8021424e>] filemap_nopage+0x14c/0x360 [<ffffffff80208e9d>] __handle_mm_fault+0x444/0x144f [<ffffffff8020622a>] hypercall_page+0x22a/0x1000 [<ffffffff8020622a>] hypercall_page+0x22a/0x1000 [<ffffffff80266d94>] do_page_fault+0xf72/0x131b [<ffffffff802456a8>] sys_rt_sigreturn+0x327/0x35a [<ffffffff8026393d>] _spin_lock_irq+0x9/0x14 [<ffffffff802296ed>] do_sigaction+0x18c/0x1a1 [<ffffffff8025f82b>] error_exit+0x0/0x6emem-info:dma per-cpu:cpu 0 hot: high 0, batch 1 used:0cpu 0 cold: high 0, batch 1 used:0dma32 per-cpu:cpu 0 hot: high 186, batch 31 used:30cpu 0 cold: high 62, batch 15 used:51normal per-cpu: emptyhighmem per-cpu: emptyfree pages: 4748kb (0kb highmem)active:114975 inactive:0 dirty:0 writeback:0 unstable:0 free:1187 slab:4839 mapped-file:541 mapped-anon:114505 pagetables:1332dma free:2004kb min:48kb low:60kb high:72kb active:540kb inactive:0kb present:9076kb pages_scanned:<phone> all_unreclaimable? yeslowmem_reserve[]: 0 489 489 489dma32 free:2744kb min:2804kb low:3504kb high:4204kb active:459360kb inactive:0kb present:500960kb pages_scanned:<phone> all_unreclaimable? yeslowmem_reserve[]: 0 0 0 0normal free:0kb min:0kb low:0kb high:0kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0highmem free:0kb min:128kb low:128kb high:128kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0dma: 1*4kb 0*8kb 1*16kb 0*32kb 1*64kb 1*128kb 1*256kb 1*512kb 1*1024kb 0*2048kb 0*4096kb = 2004kbdma32: 12*4kb 3*8kb 1*16kb 1*32kb 1*64kb 0*128kb 0*256kb 1*512kb 0*1024kb 1*2048kb 0*4096kb = 2744kbnormal: emptyhighmem: empty586 pagecache pagesswap cache: add 0, delete 0, find 0/0, race 0+0free swap = 0kbtotal swap = 0kbfree swap: 0kb131072 pages of ram5993 reserved pages5581 pages shared0 pages swap cachedklogd invoked oom-killer: gfp_mask=0x201d2, order=0, oomkilladj=0call trace: [<ffffffff802c1b64>] out_of_memory+0x8b/0x203 [<ffffffff8020fa5d>] __alloc_pages+0x27f/0x308 [<ffffffff802139dd>] __do_page_cache_readahead+0xc8/0x1af [<ffffffff8021424e>] filemap_nopage+0x14c/0x360 [<ffffffff80208e9d>] __handle_mm_fault+0x444/0x144f [<ffffffff80263929>] _spin_lock_irqsave+0x9/0x14 [<ffffffff80263929>] _spin_lock_irqsave+0x9/0x14 [<ffffffff80251144>] finish_wait+0x32/0x5d [<ffffffff80266d94>] do_page_fault+0xf72/0x131b [<ffffffff802ff918>] kmsg_read+0x3a/0x44 [<ffffffff8025f82b>] error_exit+0x0/0x6emem-info:dma per-cpu:cpu 0 hot: high 0, batch 1 used:0cpu 0 cold: high 0, batch 1 used:0dma32 per-cpu:cpu 0 hot: high 186, batch 31 used:45cpu 0 cold: high 62, batch 15 used:51normal per-cpu: emptyhighmem per-cpu: emptyfree pages: 4748kb (0kb highmem)active:114975 inactive:0 dirty:0 writeback:0 unstable:0 free:1187 slab:4824 mapped-file:541 mapped-anon:114505 pagetables:1332dma free:2004kb min:48kb low:60kb high:72kb active:540kb inactive:0kb present:9076kb pages_scanned:<phone> all_unreclaimable? yeslowmem_reserve[]: 0 489 489 489dma32 free:2744kb min:2804kb low:3504kb high:4204kb active:459360kb inactive:0kb present:500960kb pages_scanned:36231106 all_unreclaimable? yeslowmem_reserve[]: 0 0 0 0normal free:0kb min:0kb low:0kb high:0kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0highmem free:0kb min:128kb low:128kb high:128kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0dma: 1*4kb 0*8kb 1*16kb 0*32kb 1*64kb 1*128kb 1*256kb 1*512kb 1*1024kb 0*2048kb 0*4096kb = 2004kbdma32: 12*4kb 3*8kb 1*16kb 1*32kb 1*64kb 0*128kb 0*256kb 1*512kb 0*1024kb 1*2048kb 0*4096kb = 2744kbnormal: emptyhighmem: empty586 pagecache pagesswap cache: add 0, delete 0, find 0/0, race 0+0free swap = 0kbtotal swap = 0kbfree swap: 0kb131072 pages of ram5993 reserved pages5581 pages shared0 pages swap cachedout of memory: killed process 21001, uid 48, (httpd).sudo invoked oom-killer: gfp_mask=0x201d2, order=0, oomkilladj=0call trace: [<ffffffff802c1b64>] out_of_memory+0x8b/0x203 [<ffffffff8020fa5d>] __alloc_pages+0x27f/0x308 [<ffffffff802139dd>] __do_page_cache_readahead+0xc8/0x1af [<ffffffff8021424e>] filemap_nopage+0x14c/0x360 [<ffffffff80208e9d>] __handle_mm_fault+0x444/0x144f [<ffffffff8020622a>] hypercall_page+0x22a/0x1000 [<ffffffff8020622a>] hypercall_page+0x22a/0x1000 [<ffffffff80266d94>] do_page_fault+0xf72/0x131b [<ffffffff8024901b>] skb_dequeue+0x48/0x50 [<ffffffff80254146>] unix_release_sock+0x19e/0x1fa [<ffffffff80261df5>] thread_return+0x6c/0x113 [<ffffffff80207116>] kmem_cache_free+0x84/0xd7 [<ffffffff80207116>] kmem_cache_free+0x84/0xd7 [<ffffffff8025f82b>] error_exit+0x0/0x6emem-info:dma per-cpu:cpu 0 hot: high 0, batch 1 used:0cpu 0 cold: high 0, batch 1 used:0dma32 per-cpu:cpu 0 hot: high 186, batch 31 used:165cpu 0 cold: high 62, batch 15 used:48normal per-cpu: emptyhighmem per-cpu: emptyfree pages: 4760kb (0kb highmem)active:114996 inactive:0 dirty:0 writeback:0 unstable:0 free:1190 slab:4821 mapped-file:541 mapped-anon:114468 pagetables:1225dma free:2004kb min:48kb low:60kb high:72kb active:540kb inactive:0kb present:9076kb pages_scanned:<phone> all_unreclaimable? yeslowmem_reserve[]: 0 489 489 489dma32 free:2756kb min:2804kb low:3504kb high:4204kb active:459444kb inactive:0kb present:500960kb pages_scanned:<phone> all_unreclaimable? yeslowmem_reserve[]: 0 0 0 0normal free:0kb min:0kb low:0kb high:0kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0highmem free:0kb min:128kb low:128kb high:128kb active:0kb inactive:0kb present:0kb pages_scanned:0 all_unreclaimable? nolowmem_reserve[]: 0 0 0 0dma: 1*4kb 0*8kb 1*16kb 0*32kb 1*64kb 1*128kb 1*256kb 1*512kb 1*1024kb 0*2048kb 0*4096kb = 2004kbdma32: 5*4kb 8*8kb 1*16kb 1*32kb 1*64kb 0*128kb 0*256kb 1*512kb 0*1024kb 1*2048kb 0*4096kb = 2756kbnormal: emptyhighmem: empty586 pagecache pagesswap cache: add 0, delete 0, find 0/0, race 0+0free swap = 0kbtotal swap = 0kbfree swap: 0kb131072 pages of ram5993 reserved pages4629 pages sharedhow do i read this in a way that can help me perform this task:in the process list that gets dumped into dmesg at the time of the oom condition, one of the columns should include how much memory each process is using. ...put that output in your question...",
    "present_kp": [
      "dmesg",
      "out of memory"
    ],
    "absent_kp": [
      "centos"
    ]
  },
  {
    "text": "ipv4 broadcast routing in linux. i have a server with three network interfaces- loopback interface lo and two physical network interfaces eth0 and eth1:1: lo: <loopback,up,lower_up> mtu 16436 qdisc noqueue state unknown link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc mq state up qlen 1000 link/ether 00:1d:09:f0:92:ab brd ff:ff:ff:ff:ff:ff inet 93.184.216.34/22 brd 93.184.219.255 scope global eth0 inet6 fe80::21d:9ff:fef0:92ab/64 scope link valid_lft forever preferred_lft forever3: eth1: <broadcast,multicast,up,lower_up> mtu 1500 qdisc mq state up qlen 1000 link/ether 00:1d:09:f0:92:ac brd ff:ff:ff:ff:ff:ff inet 10.228.2.2/24 scope global eth1 inet6 fe80::21d:9ff:fef0:92ac/64 scope link valid_lft forever preferred_lft forevernow if i check the routing for 255.255.255.255 or 0.0.0.0.0(older ip broadcast address), then i would expect, that packet is forwarded on all three network interfaces. instead, for 255.255.255.255 only the eth0 is used and for 0.0.0.0 the lo is used:root@server:~# ip route get 255.255.255.255broadcast 255.255.255.255 dev eth0 src 93.184.216.34 cache <local,brd> root@server:~# ip route get 0.0.0.0local 127.0.0.1 dev lo src 127.0.0.1 cache <local> root@server:~# why is that so?",
    "present_kp": [
      "routing",
      "ipv4"
    ],
    "absent_kp": []
  },
  {
    "text": "how to solve apparmor profile transition not found. i get repeated apparmor messages like the following in my syslog (profile is in complain mode):aug 29 02:07:13 titan kernel: [<phone>] audit: type=1400 audit(<phone>.147:1131): apparmor=allowed operation=exec info=profile transition not found error=-13 profile=/usr/sbin/dovecot name=/usr/lib/dovecot/anvil pid=5983 comm=dovecot requested_mask=x denied_mask=x fsuid=0 ouid=0 target=/usr/lib/dovecot/anvilwhat needs to be added to the usr.bin.dovecot profile to address this? aa-logprof finds nothing.the profile already has this line, which i though addressed this:/usr/lib/dovecot/anvil rpx,",
    "present_kp": [
      "apparmor"
    ],
    "absent_kp": []
  },
  {
    "text": "move only uniq files from one directory to other. i want to move files from directory a to directory b. but there are some conditions.directory a structure:a.txt_20170502 b.txt_20170502a.txt_20170507asd.txt_20170509asd.txt_20170522so, i want to rename a.txt_20170502 to a.txt and move that file to directory b, but if a.txt is present in directory b, it will not move that file.example:a.txtasd.txtthis process continue until all the candidate files are moved from directory a to b.i am confused how i can check if files are already in that directory,it will not move that file.condition :-there is another script running in background which will fetching data from directory b.so, if any files are present in directory b , it will be automatically copied mainframe server.",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "ksh",
      "file copy",
      "mv"
    ]
  },
  {
    "text": "linear diophantine equation in non-negative integers. there's only very little information i can find on the np-complete problem of solving linear diophantine equation in non-negative integers. that is to say, is there a solution in non-negative $x_1,x_2, ... , x_n$ to the equation $a_1 x_1 + a_2 x_2 + ... + a_n x_n = b$, where all the constants are positive? the only noteworthy mention of this problem that i know of is in schrijver's theory of linear and integer programming. and even then, it's a rather terse discussion.so i would greatly appreciate any information or reference you could provide on this problem.there are two questions i mostly care about:is it strongly np-complete?is the related problem of counting the number of solutions #p-hard, or even #p-complete?",
    "present_kp": [],
    "absent_kp": [
      "cc.complexity theory",
      "reference request",
      "np hardness",
      "counting complexity"
    ]
  },
  {
    "text": "is testing the easiest way to contribute to an open source project?. i want to contribute to an open source project, but i don't know much about unit testing. i want to learn how to test and then practice my skills on an open source. will this also be acknowledged as a contribution.i want to first get my name out there and then conc. on development.",
    "present_kp": [
      "unit testing"
    ],
    "absent_kp": []
  },
  {
    "text": "using tee to append string to a file and also use it as replacement for a pattern in another file. i have the following code:cat file | grep example | sed 's/http/https/' >> report.txtoutput of that command: <url> will add a link, with https, to the file. i would like, however, for that same output to also replace url in a second file. content of the second file:text texttexturltext textdesired change in second file:text texttexthttps://example.com/page/index.htmltext textis this possible?p.s.: i can't repeat the command again, as it is actually not a simple cat but an upload process that starts the command.",
    "present_kp": [
      "sed",
      "tee"
    ],
    "absent_kp": [
      "awk"
    ]
  },
  {
    "text": "do i need an ssl certificate?. i'm thinking about building an app that lets users upload images to sites like flickr. they would need to enter their password to do this. i would send the data through php, do i need to get a ssl certificate for that?",
    "present_kp": [],
    "absent_kp": [
      "security",
      "https",
      "security certificate"
    ]
  },
  {
    "text": "kde's network applet not listing aps, while iwlist does after some extra steps. kde's network applet doesn't list any wireless network. it used to, but i must have made an unintended change. this much i know about my situation (the device is called wlp4s0):upon login, the applet has two initially unticked and unlabelled tick boxes, one of which must be the enable wireless one.on the command line, my only route to listing present networks with iwlist wlp4s0 scan requires these steps:rfkill unblock allsudo ifconfig wlp4s0 upto get to a network listing, these steps are necessary each time after login or switching the device off and on, and the device is always down upon login.my os is: linux miraculix 4.2.0-34-generic #39-ubuntu smp thu mar 10 22:13:01 utc 2016 x86_64 x86_64 x86_64 gnu/linuxkde:$ plasmashell -vplasmashell 5.4.2i have also deleted and re-created my kwallet settings to rule out that kind of permission issue.any help to get my kde network applet to recognize networks again is appreciated.",
    "present_kp": [
      "kde"
    ],
    "absent_kp": [
      "networking",
      "wifi",
      "networkmanager"
    ]
  },
  {
    "text": "edit distance of list with unique elements. levenshtein-distance edit distance between lists is a well studied problem. but i can't find much on possible improvements if it is known that no element does occurs more than once in each list. let's also assume that the elements are comparable/sortable (but the lists to compare are not sorted to begin with).in particular i am interested if the uniqueness of elements makes it possible to improve upon ukkonen's algorithm for edit distance which has time complexity $o(\\min(m,n)s)$ and space complexity $o(\\min(s,m,n)s)$, where $s$ is the minimum cost of the editing steps. more formally, how efficiently can we compute the edit distance between two given strings $s,t \\in \\sigma^*$ with the promise that they don't have any repeated letters?$\\sigma$ is a very large alphabet.",
    "present_kp": [
      "strings",
      "edit distance"
    ],
    "absent_kp": [
      "algorithms",
      "string metrics"
    ]
  },
  {
    "text": "how to setup kiosk type functionality in linux mint cinnamon?. i'm using linux mint cinnamon. i want to setup the computer to act as a kiosk, where the user can only really interact with firefox in full screen mode.what is the easiest way to lock the machine down? does dconf or gconf work with cinnamon? should i just ditch cinnamon for xfce, or some other wm with built in kiosk mode?",
    "present_kp": [
      "linux mint",
      "firefox",
      "cinnamon",
      "kiosk"
    ],
    "absent_kp": [
      "window manager"
    ]
  },
  {
    "text": "installing python modules for python2.6. on my centos 5.8 system (el5 , 64bit), i had python2.4 after os install and i installed python2.6 now. now i want to install python modules using yum. but whenever i install a new python module it goes to the python2.4 and is not installed for python2.6. i tried to replace the python2.4 binary with python2.6 binary. but this broke yum and i had to restore python2.4. so i concluded that it is not a good idea to uninstall python2.4 (that came with base os) as it might break other system dependencies.my question is how do i safely install python modules targeting python2.6 without breaking python2.4?",
    "present_kp": [
      "centos",
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "an optional_ref. i omitted all free operators but the equality comparisons ones because of verbosity. i am glad about any comments and improvements.motivationi know that optional references are equivalent to pointers and their implementation is just such a wrapper. but i believe they make sense in some circumstances and please correct me if i am wrong.while implementing and using my interval map i needed to return an optional reference in one of its accessor methods, namely operator[](key). the idea is to get a reference to a stored value or nothing. thus i did it there with an std::optional<std::reference_wrapper<const t>>. following this pattern of optional refs led to complications when i tried accessing an std::optional<std::reference_wrapper<t>> at some other point of time. i couldn't write something like thisint a = 0;std::optional<std::reference_wrapper<int>> opt{a};*opt = 42;assert(a == 42);but instead one has to explicitly unwrap the reference_wrapper like thisopt.value().get() = 42;assert(a == 42);oropt->get() = 42assert(a == 42);and my motivation for optional_ref was born.source codehere is the complete source code on wandbox.optional_ref.hpp#include <type_traits>#include <cassert>#include <stdexcept>#include range/v3/utility/concepts.hppnamespace fub{struct bad_optional_access : std::runtime_error { using runtime_error::runtime_error;};template <typename t> class optional_ref { public: using element_type = t; using reference = element_type&; using pointer = element_type*; // constructors optional_ref() = default; template <typename s, concept_requires_(ranges::convertibleto<s*, t*>())> constexpr optional_ref(const optional_ref<s>& other) noexcept : m_pointer{other.get_pointer()} {} constexpr optional_ref(reference element) noexcept : m_pointer{std::addressof(element)} {} // assignment template <typename s, concept_requires_(ranges::convertibleto<s*, t*>())> constexpr optional_ref& operator=(const optional_ref<s>& other) noexcept { m_pointer = other.get_pointer(); } // destructor ~optional_ref() = default; // swap void swap(optional_ref& other) noexcept { swap(m_pointer, other.m_pointer); } // observers constexpr bool has_value() const noexcept { return m_pointer != nullptr; } constexpr pointer get_pointer() const noexcept { return m_pointer; } constexpr reference value() const { if (!has_value()) { throw bad_optional_access( fub::optional_ref::value: optional_ref is empty. ); } return *get_pointer(); } template <typename u, concept_requires_(ranges::convertibleto<u, reference>())> constexpr reference value_or(u&& alternative) const noexcept { if (has_value()) { return *get_pointer(); } return alternative; } constexpr pointer operator->() const noexcept { assert(has_value()); return get_pointer(); } constexpr reference operator*() const noexcept { assert(has_value()); return *get_pointer(); } constexpr operator bool() const noexcept { return has_value(); } // modifiers void reset() noexcept { m_pointer = nullptr; } private: pointer m_pointer{nullptr}; };// equality comparisontemplate <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator==(optional_ref<t> left, optional_ref<s> right) noexcept(noexcept(*left == *right)) { return (!left && !right) || (left && right && *left == *right); }template <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator!=(optional_ref<t> left, optional_ref<s> right) noexcept(noexcept(left == right)) { return !(left == right); }// equality comparison with ttemplate <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator==(optional_ref<t> left, const s& right) noexcept(noexcept(*left == right)) { return left && *left == right; }template <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator==(const t& left, optional_ref<s> right) noexcept(noexcept(left == *right)) { return right && left == *right; }template <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator!=(optional_ref<t> left, const s& right) noexcept(noexcept(left == right)) { return !(left == right); }template <typename t, typename s, concept_requires_(ranges::equalitycomparable<t, s>())> bool operator!=(const t& left, optional_ref<s> right) noexcept(noexcept(left == right)) { return !(left == right); }some tests (see also on wandbox)test_case(optional refs are regular types){ require(ranges::regular<optional_ref<int>>()); require(ranges::regular<optional_ref<std::unique_ptr<int>>>()); require(ranges::regular<optional_ref<char[30]>>()); require(ranges::regular<optional_ref<double[]>>());}test_case(compare const int refs with int refs){ int a = 42; int b = 24; const int c = 42; optional_ref<int> ref_a = a; optional_ref<const int> ref_x; require(!ref_x); require(!ref_x.has_value()); require(ref_a != ref_x); ref_x = c; require(ref_a == ref_x); require(ref_a.get_pointer() != ref_x.get_pointer()); ref_x = b; require(ref_a != ref_x); ref_x = a; require(ref_a.get_pointer() == ref_x.get_pointer());}test_case(arrow operator works with objects){ struct a { int foo; char bar; }; a a{4, '2'}; optional_ref<a> ref{a}; require(ref->foo == 4); require(ref->bar == '2');}void access_throws(optional_ref<const int> ref){ require_throws_as(ref.value(), bad_optional_access);}test_case(throw error on using empty optional_ref){ auto ref = optional_ref<int>{}; access_throws(ref);}test_case(assign reference){ int a = 0; optional_ref<int> ref{a}; require(ref == 0); *ref = 42; require(ref == 42);}",
    "present_kp": [
      "pointers",
      "optional"
    ],
    "absent_kp": [
      "c++",
      "c++14"
    ]
  },
  {
    "text": "is there a difference between clicking reply and writing a new tweet with @somesone?. on twitter web, when i click the reply button for a tweet, there's @someone inserted in front of the message automatically.is there any difference compared to writing a new tweet and entering @someone manually?",
    "present_kp": [
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "collecting retainers. i am trying to create a form that will subtotal a series of charges, but then collect only 50% of that total as a retainer. and then collect the balance at a later date. is this possible?",
    "present_kp": [],
    "absent_kp": [
      "cognito forms"
    ]
  },
  {
    "text": "gpg2 won't import .key files : no valid openpgp data found. i want to import my old gpg2 secret keyring from a backup. i only have my old .gnupg directory.but all files in this folder are unrecognized by gpg2, which says no valid openpgp data found when i try to --import them.how can i import my old secret keys ?",
    "present_kp": [
      "gpg"
    ],
    "absent_kp": []
  },
  {
    "text": "why does :r!vi jam my terminal?. is it legal to do :r!vi in vi?a friend asked me to try it and it jammed my terminal. what exactly causes this? is there anyway to recover the terminal without closing it and opening a new one?",
    "present_kp": [
      "terminal"
    ],
    "absent_kp": [
      "external command"
    ]
  },
  {
    "text": "yum update dependency in centos 6.6. after installing a rpm, by running sudo yum updatein centos 6.6, i am getting the errorerror: package: qgis-python-2.8.1-3.el7.centos.x86_64 (neteler-qgis-2.8-wien) requires: libpython2.7.so.1.0()(64bit)however, libpython2.7.so.1.0 (or at least its soft link) can be seen in the /usr/lib. any ideas how to fix this?",
    "present_kp": [
      "centos",
      "yum"
    ],
    "absent_kp": []
  },
  {
    "text": "how to renice all threads (and children) of one process on linux?. linux does not (yet) follow the posix.1 standard which says that a renice on a process affects all system scope threads in the process, because according to the pthreads(7) doc threads do not share a common nice value.however, sometimes, it can be convenient to renice everything related to a given process (one example would be apache child processes and all their threads). so, how can i renice all threads belonging to a given process ?how can i renice all child processes belonging to a given process ?i am looking for a fairly easy solution. i know that process groups can sometimes be helpful, however, they do not always match what i want to do: they can include a broader or different set of processes. using a cgroup managed by systemd might also be helpful, but even if i am interested to hear about it, i mostly looking for a standard solution.edit: also, man (7) pthreads says all of the threads in a process are placed in the same thread group; all members of a thread group share the same pid. so, is it even possible to renice something which doesn't have it's own pid?",
    "present_kp": [
      "linux",
      "process",
      "nice",
      "thread"
    ],
    "absent_kp": []
  },
  {
    "text": "how to find maximum number of different strings?. i have a file:2.0-00-042.0-00-032.0-00-022.0-00-012.0-00-001.0-00-021.0-00-011.0-00-00how can i find maximum number of each group? in the string above, output should be:2.0-00-041.0-00-02",
    "present_kp": [],
    "absent_kp": [
      "text processing",
      "scripting",
      "sort"
    ]
  },
  {
    "text": "struct with abstract type member in c. i am writing c code that has some dynamic arrays/list that are represented with a struct that contains the number of elements and a pointer to the elements.i have some functions that are doing some similar work with that structs, for example printing the elements. to use the same code i decided to create a struct to that holes an abstract data type and the printing function receives a pointer to that struct.a specific struct looks like that:typedef struct { int numofelements; int *element;} list_int, *plist_int; the generic struct look like that:typedef struct { int numofelements; void *element;} list_gen, *plist_gen;is that the right approach? this is the code example:#include <stdio.h>#include <stdlib.h>typedef struct { int numofelements; char *element;} list_char, *plist_char;typedef struct { int numofelements; int *element;} list_int, *plist_int;typedef struct { int numofelements; void *element;} list_gen, *plist_gen;typedef void(*fpprintelement)(void *element);void print_list(plist_gen list, int elementsize, fpprintelement printelement) { int i = 0; int num = list->numofelements; for (i = 0; i < num; ++i) { printelement(((char *)(list->element) + i * elementsize)); } return;}void print_int(int * element) { printf(%d , *element);}void print_char(char * element) { printf(%c , *element);}void main() { list_int list_int; list_int.numofelements = 10; list_int.element = malloc(sizeof(list_int.element) * list_int.numofelements); for (int i = 0; i < list_int.numofelements; ++i) { list_int.element[i] = i * 1000; } list_int list_char; list_char.numofelements = 7; list_char.element = malloc(sizeof(list_char.element) * list_char.numofelements); for (int i = 0; i < list_char.numofelements; ++i) { list_char.element[i] = i + 35; } print_list((plist_gen)&list_int, sizeof(*list_int.element), print_int); print_list((plist_gen)&list_char, sizeof(*list_char.element), print_char); return;}",
    "present_kp": [
      "c"
    ],
    "absent_kp": []
  },
  {
    "text": "sles cant upgrade packages via zypper or yast2. getting errors whenever this box tries to phone to grab a packagevia yast:there was an error in the repository initialization.download (curl) error forhttps://nu.novell.com/repo/repoindex.xml?cookies=0&redentials=ncccredentials':error code: unrecognized errorerror message: ssl certificate problem, verify that the cacert is ok. details:error:<phone>:sslvia zypper:check if the uri is valid and accessible.download (curl) error for '<url> code: unrecognized errorerror message: ssl certificate problem, verify that the ca cert is ok. details:error:<phone>:ssl routines:ssl3_get_server_certificate:certificate verify failedany ideas? i know this box is sitting behind a proxy, but i can hit this website via firefox and the proxy is set up correctly because i can hit other sites outside of my network.",
    "present_kp": [
      "ssl"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i run a bash variable as a command exactly without additional quotation?. i'm trying to make a script which needs to save a command to be run as a string. the string in question needs to contain quotes, and when attempting to execute it bash adds additional quotation characters which in some cases causes the command to not run as expected.here is an example script. the command example run in this example script obviously doesn't do anything and it will simply say command not found, however you can still run the script and see what i'm talking about because i added -x to the #!/bin/bash line so that the exact command being run is printed out.example:#!/bin/bash -x#command typed explicitlyexample -options -i filename#command stored in string firstcommandstring='example -options -i filename'echo running command: ${commandstring}${commandstring}the output of running this script for me is (ignoring the two command not found errors):+ example -options '-i filename'+ commandstring='example -options -i filename'+ echo 'running command: example -options -i filename'running command: example -options -i filename+ example -options '-i' 'filename'so you can see that the first line of course is run as expected giving the command line parameter:-i filenamehowever, although the echo command prints the string in a way that would execute perfectly as well, when the string is placed on the command line it changes and the parameter being passed in becomes'-i' 'filename'which contains additional quote characters, and this is causing the actual command i'm using in my real script to fail.is there any way to prevent this?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "quoting"
    ]
  },
  {
    "text": "how to clean up file extensions?. i have a directories with .mp3 files which i'd like to change the extensions to .mp3. what's the easiest way to do this? i'm think something along the lines of:find /rootpath -type f -iname *.mp3 -exec mv {} sed s/.*mp3/.mp3/ \\; ...though i know that isn't quite right. :) the substitution isn't correct and i'm not sure how to use both a mv and a sed command with -exec in find.would i need a bash script for this?",
    "present_kp": [
      "find"
    ],
    "absent_kp": [
      "shell",
      "rename"
    ]
  },
  {
    "text": "removing a directory that has no files in it. i recently created a username and a group called gamesforadmin. since then i deleted it and the folder i made for it is still there:drwxr-xr-x 5 root root 4096 jul 4 11:28 .drwxr-xr-x 23 root root 4096 may 29 12:41 ..drwxr-xr-x 2 sftpuser sftpaccess 4096 jul 4 11:24 gamesforadmindrwxr-xr-x 27 ryan ryan 4096 jul 4 11:31 ryandrwxr-xr-x 3 root sftpaccess 4096 jul 4 11:29 sftpuserwhen i try to run a sudo rmdir gamesforadmin, i get this error message:rmdir: failed to remove gamesforadmin: directory not emptybut theres nothing in the directory! when i run an ls, there is nothing listed.why does this occur?how i can successfully remove this directory?output of ls -la gamesforadmin:total 28drwxr-xr-x 2 sftpuser sftpaccess 4096 jul 4 11:24 .drwxr-xr-x 5 root root 4096 jul 4 11:28 ..-rw------- 1 sftpuser sftpaccess 471 jun 9 19:49 .bash_history-rw-r--r-- 1 sftpuser sftpaccess 220 apr 8 21:03 .bash_logout-rw-r--r-- 1 sftpuser sftpaccess 3637 apr 8 21:03 .bashrc-rw-r--r-- 1 sftpuser sftpaccess 675 apr 8 21:03 .profile-rw------- 1 sftpuser sftpaccess 644 jun 9 17:48 .viminfo",
    "present_kp": [
      "directory",
      "ls",
      "rm"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "why can't i ping google with a static ip address?. i'm trying to install vicibox, an opensuse distro which includes asterisk. the fine manual says to set a static ip address with yast lan.what's the difference between: [ ] change hostname via dhcp [x] assign hostname to loopback ip i have my hostname set:yast2 - lan @ arrakis network settings global optionsoverviewhostname/dnsrouting hostname and domain name hostname domain name arrakis bounceme.net [ ] change hostname via dhcp [x] assign hostname to loopback ip modify dns configuration custom policy rule use default policy name servers and domain search list name server 1 domain search 8.8.8.8 google.com name server 2 8.8.4.4 name server 3 with good connectivity:arrakis:~ # arrakis:~ # uname -alinux arrakis 3.11.10-21-default #1 smp mon jul 21 15:28:46 utc 2014 (9a9565d) x86_64 x86_64 x86_64 gnu/linuxarrakis:~ # arrakis:~ # cat /etc/hosts## hosts this file describes a number of hostname-to-address# mappings for the tcp/ip subsystem. it is mostly# used at boot time, when no name servers are running.# on small systems, this file can be used instead of a# named name server.# syntax:# # ip-address full-qualified-hostname short-hostname#127.0.0.1 localhost# special ipv6 addresses::1 localhost ipv6-localhost ipv6-loopbackfe00::0 ipv6-localnetff00::0 ipv6-mcastprefixff02::1 ipv6-allnodesff02::2 ipv6-allroutersff02::3 ipv6-allhosts127.0.0.2 arrakis.bounceme.net arrakisarrakis:~ # arrakis:~ # hostnamearrakisarrakis:~ # arrakis:~ # ping arrakis.bounceme.netping arrakis.bounceme.net (127.0.0.2) 56(84) bytes of data.64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=1 ttl=64 time=0.040 ms64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=2 ttl=64 time=0.050 ms64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=3 ttl=64 time=0.049 ms^c--- arrakis.bounceme.net ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 1998msrtt min/avg/max/mdev = 0.040/0.046/0.050/0.007 msarrakis:~ # arrakis:~ # arrakis:~ # ping arrakisping arrakis.bounceme.net (127.0.0.2) 56(84) bytes of data.64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=1 ttl=64 time=0.036 ms64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=2 ttl=64 time=0.041 ms64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=3 ttl=64 time=0.041 msc64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=4 ttl=64 time=0.040 ms64 bytes from arrakis.bounceme.net (127.0.0.2): icmp_seq=5 ttl=64 time=0.043 ms^c--- arrakis.bounceme.net ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 3996msrtt min/avg/max/mdev = 0.036/0.040/0.043/0.004 msarrakis:~ # arrakis:~ # arrakis:~ # ifconfigenp5s0 link encap:ethernet hwaddr 50:e5:49:c2:c8:05 inet addr:192.168.0.21 bcast:192.168.0.255 mask:255.255.255.0 inet6 addr: fe80::52e5:49ff:fec2:c805/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:2632 errors:0 dropped:0 overruns:0 frame:0 tx packets:278 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:173852 (169.7 kb) tx bytes:38509 (37.6 kb)lo link encap:local loopback inet addr:127.0.0.1 mask:255.0.0.0 inet6 addr: ::1/128 scope:host up loopback running mtu:65536 metric:1 rx packets:40 errors:0 dropped:0 overruns:0 frame:0 tx packets:40 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 rx bytes:3248 (3.1 kb) tx bytes:3248 (3.1 kb)arrakis:~ # but want to set the ip address to static:yast2 - lan @ arrakis network card setup generaladdresshardware device type configuration name ethernet enp5s0 ( ) no link and ip setup (bonding slaves) [ ] use ibft values ( ) dynamic address dhcp dhcp both version 4 and 6 (x) statically assigned ip address ip address subnet mask hostname 192.168.0.21 255.255.255.0 arrakis.bounceme.net additional addresses alias nameip addressnetmask yet, as soon as i do so, i lose connectivity:arrakis:~ # yast lanarrakis:~ # arrakis:~ # arrakis:~ # ifconfigenp5s0 link encap:ethernet hwaddr 50:e5:49:c2:c8:05 inet addr:192.168.0.21 bcast:192.168.0.255 mask:255.255.255.0 inet6 addr: fe80::52e5:49ff:fec2:c805/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:4027 errors:0 dropped:0 overruns:0 frame:0 tx packets:858 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:271734 (265.3 kb) tx bytes:265009 (258.7 kb)lo link encap:local loopback inet addr:127.0.0.1 mask:255.0.0.0 inet6 addr: ::1/128 scope:host up loopback running mtu:65536 metric:1 rx packets:40 errors:0 dropped:0 overruns:0 frame:0 tx packets:40 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 rx bytes:3248 (3.1 kb) tx bytes:3248 (3.1 kb)arrakis:~ # arrakis:~ # arrakis:~ # ping google.comping: unknown host google.comarrakis:~ # why can't i ping google?see also:<url> changing to a static ip address. it's the same ip address as when dynamic.with static ip:arrakis:~ # arrakis:~ # ifconfigenp5s0 link encap:ethernet hwaddr 50:e5:49:c2:c8:05 inet addr:192.168.0.21 bcast:192.168.0.255 mask:255.255.255.0 inet6 addr: fe80::52e5:49ff:fec2:c805/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:10438 errors:0 dropped:0 overruns:0 frame:0 tx packets:1133 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:671095 (655.3 kb) tx bytes:300227 (293.1 kb)lo link encap:local loopback inet addr:127.0.0.1 mask:255.0.0.0 inet6 addr: ::1/128 scope:host up loopback running mtu:65536 metric:1 rx packets:40 errors:0 dropped:0 overruns:0 frame:0 tx packets:40 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 rx bytes:3248 (3.1 kb) tx bytes:3248 (3.1 kb)arrakis:~ # arrakis:~ # ip addr1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 brd 127.255.255.255 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: enp5s0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up qlen 1000 link/ether 50:e5:49:c2:c8:05 brd ff:ff:ff:ff:ff:ff inet 192.168.0.21/24 brd 192.168.0.255 scope global enp5s0 valid_lft forever preferred_lft forever inet6 fe80::52e5:49ff:fec2:c805/64 scope link valid_lft forever preferred_lft foreverarrakis:~ # arrakis:~ # ip route127.0.0.0/8 dev lo scope link 192.168.0.0/24 dev enp5s0 proto kernel scope link src 192.168.0.21 arrakis:~ # arrakis:~ # ping <url> unknown host <url>~ # arrakis:~ # yast lanarrakis:~ # and then, switching back to dhcp should, i would think, restore an ability to ping google:arrakis:~ # arrakis:~ # ping <url> unknown host <url>~ # arrakis:~ # ip route127.0.0.0/8 dev lo scope link 192.168.0.0/24 dev enp5s0 proto kernel scope link src 192.168.0.21 arrakis:~ # arrakis:~ # ip addr1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 brd 127.255.255.255 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: enp5s0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up qlen 1000 link/ether 50:e5:49:c2:c8:05 brd ff:ff:ff:ff:ff:ff inet 192.168.0.21/24 brd 192.168.0.255 scope global enp5s0 valid_lft forever preferred_lft forever inet6 fe80::52e5:49ff:fec2:c805/64 scope link valid_lft forever preferred_lft foreverarrakis:~ # arrakis:~ # ifconfigenp5s0 link encap:ethernet hwaddr 50:e5:49:c2:c8:05 inet addr:192.168.0.21 bcast:192.168.0.255 mask:255.255.255.0 inet6 addr: fe80::52e5:49ff:fec2:c805/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:11178 errors:0 dropped:0 overruns:0 frame:0 tx packets:1490 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:723997 (707.0 kb) tx bytes:415085 (405.3 kb)lo link encap:local loopback inet addr:127.0.0.1 mask:255.0.0.0 inet6 addr: ::1/128 scope:host up loopback running mtu:65536 metric:1 rx packets:40 errors:0 dropped:0 overruns:0 frame:0 tx packets:40 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 rx bytes:3248 (3.1 kb) tx bytes:3248 (3.1 kb)arrakis:~ # apparently not..",
    "present_kp": [
      "opensuse",
      "ip",
      "yast",
      "ifconfig"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "xubuntu and gtk apps problem. after upgrade from ubuntu 11.04 to ubuntu 11.10 i got disappointed with unity. i wanted my old-style gnome 2 back. that's why i purged unity and installed xfce4. but, now i have a problem: all my gtk+ apps i have used to (like totem) have windows 95 kind of interface...they look very bad. is there any libgtk i should install to fix that? currently, i have libgtk-3.0 installed but i'm kind of new to linux so i don't even know if instaling some old libgtk would solve my problem.can you guys help me?",
    "present_kp": [
      "ubuntu",
      "xfce",
      "gtk",
      "xubuntu"
    ],
    "absent_kp": []
  },
  {
    "text": "why the inconsistency with using cat vs. echo piped to this sed command?. inspired by this question: sed: n command does not read single line i wanted to understand why there appears to be an inconsistency between the following 2 commands:#1. echothis command produces no output$ echo -en 'abc ' | sed -n 'n;p'$a hex dump of the output from echo:od - octal dump$ echo -en 'abc ' | od -tx10000000 61 62 63 0a0000004hexdump$ echo -en 'abc ' | hexdump -c00000000 61 62 63 0a |abc.|<phone>#2. catif i put the string 'abc ' in a file such as this:1: abc2:that's a line with the string abc on it followed by a linefeed ( aka. 0x0a). then pipe it to sed as before, i get this:$ cat abc.txt | sed -n 'n;p'abc$that's output that includes the string abc followed by 2 linefeeds.od - octal dump$ cat abc.txt | od -tx10000000 61 62 63 0a 0a0000005hexdump$ cat abc.txt | hexdump -c00000000 61 62 63 0a 0a |abc..|00000005i'm a little perplexed as to what's going on?updateok so my issue was with how i was creating the file abc.txt as @choroba pointed out. i was creating the file in vim and not realizing that it was adding 2 linefeeds. when i enabled visibility of special characters it became a little more obvious::set listchars=eol:$,tab:>-,trail:~,extends:>,precedes:<,:set listnow in vim file abc.txt looked like this:abc$$if i created the file as @choroba suggested then the file abc.txt showed up as expected:$ cat abc.txt | od -tx10000000 61 62 63 0a0000004and it behaved identical to the original echo example:$ cat abc.txt | sed -n 'n;p'$ original issuemy original issue with why sed -n 'n;p' wasn't displaying anything was answered thanks to @enzotib's answer. the bit from the posix standard is what i wasn't picking up on:if no next line of input is available, the n command verb shall branch to the end of the script and quit without starting a new cycle or copying the pattern space to standard output",
    "present_kp": [
      "sed",
      "cat",
      "echo"
    ],
    "absent_kp": [
      "scripting",
      "newlines"
    ]
  },
  {
    "text": "using a gpl game engine. i am confused. i thought i would try and use a new game engine in order to expand my abilities, and found a nice engine called springrts. i was looking through the licensing info and it is licensed under the gpl 2 licence. if i remember correctly, does that mean that anything i make with it, i have to distribute the source code to?",
    "present_kp": [
      "gpl"
    ],
    "absent_kp": []
  },
  {
    "text": "extracting geometry data from gaussian09 geometry optimization. i want to extract the geometry for every single step of a gaussian09 optimization from the .log file. i need the results in cartesian xyz format, either in one file or in multiple files.first i tried to do this in open babel, but when i runobabel -ig09 gaussian_output.log -oxyz -m -o geometry.xyzthe program seems to fetch only the last geometry.any other suggestions for a quick solution?",
    "present_kp": [],
    "absent_kp": [
      "computational chemistry"
    ]
  },
  {
    "text": "how to make a script toggle between two commands when it is executed?. i am trying to write a script file and invoke it using xfce global shortcut. the script should continue the audacity application if it is in the stopped state and stop it (pause recording) if it is in the run state. this will be useful when i have defined the same keyboard shortcut for vlc's playback/pause. this way, i can do playback/pause (in vlc) and record/pause (in audacity) at the same time using the same keyboard shortcut. getting some ideas from this post i have written the following script and added it to xfce's custom keyboard settings. but it does not work. #!/bin/bash if pgrep -f audacity ; then pkill -stop audacity && notify-send recording stopped else pkill -cont audacity",
    "present_kp": [
      "xfce",
      "vlc",
      "audacity"
    ],
    "absent_kp": [
      "scripting",
      "keyboard shortcuts"
    ]
  },
  {
    "text": "second order function formalization. i need to work on a optimizer for a language whose operator are second order functions. they are the well known ones filter, map, reduce, fold, foreach etc. etc.i need to formalize as much as possible the language. i mean i would like to have at the end a description such this: filter is function from this domain to that codomain, it has this and that properties, under some condition also this property holdscan you suggest me some publication/book where this work has been (at least partially) done?",
    "present_kp": [],
    "absent_kp": [
      "programming languages",
      "functional programming",
      "formal methods",
      "program optimization",
      "abstract data types"
    ]
  },
  {
    "text": "why kill -9 -1 doesn't work?. from man kill:kill -9 -1kill all processes you can kill.but when i do sudo /bin/kill -9 -1 nothing happens.my uname -a for info: linux michal-q530 3.16.0-45-generic #60~14.04.1-ubuntu smp fri jul 24 21:16:23 utc 2015 x86_64 x86_64 x86_64 gnu/linuxand i'm on lubuntu.update:$ ps -e | wc -l169$ sudo /bin/kill -9 -1$ ps -e | wc -l169",
    "present_kp": [
      "kill"
    ],
    "absent_kp": []
  },
  {
    "text": "build a sentence from tokens / words in a string-array. i'm facing an interesting issue at the moment: my situation: i'm having (in java) string-arrays like the following (more complicated, of course). each string-array represents one sentence (i cant change the representation): string[] tokens = {this, is, just, an, example, .};my problem: i want to rebuild the original sentences from this string-arrays. this doesn't sound that hard at first, but becomes really complex since sentence structure can have many cases. sometimes you need whitespaces and sometimes you don't. my approach:i've implemented a method that should do most of the tasks, which means rebuilding a sentence from the original string-array. as you can see, it's very complex and complicated already, but works okay for the moment - i don't know how to improve it at the moment. public static string detokenize(string[] tokens) { stringbuilder sentence = new stringbuilder(); boolean sentenceinquotation = false; boolean firstwordinquotationsentence = false; boolean firstwordinparenthisis = false; boolean date = false; for (int i = 0; i < tokens.length; i++) { if (tokens[i].equals(.) || tokens[i].equals(;) || tokens[i].equals(,) || tokens[i].equals(?) || tokens[i].equals(!)) { sentence.append(tokens[i]); } else if(tokens[i].equals(:)){ pattern p = pattern.compile(\\d); matcher m = p.matcher(tokens[i-1]); if(m.find() == true){ date = true; } sentence.append(tokens[i]); } else if(tokens[i].equals(()){ sentence.append( ); sentence.append(tokens[i]); firstwordinparenthisis = true; } else if (tokens[i].equals())) { sentence.append(tokens[i]); firstwordinparenthisis = false; } else if(tokens[i].equals(\\)){ if(sentenceinquotation == false){ sentence.append( ); sentence.append(tokens[i]); sentenceinquotation = true; firstwordinquotationsentence = true; } else if(sentenceinquotation == true){ sentence.append(tokens[i]); sentenceinquotation = false; } } else if (tokens[i].equals(&) || tokens[i].equals(+) || tokens[i].equals(=)) { sentence.append( ); sentence.append(tokens[i]); } //words else { if(sentenceinquotation == true){ if(firstwordinquotationsentence == true){ sentence.append(tokens[i]); firstwordinquotationsentence = false; } else if(firstwordinquotationsentence == false){ if(firstwordinparenthisis == true){ sentence.append(tokens[i]); firstwordinparenthisis = false; } else if(firstwordinparenthisis == false){ sentence.append( ); sentence.append(tokens[i]); } } } else if(firstwordinparenthisis == true){ sentence.append(tokens[i]); firstwordinparenthisis = false; } else if(date == true){ sentence.append(tokens[i]); date = false; } else if(sentenceinquotation == false){ sentence.append( ); sentence.append(tokens[i]); } } } return sentence.tostring().replacefirst( , );}as i said, this works quite good, but not perfect. i suggest you try my method with copy/paste and see it on your own. do you have any ideas or a better solution for my problem?examples: for example, as i just tried some texts out i noticed that i don't yet check about tokens like [, ], or e.g. the different types of quotations, or . i also heard that it can make a different if if use ... (three points) or one unicode sign (mark it and you'll see it). so it becomes more and more complex.",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "strings"
    ]
  },
  {
    "text": "fill a column with consecutive numbers concatenated with a letter. i want to concatenate a string after a numerical value in some columns automatically so that way they are still treated as numeric values.for example:a 4010h4011h4012h4013hi want to be able to set one number and drag select it and fill in the rest of the column like you normal would with numbers. ex:type 4010 and then drag select the others and it fills the numbers 4011-4013. however i need to keep the h. the h breaks the numeric programming of the cells and it just duplicates the first cell.like this:4010h4010h4010h4010h my plans was to concatenate the h, but how would i do that but keep editablility of the numbers? is there a way to say current value+h?",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "what is the keyboard shortcut opposite to ctrl+k?. ctrl + k deletes rest of line in an unix command line. how do i delete all the text before the cursor?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "keyboard shortcuts"
    ]
  },
  {
    "text": "lga 2011 vs. am3+. i'm completing the hardware list for desktop unit, which will be used for programming (60%), data analysis & ai (15%) and gaming (15%), the rest beeing internet browsing.budget: 1200$.i want to go with a setup that could be extended in the future and last for years, and it's my primary objective. the absolute must-have: pci-e v.3.0 usb 3.0couple of sata iii interfacesnice to have:sli ddr4 supporti'm pretty convinced, that i'll go with geforce gtx 960, 1x8gb ram, 256gb adata ssd, and then, when upgrading i will:add more drives (ssds are fast, but having 2+ ssds in raid 0 is faster)add more ramif sli is present, add second 960 gtxbuy better processornow the question is: is the above logic sound (1) and about the main board and processor (2):should i go with a more cost effective, and 100% satysfying my current needs amd fx-8320 (i'ts actually top 50 best value on cpu-benchmark) sacrificing extensibility, or some cheapest, but still extremly not-cheap, lga2011-v3 processor, like i7-5820k (or maybe some xenon?) to have the shiny lga2011 platform, ddr4 support & and all the goodies of msi x99 sli plus? the disk, memory and graphic card would be same for both amd and intel, and cost for all 340$, which leaves about just enough for used i7-xxx and new msi-x99 sli plus, or amd 8 core (8320/ 8350/ 9590?) + motherboard and 3xx $ in pocket.what do you think, what would you choose? am i missing something?edit: this question is about chipset, so it may be treated as a question about motherboard. the difference between ex. amd 9590 and i7-5820k are not of interest, as long as they do not impact ex. ddr memory, sli etc.",
    "present_kp": [
      "processor",
      "desktop",
      "motherboard"
    ],
    "absent_kp": []
  },
  {
    "text": "how to link or share an email in gmail?. i often want to share an old email chain with a friend -- usually someone who was on on the chain in the first place.is there an easy way to send a link or otherwise share that email?",
    "present_kp": [
      "gmail",
      "email",
      "share"
    ],
    "absent_kp": [
      "links"
    ]
  },
  {
    "text": "evaluate the sum. i want to evaluate the sum $$\\sum_{k=1}^\\infty \\left( rac{i+1}{\\sqrt{2}} ight)^k\\cdot k^{-lpha}$$ where $i=\\sqrt{-1}$ and $lpha\\in[ rac{3}{4},1]$ with 8 digits accuracy.if i am willing to expend up to a second of cpu time per calculation, how should i proceed?suppose i want a really fast scheme for the evaluation and i am willing to expend a lot of work. how should i proceed? any leads, clues or suggestions would be greatly appreciated.",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "numerics",
      "performance",
      "fortran",
      "special functions"
    ]
  },
  {
    "text": "counting the elements of one array that are less than or equal to some other numbers. i have a method which compares two array (n2), maxes with each element in nums against <= condition then it prints out the new array with total count for each case, but it's too slow for large arrays, what's the most efficient way to solve this problem?def counts(nums, maxes) total = 0 total_array = [] maxes.each do |m| nums.each do |n| if n <= m total += 1 end end total_array.push(total) total = 0 end total_arrayendnums = [2,10,5,4,8]maxes = [3,1,7,8]print counts(nums, maxes) => # [1,0,3,4]# explanation:# 1. maxes[0] >= nums[0]# 2. maxes[1] >= 0# 3. maxes[2] >= nums[0], nums[2], nums[3]# 4. maxes[3] >= nums[0], nums[2], nums[3], nums[4]",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "algorithm",
      "ruby",
      "time limit exceeded"
    ]
  },
  {
    "text": "are ansi* escape sequences proper for coloring text in terminal(linux)?. i just switched back to linux after a few years of windows use and am wondering if ansi escape sequences are okay for coloring text. i ask because the way i did it on windows isn't capable of crossing platforms because of the use of windows.h.someone had mentioned ncurses or something but didn't explain it to me. would this be a good alternative? is there any negative aspects of ncurses or ansi esc? sorry if this question is dumb, i'm still a newbie.this was the code i used for colored text on windows.int setcolor(const int foreground, const int background){ int color = foreground + (background * 16); handle hconsole = getstdhandle(std_output_handle); setconsoletextattribute(hconsole, color); return 0;}thanks,xchubz",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "c++"
    ]
  },
  {
    "text": "what is the history of the use of foo and bar in source code examples?. why do many code examples, especially tutorials, use the names foo and bar so often? it is almost a standard.for example:void foo(char* bar) { printf(%s, bar);}",
    "present_kp": [
      "history"
    ],
    "absent_kp": [
      "terminology",
      "variables"
    ]
  },
  {
    "text": "what are exceptions and how they will be raised in pipeline. hi i am not sure what is exception here and how it will be raised in following case sub $11,$2,$4and $12,$2,$5or $13, $2,$6add $1,$2,$1slt $15,$6,$7i was reading and encountered that add $1,$2,$1will cause an exception. could you guys please help in understanding what is exception here.",
    "present_kp": [],
    "absent_kp": [
      "computer architecture",
      "cpu pipelines"
    ]
  },
  {
    "text": "check for duplicate 'id' values in a html page. i am developing a web application and i would like to check for duplicate id values in a html page. i am running the application on my local machine.there is a way to do that?p.s.: i am using firefox and firebug.",
    "present_kp": [
      "html"
    ],
    "absent_kp": [
      "css",
      "web development",
      "duplicate content"
    ]
  },
  {
    "text": "what is the name of text analysis where emotional tone of words is analyzed?. i'm interested in knowing what can be learned about people by analyzing the emotional content of the words they use in casual speech or writing. i've heard it being referred to as ... analysis.what is the name of text analysis where the person's words are analyzed based on their emotional context?for example, statements like life sucks would be interpreted as negative, while it's very helpful and i recommend it as positive.",
    "present_kp": [
      "emotion"
    ],
    "absent_kp": [
      "terminology",
      "language"
    ]
  },
  {
    "text": "does the stop keywords matter?. possible duplicate:how to write content that uses keyword terms which are google stop words i am using wordpress seo plugin by yoast. when i have a title like,how to get slim in 30 daysand the keyword to rank high is choosen to be 'get slim 30 days' it does not accept get slim in 30 days to have the keyword inside it. now i am a little confused because when i search in google, it highlights all of the matching keywords, irrespective if a stop keyword like in is placed between them. is the plugin not perfect or does it really matter if i remove the in from the title?",
    "present_kp": [
      "seo",
      "keywords"
    ],
    "absent_kp": [
      "meta keywords"
    ]
  },
  {
    "text": "how to avoid column wise access in matrix multiplication?. i know when we access elements in rows it will be much faster than if it is accessed column wise. in matrix multiplication one of the matrices must be accessed column wise. in gpus with cuda/opencl i could resolve this issue by explicitly copying both matrices row-wise into user-managed shared(cache)-memory (or local memory in opencl), and then can access data for matrix multiplication in anyway- no penalty for column access.my question is how do i avoid such column access if i am implementing matrix-multiplication on cpu, where i do not have any access to such shared memory as in gpu?",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "cpu cache",
      "performance"
    ]
  },
  {
    "text": "amavisd: unrecognized character \";. i have a problem to start the amavisd. when i try to start with /etc/init.d/amavis starti get the following error:starting amavisd: problem in amavis::dkim code: unrecognized character \"; marked by <-- here after <-- here near column 1 at /usr/lib/perl5/net/dns/rr/unknown.pm line 1.compilation failed in require at /usr/lib/perl5/net/dns/rr.pm line 15.begin failed--compilation aborted at /usr/lib/perl5/net/dns/rr.pm line 15.compilation failed in require at /usr/lib/perl5/net/dns/packet.pm line 16.begin failed--compilation aborted at /usr/lib/perl5/net/dns/packet.pm line 16.compilation failed in require at /usr/lib/perl5/net/dns/resolver/base.pm line 25.begin failed--compilation aborted at /usr/lib/perl5/net/dns/resolver/base.pm line 25.compilation failed in require at /usr/lib/perl5/net/dns/resolver/unix.pm line 9.begin failed--compilation aborted at /usr/lib/perl5/net/dns/resolver/unix.pm line 9.compilation failed in require at /usr/lib/perl5/net/dns/resolver.pm line 19.begin failed--compilation aborted at /usr/lib/perl5/net/dns/resolver.pm line 22.compilation failed in require at /usr/lib/perl5/net/dns.pm line 91.begin failed--compilation aborted at /usr/lib/perl5/net/dns.pm line 91.compilation failed in require at /usr/share/perl5/mail/dkim/dns.pm line 14.begin failed--compilation aborted at /usr/share/perl5/mail/dkim/dns.pm line 14.compilation failed in require at /usr/share/perl5/mail/dkim/publickey.pm line 18.begin failed--compilation aborted at /usr/share/perl5/mail/dkim/publickey.pm line 18.compilation failed in require at /usr/share/perl5/mail/dkim/signature.pm line 13.begin failed--compilation aborted at /usr/share/perl5/mail/dkim/signature.pm line 13.compilation failed in require at /usr/share/perl5/mail/dkim/verifier.pm line 13.begin failed--compilation aborted at /usr/share/perl5/mail/dkim/verifier.pm line 13.compilation failed in require at (eval 95) line 47.begin failed--compilation aborted at (eval 95) line 47.(failed).i think there is somthing like a bom in any file. but where can i find it? i tryed to find the error with searching for the \" but no success.thank you for your help!regardsphil",
    "present_kp": [
      "perl",
      "amavis"
    ],
    "absent_kp": []
  },
  {
    "text": "can ssh -x be considered as saas?. i am trying to understand saas (software as a service).what are the different ways of delivering it? we all know using ssh -x $host we can run software on a remote computer.can this be considered saas?",
    "present_kp": [
      "software as a service"
    ],
    "absent_kp": [
      "cloud"
    ]
  },
  {
    "text": "running screen in a shell can't find sessions but running screen during ssh login can. i am using the remoteloginautoscreen script to start a screen session when i ssh into a host.differences from linked script: i am using zsh and the remoteloginautoscreen uses bashthe problem that i'm running into is that my ssh connect was disconnected (which happens frequently and hence the auto-screen configuration) and i'm having trouble reconnecting to my existing screen session.on the host i can see that my screen process is still running and the screen sockets still exist:$ ps auxww | grep -i screen | grep alexqalexq 1818 0.0 0.0 103452 868 pts/19 s+ 18:08 0:00 grep --color=auto -i screenalexq 20270 0.0 0.0 120040 2004 ? ss jul21 0:19 screen -r$ ls -al /var/run/screen/s-alexqtotal 6drwx------ 2 alexq alexq 4096 jul 29 17:26 .drwxrwxr-x 5 root screen 4096 jul 21 21:33 ..prwx------ 1 alexq alexq 0 jul 29 17:46 20270.pts-14.myhostbut when i'm logged in (without being in a screen session) screen can't find my existing session:$ screen -lsno sockets found in /tmp/uscreens/s-alexq.based on this question i've tried setting the screendir environment variable to /var/run/screen/s-alexq but when i do that screen still can't find the sessions:$ export screendir=/var/run/screen/s-alexq$ screen -lsno sockets found in /var/run/screen/s-alexq.$ export screendir=/var/run/screen$ screen -lsyou are not the owner of /var/run/screen.what i'm really confused about is that when i replace starting screen with screen -ls in my ~/.zshrc file i get the following printed to the console:there are screens on: 20270.pts-14.myhost (attached)1 sockets in /var/run/screen/s-alexq.so for some reason screen during my ssh login can find the existing session but when i'm on the console screen can't find the session.can anyone help me to figure out why screen can only see the sessions during my ssh login and not afterwards?",
    "present_kp": [
      "ssh",
      "zsh",
      "login"
    ],
    "absent_kp": [
      "gnu screen"
    ]
  },
  {
    "text": "ansible: running from virtualenvwrapper with pip installation. i'm trying to test ansible with a pip installation of ansible in a virtualenv of python managed by virtualenvwrapper. however, i am having problems to use the ssh-agent and the ssh keys:(ansible)$ ansible all -m pingenter passphrase for key '/home/jtbpizac/.ssh/id_rsa':enter passphrase for key '/home/jtbpizac/.ssh/id_rsa':enter passphrase for key '/home/jtbpizac/.ssh/id_rsa':enter passphrase for key '/home/jtbpizac/.ssh/id_rsa':enter passphrase for key '/home/jtbpizac/.ssh/id_rsa':however, i can use the ssh-agent from this shell to connect remotely through ssh without problems:(ansible)$ ssh <email> the ssh-agent seems to be available from the shell i launch ansible:(ansible)$ ssh-add -l2048 sha256:.. (rsa)1024 sha256:.. (dsa)2048 sha256:.. (rsa)(ansible)$ ssh-agent -sssh_auth_sock=/tmp/ssh-ye20hcbylzcj/agent.14461; export ssh_auth_sock;ssh_agent_pid=14462; export ssh_agent_pid;echo agent pid 14462;any idea? i am using ubuntu 15.10. thanks!",
    "present_kp": [
      "ubuntu",
      "ssh",
      "ansible"
    ],
    "absent_kp": [
      "openssh",
      "ssh agent"
    ]
  },
  {
    "text": "ways to organize interface and implementation in c++. i've seen that there are several different paradigms in c++ concerning what goes into the header file and what to the cpp file. afaik, most people, especially those from a c background, do:foo.h class foo { private: int mem; int bar(); public: foo(); foo(const foo&); foo& operator=(foo); ~foo(); }foo.cpp #include foo.h foo::bar() { return mem; } foo::foo() { mem = 42; } foo::foo(const foo& f) { mem = f.mem; } foo::operator=(foo f) { mem = f.mem; } foo::~foo() {} int main(int argc, char *argv[]) { foo f; }however, my lecturers usually teach c++ to beginners like this:foo.h class foo { private: int mem; int bar() { return mem; } public: foo() { mem = 42; } foo(const foo& f) { mem = f.mem; } foo& operator=(foo f) { mem = f.mem; } ~foo() {} }foo.cpp #include foo.h int main(int argc, char* argv[]) { foo f; } // other global helper functions, dll exports, and whatnotoriginally coming from java, i have also always stuck to this second way for several reasons, such as that i only have to change something in one place if the interface or method names change, that i like the different indentation of things in classes when i look at their implementation, and that i find names more readable as foo compared to foo::foo.i want to collect pro's and con's for either way. maybe there are even still other ways?one disadvantage of my way is of course the need for occasional forward declarations.",
    "present_kp": [
      "c++"
    ],
    "absent_kp": [
      "implementations",
      "headers"
    ]
  },
  {
    "text": "not able to create a custom tiny core linux iso image. i'm trying to create a custom version of tiny core linux. i extracted the iso image, added the required tcz files, and made a new iso, but vmware virtual machine was not able to boot from it. so i just extracted the iso, recreated it without any changes, and it still didn't get detected by the vm. what am i doing wrong?",
    "present_kp": [
      "linux",
      "iso"
    ],
    "absent_kp": []
  },
  {
    "text": "review website done after one week of learning html and css. i've just started learning css/html a week ago and i made a quick site today. it looks pretty good, but i think that i reused/wrote some really messy css. this is because i haven't used the float property in css too well, so i keep using position:relative and top to offset the float.html:<?xml version=1.0 encoding=utf-8?><!doctype html public -//w3c//dtd xhtml 1.1//en <url> xmlns=<url> xml:lang=en><head> <title>kevin li</title> <link rel=stylesheet type=text/css href=css/style.css /></head><body> <div id=wrapper> <div id=header> <h1>kevin li</h1> </div> <div id=links> <ul> <li><a href=#>home</a></li> <li><a href=#>biography</a></li> <li><a href=#>portfolio</a></li> <li><a href=#>blog</a></li> <li><a href=#>images</a></li> <li><a href=#>contact me</a></li> </ul> </div> <div class=sidebar_left> lorem ipsum dolor sit amet...<br /> </div> <div id=post> <b>introduction</b><br /> <i>thursday, january 27, 2011</i> </div> <br /> <div id=content> <img id=tree src=images/c2_i6.png /> <p> lorem ipsum dolor sit amet...<br /> <br /> <img id=blackwhite src=images/c3_i7.png /> ut venenatis diam nunc...<br /> <br /> </p> </div> <div id=footer> <b>copyright 2010 kevin li</b> </div> </div></body></html>css:/* general elements* /body { background: #53777a; font-family: garamond, baskerville, baskerville old face, hoefler text, times new roman, serif; }h1 { font-size: 28pt; }h2 {}p {}a:link { color: black; text-decoration: none;}a:visited { color: purple; text-decoration: none;}a:hover { color: green; text-decoration: underline;}a:active { color:yellow; text-decoration: none;}/* curvy shapes */ #wrapper, #footer { -moz-border-radius-bottomright: 50px; -moz-border-radius-topleft: 50px; -moz-border-radius-topright: 50px; -moz-border-radius-bottomleft: 50px; border-bottom-right-radius: 50px; border-top-left-radius: 50px; border-top-right-radius: 50px; border-bottom-left-radius: 50px;}#links { -moz-border-radius-bottomright: 50px; -moz-border-radius-bottomleft: 50px; border-bottom-right-radius: 50px; border-bottom-left-radius: 50px;}#header { -moz-border-radius-topleft: 50px; -moz-border-radius-topright: 50px; border-top-left-radius: 50px; border-top-right-radius: 50px; }/* structure */#wrapper { width: 900px; margin: 0 auto; margin-top: 30px; overflow: auto; background: #e0e4cc; padding: 20px; -moz-border-radius-bottomright: 50px; -moz-border-radius-topleft: 50px; -moz-border-radius-topright: 50px; -moz-border-radius-bottomleft: 50px; border-bottom-right-radius: 50px; border-top-left-radius: 50px; border-top-right-radius: 50px; border-bottom-left-radius: 50px; }#header { text-align: center; background: #ecd078; padding: 4px;}#links { width: 900px; background-color: #a7dbd8; position: relative; top: -20px; text-align: center;}#links ul { list-style-type: none; padding: 5px;}#links li{ display: inline; font-size: 14pt; padding: 20px;}.sidebar_left { float: left; width: 180px; margin-left: 10px; position: relative; top: -10px; text-align: justify; line-height: 150%;}#post { float: right; width: 680px; margin-left: 0px; margin-right: 10px; position: relative; top: -25px; text-align: justify; line-height: 150%; }#post b { font-size: 18pt; text-decoration: underline;}#content { float: right; width: 680px; margin-left: 0px; margin-right: 10px; position: relative; top: -25px; text-align: justify; text-indent: 25px; line-height: 150%;}#social { float: right;}#footer { width: 890px; background: #a7dbd8; float: left; padding: 5px; text-align: right;}#footer b { margin-left: 10px;}/* end structure *//*images*/.navimg { width: 2px; height: 20px;}#tree { width: 175px; height: 200px; float: right; margin-left: 20px; margin-top: 24px;}#blackwhite { width: 200px; height: 125px; float: left; margin-right: 20px; margin-top: 10px; }#quickshot { width: 125px; height: 100px; display: block; margin-left: auto; margin-right: auto; }by the way, i know it doesn't validate. i am working on that now.",
    "present_kp": [
      "html",
      "css"
    ],
    "absent_kp": []
  },
  {
    "text": "derive logitboost using the logistic loss function. an additive model constructed using the exponential loss function l(y, f (x))=exp(yf (x))gives adaboost. how can we derive the corresponding additive model (known as logitboost) using the logistic loss function l(y, f (x)) = log(1 + exp(yf (x))).what steps i should take to do the above proof?",
    "present_kp": [],
    "absent_kp": [
      "machine learning",
      "convex optimization"
    ]
  },
  {
    "text": "does mean removal increase accuracy of numerical differentiation?. i wish to compute the derivative of a vector through numerical differentiation. let's say, we use a standard 2nd order central difference scheme, to arrive at a differentiation matrix, and apply it on a numerical vector, $u$.$$u' = d u$$at the top and bottom few elements of the resulting derivative vector, i get spurious numerical round-off even by using complicated stencil. now, if i remove the mean from every element of my vector, and then pre-multiply it with my differentiation matrix $d$, $$ ilde u' = d (u - mean(u))$$it seems to get better results (i.e. better accuracy), although not fully accurate.did i happen to get lucky by chance for this specific vector i am working with, or is there a fundamental mathematical reason why the same differentiation matrix performed remarkably on the mean-removed input vector ?",
    "present_kp": [],
    "absent_kp": [
      "linear algebra",
      "finite difference",
      "numerical analysis",
      "floating point",
      "numerical limitations"
    ]
  },
  {
    "text": "at the root level (/) directory, why is that .. refers to itself?. possible duplicate:why does '/' have an '..' entry? i understand that in the filesystem hierarchy starting with / as top-level directory, under which all the other sub directories or files are stored. in each subdirectory, we see two special directories referred as . and .. which are special because they are hardlinks pointing to the current directory inode and the parent directory inode respectively. they are common for every sub directory in the filesystem. however, when i look at /, those two special directories behaviour changes. they refer to the / again. for example:[root@centos /]# pwd/[root@centos /]# ls -ldi . ..2 drwxr-xr-x 26 root root 4096 dec 3 16:53 .2 drwxr-xr-x 26 root root 4096 dec 3 16:53 ..[root@centos /]# cd root[root@centos ~]# ls -ldi . ..195265 drwxr-x--- 10 root root 4096 dec 3 20:33 . 2 drwxr-xr-x 26 root root 4096 dec 3 16:53 ..[root@centos ~]# i want to understand what part of the filesystem controls this? but how is this done in detail. can someone please explain this behaviour? (let me guess, this is part of the kernel's filesystem management routines). i have my own theory about this but would like to listen more from the experts here.cheers.",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "filesystems"
    ]
  },
  {
    "text": "how do i do a command line only boot of centos 7?. can someone please explain how to trigger a command line only boot of centos 7 from a usb boot stick? i want to boot the terminal only and then use the normal centos 7 terminal to swap out the graphics card drivers using yum. that way i will be able to subsequently use the same boot stick to boot the full version of centos 7 incuding the gnome gui.currently, when i try to boot using the usb stick, the gnome gui cannot be loaded because an attempt to use the graphics card throws a driver error that i want to address by replacing the drivers as above. here are the steps that i have taken so far, which are failing: 1.) insert usb boot stick2.) turn on power for pc3.) press esc every second until a list of options appears4.) press f9: boot device options5.) three options appear: a.) os boot manager (uefi) windows boot manager b.) usb hard drive (uefi) pny usb 2.0 fd c.) boot from efi file6.) i selected usb hard drive (uefi) pny usb 2.0 fd7.) the computer tried to boot centos 7 but crashed and gives the dracut emergency shell instead of the normal terminal. the dracut shell does not have all the same commands as the normal terminal. pressing esc, f2, f12, or del repeatedly did not stop this on a repeated tries either.what do i need to do differently?",
    "present_kp": [
      "centos",
      "boot"
    ],
    "absent_kp": [
      "dual boot",
      "live usb",
      "bootable"
    ]
  },
  {
    "text": "small factory class. class controllerfactory { public function createcontroller($controller) { if (file_exists($path = __dir__ . 'app/controllers/' . $controller . '.php')) { require_once $path; return true; } }}it seems a bit overkill to have a class to do this. to intiate a class to build another one, am i correct? anyother way i can do these/ or to improve this one. i guess make it static would be an alternative?",
    "present_kp": [
      "php"
    ],
    "absent_kp": []
  },
  {
    "text": "cannot execute files on another partition. on my system i have three partitions: one is shared between w7 and linux mint (ntfs), and the other two are os-specific.in my home directory i have created a symbolic link to another directory on the shared partition.i have a simple .cpp file there which i compiled via g++ name.cpp. usually, this would also make the file executable, but this time i had to manually chmod 755 it.strangely, this didn't work either, the console said it did not have the required permission. so i executed sudo chmod 755 a.out. this asked me for my password, and reported no errors. however, it had no effect. a.out was not executable. i've noticed some other strange behaviors in symlink directories too.whats going on and how can i fix it?edit: my mount options:# /etc/fstab: static file system information.## use 'blkid' to print the universally unique identifier for a# device; this may be used with uuid= as a more robust way to name devices# that works even if disks are added and removed. see fstab(5).## <file system> <mount point> <type> <options> <dump> <pass>proc /proc proc nodev,noexec,nosuid 0 0# / was on /dev/sda6 during installationuuid=7c50dab1-730b-4d3c-a944-51da19c8e2c6 / ext4 errors=remount-ro 0 1# swap was on /dev/sda7 during installationuuid=12e39b76-7f19-4c6d-a724-81ea29211db1 none swap sw 0 0/dev/sda5 /media/yannbane/shared ntfs defaults,fmask=117,dmask=007,gid=46 0 0",
    "present_kp": [
      "linux",
      "ntfs"
    ],
    "absent_kp": [
      "filesystems",
      "permissions"
    ]
  },
  {
    "text": "gilbreath's conjecture in python. i've written some code for testing gilbreath's conjecture in python (2.x). the conjecture was shown (in the 90s) to be true up to n=1012. my code uses the primesieve module to quickly generate primes and, by ignoring blocks of 0s and 2s, only calculates values in the array when necessary. however, it's quite slow; it makes heavy use of dictionary lookup, addition and deletion, and i expect would benefit from modification of this aspect.def gilbreath(nmax): import primesieve def fill(d, j, k): if (j, k-1) not in d: fill(d, j, k-1) d[(j, k)] = abs(d[(j+1, k-1)]-d[(j, k-1)]) # remove unneeded entries if (j-1, k) in d: del d[(j, k-1)] if (j+1, k) in d: del d[(j+1, k-1)] primes = primesieve.iterator() d = {} depthleft, depth, maxdepth, ndepth = -1, -1, -1, -1 for n in xrange(1, nmax+1): d[(n, 0)] = int(primes.next_prime()) j, k = n, 0 while (d[(j, k)] > 2) or (k <= depthleft): if d[(j, k)] > 2: depth = k j -= 1 k += 1 fill(d, j, k) if (j == 1) and d[(j, k)] > 1: print conjecture false at n = %d %n depthleft = depth if depth > maxdepth: maxdepth, ndepth = depth, n print max depth %d at n = %d of %d %(maxdepth, ndepth, nmax)",
    "present_kp": [
      "python",
      "primes"
    ],
    "absent_kp": [
      "performance",
      "python 2.7"
    ]
  },
  {
    "text": "wouldn't an ai that specializes in making other ai be an agi if they can cooperate?. if said ai can assess scenarios and decide what ai is best suited and construct new ai for new tasks. in sufficient time would the ai not have developed a suite of ais powerful/specialized for their tasks, but versatile as a whole, much like our own brains architecture? whats the constraint ?",
    "present_kp": [
      "agi"
    ],
    "absent_kp": [
      "neural networks",
      "philosophy"
    ]
  },
  {
    "text": "what return/exit values can i use in bash functions/scripts?. i want to know what return values we can use that will not be mistaken by for ex. sigint?ex.:$sleep 10$#hit ctrl+c$echo $?130so i know i must not use anything like return 130 or exit 130so this would be misleading:$function func(){ return 130; };func;echo $?130",
    "present_kp": [
      "bash",
      "function",
      "exit"
    ],
    "absent_kp": [
      "shell",
      "return status"
    ]
  },
  {
    "text": "is there any tool in linux which will help me specify baud rate which i need. i have tried gtkterm and a couple of other tools. none of them seem to support a baud rate which is higher than 115200. could someone suggest some tools which will allow higher baud rates?",
    "present_kp": [],
    "absent_kp": [
      "serial port",
      "serial console"
    ]
  },
  {
    "text": "file quantity limit in a directory on a linux file server and why?. what is a good limit to use on the quantity of files in a directory, and why?edit:why shouldn't someone create a system that puts hundreds of thousands of files in the same directory?why i ask:someone set up a system that dumps files in a folder with a human readable date-time.my task it to create a system that gets the files for a select time period.normally this wouldn't be a problem but the folder has 500,000 files in it and is growing and my system is expected to get them in real time.parsing 500,000 files takes too long, so i think it is the responsibility of the person who built the system that inputs the files on the ftp server to create a directory structure such as having a sub folder for each day.",
    "present_kp": [
      "parsing"
    ],
    "absent_kp": [
      "file structure",
      "file systems"
    ]
  },
  {
    "text": "does ssh have an option to query the signature of a server without logging in first?. for reasons of security does ssh have an option to query the signature of a server without logging in first, ie execute a command like:ssh --getkey host.example.com",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": []
  },
  {
    "text": "failure to start custom service using systemd. good morning,we are trying to start a custom service on a raspberry pizero wireless. the procedure we are using works on a pi3 under ubuntu 14.04. the pizero runs 2017-04-10-raspbian-jessie. i'll use the name custom_service below.i tried different things without success. querying the status of the service reports:sudo systemctl status custom_service.service custom_service.service - custom service loaded: loaded (/etc/systemd/system/custom_service.service; enabled) active: activating (auto-restart) (result: exit-code) since wed 2017-04-26 14:44:40 utc; 32s ago process: 1516 execstart=/usr/local/etc/startcustomservice (code=exited, status=203/exec) main pid: 1516 (code=exited, status=203/exec)apr 26 14:44:40 raspberrypi systemd[1]: custom_service.service: main process exited, code=exited, status=203/execapr 26 14:44:40 raspberrypi systemd[1]: unit custom_service.service entered failed state.using the command:sudo ls -l /etc/systemd/system/multi-user.target.wants/*.serviceoutput:...lrwxrwxrwx 1 root root 40 apr 10 09:24 /etc/systemd/system/multi-user.target.wants/avahi-daemon.service -> /lib/systemd/system/avahi-daemon.servicelrwxrwxrwx 1 root root 38 apr 26 13:53 /etc/systemd/system/multi-user.target.wants/custom_service.service -> /etc/systemd/system/custom_service.service...the service unit file is defined as:more /etc/systemd/system/multi-user.target.wants/custom_service.service[unit]description=custom serviceafter=network-online.target[service]type=simplerestartsec=60restart=alwaysexecstart=/usr/local/etc/startcustomservice[install]wantedby=multi-user.targetwhere /usr/local/etc/startcustomservice is defined asmore /usr/local/etc/startcustomservice#!/bin/sh/usr/local/sbin/customserviceas i said, the service is launched and running correctly under ubuntu 14.04. also note that the file /usr/local/etc/startcustomservice can be launched manually on pizero.any suggestions?regards,daniel",
    "present_kp": [
      "systemd",
      "raspberry pi",
      "raspbian"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a way to load previous message on web version of wechat?. i am using wechat to communicate with my customer from mainland china. wechat got a web version for better input and reading on pc. it is very much like the web version of whatsapp, except that it does not load previous messages.the problem is that i usually read the message on phone first, and only open the web version if i need to reply using pc. (e.g. long reply or reply that require screen shot of pc screen) as the question is already read on phone, it is omitted on web version. it feels odd that the question is not at the top of the screen.is there a way to make wechat load previous message? only message that are on stored on phone would be enough.",
    "present_kp": [
      "wechat"
    ],
    "absent_kp": []
  },
  {
    "text": "change string with sed. i would like to change the following stringallow ^120\\.123\\.178\\.254$into allow ^124\\.130\\.23\\.235$with sed.i tried the following but it does not work.sed -e 's/allow ^120\\.123\\.178\\.254$/allow ^124\\.130\\.23\\.235$/g' /etc/xxx/file.confmay you can help me?",
    "present_kp": [
      "sed"
    ],
    "absent_kp": []
  },
  {
    "text": "filtering spam / scraped / auto generated sites from google alerts. i use google alerts to monitor our company name online, my alerts search query is: company name or company.com -site:pinterest.comrecently we have seen a ton of spam sites crawling, article spinning other sites and then publishing them on pages covered in advertising. the pages are practically illegible to humans and just a random collection of industry terms, display ads (usually served by google.. the irony) and keywords which sometimes include our company name, as the site they scraped must have had an article about us. the only thing i've thought of so far is to block them by individual domain, in the same way i have blocked pinterest in the query above, failing that i was thinking perhaps by ip range. but these both are manual fixes and would have to be constantly updated. is there a stronger way i can block these sites from showing up in my google alerts feed. i've found google alerts to be a really great tool in the past, but with 99% of the alerts being spam its a pain to read through the alert emails.",
    "present_kp": [
      "google alerts"
    ],
    "absent_kp": [
      "spam prevention"
    ]
  },
  {
    "text": "what does least fix point and greatest fix point mean in safety games. in safety games there are these mathematical notation about greatest fix points and least fix points but i don't get it. how would we describe them plain english without mathematical symbols.",
    "present_kp": [],
    "absent_kp": [
      "terminology",
      "formal methods",
      "model checking",
      "mu calculus"
    ]
  },
  {
    "text": "lvm raid 1 for root. i have lvm raid 1 (not mdadm raid 1, but exactly lvm2 raid 1) for my root partition. i would like to make my system boot without either of the hdds where the underlying pvs of the root lvm partition reside.the kernel launch line in grub.cfg (automatically generated by grub2) looks like:linux /kernel-genkernel-x86-3.11.7-hardened-r1-3 root=/dev/mapper/vg-root ro dolvmit looks perfectly with both disks enabled and the system is hdd fault-tolerant runtime, i.e. it works properly if either of hdds are down during runtime. however, if i try to boot without one of hdds, i am getting refusing activation of partial lv root. use --partial to override.during boot and kernel panic. from one side it seems reasonable since it's not a normal behavior for lvm to launch when one of pv is absent. however, it's absolutely necessary in order to boot server. the potential workaround i can think of is adding some additional option to kernel launch line.do you know how to make the lvm raid 1 work for root partition when on of hdds does not work?",
    "present_kp": [
      "boot",
      "lvm"
    ],
    "absent_kp": [
      "linux kernel",
      "raid1",
      "root filesystem"
    ]
  },
  {
    "text": "video rental store application design. i need some help in working video rental store application design optimization. the application describes the following tasks:inventory stores videos. inventory can add/delete/change and receive all videos. inventory has 3 types of films: old, new, regular.videos have a title, type (described above) and availability which will be changed to 'not available'/'available' if this video is rented by someone.customer can rent only available videos(not rented by someone) with additional option to rent film for bonus points which gathers every time when a customer rents a video (1 point for rent)before the customer rents a video he/she set renting days. the price for rent calculated automatically based on rent days, video type. after the price is calculated for this rent transaction than customer is presented terms where he/she has a choice to accept or reject them. if a customer accepts terms than rent transaction is executed successfully.data is not persisted anywhere, data exists in runtime. inventory and rentalstore class generates some fake records for presentation.could you please review my app and offer some tips or optimization tricks?in general, i'm not sure in rentalstore class which implements connections to the inventory and rentaltransactions classes. i don't know how to implement elegant class which will work with rental transactions and will know what items have inventory. i read some principles of design patterns how to organize application that it will be flexible as much as possible but it seems i need more experience in design area. that is why i contact with you. someone suggested me that it is possible to do it better than my way.rentalstore class:public interface rentaldao {void rentitem(person person, item item, int days, boolean temsacceptance);list<rentaltransaction> getallrentals();list<rentaltransaction> getallrentalsforcustomer(person person);}public class rentalstore implements rentaldao { private inventory inventory; private list<rentaltransaction> rentaltransactions; public rentalstore() { this.inventory = new inventory(); this.rentaltransactions = new linkedlist<rentaltransaction>(); generatefakerentaltransactions(); } public inventory getinventory() { return inventory; } private void generatefakerentaltransactions() { rentitem(new customer(kauri), inventory.getallavailableitems().get(new random().nextint(inventory.getallavailableitems().size() - 1) + 1), new random().nextint(30) + 1, true); rentitem(new customer(lauri), inventory.getallavailableitems().get(new random().nextint(inventory.getallavailableitems().size() - 1) + 1), new random().nextint(30) + 1, true); } @override public void rentitem(person person, item item, int days, boolean temsacceptance) { if (item.isavailable()) { rentaltransaction newrentaltransaction = new rentaltransaction(person, item, days, temsacceptance); if (!rentaltransactions.contains(newrentaltransaction)) { rentaltransactions.add(newrentaltransaction); } } } @override public list<rentaltransaction> getallrentals() { return rentaltransactions; } @override public list<rentaltransaction> getallrentalsforcustomer(person person) { list<rentaltransaction> rentaltransactionsforcustomer = new linkedlist<rentaltransaction>(); for (rentaltransaction rentaltransaction : rentaltransactions) { if (rentaltransaction.getperson().equals(person)) { rentaltransactionsforcustomer.add(rentaltransaction); } } return rentaltransactionsforcustomer; }}in rentalstore class i don't like also that rentitem() method has hardcoded person argument. it doesn't take me, for instance, define this object is really customer or, may be, employee. also it doesn't take me to invoke person.chargebonus() due to it concern only to customer objects. i can do so (customer) person.chargebonus() but it can cause exception in some cases and looks somehow bad, how to optimize it too?rentaltransaction class:public class rentaltransaction {private static final double premium_fee = 40;private static final double regular_fee = 30;private person person;private item item;private int days;private double price;private boolean termsacceptance;public rentaltransaction(person person, item item, int days, boolean termsacceptance) { this.person = person; this.item = item; this.days = days; this.price = calculate(); this.termsacceptance = termsacceptance;}public person getperson() { return person;}public item getitem() { return item;}public int getdays() { return days;}public void setdays(int days) { this.days = days; this.price = calculate();}public double getprice() { return price;}private double calculate() { switch (item.gettype()) { case new_releases: this.price = premium_fee * days; break; case regular: if (days > 3) { this.price = regular_fee + regular_fee * (days - 3); } else { this.price = regular_fee * days; } break; case old: if (days > 5) { this.price = regular_fee + regular_fee * (days - 5); } else { this.price = regular_fee * days; } break; } return this.price;}public boolean istermsaccepted() { return termsacceptance;}public void settermsacceptance(boolean termsacceptance) { this.termsacceptance = termsacceptance;}}inventory class:public class inventory implements inventorydao {private static string[] itemnames = {shrek, spider man iii, game of thrones, mortal combat};private list<item> items;public inventory() { items = new linkedlist<item>(); for (string itemname : itemnames) { items.add(new item(itemname, true, type.getrandom())); }}@overridepublic void additem(item item) { if (!items.contains(item)) items.add(item);}@overridepublic void removeitem(item item) { if (items.contains(item)) items.remove(item);}@overridepublic void changeitemtype(string title, type type) { for (item item : items) { if (item.gettitle().equals(title) && !item.gettype().equals(type)) { item.settype(type); } }}@overridepublic list<item> getallitems() { return items;}@overridepublic list<item> getallavailableitems() { list<item> availableitems = new linkedlist<item>(); for (item item : items) { if (item.isavailable()) availableitems.add(item); } return availableitems;}}public interface inventorydao {void additem(item item);void removeitem(item item);void changeitemtype(string title, type type);list<item> getallitems();list<item> getallavailableitems();}another thing is type class. is it possible to do base enum type class for item and redefine it to concrete enum type in video class, as example?type class:public enum type { new_releases(new releases), regular(regular), old(old); private final string type; private type(string type) { this.type = type; } public static type getrandom() { return values()[(int) (math.random() * values().length)]; } @override public string tostring() { return type; }}where i use type(is it possible to make base enum type class for redefining in video class?):public class item { private string title; private boolean avability; private type type; public item(string title, boolean avability, type type) { this.title = title; this.avability = avability; this.type = type; } public string gettitle() { return title; } public void settitle(string title) { this.title = title; } public boolean isavailable() { return avability; } public void setavability(boolean avability) { this.avability = avability; } public type gettype() { return type; } public void settype(type type) { this.type = type; }}any suggestions?",
    "present_kp": [],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "markov chains: how much steps to conclude a transition matrix. i have just learned markov chains which i am using to model a real world problem. the model comprises 3 states [a b c]. for now i am collection data and calculating transitional probabilities:-t[a][b] = #transitions from a to b / #total transitions to ahowever i am stuck at determining the correct transition matrix. as i am getting more data, the matrix is changing drastically. so when do i finalize transition matrix? does that mean that my data is too random and cannot be modelled or i am doing some mistake here?",
    "present_kp": [],
    "absent_kp": [
      "machine learning",
      "markov process"
    ]
  },
  {
    "text": "nfsv3 works but not nfsv4 on armbian. i am trying to mount a nfs share from a nas, it work flawlessly on my pc (arch) but on my odroid (armbian), only nfsv3 works, not nfsv4.$ sudo mount.nfs -vvv 10.10.0.131:/volume1/owncloud data rwmount.nfs: timeout set for wed jun 1 12:01:19 2016mount.nfs: trying text-based options 'vers=4,addr=10.10.0.131,clientaddr=10.10.0.130'mount.nfs: mount(2): no such file or directorymount.nfs: trying text-based options 'addr=10.10.0.131'mount.nfs: prog 100003, trying vers=3, prot=6mount.nfs: trying 10.10.0.131 prog 100003 vers 3 prot tcp port 2049mount.nfs: prog 100005, trying vers=3, prot=17mount.nfs: trying 10.10.0.131 prog 100005 vers 3 prot udp port 42889maybe a package is missing ? i have installed nfs-common, i think that's all i need.the other thing is that the owner of the mounted directory is set to 999, i don't know what user it is. it weird because on my pc it's just root or me if i add the 'user' option, and there is no user with uid 999 on my nas ...",
    "present_kp": [
      "nfs"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "how do i find an upper bound on this recurrence. $f(n)=f(n-\\sqrt{n})$i believe $f(n)\\in o(\\sqrt{n})$however i cannot seem to prove it, my intuition comes from the fact that we can remove $\\sqrt{n}$ exactly $\\sqrt{n}$ times, but if $n$ shrinks then does anything change?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "asymptotics",
      "recurrence relation"
    ]
  },
  {
    "text": "run kde settings strating awesome wm. i'm running an up to date manjaro kde and awesome wm on side.i did some mouse/touchpad configuration via kde > system settings.wich i'm able to activate in awesome wm with this sequence :mod4 + pselect settings > kde system settings > input devices > touchpadclick to [apply]how to do the same at awesomewm's bootstrap in a script ?",
    "present_kp": [
      "kde",
      "awesome"
    ],
    "absent_kp": [
      "arch linux"
    ]
  },
  {
    "text": "pdsh command failed with connection refused. i'm able to remote login the target host with ssh. but when i execute a command through pdsh, it fails with connection refused. both systems are sles11.i found a description of the error on this page as follows.message:pdsh@local_hostname: target_hostname:connect: connection refused cause:the target system is unreachable, or the r services may be disabled for this system. to correct:check the r services and whether the target system is up and connected.in my case, the target system is up so the cause should be the disabled r services.so what are r services and how could i enable it?",
    "present_kp": [
      "ssh",
      "sles"
    ],
    "absent_kp": []
  },
  {
    "text": "what is darwin's 'private' directory for?. darwin has a private directory that i don't see in the unix documentation i've found. is that a mac-specific directory? what is it for? is it preserved between system upgrades?",
    "present_kp": [
      "darwin"
    ],
    "absent_kp": [
      "directory structure"
    ]
  },
  {
    "text": "what's the most absurd myth about programming issues?. to put it another way... what is the most commonly held and frustrating misunderstanding about programming, you have encountered?which widespread and longstanding myths/misconceptions do you find hard for programmers to dispel/correct.please, explain why this is a myth.",
    "present_kp": [],
    "absent_kp": [
      "experience",
      "self improvement",
      "code quality",
      "mistakes"
    ]
  },
  {
    "text": "underlying model for prediction using different prediction variables. i have time-series energy consumption data for a duration of one-month. the frequency of data is half-hourly. the features of dataset aretemperature - temperature value at particular time instanthumidity - humidity value at particular time instanttimeofday - this corresponds to 48 half-hourly durations of a day.weekday - day of the week (value between 1 - 7)prevday1 - energy consumption at the same time-instant on previous dayprevday2 - energy consumption at the same time-instant on a day before the previous dayprev_instant1 - energy consumption at the previous time instant. for example, for 7 pm, previous_instant1 is 6:30 pmprev_2_hour - average energy consumption during the last two hoursusing these variable i need to forecast power (energy) consumption. the pairs plot of these variables is i started with a linear model, but it seems that the model is performing very badly. i want to know is there any automatic technique, which can check all possible combinations of predictor variables and output the best fitted model. i can check all models (linear combinations, non-linear, splines etc) manually, but it will take huge time.updatei am forecasting in real-time at a half-hourly rate (very short term forecasting). also, i use separate models corresponding to different half-hours of the day. for example, in a day we have 48 half-hours so corresponding to each half-hour i have a separate model. for the whole process, i use following approach:create a training data set with above mentioned features. this training data set is of one month duration (30 days)in the next step, i forecast for the next day (testing day) using specific models for each of 48 half-hour durationsat the end of the day, i retrain all my 48 models with recently updated data (recent historical 30 days)steps 2 and 3 continue till stopping condition. stopping condition used is the no. of testing days. a screenshot of my training data is as:head(training_data)tail(training_data)",
    "present_kp": [
      "r"
    ],
    "absent_kp": [
      "predictive modeling",
      "regression",
      "time series",
      "feature selection"
    ]
  },
  {
    "text": "time conversion in unix/linux. i need to convert a unix timestamp (number of seconds since 2000) into a standard human-readable format. i found that the command date -d @3926<phone> works like a charm but the default start date is 1970.",
    "present_kp": [
      "time",
      "conversion"
    ],
    "absent_kp": []
  },
  {
    "text": "i've just purchased a domain and getting cold called. i've just bought a domain and i've just been cold called 7 times today. i would like to know what companies are selling new registrations as leads? i am aware of privatising my information but i'm not paying 4 per annum for the right to be anonymous.",
    "present_kp": [],
    "absent_kp": [
      "domains"
    ]
  },
  {
    "text": "grep + operator. according to the grep manual: * the preceding item will be matched zero or more times. + the preceding item will be matched one or more times.let's test itecho 'agb' | grep 'a.*b' # returns agbecho 'agb' | grep 'a.+b' # returns nothingwhy + did not match three gs? according to my knowledge 3 is more than 1.",
    "present_kp": [
      "grep"
    ],
    "absent_kp": [
      "regular expression"
    ]
  },
  {
    "text": "what are the best seo practices when changing domain names?. i'm using the yoast seo plugin on a wordpress site on a new, more memorable domain to replace an old static html site with no seo. i've followed google's documentation for moving a site, set up 301 redirects from the old domain to the new one, and filed a change of address in the google search console. however, after a few days, the old site still shows in search results, and is ranked higher than the new one if you google our company name. and, if i try to set the preferred domain in the google search console site settings for the new site, i see this in place of the options to prefer www/non-www/http/https:not all options are available because of a change of address request related to this site.i've read of some cases where this condition has lasted for least least a month.is there anything more i can do to fix this? have i done something wrong, or do i just need to wait, and for how long?",
    "present_kp": [
      "seo",
      "google search console",
      "google search"
    ],
    "absent_kp": [
      "domains"
    ]
  },
  {
    "text": "pagination algorithm based on scores. i need to divide scoreresult into pages (which is already ordered by score column from highest to lowest), and each page cannot contain too many records (e.g. 12 is a limitation in my example), and each page cannot contain duplicate id1, and each page needs to be ordered by score from highest to lowest.here is my working code; i am seeking advice, especially of smarter and more efficient solutions.scoreresult = [#id1,id2,score,1,28,300.1,4,5,209.1,20,7,208.1,23,8,207.1,16,10,206.1,1,16,205.1,1,31,204.6,6,29,204.1,7,20,203.1,8,21,202.1,2,18,201.1,2,30,200.1,15,27,109.1,10,13,108.1,11,26,107.1,12,9,106.1,13,1,105.1,22,17,104.1,1,2,103.1,28,24,102.1,18,14,11.1,6,25,10.1,19,15,9.1,3,19,8.1,3,11,7.1,27,12,6.1,1,3,5.1,25,4,4.1,5,6,3.1,29,22,2.1,30,23,1.1]pagelimit = 12def pageresult(): #store final resutls pages = {} # store dictionary to see if page exists # key = host_id+#+page_id, value = item pagedict = {} # key: page id, value: # of items pagecount = {} for item in scoreresult: page= 0 host_id=item.split(',')[0] while pagedict.has_key(str(host_id)+'#'+str(page)) or (pagecount.has_key(page) and pagecount[page] >= pagelimit): #print page page += 1 pagedict[str(host_id)+'#'+str(page)] = true if pages.has_key(page): pages[page].append(item) else: pages[page]=[] pages[page].append(item) if pagecount.has_key(page): pagecount[page] += 1 else: pagecount[page] = 1 for k,v in pages.items(): print k print vif __name__==__main__: pageresult()",
    "present_kp": [
      "algorithm",
      "pagination"
    ],
    "absent_kp": [
      "python",
      "sorting"
    ]
  },
  {
    "text": "kvm - which web based management to use?. i would like to became an expert of managing kvm on debian squeeze.i still use virt-manager. yes, it is easy and quiet safe and quick for me.i tried a lot of web based management ui and non of them was good enough like virt-manager.you know, i'm one of those guys, who used to have vmware before, where 90% of managing is clicking. my questions :1) are there any cli interactive utility like mc (midnight commander) or something how to control kvm ? (on/off vms, increasing memmory, reseting vms, adding virtual hardware, adding new disks, and so on...)2) could you recommend me some web based management ui for kvm on debian squeeze? did you see vmware server 2? there is web management. i know it was slow, but it is fine, when you are somewhere without terminal. (for example on android with web browser)i tried a lots of them, but nothing i tried was working.3) what tutorials could you recommend me to improve myself in commands to control virsh, kvm and so on? google is full of low quality tutorials with mistakes and misunderstandings. i need something for debian.4) could you recommend me some tutorials how to improve performance for kvm? google is full of a lot of tutorials, but i need some recommendations from real experts, who knows, how to improve it. 5) how to improve security of kvm? can solve this problem some web based ui? (for example accounting, user management ?)i know there is google, wiki, there is a long list of ui for kvm, but i need opinions, experiences from experts or users who use kvm. i hope this isn't any stupid question. thank you all for answering my questions.",
    "present_kp": [
      "debian",
      "kvm"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "word search program. my word search goes through and searches for the first letter in the word slowly. i am looking for a way to optimize the program to search faster and efficiently. i want to find a way to search faster by using a single loop instead of nested loops in my findwords method. i think it would be better to use the appropriate arraylist from the hashtable to go only to the row, col coordinates that contain the first letter of the word.public class wordsearch { vjframe f; int dx = 30; int dy = 30; int timing = 10; arraylist < string > word; private class coordinate { integer r; integer c; private coordinate(integer row, integer col) { this.r = row; this.c = col; } } hashtable < string, arraylist < coordinate >> h = new hashtable < string, arraylist < coordinate >> (); public wordsearch(vjframe f) { this.f = f; } public void initialize(string[][] mat, int rows, int cols, string filename) throws ioexception { bufferedreader buffer = new bufferedreader(new filereader(filename)); string s; for (int i = 0; i < rows; i++) { s = buffer.readline(); for (int j = 0; j < cols; j++) { mat[i][j] = s.substring(j, j + 1); if (!h.containskey(mat[i][j])) { h.put(mat[i][j], new arraylist < coordinate > ()); } h.get(mat[i][j]).add(new coordinate(i, j)); } } } public void display(string[][] mat) { for (int i = 0; i < mat.length; i++) { for (int j = 0; j < mat[i].length; j++) { system.out.print(mat[i][j] + ); f.add(new jrectangle(dx * j, dy * i, dx, dy, color.black, color.white), timing); f.add(new jstring(dx * j + 5, dy * i + 25, mat[i][j], color.black), timing); } system.out.println(); f.add(new jstring(dx * mat[i].length + 5, dy * i + 25, integer.tostring(i), color.white), timing); } for (int j = 0; j < mat[0].length; j++) { f.add(new jstring(dx * j + 5, dy * mat.length + 25, integer.tostring(j), color.white), timing); } } public boolean match(string[][] matrix, int row, int col, string word, direction d) { string check = word.substring(0, 1); int index = 1; while (index < word.length()) { if (matrix[row + d.deltarow][col + d.deltacol].equals(word.substring(index, index + 1))) { index++; check = check + matrix[row + d.deltarow][col + d.deltacol]; row = row + d.deltarow; col = col + d.deltacol; } else { return false; }; } if (check.equalsignorecase(word)) { return true; } else { return false; } } public void displayword(string[][] matrix, int row, int col, string word, direction d) { for (int index = 0; index < word.length(); index++) { int drow = index * d.getdeltarow(); int dcol = index * d.getdeltacol(); f.add(new jrectangle(dx * (col + dcol), dy * (row + drow), dx, dy, color.black, color.green), timing); f.add(new jstring(dx * (col + dcol) + 5, dy * (row + drow) + 25, matrix[row + drow][col + dcol], color.black), 500); } try { thread.sleep(2000); } catch (exception e) {} for (int index = 0; index < word.length(); index++) { int drow = index * d.getdeltarow(); int dcol = index * d.getdeltacol(); f.add(new jrectangle(dx * (col + dcol), dy * (row + drow), dx, dy, color.black, color.white), timing); f.add(new jstring(dx * (col + dcol) + 5, dy * (row + drow) + 25, matrix[row + drow][col + dcol], color.black), 500); } } public void findwords(string[][] matrix, string filename) throws ioexception { bufferedreader buf = new bufferedreader(new filereader(filename)); int wrdcnt = 0; int row = 1; int deltax = this.dx * (3 + matrix.length); while (buf.ready()) { boolean found = false; direction d; string word = buf.readline(); f.add(new jstring(deltax, dy * row, word, color.yellow), timing); wrdcnt++; if (wrdcnt % 2 == 0) { deltax = this.dx * (3 + matrix.length); row++; } else { deltax += 150; } for (integer i = 1; (i < matrix.length - 1) && (!found); i++) { for (integer j = 1; (j < matrix[i].length - 1) && (!found); j++) { f.add(new jrectangle(dx * j, dy * i, dx, dy, color.black, color.yellow), 20); f.add(new jstring(dx * j + 5, dy * i + 25, matrix[i][j], color.black), 20); if (matrix[i][j].equals(word.substring(0, 1))) { for (directions dir = new directions(); (!found) && (dir.hasnext());) { d = (direction) dir.next(); found = match(matrix, i, j, word, d); if (found) { displayword(matrix, i, j, word, d); system.out.println(word + found at ( + i + , + j + ) heading + d.getname()); } } } f.add(new jrectangle(dx * j, dy * i, dx, dy, color.black, color.white), 20); f.add(new jstring(dx * j + 5, dy * i + 25, matrix[i][j], color.black), 20); } } if (!found) system.out.println(word + not found); } }} public class directions implements iterator{ direction[] d = new direction[8]; integer index; public directions(){ this.d[0] = new direction(north , -1, 0); this.d[1] = new direction(northeast, -1, 1); this.d[2] = new direction(east , 0, 1); this.d[3] = new direction(southeast, 1, 1); this.d[4] = new direction(south , 1, 0); this.d[5] = new direction(southwest, 1, -1); this.d[6] = new direction(west , 0, -1); this.d[7] = new direction(northwest, -1, -1); this.index = 0; } public object next(){ assert this.index<8: iteration error; return d[this.index++]; } public boolean hasnext(){ return this.index<8; } public void remove(){ }} public class direction { public string name; public integer deltarow; public integer deltacol; public direction (string name, integer drow, integer dcol){ this.name = name; this.deltarow = drow; this.deltacol = dcol; } public integer getdeltarow(){ return this.deltarow;} public integer getdeltacol(){ return this.deltacol;} public string getname(){ return this.name;} public string tostring(){ return this.name+ +this.deltarow+ +this.deltacol; } } public class wordsearchmain{ public static void main(string [] argv) throws ioexception { int rows = 17; int cols = 17; string [][] matrix = new string[rows][cols]; vjframe vws = new vjframe(word search); wordsearch w = new wordsearch(vws); w.initialize(matrix, rows, cols, matrixb.txt); w.display(matrix); w.findwords(matrix, words.txt); }}",
    "present_kp": [],
    "absent_kp": [
      "java",
      "performance"
    ]
  },
  {
    "text": "is embedding a solution feasible for sat?. i am interested in hard individual instances of np-complete problems.ryan williams discussed the sat0 problem at richard lipton's blog. sat0 asks whether a sat instance has the specific solution consisting of all 0's. this got me thinking about constructing sat instances that are likely to be hard.consider a sat instance $\\phi$ with $m$ clauses and $n$ variables, where $lpha = m/n$ is large enough, in the sense that it falls into the region beyond the phase transition, where nearly all instances are unsatisfiable. let $x$ be a random assignment to the values of $\\phi$.is it possible to modify $\\phi$ to obtain a new instance $\\phi|x$, so that $\\phi|x$ is largely similar to $\\phi$, but so that $x$ is a satisfying assigment for $\\phi|x$?for instance, one could try to add to each clause a randomly chosen literal from the solution, that does not already occur in the clause. this will guarantee that $x$ is a solution.or is this hopeless, leading to a fast algorithm for finding the hidden solution, along the lines of the following recent paper?uriel feige and dorit ron, finding hidden cliques in linear time, dmtcs proc. am, 2010, 189204.i am aware of the discussion by cook and mitchell and work they reference. however, i couldn't find anything about what happens to the structure of a formula when one tries to explicitly embed a satisfying assignment into it. if this is folklore, pointers would be very welcome!stephen a. cook and david g. mitchell, finding hard instances of the satisfiability problem: a survey, dimacs series in discrete mathematics and theoretical computer science 35 117, ams, isbn 0-8218-0479-0, 1997. (ps)",
    "present_kp": [
      "sat",
      "hard instances"
    ],
    "absent_kp": [
      "cc.complexity theory"
    ]
  },
  {
    "text": "is it a good idea to filter input before running awk action?. if i have some input, is it better to filter the data before i run my awk action or should i do all the filtering in awk?for example given the following input:$ echo foo bar bazfoobarbazshould i run:$ echo foo bar baz | sed 1q | awk '{ print $0 cats }'foo catsor:$ echo foo bar baz | awk 'nr == 1 { print $0 cats }'foo catswhy should i run either one?should i use a different tool?what factors should i be considering?how can i test those factors?",
    "present_kp": [
      "awk",
      "sed"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "how can this function be faster? solving for a row of pascal's triangle. i saw a posting on hacker news this morning that was ranting about people not being able to solve an interview question. i thought i would give it a shot, but i would like to know how my attempt could be improved.def get_pascal_row(n): returns the nth row of pascal's triangle for a given n. uses gray's algorithm. if n == 0: return [] n -= 1 row = [1] for i in xrange(1,n+1): row.append(row[-1] * n/i) n -= 1 return row",
    "present_kp": [],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "background application which pops up a ui based on events. i need to code a java application which runs on the desktop. it's a continuously running application. it runs all the time. it should not show any ui unless there is an event.the application polls a server for the event. when the event happens, the application should popup a message - the message should remain till the time the user clicks on it.when the user clicks on the message, it should show a ui allowing him to do further actions with the ui. when the user is done - he dismisses the ui till the next event happensi am exploring ways by which i can achieve this. i was thinking of a system tray application which pops up a message. from the docs, it seems as if the message disappears after some time even if the user does not click it. i do not want this behavior. what would be the best ui design i should use for this?",
    "present_kp": [
      "java",
      "ui"
    ],
    "absent_kp": []
  },
  {
    "text": "business not appearing in google maps at all. i'm having problems with listing my business on google places for business. i wish i can send you a link to my business page but can't find it even if i type on google my business address!. anyway, the business web site associated with my google business page is pressurecleaningandsealing.com. i used a domain forward from a godaddy domain (pressurecleaningandsealing.com) to aqua-pressure.net. i can see that the way this forwarding is done is by showing the actual page in an iframe inside the new domain. i once did this before for another business and it worked great. it ranked up as soon as i did the forwarding from a domain that contained a couple of keywords i wanted to rank for and listed this domain on the google business page.the weird thing is that my business doesn't appear at all on google results when i type pressure cleaning and sealing near cooconut creek. almost seems like the business is being banned for some reason. i have a google webmaster tools and it doesn't show any error. the domain is about 3 weeks old (the other business i mentioned above ranked up to first page the very same day i purchased the domain).",
    "present_kp": [
      "google",
      "google maps"
    ],
    "absent_kp": [
      "seo",
      "google local search"
    ]
  },
  {
    "text": "unmet dependencies. i am trying to compile vim and install with --enable-pythoninterp flag, which needs the python-dev package.infoi obtained the vim source from <url> is not available yet using apt.using ubuntu 10.10but, sudo apt-get python-dev results in broken packages error message ->the following packages have unmet dependencies: python-dev : depends: python (= 2.6.6-2ubuntu1) but 2.6.6-2ubuntu2 is to be installede: broken packageshow can i best resolve this issue?$ apt-cache policy vim python python-dev python: installed: 2.6.6-2ubuntu2 candidate: 2.6.6-2ubuntu2 version table: *** 2.6.6-2ubuntu2 0 100 /var/lib/dpkg/status 2.6.6-2ubuntu1 0 500 <url> maverick/main i386 packagesvim: installed: (none) candidate: 2:7.2.330-1ubuntu4 version table: 2:7.2.330-1ubuntu4 0 500 <url> maverick/main i386 packagespython-dev: installed: (none) candidate: 2.6.6-2ubuntu1 version table: 2.6.6-2ubuntu1 0 500 <url> maverick/main i386 packages",
    "present_kp": [
      "vim",
      "apt",
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "paragraph transfer from one file to another. which commands can you use to take a paragraph from one file and insert it in a second file?",
    "present_kp": [],
    "absent_kp": [
      "cut copy paste",
      "gvim"
    ]
  },
  {
    "text": "google sheets formula for if contains. i'm trying to figure out how to identify 'if' a list of items in one cell contains a value or string. examplecell a1 contains sites, sheets, docs, slides. i want cell b1 to display a 1 'if' cell a1 contains the string sites.formula=if(a1 ?????? sites, 1,0)i'm not sure what to replace the ?????? with in the above formula or if this formula is possible. any ideas on how to accomplish the desired outcome is greatly appreciated.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets",
      "formulas"
    ]
  },
  {
    "text": "how do i view the case-sensitive file names of iso9660/joliet+ucs-3 volumes?. i have an iso that i am trying to use to install software via wine. i have the iso mounted as a loopback device. the windows installer keeps complaining that it cannot locate particular cab files and it asks me to locate them. the file name that the installer software asks me to locate has mixed case, but when i mount the iso under linux all directory listings show the files as being all lowercase. if i set -o check=relaxed when i mount the iso, then i can ask for files in mixed case and linux will 'find' them. but if i do a directory listing i still get all lowercase.i guess the windows installer package is either doing a directory listing or for whatever reason it is getting an all-lower-case version of the filename it is expecting. i am thinking there are several paths forward:get linux to show the mixed-case filenames as they are encoded in the joliet extensionextract the iso into a native linux filesystem in a way that preserves the original casingfind a copy of windows and use that to copy the files to a windows native file system that linux can also read and is case sensitive (ntfs).something involving wine.some example commands:% isoinfo -d -i example.iso...joliet with ucs level 3 foundno rock ridge present% # when using isoinfo, filenames are all caps% isoinfo -f -i example.isodirname/dirname/long_file_name.cab% # when using ls, filenames are all lowercase% ls /mnt/iso/dirname/dirnamelong_file_name.cab",
    "present_kp": [
      "mount",
      "wine",
      "iso"
    ],
    "absent_kp": [
      "case sensitivity"
    ]
  },
  {
    "text": "how can you create text as a png file to minimize file size?. i've seen this trick on lots of websites, but i don't know how i could create this myself easily. it's basically text or a logo which is saved on a transparent background with a small border, to minimize the file size. for example on postmarkapp, they have this transparent logo, with a yellow border:postmark logo <url> there are a lot more of these examples on the web.what's an easy way to create such a png file with a small border so your text or logo will seamlessly blend into the background color?",
    "present_kp": [
      "png"
    ],
    "absent_kp": [
      "images",
      "transparency"
    ]
  },
  {
    "text": "marking up symbols in a programming language. given a text file with source code in some language, does anyone know of a command-line tool to markup symbols like identifiers, comments etc and output an xml document?",
    "present_kp": [
      "xml"
    ],
    "absent_kp": []
  },
  {
    "text": "in android can we let a fragment know other fragments?. i think i have found contradictory design guidance within the google android documentation on fragmentation.the first statement below advises each fragment be unaware of other fragments and always communicate only to the activity and let the activity decides what needs to be done.creating event callbacks to the activityin some cases, you might need a fragment to share events with the activity. a good way to do that is to define a callback interface inside the fragment and require that the host activity implement it. when the activity receives a callback through the interface, it can share the information with other fragments in the layout as necessary.for example, if a news application has two fragments in an activityone to show a list of articles (fragment a) and another to display an article (fragment b)then fragment a must tell the activity when a list item is selected so that it can tell fragment b to display the article. in this case, the onarticleselectedlistener interface is declared inside fragment a:but a second statement later on the same page, a list fragment directly instantiates detail fragment. if (mdualpane) { // we can display everything in-place with fragments, so update // the list to highlight the selected item and show the data. getlistview().setitemchecked(index, true); // check what fragment is currently shown, replace if needed. detailsfragment details = (detailsfragment) getfragmentmanager().findfragmentbyid(r.id.details); if (details == null || details.getshownindex() != index) { // make new fragment to show this selection. details = detailsfragment.newinstance(index); // execute a transaction, replacing any existing fragment // with this one inside the frame. fragmenttransaction ft = getfragmentmanager().begintransaction(); if (index == 0) { ft.replace(r.id.details, details); } else { ft.replace(r.id.a_item, details); } ft.settransition(fragmenttransaction.transit_fragment_fade); ft.commit();so my questions: are these contradicting each other?should this be left to activity?i feel confused, so any clarification is appreciated.",
    "present_kp": [
      "design",
      "android"
    ],
    "absent_kp": []
  },
  {
    "text": "disk space on fedora 12. i'm using fedora 12 on my laptop. i have 10gb disk space and 2gb of them are free. after 2-3 days uptime the space ends and i must reboot. after rebooting i get 2gb free space back. how can i prevent this?mostly i use firefox, chrome, gedit, rhythmbox and in background: httpd, mysqld, conky. ram: 1gb, swap: 1.2 gb.",
    "present_kp": [
      "fedora"
    ],
    "absent_kp": [
      "disk usage"
    ]
  },
  {
    "text": "how to implement a hybrid role-based access control model?. i am writing an enterprise web-forms-frontend application for in-house use. it has direct access control (dac) masquerading as role-based access control (rbac). for anonymization purposes, let's call the main unit of information stored in my application a document, and the roles in the company a boss, a grunt and a c-level executive. there are also externals (e.g. somebody working for a business partner of ours). the general guideline is that everybody but externals should be able to read all documents, c-level execs can write everything, bosses can write the documents belonging to their own department, and grunts can only write documents personally assigned to them. fairly standard thus far. but what users actually want is that they can make arbitrary exceptions to the above. they want that any person in the system can be granted write access to any document, and that externals can be granted read access to any document. (actually, it is more complicated than that, with more roles and finer granularity of permissions, including management of who can propagate which permission to others, but the above description illustrates the core of the problem well enough). so what i have is basically permissions on a personal level, and the roles are only a convenient way of having default settings for the personal-level permissions when a user or a document is added to the system, instead of having somebody fill out a whole row or column in an access control matrix by hand. now i have already designed a permissions table in my database, which has a user fk, document fk and columns for the different types of permissions. what i am not sure is what i should save in the table. alternative 1: i save all permissions in this table (pure dac) and have the logic tier mimic a rbac. e.g. when a new boss is added, a row for each document in the system is added to the db, with read permissions for all documents and write for the documents of her department. alternative 2: i save the deviations from the role guidelines only. so when a new boss is added, nothing is written to the permissions table. but when an executive gives a boss the rights to write to a document from a different department, then a single row is added to reflect that information. i am not sure which alternative would be better. the first one feels closer to textbook implementation, and if a principle has made it into a textbook, then there is normally good reason to use it. but in my case, it also hurts the dry principle - after all, if the information that a c-level exec can write to document x is derivable from his role, writing a row with this information in the db is redundant. what are the advantages and disadvantages of each approach in terms of a) application performance and b) complexity of implementation? what headaches can i expect from each? keep in mind that 1) i don't plan to implement a full logic tier. the whole application is practically a convenient crud frontend to a database, so i will be doing db queries for each page view instead of keeping a collection of document objects in memory. (i know the advantages of a mvc pattern, but it was decided that it will be overkill for this project). 2) i am programming this in asp .net 4.5, so the closer i stay to roles, the more i can let the framework do the heavy lifting for me. 3) i have thought of implementing groups orthogonal to the roles to manage access, but it doesn't make sense in my case.",
    "present_kp": [
      "access control"
    ],
    "absent_kp": [
      "patterns and practices"
    ]
  },
  {
    "text": "oblique epi in afni. it is my very first time with afni and i am having problems with the creation of the afni dataset from dicom images.i runned:dimon -infile_prefix im -gert_create_datasetand i got this error:dimon version 4.18 (november 9, 2016) running, use <ctrl-c> to quit...-- scanning for first volume++ data detected to be oblique** cannot find a volume in 4400 image files (max allowable = 3000, see -max_images)as i want to keep my epi dataset oblique i added the -use_obl_origin option running:dimon -infile_prefix im -gert_create_dataset -use_obl_originbut i still get the same error. how can i deal with this issue?",
    "present_kp": [
      "data"
    ],
    "absent_kp": [
      "fmri",
      "signal processing"
    ]
  },
  {
    "text": "should i strictly follow every single html and css standard?. a few years ago i considered myself somewhat of a web developer, knowing the basic 3 languages (html, css, js) and lots of php. moving on from simple text to actual websites was a pain because of the so called standards out there, which at the time were ridiculously complicated for me. it pretty much boiled down to this (minus the ie related stuff):standards are there to replace old ways of doing things in a simpler way. however when trying to actually implement some of the stuff (entirely css based layout for example), it took me 10x longer to actually do it then if i did the simpler and still working solution. if it rendered the same, then why should i use the more complicated example that takes 10x longer and breaks once you change browsers? this sparked many long religious debates in ##php, ##css, and ##js in freenode irc and actually got me banned from ##css because i messed with their little world over there.my question: should i follow every single standard and coding conventions even if they take me 10x longer but get me the same result as the simple one?for the poll tag, those of you who have websites of any size (huge or small), do you follow all the standards?",
    "present_kp": [
      "html",
      "css"
    ],
    "absent_kp": [
      "coding standards"
    ]
  },
  {
    "text": "problem with login using facebook. i'm trying to login to slideshare using facebook login and all i get is a popup window pointing to this address:<url>}}the login never takes place.any help?",
    "present_kp": [
      "facebook",
      "login",
      "slideshare"
    ],
    "absent_kp": []
  },
  {
    "text": "google using logo alt text rather than meta description in search results when searching for our brand name. i have a page (not well ranked though) that if i search for using the name, so let's say my page is <url>, when i search for example-example, the title is correct, but in description it shows me alt text of an image (logo), which happens to contain example-example logo. the meta description is set in html.any suggestions on how this can be fixed?",
    "present_kp": [],
    "absent_kp": [
      "seo",
      "google search",
      "alt attribute"
    ]
  },
  {
    "text": "regular expression to match (not x) and y (!x & y). i received a desktop day-to-day calendar with puzzles. one such puzzle was deciphering a quote where the letters were substituted with symbols. i used some regexs to find longer words, then used the returned words to solve smaller words. in the puzzle, white background symbols were vowels (including 'y') and shaded background symbols were consonants.i'll use random letters below where bolded means consonant, plain means vowel, and italicized means the letter was given in the directions.boqqethe example above was deciphered as happy ('e' was already given in the puzzle) by using the regex egrep -i '^[bcdfghjklmnpqrstvwxz][aiouy][bcdfghjklmnpqrstvwxz]{2}[aiouy]$' wordsthere were a lot of results, but i feel i could have made the regex better by specifying the regex logically as char 1 is a consonantchar 2 is a vowel, but not 'e' because that was given in the directions.chars 3 & 4 are the same consonant, but are different from char 1.char 5 is a vowel, but different from char 2.another example would beo r e w y d o nwhere i used the grep statementegrep -i '^([aiouy])[bcdfghjklmnpqrstvwxz]e[bcdfghjklmnpqrstvwxz][aiouy][bcdfghjklmnpqrstvwxz]n$' wordsto logically define the search aschar 1 is a vowel, and is a captured group because the same char appears later in the word.char 2 is a consonant.char 3 is 'e', given.char 4 is a consonant.char 5 is a vowel.char 6 is a consonant.char 7 is the same vowel as char 1.char 8 is 'n', given.fortunately, the grep statement returned one word, american (the cipher-text was a movie quote). i would like to have been able to specify in the regex that char 4 is a consonant and not the same as char 2, char 5 is a vowel and not the same as char 1, etc.is it possible to ask this kind of pattern matching with regexs? i'm aware of the (x|y) syntax to state that a character may be 'x' or 'y', but i don't know of the syntax, if it exists, to specify (!x) & y",
    "present_kp": [
      "regular expression",
      "search"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "how does production server and staging server actually work in production. i have one linux vps server for my company and we develop php sites.what i normally do is just make the subdomain of main site like test1.mainsite.com and work on that till it finishes. and then chnage the domain name.i have heard that big companies have the staging server and production server.i just want to know how that system works and when site is complete how do they transfer the site via ftp , ssh , rsync , what they do with old staging server.i jsut want to implement the enterprise strategies in my company and want to know how to proceedthanks",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "enterprise development"
    ]
  },
  {
    "text": "command to mass rename files according to pattern. i have a lot of files in a directory that are named as follows id_other_stuff.txt i'd like to rename them all to id.txt. this isn't a duplicate because i don't know how to specify this pattern.",
    "present_kp": [
      "rename"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "finding string roots. this is the following python code that i have coded for an algorithmic problem online. for each line of input, the goal is to find the greatest number of repeating blocks into which the string can be split. for example, if the input is abcabcabcabc, then the output should be 4, because the string is equal to 4 repetitions of abc.the online compiler says time limit exceeded. where in the following code can i optimize to make it much more efficient in terms of time?inputstring = raw_input()while (inputstring !='*'): scanned_string = matched_characters = frequency = 0 if (len(inputstring) == 1): print frequency for current_symbol in inputstring: if not scanned_string: scanned_string = scanned_string + current_symbol if scanned_string: matched_characters = matched_characters + current_symbol if (scanned_string.startswith(matched_characters)): if (len(scanned_string) == len(matched_characters)): frequency = frequency + 1 matched_characters = else: scanned_string = scanned_string+matched_characters matched_characters = frequency = 1 print frequency inputstring = raw_input()",
    "present_kp": [
      "python",
      "algorithm",
      "time limit exceeded"
    ],
    "absent_kp": [
      "strings",
      "programming challenge"
    ]
  },
  {
    "text": "implementation of instance testing in java, c++, c#. for curiosity purposes as well as understanding what they entail in a program, i'm curious as to how instance testing (instanceof/is/using dynamic_cast in c++) works. i've tried to google it (particularly for java) but the only pages that come up are tutorials on how to use the operator.how do the implementations vary across those langauges? how do they treat classes with identical signatures?also, it's been drilled into my head that using instance testing is a mark of bad design. why exactly is this? when is that applicable, instanceof should still be used in methods like .equals() and such right?i was also thinking of this in the context of exception handling, again particularly in java. when you have mutliple catch statements, how does that work? is that instance testing or is it just resolved during compilation where each thrown exception would go to?",
    "present_kp": [
      "java",
      "c#",
      "c++"
    ],
    "absent_kp": [
      "inheritance"
    ]
  },
  {
    "text": "properties file mru cache. i made an attempt to implement a properties file mru cache with a limited cache size which are of the most recently used properties can only be held in. a read miss from this cache leads to a read from the file for that particular property and keep it in the cache until it goes out of the limit where other recently properties gets read into the cache from the file.import java.io.bufferedreader;import java.io.filenotfoundexception;import java.io.filereader;import java.io.ioexception;import java.util.linkedhashmap;public class propertiesfilemrucache { private linkedhashmap<string, string> propertiesmap = new linkedhashmap<>( 10); private int limit = 8; private string propertiesfile = default.properties; public propertiesfilemrucache() { } public propertiesfilemrucache(string propertiesfile) { this.propertiesfile = propertiesfile; } public propertiesfilemrucache(int limit, string propertiesfile) { this(propertiesfile); this.limit = limit; } public string getcapital(string country) { string capital = propertiesmap.get(country); if (capital == null) { capital = readfromfile(country); if (propertiesmap.size() == limit) { propertiesmap.remove(propertiesmap.keyset().iterator().next()); } } else { propertiesmap.remove(country); } propertiesmap.put(country, capital); return capital; } private string readfromfile(string country) { try (bufferedreader br = new bufferedreader(new filereader( propertiesfile))) { for (string line; (line = br.readline()) != null;) { if (line.startswith(country)) { return line.substring(line.indexof('=') + 1); } } } catch (filenotfoundexception e) { e.printstacktrace(); } catch (ioexception e) { e.printstacktrace(); } return null; } public static void main(string[] args) { propertiesfilemrucache pfc = new propertiesfilemrucache(res\\countrycapital.properties); pfc.getcapital(india); pfc.getcapital(usa); pfc.getcapital(uk); pfc.getcapital(kuwait); pfc.getcapital(iraq); pfc.getcapital(canada); pfc.getcapital(australia); pfc.getcapital(india); pfc.getcapital(india); pfc.getcapital(india); pfc.getcapital(germany); pfc.getcapital(india); pfc.getcapital(germany); pfc.getcapital(china); pfc.getcapital(pakistan); system.out.println(pfc.propertiesmap); }}for testing purpose i provided a user specified property as res\\countrycapital.properties with the default cache limit as 8. the content of the countrycapital.properties is provided below for reference:india=new delhiusa=washingtonegypt=cairosrilanka=columbosouth korea=seoultailand=bangkokqutar=dohalebanon=beirutcanada=torontonorway=oslosweden=stockholmfinland=helsinkichina=beigingjapan=tokyobangladesh=dhakapakistan=karachiafganistan=kabulaustralia=sydneynewzeland=wellingtonireland=dublingermany=berlinitlay=romenepal=kadmantunorth korea=pyongyangbrazil=braziliasouth africa=cape townfrance=parisczech repulic=pragueaustria=viennaisrael=jerusalemkuwait=kuwait citygreece=athensiraq=bagdadsyria=demascausdenmark=copengahenuk=london",
    "present_kp": [
      "java",
      "cache",
      "properties"
    ],
    "absent_kp": []
  },
  {
    "text": "how to zip or compress resources of your .net application. i am a windows application developer, i'd build a few .net applications and i can see it is very easy to crack out resources of my application even some simple applications like resource editor are able to crack my application by just deleting the registration dialog box to make my application a freeware without having a proper license key.is there any .exe compressor or any other other tool which i can use to save my application resources as well as my scripts, can anyone suggest me how can i avoid recompilation of my script. any help will be appreciated.",
    "present_kp": [],
    "absent_kp": [
      "decompilation",
      "unpacking",
      "compilers"
    ]
  },
  {
    "text": "google spreadsheets loading bug. a few days ago, i created a google spreadsheet and from what i remember, it was working fine. when i came back to it today, i saw that a few cells said loading... despite all cells in the column have the same formula (except for the cell reference). what i've tried to fix this:i figured it must be an issue with my custom function, so i put a return statement at the beginning of the function to verify that, and that didn't fix the issue.i changed the equation and changed it back because i saw similar questions get solved by doing that.i flipped the equations (cell references) in a working cell and a nonworking cell, and the value was displayed in both, which seems to show that the equation isn't broken, and the cell isn't broken, but somehow it still doesn't work.i tried it on a different browser to see if caching is the issue.this is what i have: cell e2: =if(j2 = yes, myfunc(c2, d2, sheet2!c$2:c), ) results in 42cell e3: =if(j2 = yes, myfunc(c3, d3, sheet2!c$2:c), ) results in loading...function myfunc(foo, bar, baz) { return 42; // more code that won't get run now}given what i've tested, it makes me think that it is a bug, especially since i don't know how i could replicate it. has anyone else seen something like this or know a solution to this problem?",
    "present_kp": [
      "google spreadsheets"
    ],
    "absent_kp": [
      "google apps script"
    ]
  },
  {
    "text": "how can x11 shortkeys be captured by a python program?. i want to have a little python program running in the background that monitors for certain shortkey presses (e.g. ctrl alt direction key). the idea is that these shortkeys can trigger various actions.here is the beginnings of an attempt, but i honestly don't know what i'm doing:import xlibimport xlib.displaydef process_event(event): keycode = event.detail if event.type == xlib.x.keypress: print(keycode)def main(): # current display display = xlib.display.display() rootwindow = display.screen().root # catch keypress events rootwindow.change_attributes(event_mask = xlib.x.keypressmask) keys = [10, 11] for keycode in keys: rootwindow.grab_key( keycode, xlib.x.mod1mask, #xlib.x.anymodifier, 1, xlib.x.grabmodeasync, xlib.x.grabmodeasync ) while true: event = rootwindow.display.next_event() process_event(event)if __name__ == '__main__': main()",
    "present_kp": [
      "x11",
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "nfa - string acceptance (decision problem) test. i am interested in testing for a given string (w) whether it is in the language (l) defined by a nondeterministic finite automaton (a). i have some blurry point in my mind.what is the complexity of this test by using the nfa and backtracking? assume my nfa has m states and string (w) has length n (|w| = n). for regular expressions, by using thompson's algorithm, the resultant nfa has the same complexity (worst case) if i use backtracking?what are the methods/algorithms other than backtracking and converting to dfa?",
    "present_kp": [],
    "absent_kp": [
      "automata",
      "nondeterminism"
    ]
  },
  {
    "text": "could there be a use case for c# style auto-properties in python. i've been doing a lot of work in c# recently (my primary language is python) and i love that i can do something likepublic string myproperty{ get; set; }going back to python i miss that sort of functionality. i don't like that i would have to do class myclass: @property def foo(self): return self._foo @foo.setter def foo(self, value): self._foo = valuea = myclass()a.foo = 7print(a.foo)i thought that this was something i could do pretty easily with a descriptor, like so.class myclass: foo = autoproperty()a = myclass()a.foo = 7print(a.foo)unfortunately, i realized while implementing this that i was violating my favorite design principle - kiss. after all, what i'd been thinking about were just instance variables. class myclass(): passa = myclass()a.foo = 7print(a.foo)the reason we don't always use properties by default in python is that, usually, getting and setting instance variables isn't nearly as involved as languages like java make it - mostly because the concept of private, protected, and public fields don't really exist in python, except by (weak) conventions and language features, and because changing from a field to a property isn't a breaking change in python.if we later decide that we do need more complex validation while setting or calculations while getting, then we can easily do that by implementing properties and not affecting the interface of our class.i'm still wondering though - is there any sort of way this technique, or a modified version of this technique, could be used to provide a useful and pythonic feature?",
    "present_kp": [
      "c#",
      "python",
      "properties"
    ],
    "absent_kp": [
      "design patterns"
    ]
  },
  {
    "text": "does providing object files satisfy lgpl relink clause?. from this question on so, i read that:proprietary source code + lgpl source codestatically linked:either you must release both parts as lgpl.or provide everything that allow the user to relink the application with a different version of the lgpl source code. in this case the other requirements are the same as if it was dynamically linked.so it does sound like providing object files is enough to satisfy lgpl in terms of statically linking a lgpl library to a proprietary code application. while the executable is statically linked, providing the object files allows the end user to recompile the application, linking to different version of the library.is this correct, and if not, then why?",
    "present_kp": [
      "lgpl"
    ],
    "absent_kp": [
      "static linking"
    ]
  },
  {
    "text": "concurrent for loop in c++ - follow-up. i have incorporated all the cool points made by chriswue in the initial iteration of this post.now, i am not reinventing the wheel for my concurrent queue, but use internally std::deque. also, i modified the api of the concurrent forp construct: now it takes any range specified by means of iterators as the input list.see what i have:concurrent.h:#ifndef forp_h#define forp_h#include <deque>#include <functional>#include <iterator>#include <thread>#include <vector>namespace net { namespace coderodde { namespace concurrent { //////////////////////////////////////////////////////////////////// // this is an adhoc concurrent queue used by forp. // //////////////////////////////////////////////////////////////////// template<class iter> class queue { typedef typename std::iterator_traits<iter>::value_type t; private: std::deque<t> m_queue; std::size_t m_index; std::mutex m_mutex; public: queue(iter begin, iter end) : m_index{0} { for (iter i = begin; i != end; ++i) { m_queue.push_back(*i); } } size_t size() { return m_queue.size(); } std::tuple<t, size_t, bool> dequeue() { std::tuple<t, size_t, bool> ret; { std::lock_guard<std::mutex> lock(m_mutex); if (m_queue.empty()) { ret = std::make_tuple(t(), 0, false); } else { ret = std::make_tuple(m_queue.front(), m_index++, true); m_queue.pop_front(); } } return ret; } }; template<class initer, class out> void thread_do(net::coderodde::concurrent::queue<initer>& input_queue, out (*process)(typename std::iterator_traits<initer>::value_type in), std::vector<out>& output_vector) { typedef typename std::iterator_traits<initer>::value_type in; while (true) { std::tuple<in, size_t, bool> data = input_queue.dequeue(); if (std::get<2>(data) == false) { return; } const in input_element = std::get<0>(data); const size_t input_element_index = std::get<1>(data); out output_element = process(input_element); output_vector[input_element_index] = output_element; } } //////////////////////////////////////////////////////////////////// // this function template implements a concurrent, thread-pool-// // based iteration construct. // //////////////////////////////////////////////////////////////////// // side effects: the input range remains intact; output_vector is // cleared and populated with the output data. //////////////////////////////////////////////////////////////////// template<class initer, class out> void forp(initer begin, initer end, out (*process)(typename std::iterator_traits<initer>::value_type), std::vector<out>& output_vector) { unsigned thread_count = std:\ud83e\uddf5:hardware_concurrency(); std::vector<std::thread> thread_vector; thread_vector.reserve(thread_count); net::coderodde::concurrent::queue<initer> input_queue(begin, end); output_vector.clear(); output_vector.resize(input_queue.size()); for (unsigned i = 0; i < thread_count; ++i) { thread_vector.push_back( std::thread(&thread_do<initer, out>, std::ref(input_queue), std::ref(process), std::ref(output_vector))); } for (std::thread& thread : thread_vector) { thread.join(); } } } /* namespace concurrent */ } /* namespace coderodde */} /* namespace net */#endif /* forp_h */main.cpp:#include concurrent.h#include <chrono>#include <cstdint>#include <iostream>#include <list>#include <vector>class currenttime { std::chrono::high_resolution_clock m_clock;public: uint64_t milliseconds() { return std::chrono ::duration_cast<std::chrono ::milliseconds> (m_clock.now().time_since_epoch()).count(); }};using net::coderodde::concurrent::forp;using std::cout;using std::list;using std::stringstream;using std::vector;static uint64_t fibonacci(uint64_t n){ if (n <= 0) { return 0; } if (n == 1) { return 1; } return fibonacci(n - 1) + fibonacci(n - 2);}template<class t>std::ostream& operator<<(std::ostream& out, std::vector<t>& vector){ out << [; if (!vector.empty()) { out << vector[0]; } for (size_t i = 1; i < vector.size(); ++i) { out << , << vector[i]; } return out << ];}int main(int argc, char** argv) { list<uint64_t> fibonacci_task_input_list = { 40, 41, 39, 33, 43, 30, 34, 40 }; currenttime ct; vector<uint64_t> result_vector1; vector<uint64_t> result_vector2; uint64_t start_time = ct.milliseconds(); for (const int i : fibonacci_task_input_list) { result_vector1.push_back(fibonacci(i)); } uint64_t end_time = ct.milliseconds(); cout << serial processing in << (end_time - start_time) << milliseconds. ; start_time = ct.milliseconds(); net::coderodde::concurrent::forp(fibonacci_task_input_list.begin(), fibonacci_task_input_list.end(), fibonacci, result_vector2); end_time = ct.milliseconds(); cout << parallel processing in << (end_time - start_time) << milliseconds. ; cout << serial result: << result_vector1 << ; cout << concurrent result: << result_vector2 << ; return 0;}any critique is much appreciated.",
    "present_kp": [
      "c++",
      "concurrency"
    ],
    "absent_kp": []
  },
  {
    "text": "reshape and index (state) products in numpy. consider the following:i start with a $2 imes 2$ matrix $w_{ij}$. i then take this $w$ matrix and make a new tensor, $t$, by doing the following:$$t_{ijkl}=\\sum_{a}w_{ai}w_{aj}w_{ak}w_{al}$$which in my code i am using the (slick) ''einsum'' tool in numpy:tt = np.einsum('ai, aj, ak, al', w, w, w, w)with import numpy as np for np. next i preform the following:$$m_{xx'y''y'}=\\sum_{y}t_{xx'yy'}t_{x''x'''y''y}$$with $x=x\\otimes x''$ and $x'=x'\\otimes x'''$. now when i do a naive reshape in numpy mtensor = np.einsum('ikma, jlan', tt, tt).reshape(4, 4, 2, 2)this simply unfolds the array and then recollects in order. however, i would like to have the power to combine certain indices (states) into a single index (like an outer product but for indices). that is, take my two, $2$ state indices, and combine them into a $4$ state index that is all the possible combinations of their states. if someone knows a slick way to do this in numpy i would greatly appreciate some documentation or an answer. thanks in advance.",
    "present_kp": [
      "numpy"
    ],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "sensitivity versus degree. given boolean function $f$, let $f$ denote the unique multiaffine real polynomial representing $f$.sensitivity of $f$ at input $x$ is $$s_x(f) = |\\{i:f(x) eq f(x^i)\\}|$$ where $x^i=x\\oplus\\bbb 1_i$ where $\\oplus$ is $xor$ operation.sensitivity of $f$ is $$s(f)=\\max_xs_x(f)$$is there an easy proof to show $s(f)\\leq \\mathsf{deg}(f)$?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory"
    ]
  },
  {
    "text": "storing .h files in sqlite using sqljet. im trying to learn as much as i can on my own by reading lots of examples, documentations, and asking here. i would like to improve my style to write efficient code and adhere to java standards.in this small sample of code i would like to get feedback on a few things:exception throwingopening/closing database connectionany other comments in general stylethere are two classes, database and main.my database class:public class database { private string dbname = ; private sqljetdb db = null; public database(string dbname) { this.dbname = dbname; } public void createdatabase() throws sqljetexception {...} public void opendatabaseconnection() throws sqljetexception {...} public void closedatabaseconnection() throws sqljetexception {...} private void insertrecord(string file) throws sqljetexception {...} public void getdirectorycontent(string dir) { file directory = new file(dir); if (directory.isdirectory()) { string[] content = directory.list(); for (string s : content) { getdirectorycontent(dir + \\ + s); } } else { string file = directory.tostring(); string extension = file.substring(file.lastindexof(.)); if (extension.equals(.h)) { try { insertrecord(file); } catch (sqljetexception e) { e.printstacktrace(); } } } }}call in main:database db = new database(test.db); try { db.createdatabase(); db.opendatabaseconnection(); db.getdirectorycontent(c:\\test); } catch (sqljetexception e) { e.printstacktrace(); } finally { try { db.closedatabaseconnection(); } catch (sqljetexception e) { e.printstacktrace(); } }}",
    "present_kp": [
      "java",
      "database",
      "sqlite"
    ],
    "absent_kp": [
      "file system",
      "error handling"
    ]
  },
  {
    "text": "ida debugging api's security. i recently saw funcap, a plugin that captures function calls made by a binary using ida's debugging api.i have setup ida on my host machine. my vms aren't fast enough to run ida in them. how do you run a plugin like this without having the risk of malware executing in your host machine?",
    "present_kp": [
      "malware"
    ],
    "absent_kp": [
      "idapro plugins"
    ]
  },
  {
    "text": "how to study the effect of sustained exercise and sport on well-being?. id like to make a little case study about the impact of including regular weight training in life. i know one man who is going to start to excercise regularly and i have an opportunity to talk with him regularly (for example every month) for about six months, maybe longer. is there any other option of making this research than via regular interview with direct questions about his view of the impact of sports in his life (for example question: what do you think youve learned from training?)? i mean - if i will watch for example self-esteem and it will grow, how can i know it grew thanks to sports and not because of any other change in his life? how to relate any watched cathegory to the regular training?",
    "present_kp": [],
    "absent_kp": [
      "measurement",
      "methodology",
      "sport psychology"
    ]
  },
  {
    "text": "how do i change the font in chrome or firefox?. i'm using arch linux with i3 window manager, and chrome and firefox seem to be the only things that won't take the gtk font that i've selected. when i try to change the font in either browser, it still looks the same.because it's happening in both browsers, i'm assuming i have some global font configured that is overriding my changes. how do i fix this?",
    "present_kp": [
      "arch linux",
      "chrome",
      "firefox"
    ],
    "absent_kp": [
      "fonts"
    ]
  },
  {
    "text": "how to check if two sequences of setoid members are mutual rotations?. real world background: there are 2 independent sources of polygon definitions, with arbitrary parameters. meaning each source has it's own floating point precision, starting point and orientation of vertices.the problem is to find an algorithm, that would receive those 2 polygon definitions and by a certain margin declare them equal or not. if a cutting machine would receive those 2 inputs, would it cut out the same shapes? (which is btw. the real motivation behind the problem.)e.g.: ifpolygona = ( (1.0001, 1.0002), (2.0000, 1.0001), (1.5001, 1.9998) )polygonb = ( (1.9998, 0.9999), (0.9999, 1.0002), (1.5002, 2.0001) )and there is precision margin of 0.001 (i.e. 1 mm) then polygona would be equal to polygonb.this problem can formally formulated as follows:task and terminologyassume we have a set $x$ and two sequences $s_1 = (a_1, a_2, \\ldots,a_n)$ and $s_2 = (b_1, b_2, \\ldots,b_n)$, where $a_i \\in x, b_i \\in x, orall i \\in [1..n]$.we define, that two sequences are congruent and denote them $s_1 \\cong s_2$ if $\\exists k,l \\in [1..n]$ such that $a_{k+i \\pmod{n}}=b_{l+i \\pmod{n}}, orall i \\in [1..n]$. (plainly said, they would define the same cycle.) if $s_1 \\cong s_2$ then we say that $s_1$ is a rotation of $s_2$ and vice-versa.the task is to find an algorithm that determines if $s_1 \\cong s_2$.problemin the case that $x$ is a total order set the task can be solved quite easily with a linear algorithm. (finding a lexicographical extremum of all rotations for both sequences and then comparing those extrema.)the question is, is there linear algorithm if $x$ is a setoid? i.e. members of $x$ can be checked only for equivalence. if not, does at least exist an algorithm with a better complexity than brute force?",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "discrete mathematics"
    ]
  },
  {
    "text": "what are some good models to test the speed of a data science machine?. i'm writing a battery of tests (in python) for the purpose of measuring the speed of my company's different computational instances. the goal is to see how fast different aws ec2 instances are at running different ml models or common data science tasks.i'm reaching out to ask if anyone knows of any time-consuming (but realistic) models that can be built using only the standard anaconda packages and either the built in datasets, or a popular dataset known in the industry? the goal would be to give end users a sense of how much computational power they need, and i think using some popular data sets or models to compare relative time to completion would be the best way for them to choose the right amount of power for their needs.",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "machine learning",
      "scikit learn"
    ]
  },
  {
    "text": "multi class-type object pool based on libgdx pool. i've done some code so you can obtain object of any class from pool, take a look at it, is it safe? at least it works.multipool class has method obtain with class param, so can know from which inner-pool obtain object.import com.badlogic.gdx.utils.pool;import java.lang.reflect.modifier;import java.util.hashmap;public class multipool { public class multipoolexception extends exception { public multipoolexception(string message) { super(message); } } public class anypool extends pool<object> { class<?> type; anypool(class<?> type) { this.type = type; } @override protected object newobject() { try { return type.newinstance(); } catch (instantiationexception e) { e.printstacktrace(); } catch (illegalaccessexception e) { e.printstacktrace(); } return null; } } hashmap<class<?>, anypool> pools = new hashmap<class<?>, anypool>(); private void initializepool(class<?> type) { pools.put(type, new anypool(type)); } @suppresswarnings(unchecked) public <t> t obtain(class<?> type) { if ( modifier.isabstract(type.getmodifiers()) ) { (new multipoolexception(type.getname() + is abstract.)).printstacktrace(); return null; } if ( pools.get(type) == null ) initializepool(type); return (t) pools.get(type).obtain(); } public void free(object object) { class<?> type = object.getclass(); if ( pools.get(type) == null ) initializepool(type); pools.get(type).free(object); }}usage:multipool multipool = new multipool();string abc = multipool.obtain(string.class);someotherclass test = multipool.obtain(someotherclass.class);multipool.free(test);",
    "present_kp": [
      "java",
      "libgdx"
    ],
    "absent_kp": [
      "android",
      "generics"
    ]
  },
  {
    "text": "should arbitrary numbers be stored as strings in a database?. i'm using google as a login system for my latest project. so, my users table has a column named googleid, which stores google's unique user id, which is a number, with a few dozen digits. for example, it might be 105561241212957286025. since i'm not going to do any mathematical operations on this data, should i store it as a number, or as a string, in my database? also note that if i used a numerical value i would actually have to specify a custom precision because the built-in numerical types in postgresql aren't big enough for this value.",
    "present_kp": [
      "database",
      "strings",
      "numbers"
    ],
    "absent_kp": [
      "authentication"
    ]
  },
  {
    "text": "recommended gid for users group in linux (100 or 1000)?. i have several gnu/linux installations that share home and data directories. over time some user files in these directories have received the group id 100 (users group under some variants of linux), others have the group id 1000 (also the users group, under other variants).now i wish to unify the users group id between all my distributions, but which one should i choose?i remember there is a linux standard, does that give a recommended gid for users? if not, is there any other recommendation or trend (i am not asking about personal preferences)?",
    "present_kp": [
      "linux",
      "group",
      "standard"
    ],
    "absent_kp": []
  },
  {
    "text": "show that if s is an arithmetic progression, then a can be recognized by a dfa. a set s of nonnegative integers is called an arithmetic progresion if there exist some integers n and p such thats = {n + ip : i 0}let a {a} and consider s = {| x |: x a}.(1) show that if s is an arithmetic progression, then a can be recognized by adfa(2) show that if a can be recognized by a dfa, then s is the union of a nite number of arithmetic",
    "present_kp": [],
    "absent_kp": [
      "finite automata"
    ]
  },
  {
    "text": "what's the relation between bcm and oja's learning rule?. a software i'm using has implemented two unsupervised learning algorithms, oja's and bienenstock, cooper, munro's (bcm) learning rule. i understand that they are two very different algorithms for adjusting a neuron's connection weight, but i was wondering what is the relation between them. do they both have the same plausibility? can they be used together or are they mutually exclusive?",
    "present_kp": [
      "learning"
    ],
    "absent_kp": [
      "theoretical neuroscience",
      "computational modeling"
    ]
  },
  {
    "text": "set baud speed for tty. how do i set the baud speed for a specific tty (in this case a serial port)? i tried using stty -f /dev/tty.iap ispeed 19200but get the error invalid argument for every speed i try (2400, 4800, etc.) except 9600 (the default). i can successfully change the speed in a c program using cfsetspeed. do i need to make a change somewhere else, like the ttys file?",
    "present_kp": [
      "tty",
      "serial port"
    ],
    "absent_kp": [
      "devices",
      "iphone"
    ]
  },
  {
    "text": "should this container be a struct or a class?. i have a class that serves purely as a data container for passing values from a parsing class to a class responsible for saving the data. i have been wondering whether it would be more appropriate as a struct. the class definition is below.internal class datacontainer{ public string firstname { get; set; } public string lastname { get; set; } public guid personid { get; set; } public string address { get; set; } public string phonenumber { get; set; } public string sensor1name { get; set; } public ienumerable<tuple<double?, int>> sensor1readings { get; set; } public string sensor2name { get; set; } public ienumerable<tuple<double?, int>> sensor2readings { get; set; }}the parser uses an iterator block to turn a large csv file into approximately 6000 datacontainers. as they are created, each datacontainer is passed to the savecontainer. the savecontainer immediately reads the values and discards each object. finally, the savecontainer saves all the values to the database:internal class fileparser{ // much yak shaving... private ienumerable<datacontainer> getfiledata() { using (streamreader readfile = new streamreader(this.filepath)) { string tabledata = null; while ((tabledata = readfile.readline()) != null) { var sensor1data = readfile.readline(); var sensor2data = readfile.readline(); datacontainer currentdata = this.createdatacontainer(tabledata, sensor1data, sensor2data); yield return currentdata; } } } private void collectdata() { savecontainer savecontainer = new savecontainer(); foreach (var data in this.getfiledata()) { savecontainer.adddata(data); } savecontainer.save(); }}i have read microsoft's choosing between class and struct guidelines and i think that i mostly understand them (enough to say that this type does not meet the qualifications). i've also read some related stack overflow answers including this and this. they seem to offer a wide variety of opinions on the matter. i have no specific need to change the type definition, but its use is so particular and basic that a class seems unnecessarily complex. would changing this class to a struct offer any compelling advantages or disadvantages?",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "classes",
      "serialization"
    ]
  },
  {
    "text": "correct usage of property vs field vs function in c#. i've been bothered by this line of code i've written and i've been a bit confused into what should be written instead.class someclass{ ibeneficiary _latestbeneficiary => new beneficiary(iban, name);}in context, the field represents the latest version of a beneficiary object that is about to be created, and i want this variable to represent its latest possible version considering whatever is inside those public properties.here are my assumptions and thought process, i'm thinking there is something wrong in there otherwise i wouldn't have an issue.so, clearly, this is a field. it's a field because it is a private variable i'm keeping inside my class, and to recognize it, i add an underscore as a prefix.that field always returns the latest ibeneficiary possible consideringiban and name (irrelevant here). those properties are public and are classic myproperty someproperty { get; set; } defined in the class.i've defined a field with a property getter, the =>. this is confusing because it's not the expected behaviour of a field to always return something new. or is it?i feel like this then should be a function, something like ibeneficiary createlatestbeneficiary (myproperty param1, myotherproperty param2){ return new beneficiary(param1, param2);} or even name it getlatestbeneficiary, but in both cases this looks and feels like a really simple getter, so i'd rather have a property with a single getter, that does exactly this, like the following. right?ibeneficiary latestbeneficiary{ get { return new beneficiary(iban, name); }}but a private property is pretty much a field. isn't it?and with that in mind we're back to square one, using a field.i feel like somewhere in there, one of my statements is wrong.are private properties okay ? or is a property by definition something public, with at least a getter ? or is it okay for a field to not be a plain old variable ?ultimately, how would you write this line of code yourself?",
    "present_kp": [
      "c#",
      "properties"
    ],
    "absent_kp": [
      "coding standards",
      "functions",
      "clean code"
    ]
  },
  {
    "text": "sparse matrix compressed sparse row (csr) in python 2.7. brief introduction for csr:the compressed sparse row (csr) or compressed row storage (crs) format represents a matrix m by three (one-dimensional) arrays, that respectively contain nonzero values, the extents of rows, and column indices. it is similar to coo, but compresses the row indices, hence the name. this format allows fast row access and matrix-vector multiplications (mx). the csr format has been in use since at least the mid-1960s, with the first complete description appearing in 1967.the csr format stores a sparse \\$m n\\$ matrix \\$m\\$ in row form using three (one-dimensional) arrays (\\$a\\$, \\$ia\\$, \\$ja\\$). let \\$nnz\\$ denote the number of nonzero entries in \\$m\\$. (note that zero-based indices shall be used here.)the array \\$a\\$ is of length \\$nnz\\$ and holds all the nonzero entries of \\$m\\$ in left-to-right top-to-bottom (row-major) order.the array \\$ia\\$ is of length \\$m + 1\\$. it is defined by this recursive definition: \\$ia[0] = 0\\$\\$ia[i] = ia[i 1]\\$ + (number of nonzero elements on the (\\$i 1\\$)th row in the original matrix)thus, the first \\$m\\$ elements of \\$ia\\$ store the index into \\$a\\$ of the first nonzero element in each row of \\$m\\$, and the last element \\$ia[m]\\$ stores \\$nnz\\$, the number of elements in \\$a\\$, which can be also thought of as the index in \\$a\\$ of first element of a phantom row just beyond the end of the matrix \\$m\\$. the values of the i-th row of the original matrix is read from the elements \\$a[ia[i]]\\$ to \\$a[ia[i + 1] 1]\\$ (inclusive on both ends), i.e. from the start of one row to the last index just before the start of the next.the third array, \\$ja\\$, contains the column index in \\$m\\$ of each element of \\$a\\$ and hence is of length \\$nnz\\$ as well.for example, the matrix:\\$ \\left (egin{matrix} 0 & 0 & 0 & 0 \\ 5 & 8 & 0 & 0 \\ 0 & 0 & 3 & 0 \\ 0 & 6 & 0 & 0 \\ \\end{matrix} ight)\\$is a 4 4 matrix with 4 nonzero elements, hence:\\$a = [ 5 8 3 6 ]\\$\\$ia = [ 0 0 2 3 4 ]\\$\\$ja = [ 0 1 2 1 ]\\$so, in array \\$ja\\$, the element 5 from \\$a\\$ has column index 0, 8 and 6 have index 1, and element 3 has index 2.my implementation:class csrimpl: def __init__(self, numrows, numcols): self.value = [] self.ia = [0] * (numrows + 1) self.ja = [] self.numrows = numrows self.numcols = numcols def get(self, x, y): previous_row_values_count = self.ia[x] current_row_valid_count = self.ia[x+1] for i in range(previous_row_values_count, current_row_valid_count): if self.ja[i] == y: return self.value[i] else: return 0.0 def set(self, x, y, v): for i in range(x+1, self.numrows+1): self.ia[i] += 1 previous_row_values_count = self.ia[x] inserted = false for j in range(previous_row_values_count, self.ia[x+1]-1): if self.ja[j] > y: self.ja.insert(j, y) self.value.insert(j, v) inserted = true break elif self.ja[j] == y: inserted = true self.value[j] = v break if not inserted: self.ja.insert(self.ia[x+1]-1,y) self.value.insert(self.ia[x+1]-1, v) def iterate(self): result = [] # a list of triple (row, col, value) for i,v in enumerate(self.ia): if i == 0: continue current_row_index = 0 while current_row_index < v-self.ia[i-1]: row_value = i - 1 col_value = self.ja[self.ia[i-1] + current_row_index] real_value = self.value[self.ia[i-1] + current_row_index] result.append((row_value, col_value, real_value)) current_row_index += 1 return result def debug_info(self): print 'value ', self.value print 'ia ', self.ia print 'ja ', self.jaif __name__ == __main__: matrix = csrimpl(4,4) matrix.set(1,0,5) matrix.set(1,1,8) matrix.set(2,2,3) matrix.set(3,1,6) matrix.debug_info() print matrix.iterate()output:value [5, 8, 3, 6]ia [0, 0, 2, 3, 4]ja [0, 1, 2, 1][(1, 0, 5), (1, 1, 8), (2, 2, 3), (3, 1, 6)]",
    "present_kp": [
      "python",
      "python 2.7",
      "matrix"
    ],
    "absent_kp": [
      "algorithm",
      "compression"
    ]
  },
  {
    "text": "how can ubuntu/truecrypt be configured so users can mount volumes if-and-only-if they have proper permissions on the mount-point?. if i add the line: all= /usr/bin/truecrypt to the sudoers file this lets all users mount volumes at arbitrary mount-points. the problem is a user could create a truecrypt volume and then mount it at /etc/apache2 or /var/www -- directories which they shouldn't be able to tamper with.if a user doesn't have sudo rights to run /usr/bin/truecrypt then truecrypt fails after prompting for the administrator/user password.what's the proper way to configure the system/truecrypt so users can mount volumes in a sane/safe way? e.g. they can only mount volumes to mount-points which they own (or have write-access to)?",
    "present_kp": [
      "permissions",
      "mount",
      "truecrypt"
    ],
    "absent_kp": []
  },
  {
    "text": "should i set values using the return or by giving a reference?. suppose i have a mouse position watcher, which should let the user extract the mouse position. should the mouse position be set in the method and returned:mouse_position mouse_watcher::get_mouse_position( void ) const{ mouse_position return_val = mouse_position( this->mp ); // memory stuff so the value can escape this scope and not cause segmentation faults return return_val;}mouse_position mp = mouse_position();mp = mouse_man::get_mouse_position();or the slightly easier way i've found:void mouse_watcher::sync_mouse_position( mouse_position & destination ) const{ // the class handles copying // if the stuff is primitive and uses this syncing method, // seems like a ton of avoided memory mishaps destination.sync_x( this->mp ); destination.sync_y( this->mp );}mouse_position mp = mouse_position();mouse_man::sync_mouse_position( mp );// at this point mp has position valuesi've been used to setting values using the return, but i don't like unnecessarily including memory management if i can help it. should i go back to using returns to keep up with standards?",
    "present_kp": [
      "memory"
    ],
    "absent_kp": [
      "c++"
    ]
  },
  {
    "text": "linux mint 17.1 incredibly slow on amd a8-5600k. i have an htpc and media server running mint 17.1 which is incredibly slow. the hardware specs are:apu - amd a8-5600k (4x 3.6ghz)mb - msi fm2-a55m-p33ram - 4gbm, 1333mhzhdd - boot: wdc wd10ealx-089ba0 (1tb, 7200rpm); other: 4x 3tb, 7200 rpm + 1x 1.5tb, 7200 rpmit used to run win 7 and there were no issues with it, but after a hdd crash i decided to try out mint.since i installed mint a few weeks ago, the computer feels like a very, very old computer. from a clean restart:opening chromium takes around 30 secondsopening the file manager takes 10-15 secondstaking an app like kodi/xbmc from fullscreen to windowed can take anything from 20-60 secondsif try to do something like have amarok scan my music collection, the pc basically freezes. it keeps scanning, but it eventually gets so slow that it takes 5 minutes just to wake up from sleep.the mouse lags in kodi/xbmcyoutube videos can stutter (unrelated to buffering)things that do work well are:video playback in kodi. i can watch 1080p videos with no issue.games. although the system isn't particularly strong, it can play games as expected. cs:go, d3 and skyrim (on very low settings) all work.often, when the computer appears to be completely frozen, ssh or workspaces would still run reasonably smoothly.plex media server usually works well. however, if the pc starts getting very slow, the videos it sends out can stutter.i basically know nothing about ubuntu/linux (this htpc is my first attempt). how can i troubleshoot this?",
    "present_kp": [
      "linux mint",
      "amd"
    ],
    "absent_kp": []
  },
  {
    "text": "nodeflow - how to connect properties in a clean way?. i have implemented a project called nodeflow. as you can see in the picture you can create multiple nodes and connect their properties with other (function)nodes to modify the properties and let the data flow through the nodes to create a result (in this case it is the addition and multiplication to the result 4). i implemented nodeflow in similarity to the node editor in the 3d software blender.you can see that nodeflow is somewhat working, but i am very unhappy about my architecture. so i decided to implement the application in a better way and it would be great if you could tell me what you think. however, i am only providing interfaces because i am right now creating the architecture of my application and i want to discuss this architecture with you.what do you need to know about the nodes?public interface inode{ string name { get; set; } nodetypes type { get; set; } bool hasinputproperties { get; } bool hasoutputproperties { get; } observablecollection<ivalueacceptorproperty> valueacceptorproperty { get; set; } observablecollection<ivalueproviderproperty> valueproviderproperty { get; set; }}more explanationsthe node is the thing you see in the picture as constant value: 1, add function and multiply function. nodes contain a name, input and output properties. i called these properties in my code valueproviderproperty and valueacceptorproperty because calling it input and outputproperty was very confusing while coding and because value providing properties (or output properties) can only be connected with value accepting properties (or input properties) you have a data flow in one direction. that means that the valueaccpetorproperties are taking (or accepting) the value of the connected valueproviderproperty.propertiespublic interface iproperty{ string name { get; set; } propertydatatypes alloweddatatypes { get; set; } iconnector connector { get; set; } inode parentnode { get; set; } bool hasvalue { get; }}public interface ivalueproviderproperty : iproperty{ // this is like variant ipropertyvalue value { get; set; }}public interface ivalueacceptorproperty : iproperty{ // this is like variant ipropertyvalue value { get; }}property code:this implements the valueacceptorproperty to show how i want to use this interface. as you can see the valueacceptorproperty is just forwarding the value of its valueproviderproperty.public class valueacceptorproperty : ivalueacceptorproperty{ public string name { get; set; } public ipropertyvalue value => this.connector.isconnected ? this.connector.connection.valueproviderproperty.value : null; public propertydatatypes alloweddatatypes { get; set; } public iconnector connector { get; set; } public inode parentnode { get; set; } public bool hasvalue => this.value != null;}every property has a connector (the visual of it is the circle next to each property) and the connectors are connected via a connection.connector and connection: (these are in separated files)public interface iconnection{ iconnector valueproviderconnector { get; set; } iconnector valueacceptorconnector { get; set; } ivalueproviderproperty valueproviderproperty { get; set; } ivalueacceptorproperty valueacceptorproperty { get; set; }}public interface iconnector{ bool isconnected { get; set; } iconnection connection { get; set; }}most of the missing definitions for propertydatatypes and so on are enums or other data structures which are in my opinion not that important to discuss the general idea of nodeflow.so my main questions is: do you think that there is a better way to model the nodes, properties, connections and connectors?if you need further information i will update this question to provide whatever you need.",
    "present_kp": [],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "flash messages in asp.net mvc without sessions. i'm developing a web application for windows azure using asp.net mvc 4. i would like to enforce one restriction in the architecture: do not use session. to achieve availability on azure, and since there is no sticky sessions, i would need to store the session data in some central service, probably either sql azure or the caching service. i would rather avoid sessions on the sql database to avoid the increased latency, and the caching service on azure is very expensive for the ammount of memory offered.on the other hand, i would like to have the ability to easily pass flash-style messages among redirects. tempdata is the recommended way to do this, but by default it uses the session object.so i would like to know:is there an alternative way to use tempdata that doesn't require sessions or shared data between servers? cookies perhaps?is there a better alternative i'm overlooking?",
    "present_kp": [
      "asp.net mvc"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "how to find mac or ip address of a device connected to the same ethernet bridge?. i have the following topology:devicex ------ | devicex bridge with two ethernet cards (created with bridge-utils) ---------------- router | | | |devicey ------ | | other devices on the same network (switches, pcs, wifi devices)i have complete control over devicex - it's a linux pc and it has two ethernet adapters, which are bridged with linux bridge-utils to provide lan access for both devicex and devicey.devicey is also a linux pc, but i have no control over it. i know only that it is using dhcp ip address received from the router through my bridge on devicex. devicey might get replaced with another physical device at any time, thus i can't just look at its mac address once and keep it - i need to determine mac address each time my devicex boots or when it detects that one of its two ethernet connections has been reset (cable disconnected and connected again etc.).it is always guaranteed that only these two devices will be connected to the bridge on devicex, and no one else.there might be many other devices connected to the router, but i need only the address of devicey which is always directly connected to one of two ethernet ports.it might not be deal-breaker if i also get address of the router itself - it will be known beforehand and i can filter it out, as long as i have adresses of only two devices - the router and devicey.now the question:from devicex, how do i reliably find mac or ip address of devicey? more info:i use bridge-utils on devicex because devicey should be in the same lan as all the other devices in the lan. custom routing from devicex to devicey is not an option because it would create a new subnetwork and it would require nat and what not to make devicey work as expected. bridge-utils is the simplest solution.",
    "present_kp": [
      "ip",
      "bridge",
      "mac address"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i display as new lines in multitail?. i am using multitail to monitor logs while i program. i really like this tool. however, it is hard to use it to view object output in a php error log because new line characters are not processed. does anyone know of a way to achieve this?",
    "present_kp": [
      "php",
      "multitail"
    ],
    "absent_kp": [
      "debugging"
    ]
  },
  {
    "text": "if $n^{\\log n}$ is not polynomial or exponential, then what this function is called?. i just found this sentence on page 6 of garey and johnson's computers and intractability.any algorithm whose time complexity function cannot be so bounded is called an exponential time algorithm (although it should be noted that this definition includes certain non-polynomial time complexity functions, like $n^{\\log n}$, which are not normally regarded as exponential functions).my question as following,if $n^{\\log n}$ is not polynomial nor exponential, then what this function is called? does this have a name or special cases or not?thank you.",
    "present_kp": [
      "polynomial time"
    ],
    "absent_kp": [
      "algorithms",
      "terminology"
    ]
  },
  {
    "text": "getting a connection to the database and executing statements. i've got two classes for getting a connection to the database and executing things, class 'a' was made by me and class 'b' was made by a colleague, we were wondering which one is better for use (security, efficiency etc), that's why we are asking it here. which one is better, and why is it? and how can we improve that one?class a: class databasehandler {private $db;private static $instance;/*this is the constructor of the php class, we create the object for databasehandler here.*/function __construct() { $this->createconnection();}/*we return an instance, if the object isn't created yet, we make it a new object and then return it.*/public static function getinstance() { if(!self::$instance) { self::$instance = new databasehandler(); } return self::$instance;} /* returns the connection to the database, so we can use it to create statments */public function getconnection() { return $this->db;}/*create a connection to the database, using constants to set the correct data for the connection.*/private function createconnection() { require 'config.php'; try { $this->db = new pdo(mysql:host= . host . ;dbname= . database . ;charset=utf8, username, password); $this->db->setattribute(pdo::attr_errmode, pdo::errmode_warning); } catch(pdoexception $e) { echo $e->getmessage(); } }}?>class b:class databaseconnection{ public $dbc, $stmt, $result; public function __construct() { global $dbc; $dbc = new pdo(mysql:host=<removed host from post>;dbname=redacted, redacted, redacted); $dbc->setattribute(pdo::attr_errmode, pdo::errmode_exception); }public function closeconn (){ global $dbc; $dbc = null;}public function selectall ($tablename){ global $dbc, $stmt, $result; $stmt = $dbc->prepare(select * from $tablename); $stmt->execute(); $result = $stmt->fetchall(); $this->closeconn(); return $result;}public function getconnection() { global $dbc; return $dbc;}public function updatestock ($artnr, $amounttodecline){ global $dbc, $stmt, $result; $stmt = $dbc->prepare(select 'stock' from 'artikelen' where 'artnr' = $artnr); $stmt->execute(); $result = $stmt->fetchall(); $updatedstock = $result[0]['stock'] - $amounttodecline; if ($updatedstock < 0) { return false; $this->closeconn(); } else { $stmt2 = $dbc->prepare(update 'artikelen' set 'stock' = '$updatedstock' where 'artikelen'.'artnr' = $artnr); $stmt2->execute(); return true; $this->closeconn(); }}}we are asking this, as we are planning to use this on our first project with an actual customer.",
    "present_kp": [
      "php",
      "mysql",
      "pdo"
    ],
    "absent_kp": [
      "comparative review"
    ]
  },
  {
    "text": "combining .css and .js files. this is one of my first oop programs in normal php, without any framework. this combines all .css files into one and all .js files into one, and it works. are there any suggestion on what i can make better in terms of oop or anything else?this is how it works:i run this: <url> have .htaccess that passes everything to index.php.i extract the type as css and page as styleindex by exploding styleindex.css.i get the array of files that needs to be combined for this page and join them.i display this on the browser with the correct mime type and cache header.<?php define('debugmode',01); class resourcehandler { /** * @var $filestoparse files that needs to be parsed */ private $filestoparse = array(); /** * @var $type weather js or css */ private $type; /** * @var $page name/category of the page */ private $page; /** * @var $allowedtypes array of allowed types js or css */ private $allowedtypes = array('css','js'); /** * @var $cachetime time for which cache is valid */ private $cachetime = 610000; function __construct($type, $page) { $this->settype($type); $this->setpage($page); header('etag: ei07072012745'); //header('content-type: text/'.$this->type. charset: utf-8); if (substr_count($_server['http_accept_encoding'], 'gzip')) { //ob_start(ob_gzhandler); } else { ob_start(); } header (vary: negotiate,accept-language,accept-charset); header (cache-control: public); header('content-disposition: attachment; filename='.$this->page.'.'.$this->type.''); if(debugmode ==0) { $expire = expires: . gmdate(d, d m y h:i:s, time() + $this->cachetime) . gmt; header ($expire); } } function setpage($pagename) { $resource = explode('.',$pagename); $this->page = $resource[0]; } function settype($type) { $type = strtolower($type); /*type needs to be js or css else dont proceed further*/ if(!in_array($type,$this->allowedtypes)) { exit; } $this->type = $type; } /** * function to minify data * @return $filecontent minified file data */ private function minifyfiles($data) { /* remove comments */ $data = preg_replace('!/\\*[^*]*\\*+([^/][^*]*\\*+)*/!', '', $data); /* remove tabs, spaces, newlines, etc. */ $data = str_replace(array( , , , , ' ', ' ', ' '), '', $data); return $data; } /** * function to parse file and merge into one variable * @return $filecontent merged file data */ private function parsefiles() { $filecontent = '' ; foreach($this->filestoparse as $file) { $filecontent = file_get_contents($file); } return $filecontent; } function __destruct() { ob_end_flush(); } /** * function to display css file * @return $output returns the combined, compresssed and gzipped data */ private function css() { switch($this->page) { case 'index' : $this->filestoparse = array('style12.css','jquery.autocomplete.css'); break; default : header($_server[server_protocol]. 404 not found); exit; } $data = $this->parsefiles('css'); if(debugmode ==0) { $data = $this->minifyfiles($data); } return $data; } /** * function to display js file * @return $output returns the combined and gzipped data */ private function js() { switch($this->page) { case 'index' : $this->filestoparse = array('jquery-1.6.2.js','jquery.autocomplete.js','facebox.js'); break; default : header($_server[server_protocol]. 404 not found); exit; } $data = $this->parsefiles('js'); return $data; } function load() { $type = $this->type; $cwd = getcwd(); chdir($type); echo $this->$type(); chdir($cwd); } } $request = explode(/resources/, $_server['request_uri']); $params = array_filter(explode(/, $request[1])); if(isset($params[0]) && isset($params[1])) { $resource = new resourcehandler($params[0],$params[1]); $resource->load(); } else { header($_server[server_protocol]. 404 not found); } ?>",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "given a mechanical assembly as a graph, how to find an upper bound on number of assembly paths. the rules are that you can only build from an existing part, so in the example below, b is the only option for the first move = a.a mechanical assembly might be represented as follows: e | c |a-b | d | fwhere the valid assembly paths when starting from a are:a, b, c, e, d, fa, b, c, d, e, fa, b, c, d, f, ea, b, d, f, c, ea, b, d, c, f, ea, b, d, c, e, fthis is a fairly simple example, but providing an upper bound for an arbitrary assembly is difficult since it's related to the connectivity of the parts.n! would be an absolute upper bound i guess, but i'm hopping to find something a little better.i've also looked at representing the graph with the parts (a, b, c, etc) as the edges and doing kirchhoff's theorem, but that doesn't work for sparsely connected graphs like the example above.any information about the problem would help. i'm not sure if there's a formal description of this type of problem or not.",
    "present_kp": [
      "graphs"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "what's the best replacement for a circa 2004 apple cinema hd 30?. for about 10 years now, i've really enjoyed my 30 apple cinema hd (2560x1600). it's showing its age, and i'd like to replace it with something a more modern. what's the best replacement? here are the features i'd like:large screen (>=30);matte screen or at least low-glare;mainly used for coding/writing; fast response needed, e.g., for games, isn't important;can be driven by a late-model macbook air.i'm indifferent to the specific panel technology. budget: up to $1600.",
    "present_kp": [],
    "absent_kp": [
      "monitors"
    ]
  },
  {
    "text": "encodingtranslatorstream - a stream object that translates character encoding. this class is a stream designed to perform character encoding translation. so you instantiate it, pass an input stream, and specify the input encoding and desired output encoding, so that when you read from this stream, is will translate the source data from one encoding type to another.i'm interested in a general code review on style/organization of code as well as for any apparent bugs and performance considerations/// <summary>/// this class is a stream designed to perform character encoding translation from one encoding to another./// </summary>public class encodingtranslatorstream : system.io.stream{ /// <summary> /// input data. this is the data that well be decoded, and re-encoded in the specified encoding /// </summary> private system.io.stream strinput_m; /// <summary> /// input stream reader. this will be responsible for decoding the input bytes into unicode characters based on the specified input encoding /// </summary> private streamreader srinput_m; /// <summary> /// output stream reader. this will be responsible for encoding unicode characters into bytes based on the specified output encoding /// </summary> private streamwriter swoutput_m; /// <summary> /// holds a stream of bytes, and when read, the bytes are automatically removed from the stream /// </summary> private stream strout_m; /// <summary> /// constructor. specifies the input and output encoding. /// </summary> /// <param name=strinput>input data, that will be decoded and re-encode into the specified output encoding</param> /// <param name=encodingin>the input character encoding to use.</param> /// <param name=encodingout>output encoding</param> /// <remarks> /// the character encoding is set by the encoding parameter. /// the streamreader object attempts to detect the encoding by looking at the first three bytes of the stream. it automatically recognizes utf-8, little-endian unicode, and big-endian unicode text if the file starts with the appropriate byte order marks. otherwise, the user-provided encoding is used. /// </remarks> public encodingtranslatorstream(system.io.stream strinput, encoding encodingin, encoding encodingout) { this.init(strinput, encodingout); this.srinput_m = new streamreader(strinput, encodingin); } /// <summary> /// constructor. specifies the input and output encoding, and a byte order mark detection option for the input stream /// </summary> /// <param name=strinput>input data, that will be decoded and re-encode into the specified output encoding</param> /// <param name=encodingin>the input character encoding to use.</param> /// <param name=encodingout>output encoding</param> /// <param name=bdetectinputencodingfrombyteordermarks>indicates whether to look for byte order marks at the beginning of the input stream.</param> /// <remarks> /// this constructor initializes the encoding as specified by the encoding parameter. /// the bdetectinputencodingfrombyteordermarks parameter, if true, detects the encoding by looking at the first three bytes of the stream. it automatically recognizes utf-8, little-endian unicode, and big-endian unicode text if the file starts with the appropriate byte order marks. otherwise, the user-provided encoding is used. /// </remarks> public encodingtranslatorstream(system.io.stream strinput, encoding encodingin, bool bdetectinputencodingfrombyteordermarks, encoding encodingout) { this.init(strinput, encodingout); this.srinput_m = new streamreader(strinput, encodingin, bdetectinputencodingfrombyteordermarks); } /// <summary> /// constructor. specifies an output encoding, and a byte order mark detection option for the input stream /// /// </summary> /// <param name=strinput>input data, that will be decoded and re-encode into the specified output encoding</param> /// <param name=encodingout>output encoding</param> /// <param name=bdetectinputencodingfrombyteordermarks>indicates whether to look for byte order marks at the beginning of the input stream.</param> /// <remarks> /// this constructor initializes the encoding to utf8encoding /// the detectencodingfrombyteordermarks parameter, if true, detects the encoding by looking at the first three bytes of the stream. it automatically recognizes utf-8, little-endian unicode, and big-endian unicode text if the file starts with the appropriate byte order marks. otherwise, the utf8encoding is used. see the encoding.getpreamble method for more information. /// </remarks> public encodingtranslatorstream(system.io.stream strinput, bool bdetectinputencodingfrombyteordermarks, encoding encodingout) { this.init(strinput, encodingout); this.srinput_m = new streamreader(strinput, bdetectinputencodingfrombyteordermarks); } private void init(stream strinput, encoding encodingout) { this.strinput_m = strinput; //because the output bytes of an encoding translation can be larger than what we want in a single read, we need //somewhere to store it this.strout_m = new memoryqueuebufferstream(); //this.strout_m = new memorystream(); this.swoutput_m = new streamwriter(this.strout_m, encodingout); } public override bool canread { get { return this.strinput_m.canread; } } public override bool canseek { get { return this.strinput_m.canseek; } } public override bool canwrite { get { return false; } } public override void flush() { this.strinput_m.flush(); } /// <summary> /// returns the length of the string in bytes. note, depending on the encoding type of the stream, the byte length will vary, /// as characters may require multiple bytes for certain encodings. some encodings allow different byte lengths depending on the /// character. this function will return the maximum amount of bytes that the string may take, as returning the actual /// requires processing the entire string which is time and memory consuming. /// </summary> public override long length { get { //this returns the length of the input stream return this.strinput_m.length; } } /// <summary> /// the actual position in bytes (not characters) /// </summary> public override long position { get { return this.strinput_m.position; } set { this.strinput_m.position = value; } } /// <summary> /// our temporary pool of characters. this acts as the middle-man when translating encodings. bytes are decoded into this as chars, then encoded back into /// bytes. we will re-use this cache so we don't have to keep instantiating the array. /// </summary> private char[] lstchars_m; /// <summary> /// reads bytes from the stream. bytes will be returned in the output encoding specified, regardless of the input encoding /// </summary> /// <param name=buffer>buffer to fill</param> /// <param name=offset>start position in the buffer</param> /// <param name=count>count of bytes to read and put in the buffer. buffer needs to be long enough to accomodate <paramref name=offset/> + <paramref name=count/></param> /// <returns></returns> public override int read(byte[] buffer, int offset, int count) { if (this.srinput_m.currentencoding.equals(this.swoutput_m.encoding)) { //the encodings are the same, lets just bypass the translation stuff return this.strinput_m.read(buffer, offset, count); } //we are reading data in one encodng, and outputing the data using another encoding //the process is to read bytes from an input stream, decode them, based on a specified encoding, //to chars which are unicode then encode them to bytes based on a specified encoding //note that the number of input bytes may be more or less than the number of output bytes because //some encodings are multibyte and some are not. even if both encodings are multibyte they still may not //use the same number of bytes for any given character. //validate the parameters passed in this.validatebufferargs(buffer, offset, count); int itotalbytesread = 0; //if there are decoded bytes still in the output stream that havent been read, return them if (this.strout_m.length > 0) { //read from output stream into the read buffer int ibytesread = this.strout_m.read(buffer, offset, count); itotalbytesread += ibytesread; //while there are still bytes to read from the output stream and we have reached our limit while (ibytesread > 0 && itotalbytesread < count) { ibytesread = this.strout_m.read(buffer, offset + itotalbytesread, count); itotalbytesread += ibytesread; } } int iremainingbytestoread = count - itotalbytesread; //if we still haven't reached our limit if (iremainingbytestoread > 0) { //we need to convert our input to chars, so ensure we have a buffer we can re-use, or create a new one if (this.lstchars_m == null || lstchars_m.length < count) { //the max number of chars we will need to deal with is the number of bytes we want to read. this.lstchars_m = new char[count]; } //convert our input bytes to chars. reading from our input streamreader will take care of decoding bytes, from the input stream, into chars. //our streams read method accepts a byte count of bytes to return, but the streamreader requires a char count. depending on the input encoding //specified, there may be more than 1 byte per character. we don't know exactly how many bytes to read from the input stream, so we will //use the byte count as the char count. at most this will read more bytes than we actually want, but that's ok. int icharsread = this.srinput_m.read(this.lstchars_m, 0, iremainingbytestoread); if (icharsread > 0) { //convert our chars to bytes using the specified output encoding. writing to our output stream writer will take care of encoding. //converting chars to bytes may result in more bytes than were requested but because we're writting to an output stream that is a memoryqueuebufferstream //that stream will hold on to the extra bytes, allowing us to only return what was asked for now, and let us return the rest on subsequent calls //to this read method. long loutputposition = this.strout_m.position; this.swoutput_m.write(this.lstchars_m, 0, icharsread); this.swoutput_m.flush(); //if we need to go back the pre-write position. //memorystream position will advance as data is written to it //memoryqueuebufferstream position will not advance as data is written to it if (this.strout_m.canseek && this.strout_m.position != loutputposition) { this.strout_m.position = loutputposition; } //the output stream now contains a series of bytes that we can return. when we read bytes from the stream, the data will be removed from the stream int ibytesread = this.strout_m.read(buffer, offset + itotalbytesread, count); itotalbytesread += ibytesread; } } return itotalbytesread; } public override long seek(long offset, system.io.seekorigin origin) { return this.strinput_m.seek(offset, origin); } public override void setlength(long value) { throw new notsupportedexception(setting the length of the stream is not supported.); } public override void write(byte[] buffer, int offset, int count) { throw new notsupportedexception(writing to the stream is not supported.); } private void validatebufferargs(byte[] buffer, int offset, int count) { if (offset < 0) { throw new argumentoutofrangeexception(offset, offset must be non-negative); } if (count < 0) { throw new argumentoutofrangeexception(count, count must be non-negative); } if ((buffer.length - offset) < count) { throw new argumentexception(requested count exceeds available size); } }}",
    "present_kp": [
      "stream"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "detect if key is pressed from script. i would like to detect if a key is being pressed when running a script. i have the following script:#!/bin/bashsleep 0.5xte 'str sometext'i run this script using a shortcut to paste sometext where i'm at in kde. i used a sleep 0.5 here because the script itself is run with a shortcut that uses ctrl and alt. if the sleep 0.5 is omitted, the result is that ctrl+s, ctrl+o, etc... is sent. i think the solution would be to add some bussy wait at the beginning that would block untill no keys are being pressed. how can i get this to work in the script?",
    "present_kp": [
      "xte"
    ],
    "absent_kp": [
      "scripting",
      "x11",
      "keyboard"
    ]
  },
  {
    "text": "count number of words between 2 fixed words. i have a file as belowfheadtheadtcusttitemttendttailtheadtcusttcusttitemtitemttendttailtheadtcusttitemttendttailtheadtcusttcusttitemttendttaili need to count thr number of occurrence of only tcust records between thead and ttail where the occurrence is more than once and print that file name and line.there will be multiple files so i need to print the filename as well.expected result is theadtcusttcusttitemtitemttendttailtheadtcusttcusttitemttendttail name of file",
    "present_kp": [],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "how do i make a subdomain visible at new url, as if it is the url?. i've built a site at subdomain.domain.org using wordpress with nixihost. it is done. i'd like to make it visible at <url> and look like the visitor is at <url> not subdomain.domain.org/page1. there should be a way to do this by pointing dns records, or something? could you please direct me to the appropriate information/instructions to make this happen?",
    "present_kp": [
      "wordpress",
      "dns",
      "subdomain"
    ],
    "absent_kp": []
  },
  {
    "text": "detail of acceptance criteria in user story. i have the following example for a user story with acceptance criteria.i would like to know if i am allowed to describe how the gui must be changed to support the new feature. how much detail can acceptance criteria have? this is my example:user story:as forum administrator i will connect persons in groups, so that people can get organized.acceptance criteria:the creation of a person group happens below a person group pool (person group pool is an object also visually available in the current software system)the creation happens with a context menu of the persongroup pool. below the pool one can create new groups.a person group contains: person group-id, description, remarkmay that be relevant an right acceptance criteria? because i describe how you can create a new group by opening a context menu.",
    "present_kp": [],
    "absent_kp": [
      "scrum"
    ]
  },
  {
    "text": "how to to remove libgcj from debian?. i am doing java programming on debian. by default debian 6.x ships with libgcj jvm. on starting eclipse it shows a warning that this jvm is deprecated and may cause problems. for this reason i downloaded the jvm from oracle's site and installed it. however after installing the oracle jvm the default jvm on system is still libgcj.when i type java -version i get following output - java version 1.5.0gij (gnu libgcj) version 4.4.5how should i remove this from my system? and after that how should i set the newly installed jvm to be the default one. this would involve two things - setting the bin directory on system path.making javaw the default program when a jar is double clicked.i'm familiar with these tasks on windows but not on linux. thanks.",
    "present_kp": [
      "debian",
      "java"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "archlinux: wifi-menu and installing dialog. i have followed the instructions at <url> installing archlinux on an older computer.i have no wired connections available and the installation was done using wifi. however when i try to start the wifi-menu after the installation i'm prompted about the dialog package. of course i can't install it without internet connection (i can't even use pacman -sy).i reboot and use the cd. when i want to install the dialog package it says it's already installed. i install it anyway and when i reboot the computer has no idea what i'm on about when i try to launch wifi-menu; it asks for the dialog package again - that needs to be downloaded. how do you get out of this catch21 situation?",
    "present_kp": [],
    "absent_kp": [
      "arch linux"
    ]
  },
  {
    "text": "why install a cms for clients?. i am a beginner freelancer eagerly trying to get my first client but i am wondering is having a cms for a website really that important? before i thought about this question i thought that it goes without saying that the client would benefit from having a cms for their website, that they would love to be able to edit their content on their own. but then i realized it's not that simple.one of my biggest concerns actually is a monetary one. if you install a cms for a client then they depend on you less which means you will do less work for them which means you will make less money from that client. sorry to sound greedy, but that really seems like the reality. or am i missing something?at the same time, if you build sites without a cms doesn't that make you seem less professional to future potential clients?",
    "present_kp": [
      "cms",
      "content",
      "freelancer"
    ],
    "absent_kp": [
      "management",
      "system"
    ]
  },
  {
    "text": "parallel multiplier: an implementation of 'recursivetask'. this class is my attempt at creating a re-usable class that simplifies the parallel calculation of products. i would appreciate hints on all aspects especially the value of the threshold for which the best performance is obtained.import java.math.biginteger;import java.util.concurrent.recursivetask;import static java.math.biginteger.one;/** * utility class that uses recursion and multi-threading to compute the * product of all the (big)integers from a given lower limit (inclusive) to a * given upper limit (exclusive). this is useful in calculating the factorial * of numbers, or the number of combinations and permutations. * * @author subhomoy haldar * @version 1.0 */public class parallelmultiplier extends recursivetask<biginteger> { /** * the threshold beyond which recursion and multithreading starts. */ private static final biginteger threshold = biginteger.valueof(500); private final biginteger upper; private final biginteger lower; /** * creates a new instance of parallelmultiplier with the desired limits. * * @param lowerlimit the inclusive lower limit. * @param upperlimit the exclusive upper limit. */ public parallelmultiplier(final biginteger lowerlimit, final biginteger upperlimit) { if (lowerlimit.compareto(upperlimit) >= 0) { throw new illegalargumentexception(lower limit >= upper limit : + upperlimit + >= + lowerlimit); } upper = upperlimit; lower = lowerlimit; } /** * returns the required product. * * @return the required product. */ @override protected biginteger compute() { if (upper.subtract(lower).compareto(threshold) <= 0) { // perform sequential multiplication biginteger product = one; for (biginteger i = lower; i.compareto(upper) < 0; i = i.add(one)) product = product.multiply(i); return product; } biginteger mid = upper.add(lower).shiftright(1); parallelmultiplier multiplier1 = new parallelmultiplier(lower, mid); parallelmultiplier multiplier2 = new parallelmultiplier(mid, upper); multiplier1.fork(); // on a (hopefully) separate thread // combine and return result return multiplier2.compute().multiply(multiplier1.join()); }}just to show that my approach actually has some benefits:i have a dual core, intel pentium b950 processor of frequency 2.10 ghz. i have tested this on a 64-bit ubuntu system. i realized that the threshold value was too low, so it set it to 10_000. after that, i wrote some test code to time the sequential and the parallel approaches to calculate the factorial of 100_000.the sequential approach:// ... the limit defined, timer set up...biginteger i = one, product = one;for (; i.compareto(limit) <= 0; i = i.add(one)) product = product.multiply(i);system.out.println(product.tostring().length());the parallel approach:// ... the limit defined, timer set up...parallelmultiplier multiplier = new parallelmultiplier(one, limit.add(one));biginteger product = multiplier.compute();system.out.println(product.tostring().length());the number of digits produced in each case is same (=456574), therefore, verifying that the code for the parallelmultiplier works correctly. but there was a major difference in the time interval:sequential: ~5.9 seconds (average)parallel : ~1.2 seconds (average)any suggestions to further improve the performance are welcome.",
    "present_kp": [
      "java",
      "performance",
      "multithreading",
      "recursion"
    ],
    "absent_kp": []
  },
  {
    "text": "first domain-driven user entity class. i'm still learning about domain driven design, and i have created my first entity class user.is this fully compliant with the ddd principles? particularly my setters because i have business rules in them. any other suggestions would be highly appreciated as well.namespace models\\entities;class user{ private $id; private $firstname; private $lastname; private $email; private $password; private $registerdate; public function setid($id) { if (!$this->id) { if (is_int($id) && $id >= 1) { $this->id = $id; return $this; } throw new \\invalidargumentexception('id must be a positive integer.'); } throw new \\invalidargumentexception('id has already been set.'); } public function getid() { return $this->id; } public function setfirstname($firstname) { if (is_string($firstname) && !empty($firstname) && ctype_alpha($firstname)) { $length = $this->stringlength($firstname); if ($length >= 1 && $length <= 35) { $this->firstname = $firstname; return $this; } } throw new \\invalidargumentexception('first name must be an alpha string inclusively between 1 and 35 characters.'); } public function getfirstname() { return $this->firstname; } public function setlastname($lastname) { if (is_string($lastname) && !empty($lastname) && ctype_alpha($lastname)) { $length = $this->stringlength($lastname); if ($length >= 1 && $length <= 35) { $this->lastname = $lastname; return $this; } } throw new \\invalidargumentexception('last name must be an alpha string inclusively between 1 and 35 characters.'); } public function getlastname() { return $this->lastname; } public function getfullname() { return $this->firstname . ' ' . $this->lastname; } public function setemail($email) { if (is_string($email) && !empty($email)) { $sanitized = filter_var($email, filter_sanitize_email); $isvalid = filter_var($sanitized, filter_validate_email); $isvalid = $isvalid ? $this->stringlength($email) <= 254 : false; if ($email === $sanitized && $isvalid) { $this->email = $email; return $this; } } throw new \\invalidargumentexception('email must be a string in this format: [local]@[domain].[ext].'); } public function getemail() { return $this->email; } public function setpassword($password) { if (is_string($password) && !empty($password)) { $length = $this->stringlength($password); if ($length >= 6 && $length <= 60) { $this->password = $password; return $this; } } throw new \\invalidargumentexception('password must be a string inclusively between 6 and 60 characters.'); } public function getpassword() { return $this->password; } public function setregisterdate($date) { if (is_int($date) && !empty($date)) { // to do: date validation unix timestamp is_int $this->registerdate = $date; return $this; } throw new \\invalidargumentexception('register date must be an integer and valid unix timestamp.'); } public function getregisterdate() { return $this->registerdate; } private function stringlength($input) { $encoding = mb_detect_encoding($input); $length = mb_strlen($input, $encoding); return $length; }}",
    "present_kp": [
      "ddd"
    ],
    "absent_kp": [
      "php",
      "object oriented"
    ]
  },
  {
    "text": "css reduction for faster loading / less bandwidth. is compacting css / removing unused rules for a specific page worthwhile in terms of bandwidth or can we rely on caching (headers/last-modified) to remove this overhead in the wild?cheersalso, good luck with the beta everyone!",
    "present_kp": [
      "css",
      "bandwidth"
    ],
    "absent_kp": [
      "optimization"
    ]
  },
  {
    "text": "binary search for inserting in array. i have written a method that uses binary search to insert a value into an array.it is working, but i would like to get a second opinion to see if i didn't write too much code for it. aka doing same thing twice for example.the code looks for the right index for insertion and is called by an insert method that uses that index value to insert.here is the code:public class ordarray { final private long[] a; // ref to array int nelems; // number of dataitems int curin; //---------------------------------------------------------------------- public ordarray(int max) { // constructor a = new long[max]; // create array nelems = 0; } public int binaryinsert(long insertkey) { int lowerbound = 0; int upperbound = nelems - 1; while (true) { curin = (upperbound + lowerbound) / 2; if (nelems == 0) { return curin = 0; } if (lowerbound == curin) { if (a[curin] > insertkey) { return curin; } } if (a[curin] < insertkey) { lowerbound = curin + 1; // its in the upper if (lowerbound > upperbound) { return curin += 1; } } else if (lowerbound > upperbound) { return curin; } else { upperbound = curin - 1; // its in the lower } } } public void display() { // display array contents for (int j = 0; j < nelems; j++) { // for each element, system.out.print(a[j] + ); // display it } system.out.println(); } public void insert(long value) { // put element into array binaryinsert(value); int j = curin; int k; for (k = nelems; k > j; k--) { // move bigger ones one up. a[k] = a[k - 1]; } a[j] = value; // insert value nelems++; // increment size. }}public static void main(string[] args) { // todo code application logic here int maxsize = 100; // array size ordarray arr; // reference to array arr = new ordarray(maxsize); // create array arr.insert(77); // insert 10 items arr.insert(99); arr.insert(44); arr.insert(55); arr.insert(22); arr.insert(88); arr.insert(11); arr.insert(00); arr.insert(66); arr.insert(33); arr.display(); }feedback appreciated.",
    "present_kp": [
      "array",
      "binary search"
    ],
    "absent_kp": [
      "java",
      "reinventing the wheel"
    ]
  },
  {
    "text": "my customer wants me to record a video of how i develop his software product. working as a freelancer, i often see strange requests from my customers, some of which can negatively affect my daily work, and others trying to set some sort of control. i usually encounter those things during preliminary negotiations, so it's easy enough at this state to explain to the customer that i do care about my work and productivity and expect my customers to trust my work.things were much harder on a project i just accepted, since it's only after the end of the negotiations (the contract being already signed and not mentioning anything about video tracking) and after i started to work on the project that my customer requested that i record a video of all i do on my machine when working on his project, that is, a video which will show that i move the cursor, type a character, open a file, move a window, etc.i work in my own company, using my own pcs.i answered to this customer that such request cannot be accepted, since:hundreds of hours of work on a dual-screen pc will require a large amount of disk space for the recorded videos. if i don't care about space, i do care about this customer wasting my bandwidth downloading those videos.recording a video can affect the overall performance and decrease my productivity (which is not actually true, since the machine is powerful enough to record this video without performance loss, but, well, it still looks like a valid argument).i can't always remember to turn the video recording on before starting the work, and off at the end.it may be a privacy concern. what if i switch to my mails when recording the video? what if, to open the directory with the files about this customers project, i first open the parent directory containing the list of all of my customers?such video cannot be a reliable source to track the cost of a project (i'm paid by the hour), since some work is done with just a pencil and a paper (which is actually true, since i do lots of draft work without using the pc).despite those points, the customer considers that if i don't want to record the video, it's because i have something to hide and want to lie about the real time spent on his project.how to explain to him that it is not an usual practice for the freelancers to record the videos of their daily work, and that such extravagant requests must be reserved to exceptional circumstances? the most frequent example is to be requested to work through remote desktop on a more-than-slow server which uses a more-than-slow internet connection, or to be forced to use an outdated software as windows me without serious reasons as legacy support. in fact, i already did a lot of management and system design related work, which is essential, but usually misunderstood by customers and perceived as a waste of time and money. observing the concerned customer, i'm pretty sure that he will refuse to pay a large amount of money for what was already done, since there is actually zero lines of code. even if legally i can easily prove that there was a lot of work on design level, i don't want to end my relation with this customer in a court. which is not as risky as it could be, since i gave to this customer the expected and the maximum cost of the project, so the customer is sure to never be asked to pay more than the maximum amount, specified in the contract, even if the real work costs more. one case when i effectively record on my own initiative the video of actions is when i have to do some manipulations directly on a production server of a customer, especially when it comes to security issues. recording those steps may be a good idea to know precisely what was done, and also ensure that there were no errors in my work, or see what were those errors.update:first of all, thank you for all your answers and comments.since the question attracted much more attention and had much more answers than i expected, i imagine that it can be relevant to other people, so i add an update. first, to summarize the answers and the comments, it was suggested to (ordered randomly):suggest other ways of tracking, as shown in twitter code swarm video, or deliver a short milestone with a simple, clear deliverable, followed by more complex milestones, etc.explain that the video is not a reliable source and can be faked, and that it would be difficult to implement, especially for support.explain that the video is not a reliable source since it shows only a small part of the work: a large amount of work is done without using a computer, not counting the extra hours spent thinking about a solution to a problem.stick with the contract; if the customer wants to change it, he must expect new negotiations and a higher price.do the video, but require that the customer put [the] entire fee into an escrow account, require a lawyer to video tape all billable time, etc., in other words, operate in an environment void of trust, requiring the customer to support the additional cost.search for the laws which forbid this. several people asked in what country i live. i'm in france. such laws exist to protect the employees of a company (there is a strict regulation about security cameras etc., but i'm pretty sure nothing forbids a freelancer to sign consciously a contract which forces him to record the screen while he works on a project.just do and send the videos: the customer will watch a few ten second snippets of activity he won't understand, then throw those videos away.say no. after all, it's my business, and i'm the only one to decide how to conduct it. also, the contract is already signed, and has nothing about video tracking.say no. the processes and practices i employ in my company can be considered as trade secrets and are or can be classified.quit. if the relation starts like this, chances are it will end badly soon or later. also, if he's treating you like a thief - and that is what he's suggesting - then it's just going to get worse later when xyz feature doesn't work exactly the way he envisioned.while all those suggestions are equally valuable, i've personally chosen to say to my customer that i accept to do the videos, but in this case, we must renegotiate the contract, keeping in mind that there will be a considerable cost, including the additional fee for copyright release. the new overall cost would be in average three times the actual cost of the project. knowing this customer, i'm completely sure that he would never accept to pay so much, so the problem is solved.second update:the customer effectively declined the proposal to renegotiate the original contract, taking in account the considerable additional cost.",
    "present_kp": [
      "trust"
    ],
    "absent_kp": [
      "freelancing",
      "time management",
      "customer relations"
    ]
  },
  {
    "text": "can a vm swap to host main memory.?. while my developer machine has a lot of memory, my vmware vm is 32 bit only and needs some swap space. can i make it to swap into the host memory?if so, is it possible to use compressed swap space for this in case the host memory gets exhausted? i want to avoid swapping to disk as it's damn slow compared to anything else.",
    "present_kp": [
      "vmware",
      "swap"
    ],
    "absent_kp": []
  },
  {
    "text": "which of these algorithms is best for my goal?. i have created a program that restricts the mouse to a certain region based on a black/white bitmap. the program is 100% functional as-is, but uses an inaccurate, albeit fast, algorithm for repositioning the mouse when it strays outside the area. currently, when the mouse moves outside the area, basically what happens is this:a line is drawn between a pre-defined static point inside the region and the mouse's new position. the point where that line intersects the edge of the allowed area is found. the mouse is moved to that point.this works, but only works perfectly for a perfect circle with the pre-defined point set in the exact center. unfortunately, this will never be the case. the application will be used with a variety of rectangles and irregular, amorphous shapes. on such shapes, the point where the line drawn intersects the edge will usually not be the closest point on the shape to the mouse. i need to create a new algorithm that finds the closest point to the mouse's new position on the edge of the allowed area. i have several ideas about this, but i am not sure of their validity, in that they may have far too much overhead. while i am not asking for code, it might help to know that i am using objective c / cocoa, developing for os x, as i feel the language being used might affect the efficiency of potential methods.my ideas are:using a bit of trigonometry to project lines would work, but that would require some kind of intense algorithm to test every point on every line until it found the edge of the region... that seems too resource intensive since there could be something like 200 lines that would have each have to have as many as 200 pixels checked for black/white....using something like an a* pathing algorithm to find the shortest path to a black pixel; however, a* seems resource intensive, even though i could probably restrict it to only checking roughly in one direction. it also seems like it will take more time and effort than i have available to spend on this small portion of the much larger project i am working on, correct me if i am wrong and it would not be a significant amount of code (>100 lines or around there).mapping the border of the region before the application begins running the event tap loop. i think i could accomplish this by using my current line-based algorithm to find an edge point and then initiating an algorithm that checks all 8 pixels around that pixel, finds the next border pixel in one direction, and continues to do this until it comes back to the starting pixel. i could then store that data in an array to be used for the entire duration of the program, and have the mouse re-positioning method check the array for the closest pixel on the border to the mouse target position.that last method would presumably execute it's initial border mapping fairly quickly. (it would only have to map between 2,000 and 8,000 pixels, which means 8,000 to 64,000 checked, and i could even permanently store the data to make launching faster.) however, i am uncertain as to how much overhead it would take to scan through that array for the shortest distance for every single mouse move event... i suppose there could be a shortcut to restrict the number of elements in the array that will be checked to a variable number starting with the intersecting point on the line (from my original algorithm), and raise/lower that number to experiment with the overhead/accuracy tradeoff. please let me know if i am over thinking this and there is an easier way that will work just fine, or which of these methods would be able to execute something like 30 times per second to keep mouse movement smooth, or if you have a better/faster method. i've posted relevant parts of my code below for reference, and included an example of what the area might look like. (i check for color value against a loaded bitmap that is black/white.)//// this part of my code runs every single time the mouse moves. //cgpoint point = cgeventgetlocation(event);float tx = point.x;float ty = point.y;if( is_in_area(tx,ty, mouse_mask)){ // target is inside o.k. area, do nothing}else{cgpoint target; //point inside restricted region:float ix = 600; // inside xfloat iy = 500; // inside y// delta to midpoint between ix,iy and tx,tyfloat dx;float dy;float accuracy = .5; //accuracy to loop until reacheddo { dx = (tx-ix)/2; dy = (ty-iy)/2; if(is_in_area((tx-dx),(ty-dy),mouse_mask)){ ix += dx; iy += dy; } else { tx -= dx; ty -= dy; }} while (abs(dx)>accuracy || abs(dy)>accuracy); target = cgpointmake(roundf(tx), roundf(ty)); cgdisplaymovecursortopoint(cgmaindisplayid(),target);}here is is_in_area(int x, int y) :boolis_in_area(nsinteger x, nsinteger y, nsbitmapimagerep *mouse_mask){ nsautoreleasepool * pool = [[nsautoreleasepool alloc] init]; nsuinteger pixel[4]; [mouse_mask getpixel:pixel atx:x y:y]; if(pixel[0]!= 0){ [pool release]; return false; } [pool release]; return true;}",
    "present_kp": [
      "objective c"
    ],
    "absent_kp": [
      "design",
      "object oriented",
      "optimization"
    ]
  },
  {
    "text": "bounding the recurrence $f(n)=2f(n-1)+2f(n/2)$. i met a recurrence equation for my algorithm $$ f(n) = 2\\cdot \\left( f(n-1) + f( rac{n}{2}) ight)$$with $f(1)=1$, $f(2)=4$, $f(3)=10$. i guess it is $\\theta((2+\\epsilon)^n)$, where $\\epsilon$ ban be arbitrarily close to 0. i want to have an asymptotic formula of $f(n)$. i do not know how to prove or disprove my guess.",
    "present_kp": [],
    "absent_kp": [
      "asymptotics",
      "recurrence relation"
    ]
  },
  {
    "text": "string classification beginner question. i analyse log files, very often there are strings that only differ on few places and are same every where else, i am trying to find the generic string that they most likely belong to e.g. :uhguyguyguyguy id = u1234 uyag*&^t*#@g*(&g@ id2 = 8767 ib97y79yh0978uhguyguyguyguy id = z1d#34 uyag*&^t*#@g*(&g@ id2 = 98h ib97y79yh0978sss3ug87g87g78ghs837g8 obj { 876t7g }937hs937hs973h97sh397 jh7897y98hsss3ug87g87g78ghs837g8 obj { 98u2 }937hs937hs973h97sh397 zn7897y98hto me the only difference is between the two the value of ids, so a generic forms/groupings will be uhguyguyguyguy id = * uyag*&^t*#@g*(&g@ id2 = * ib97y79yh0978sss3ug87g87g78ghs837g8 obj { * }937hs937hs973h97sh397 *7897y98hi am not sure what in machine learning i should be looking up for this problem, or even if this problem has a name.of course this is a very simplified example, the number, location of id's can vary for different generic cases, that is why i can not write old fashioned code for this, too many things can change.is there anything in machine learning to help find groups for such strings? if yes, what is it called?",
    "present_kp": [
      "beginner"
    ],
    "absent_kp": []
  },
  {
    "text": "yum [errno 28] no space left on device. i am at a situation that i want to install some packages with yum on an amazon emr master node which has the root volume limited to 10gb at some point, i constantly end up getting this error because i require more space: could not create lock at /var/run/yum.pid: [errno 28] no space left on devicehow should i change the filesystem at which yum installs packages to the /mnt one for example?this is my full df -h outputfilesystem size used avail use% mounted ondevtmpfs 4.0g 29k 4.0g 1% /devtmpfs 4.0g 0 4.0g 0% /dev/shm/dev/xvda1 11g 7.1g 3.3g 69% / ---this becomes 100% at some point/dev/xvdb1 5.4g 35m 5.4g 1% /emr/dev/xvdb2 446g 3.1g 443g 1% /mnt/dev/xvdc 451g 35m 451g 1% /mnt1i found this proposed solution but i would require some more thoughts if possible because i haven't really found anything else on this.thanks,",
    "present_kp": [
      "yum"
    ],
    "absent_kp": [
      "amazon linux"
    ]
  },
  {
    "text": "why does buildroot automatically remove manually added in-tree package from .config when make is run?. i've added a simple hello world package to the buildroot source tree under package/hello.if i do: make qemu_x86_64_defconfigand edit .config with vim to add: br2_package_hello=ythen:makethe package gets installed.but if i look again at the .config, it has been modified, and br2_package_hello=y was removed.how to prevent that?",
    "present_kp": [
      "buildroot"
    ],
    "absent_kp": []
  },
  {
    "text": "should version control softwares be used from command line or gui. i was going through some tutorials on tortoisehg. despite having a rich gui, the first examples are given using command line options. does the ideal usage involve command line or it was started that way so one has idea of what is happening under the hood and gui internally uses this command anyway.",
    "present_kp": [
      "version control",
      "command line"
    ],
    "absent_kp": []
  },
  {
    "text": "how do sites like alexarank and w3spy.net work?. i am curious as to how companies are able to track the number of unique visitors to other people's sites. seems like an impossible task to me. any ideas?",
    "present_kp": [
      "visitors"
    ],
    "absent_kp": [
      "tracking",
      "users"
    ]
  },
  {
    "text": "using markdown for large complex documents. i am trying to find an easy way to manage/edit a set of standard operating procedures that's around 400+ pages between 4 word documents. i would like to move it to the web. i have used markdown on this site and other sites to easily make short documents. these tend to be short in nature, on the order of a page or two.i've been thinking about going with markdown but i'm unsure of how to manage and organize the large number of chapters and sections it has. i haven't found many articles regarding markdown and large, complex documents. is markdown a suitable solution?is there a limit to the length of the document in markdown? and are there any web services that host markdown to make large complex documents.i know about google docs, and microsoft live, but i am more interested in the ease of web formatting in markdown.",
    "present_kp": [
      "markdown"
    ],
    "absent_kp": [
      "document management",
      "books",
      "documentation"
    ]
  },
  {
    "text": "x64 assembly clearmem / zeromem. i've just started learning assembly yesterday, and the first useful thing i've written is a clearmem function.i'm looking for general feedback regarding my coding of this function, whether there any flaws with it other than the obvious one of a user passing a value <= 0 to the size argument, or an invalid pointer to the ptr argument (should i really even check for that in practical use)?i also observed an odd behavior that i still don't quite understand, so if you can explain that, then that would be much appreciated as well. intel x64 assembly - on linuxclearmem: ; void clearmem( void* ptr, long size ) mov rcx, rsi ; copy rsi/size to rcx (aka the counter register) next: ; for( long i = size; i > 0; i-- ) mov byte [rdi+rcx-1], 0 ; *(reinterpret_cast<char*>(ptr+i-1)) = 0; loop next ; dec rcx; cmp rcx, 0; jg next ret ; returnintel x64 assembly - on windowsclearmem proc xchg rcx, rdx ; swap arg1 and arg2... windows uses rcx for arg1, and rdx for arg2 next: mov byte ptr[rdx+rcx-1], 0 loop next retclearmem endpexample usage in c++#include <iostream>// ...extern c void clearmem( void* ptr, long size );// ...int main( int argc, char* argv[] ){ int z[] = {1,2,3,4,5,6,7,8,9,10}; int zlen = sizeof(z) / sizeof(int); std::cout << z[] before clearmem() = ; print_array<int>(z, zlen); clearmem(&z, sizeof(z)); std::cout << z[] after clearmem() = ; print_array<int>(z, zlen); return 0;}output of c++ programz[] before clearmem() = 1,2,3,4,5,6,7,8,9,10z[] after clearmem() = 0,0,0,0,0,0,0,0,0,0odd behaviorif i change all of the registers and variables to their 4 byte equivalent (e.g. rcx -> ecx, long -> int) then it still works fine in windows, but on linux it will segfault. i used gdb to set a break point on mov byte[rdi+rcx-1], 0 and used info registers to see the values in the registers and they were extrmely high. for instance rdi was 0x00007fffffffe6e0 at the time, and considering i only have 16 gb of ram, i would have expected a value less than 0x0000000400000000.what's going on here? why does this work on windows, but not on linux? note: obviously, i know i shouldn't do this, but i like breaking things...",
    "present_kp": [
      "c++",
      "linux",
      "assembly",
      "windows"
    ],
    "absent_kp": []
  },
  {
    "text": "i want to try out aix in my pc, can i emulate it or get it to run for a very affordable price?. sorry, i'm to new to aix. i love unix and i try different kinds.so can it be emulated with qemu or can i buy an old ibm processor to use it? or some other easy way?thanks",
    "present_kp": [
      "aix",
      "qemu"
    ],
    "absent_kp": []
  },
  {
    "text": "single linked list implementation in ruby. the #traverse_until method is a helper function that traverses the linked list and returns the node and index of the node once a condition (in a block) is met or until the end of the list. i would greatly appreciate feedback about verbosity, efficiency, readability, etc. module datastructures class node attr_accessor :value, :next_node def initialize(value = nil, next_node = nil) @value = value @next_node = next_node end end class linkedlist attr_accessor :head def initialize(element = nil) element.nil? ? @head = nil : @head = node.new(element) end def append(data) prepend(data) if @head.nil? current = @head until current.next_node.nil? current = current.next_node end current.next_node = node.new(data) end def prepend(data) @head = node.new(data, @head) end def find(data) result = traverse_until { |node, index| node.value == data } result[:node].value == data ? result[:index] : data not found. end def contains? (data) result = traverse_until { |node, index| node.value == data } result[:node].value == data end def node_at_index(index) result = traverse_until { |node, i| i == index } node at index #{index}: #{result[:node].value} end def head @head.nil? ? empty list : @head.value end def tail last_node = traverse_until { |node, index| node.next_node.nil? } last_node[:node].value end def size last_node = traverse_until { |node, index| node.next_node.nil? } list size: #{last_node[:index] + 1} end def insert_at(data, index) current = @head (index - 1).times do |n| current = current.next_node end node_shifted_right = current.next_node current.next_node = node.new(data, node_shifted_right) end def remove_at(index) node_after_index = @head previous = node_after_index (index + 1).times do |n| node_after_index = node_after_index.next_node end (index - 1).times do |n| previous = previous.next_node end previous.next_node = node_after_index end def pop node_before = nil current = @head until current.next_node.nil? node_before = current current = current.next_node end node_before.next_node = nil end def to_s result = current = @head loop do result += (#{current.value}) -> break if current.next_node.nil? current = current.next_node end result += nil end private def traverse_until current = @head index = 0 until current.next_node.nil? || yield(current, index) current = current.next_node index += 1 end {node: current, index: index} end endend",
    "present_kp": [
      "ruby",
      "linked list"
    ],
    "absent_kp": [
      "algorithm"
    ]
  },
  {
    "text": "how can i add a shebang to file in a specific directory. i need to configure vim to add the shebang #!/bin/bash if the edited file is in the directory /usr/bin/ and if it is empty (or even better if it doesn't exist)",
    "present_kp": [],
    "absent_kp": [
      "vimrc"
    ]
  },
  {
    "text": "automatic translation of forms. i want my application to support multiple ui-languages (aka i18n). to do so, i have built the static class below, to automatically translate the form and all its contents to the desired language. it looks into a resource file for the user's culture, and replaces the .text properties of the controls with the strings it finds there, or falls-back to the initial strings, which is english.usage is calling translateform(this) from each form's constructor.two concerns about my code:* the overloading of the translate method. i didn't find any way to overcome this.* the special handling of different controls, which seems unnecessary.i'm not a professional programmer, so any correction / enhancement / fix to my code is more than welcomed!using system;using system.collections.generic;using system.componentmodel;using system.data;using system.drawing;using system.linq;using system.text;using system.windows.forms;using system.threading;using system.globalization;using system.resources;using system.reflection;using system.runtime.interopservices;using system.collections;namespace blahblah{ static class translationhelper { static private resourcemanager rm = null; static private cultureinfo default_ci = null; static private cultureinfo lang_ci = null; /// <summary> /// translate control into the specific lang, or leave it untranslated if no translation string found /// </summary> /// <param name=ctrl></param> /// <param name=lang></param> static private void translate(control ctrl, string lang) { string str = translatestring(ctrl.name, lang); if (str != null) ctrl.text = str; } static private void translate(toolstripmenuitem o, string lang) { string str = translatestring(o.name, lang); if (str != null) o.text = str; } static private void translate(toolstripitem o, string lang) { string str = translatestring(o.name, lang); if (str != null) o.text = str; } static private void translate(form o, string lang) { string str = translatestring(o.name, lang); if (str != null) o.text = str; } /// <summary> /// returns the <c>name</c> string from the <c>lang</c> resource /// </summary> /// <param name=name>string/key name</param> /// <param name=lang>the language to translate to</param> /// <returns>a translated string for <c>name</c></returns> static public string translatestring(string name, string lang) { if (lang_ci == null || !lang_ci.twoletterisolanguagename.equals(lang)) lang_ci = new cultureinfo(lang); try { return rm.getstring(name, lang_ci); } catch (exception) { // no translation yet try { return rm.getstring(name, default_ci); } catch (exception) { return null; //messagebox.show(ex.message.tostring(), name); //system.console.writeline(ex.message.tostring()); } } } static public void translateform(string lang, form parent) { if (rm == null) rm = new resourcemanager(etimet.i18nresources.i18n, assembly.getexecutingassembly(), null); if (default_ci == null) default_ci = new cultureinfo(en); // handle direction if (program.conf.currentlang.equals(he) || program.conf.currentlang.equals(ar) || program.conf.currentlang.equals(fa)) { parent.righttoleft = righttoleft.yes; } else { parent.righttoleft = righttoleft.no; } // translate the form itself translate(parent, lang); // translate all the children controls, recursively control.controlcollection c = parent.controls; foreach (control o in c) { // special handling for the menu if (o.gettype() == typeof(menustrip)) { foreach (toolstripmenuitem it in ((menustrip)o).items) { translate(it, lang); //messagebox.show(it.text); foreach (toolstripitem f in it.dropdownitems) { if (typeof(toolstripseparator) != f.gettype()) translate(f, lang); } } } recursivetranslatectrl(lang, o); } } static private void recursivetranslatectrl(string lang, control ctrl) { translate(ctrl, lang); foreach (control c in ctrl.controls) { recursivetranslatectrl(lang, c); } } }}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      ".net"
    ]
  },
  {
    "text": "generate a sequence of numbers. i want to generate an infinite sequence of numbers between $0$ and $9$ such that the percentage of number $i$ appearing in the sequence is $p_i$. let $p=\\lbrace p_0,...,p_9 brace$.another agent $b$ will observe $k$ consecutive elements from the sequence. then it will update its belief about the probability of $p_i$ using a belief update rule (let's say a simple frequentist, i.e., the number of occurrences of each digit divided by $k$).the question is how can i generate the sequence such that $b$'s belief $q$ is close to $p$, i.e., $d(p,q)$ is minimized where $d(p,q)$ is the dsitance function of two distributions, e.g., $d(p,q)=(\\sum_i (p_i-q_i)^2)^0.5$.note that i don't know how $b$ will choose the $k$ numbers. let's consider the worst case (i.e., worst $p'$).",
    "present_kp": [],
    "absent_kp": [
      "machine learning",
      "gt.game theory",
      "st.statistics"
    ]
  },
  {
    "text": "how to install ubuntu 14.04 alongside the same existing os in laptop?. i already have ubuntu 14.04 installed on my laptop. but it's not working properly. i've a related thread here. i urgently require an audio/video cutter like ffmpeg, avconv etc. to be installed which isn't happening in the current system. so, the need to install a fresh one where i will install the cutter.i want to install again the same os but where! for that please look at my existing hard disk in my laptop.see, i've windows on sda2 & sda3. but it's not working any more & so i'm interested to delete sda2 & install the new ubuntu 14.04 there. but i need 3 partitions for the new installation. if i delete sda2, then can i install ubuntu 14.04 by creating 3 partitions? i'm doubtful as already there is 1 extended & 3 primary. so, if i delete one primary (sda2), then how to get the 3 partitions as logical partitions can't be made inside primary!!another method: just now something striked my mind. shall i create only root (or boot even required) partition on sda2 & use the other partitions (/home etc) from the existing ones?",
    "present_kp": [],
    "absent_kp": [
      "system installation",
      "dual boot"
    ]
  },
  {
    "text": "library to play and create ai for connect four. i am looking for some advice to this code i made, which enables a fellow programmer to create his own ai for connect four whilst not really having to code the game itself.match classpublic sealed class match{ public const int cwidth = 7; public const int cheight = 6; private static random random = new random(); private int _currentturn; private list<baseplayer> _players; private bool _isgameover; private disc[,] _discs; internal disc[,] discs => _discs; internal baseplayer currentplayer { get; set; } public int width { get; private set; } public int height { get; private set; } public disc recentdisc { get; internal set; } public bool ispositionwithinboundries(int x, int y) { if (x < 0 || x >= width) return false; if (y < 0 || y >= height) return false; return true; } public bool isrowvalidmove(int x) { if (!ispositionwithinboundries(x, 0)) return false; for (int y = 0; y < height; y++) if (_discs[x, y] == null) return true; return false; } public int getcolumnheight(int x) { if (!ispositionwithinboundries(x, 0)) return -1; int y = 0; for (; y < height; y++) if (_discs[x, y] == null) return y; return y; } public disc getdiscat(int x, int y) { if (!ispositionwithinboundries(x, y)) return null; return _discs[x, y]; } public disc getlastdiscincolumn(int x) { var y = getcolumnheight(x); return getdiscat(x, y - 1); } public static match creatematch(baseplayer player1, baseplayer player2) { return creatematch(player1, player2, cwidth, cheight); } public static match creatematch(baseplayer player1, baseplayer player2, int width, int height) { if (player1 == null) throw new argumentnullexception(nameof(baseplayer) + 1 is null); if (player2 == null) throw new argumentnullexception(nameof(baseplayer) + 2 is null); if (width < 1) throw new argumentnullexception(nameof(width) + 1 is null); if (height < 1) throw new argumentnullexception(nameof(baseplayer) + 2 is null); return new match(player1, player2, width, height); } public void startmatch() { if (_isgameover) return; for (;;) { _isgameover = true; foreach (var player in _players) { _currentturn++; if (checkgridfull()) { endgame(draw - grid is filled); return; } currentplayer = player; currentplayer.planmove(); domove(currentplayer); if (checkwin()) { endgame(currentplayer.name + wins); return; } } } } private bool checkwin() { if (checkdirectionsfordisc(recentdisc)) return true; return false; } private bool checkgridfull() { for (int x = width - 1; x >= 0; x--) { for (int y = height - 1; y >= 0; y--) { if (getdiscat(x, y) == null) return false; } } return true; } private bool checkdirectionsfordisc(disc disc) { return checkdirectionfordisc(disc, edirection.diagonal) || checkdirectionfordisc(disc, edirection.vertical) || checkdirectionfordisc(disc, edirection.horizontal); } private bool checkdirectionfordisc(disc disc, edirection direction) { var streak = 1; for (int i = 1; i < 4; i++) { var x = disc.x + i * (direction.getoffsetx()); var y = disc.y + i * (direction.getoffsety()); var curdisc = getdiscat(x, y); if (curdisc != null && curdisc.owner == disc.owner) streak++; else break; } for (int i = -1; i > -4; i--) { var x = disc.x + i * (direction.getoffsetx()); var y = disc.y + i * (direction.getoffsety()); var curdisc = getdiscat(x, y); if (curdisc != null && curdisc.ismine()) streak++; else break; } return streak >= 4; } internal void endgame(string message) { printfield(); } private void printfield() { for (int y = height - 1; y >= 0; y--) { system.diagnostics.debug.writeline(); for (int x = 0; x < width; x++) { { var disc = getdiscat(x, y); if (disc == null) system.diagnostics.debug.write(-); else if (disc.owner == _players[0]) system.diagnostics.debug.write(x); else system.diagnostics.debug.write(0); } } } } internal void domove(baseplayer player) { var y = getcolumnheight(player.nextcolumn); if (ispositionwithinboundries(player.nextcolumn, y)) disc.createdisc(this, player.nextcolumn, y); } private match(baseplayer player1, baseplayer player2, int width, int height) { width = width; height = height; _discs = new disc[width, height]; player1.match = this; player2.match = this; _players = new list<baseplayer>(); //var swapplayers = random.nextdouble() >= 0.5; _players.add(player1); //if (swapplayers) _players.add(player2); //else // _players.insert(0, player2); }}baseplayer which library users would have to extendpublic abstract class baseplayer{ public match match { get; internal set; } internal string name { get; private set; } private int _nextrow = 0; public int nextcolumn { get { return _nextrow; } protected set { //if(match.isrowvalidmove(row)) _nextrow = value; } } public abstract void planmove(); public abstract void initialize();}discpublic sealed class disc{ private match _match; public int x { get; } public int y { get; } internal baseplayer owner { get; } internal static disc createdisc(match match, int x, int y) { if (match == null) throw new argumentnullexception(nameof(match)); if (match.currentplayer == null) throw new nullreferenceexception(nameof(match.currentplayer) + == null); if (!match.ispositionwithinboundries(x, y)) throw new argumentoutofrangeexception(x and y out of boundries); if (!match.isrowvalidmove(x)) throw new argumentoutofrangeexception(x exceeds row); if (match.getdiscat(x, y) != null) throw new argumentexception(position already occupied); return new disc(match, x, y, match.currentplayer); } private disc(match match, int x, int y, baseplayer owner) { _match = match; x = x; y = y; owner = owner; match.discs[x, y] = this; match.recentdisc = this; } public bool ismine() { return _match.currentplayer == owner; } public override string tostring() { return owner.name + + base.tostring(); }}enumsinternal enum edirection{ horizontal, vertical, diagonal}internal static class edirectionextension{ internal static int getoffsetx(this edirection direction) { switch (direction) { case edirection.horizontal: case edirection.diagonal: return 1; case edirection.vertical: default: return 0; } } internal static int getoffsety(this edirection direction) { switch (direction) { case edirection.vertical: case edirection.diagonal: return 1; default: case edirection.horizontal: return 0; } }}",
    "present_kp": [
      "library",
      "connect four"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "what's the deal with all these popular website having poor usability. i'm wondering this for quite some time, and it's a question about human-computer interaction and usability.a lot of popular websites have (in my opinion) poor usability, and i wonder what you guys think of that, and i also wonder why users still prefer these websites. i'll start off with a few examples.wikipedia i'm not talking here about the actual wiki's. but if you want to get into editing these pages it starts with a big mess. there are tons of discussions in the pages behind the wiki's. for example: <url>)#30_kbthis is bulletin board with thousands of lines of comments, no proper way to identify who's posting what. and all that indentation. it's really annoying me and it's one of the reasons i'm not editing wiki's.twitter okay, i get the deal with the 140 characters in a message. it forces people to make small messages, and it's ideal for mobile devices. however, a lot of people nowadays are having conversations over twitter. and that's where it gets messy, if someone replies at a tweet of someone else, it's almost impossible to find the corresponding tweet. also, you're forced to cramp #hastags and @people in your message, so for me it's very messy.craigslist euhm, yeah craigslist... i'm not even starting on this one.this post is not a complaint about these websites. i'm just surprised they are lacking even the most basic usability features. and that makes me wonder the following thing.everyone on this website is talking about usability, and human computer interaction. a lot of people study the effects of them on websites. people have gained phd's in them.then why is it, that the most popular websites on the internet, do not follow the basic rules of usability, and have a lot of things that can improved for better user experience. then, another question, is it even proven that adding usability features actually improve the quality of the user experience of the website",
    "present_kp": [
      "usability"
    ],
    "absent_kp": []
  },
  {
    "text": "how to explain that writing universally cross-platform c++ code and shipping products for all oses is not that easy?. our company ships a range of desktop products for windows and lots of linux users complain on forums that we should have been written versions of our products for linux years ago and the reason why we don't do that iswe're a greedy corporationall our technical specialists are underqualified idiotsour average product is something like 3 million lines of c++ code.my and my colleagues analysis is the following:writing cross-platform c++ code is not that easypreparing a lot of distribution packages and maintaining them for all widespread versions of linux takes timeour estimate is that linux market is something like 5-15% of all users and those users will likely not want to pay for our effortwhen this is brought up the response is again that we're greedy underqualified idiots and that when everything is done right all this is easy and painless.how reasonable are our evaluations of the fact that writing cross-platform code and maintaining numerous ditribution packages takes lots of effort? where can we find some easy yet detailed analysis with real life stories that show beyond the shadow of a doubt what amount of effort exactly it takes?",
    "present_kp": [
      "c++"
    ],
    "absent_kp": [
      "development process",
      "cross platform"
    ]
  },
  {
    "text": "truncating folder names after first space. i have a directory full of sub-directories with names like 01 - title of folder 02 - second title03 - etc04 - etc...30 - final folderi want to truncate all of these folder names to just be the numbers so they would appear like so:010203is there a way to write a script or a simple command that will accomplish this?",
    "present_kp": [
      "directory"
    ],
    "absent_kp": [
      "ubuntu",
      "rename",
      "mv"
    ]
  },
  {
    "text": "shell command cd !$. i looked at this question and googled, but can't find a definitive answer. what does !$ do when typed into terminal?i typedmkdir /path/to/dircd !$which brought me to /path/to/dir but i still would like to know exactly what the !$ operator does in general.",
    "present_kp": [
      "terminal"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "what is the best way to invalidate an entire amazon cloudfront cache or recreate the entire distribution?. after asking this question, i have decided to recreate some cloudfront distributions, as so many files need to be invalidated.but instead of creating a new distribution, is it possible to just delete the origin and making an identical one? would that work?",
    "present_kp": [
      "cache",
      "amazon cloudfront"
    ],
    "absent_kp": [
      "cdn"
    ]
  },
  {
    "text": "reference request: factorization of pseudoprimes?. is there any literature/survey/papers/books regarding the factorization of strong pseudoprimes (wrt. to a given base). i am aware of the fact that weak pseudo primes can be factorized in polynomial time. but, i was unable to get anything significant/detailed regarding strong pseudoprime factorization (i am aware the general problem is considered hard), but i am looking for much more detailed analysis of the subsets that are easy (factorizable in polynomial time, sub exponential time etc.) rather than this blanket generalization.",
    "present_kp": [
      "reference request",
      "primes"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "two vsftpd instances - check passive port on ftps. i have configured vsftpd in a centos machine to run on two instances, with vsftpd.conf and vsftpd2.conf. here the content of the second conf file:anonymous_enable=nochroot_list_enable=yeschroot_list_file=/etc/vsftpd/chroot_listchroot_local_user=yesconnect_from_port_20=yesdirmessage_enable=yesforce_local_data_ssl=yesforce_local_logins_ssl=yesftpd_banner=hello.listen=yeslisten_port=30local_enable=yeslocal_umask=022pam_service_name=vsftpdpasv_enable=yespasv_address=192.168.100.162pasv_max_port=389pasv_min_port=389rsa_cert_file=/etc/vsftpd/vsftpd.pemssl_enable=yesssl_sslv2=nossl_sslv3=nossl_tlsv1=yesssl_ciphers=highuser_config_dir=/etc/vsftpd/user_confuserlist_enable=nowrite_enable=yesxferlog_enable=yesxferlog_file=/var/log/xferlog2xferlog_std_format=nodual_log_enable=yeslog_ftp_protocol=yesthe fist conf file is identical excepting the xferlog file, and the listen_port that is missing, and the pasv_max_port/pasv_min_port that are 65000/60000so i have one ftps working on port 21 and the other on port 30. both are working fine, but i want to make sure that 389 is really being used. so, i started a session with wireshark, where i could see all my tcp packets to port 30, but no one to 389. instead, i see packets to my remote server on port 49276.how can i make sure that this is working fine?",
    "present_kp": [
      "ftp",
      "vsftpd",
      "vsftp"
    ],
    "absent_kp": []
  },
  {
    "text": "generate next available filename based on current date. i have a bit of code that i would like your collective opinions on. currently, my working code has two return statements. i'm not sure how i feel about having multiple points of exit, however, the alternative introduces the inclusion of else, which looks like it will eventually be harder to maintain if more logic is added to the code later on. my current code (feel free to comment on other aspects as well): function generatefilename() { var k = 0; var today = new date(); today = (today.getmonth() + 1).tostring() + '-' + today.getdate().tostring() + '-' + today.getfullyear().tostring(); while (true) { if (!fs.existssync('./'+ today + '.pdf')) { return './' + today + '.pdf'; } if (!fs.existssync('./' + today + '(' + k + ').pdf')) { return './' + today + '(' + k + ').pdf'; } k++; }}as you see, here there are two different return statements. if the file does not exist in the system, a file will be generated with the name 5-19-2017.pdf, i.e., the current date. if there is already a file named that, the file will be named 5-19-2017 (0).pdf, then 5-19-2017(1).pdf, and so on...this code works just fine, however - i am wondering if maybe a single point of exit might be better, such as :function generatefilename() { var k = 0; var today = new date(); today = (today.getmonth() + 1).tostring() + '-' + today.getdate().tostring() + '-' +today.getfullyear().tostring(); var result = today; var stop = false; while (!stop) { if (fs.existssync('./'+ today + '.pdf')) { if (fs.existssync('./' + today + '( ' + k + ' ).pdf')){ k++; } else { result = today + '( ' + k + ' )'; stop = true; } } else { stop = true; } } return result;}now, the code has a single point of exit, however the added else statements make the code unbearable to read, in my opinion.thoughts?",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "datetime",
      "comparative review",
      "file system"
    ]
  },
  {
    "text": "what is the nearest problem to the collatz conjecture that has been successfully resolved?. i am interested in the nearest (and most complex) problem to the collatz conjecture that has been successfully solved (which erdos famously said mathematics is not yet ripe for such problems). it has been proven that a class of collatz-like problems is undecidable. however, problems that are vaguely similar such as hofstadter's miu game (resolved, but admittedly more of a toy problem) are indeed decidable or have been solved.related questionscollatz conjecture & grammars / automata",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "open problem",
      "nt.number theory",
      "halting problem",
      "computability"
    ]
  },
  {
    "text": "website restructuring, 301 redirect or complete de-index?. i am managing an e-store site created by another colleague, that was badly created from the start.because of the structure, pagination and user browser capabilities combined with lack of meta robots directives to noindex certain pages it ended up with over 20k pages indexed in google. i am working on a website restructure, to follow all the seo meta robots directives correctly as well as eliminate a lot of browsing capabilities to eliminate tons of duplicated and useless pages.however, doing bulk 301 redirects of the eliminated urls might(most probably will) cause 404 errors according to google's webmaster's guidelines.also, if i remove the pages from the website's internal linking, i will have to manually deindex pages one by one in webmaster's tools as the crawler will not have access to it so that it can read the noindex directives and update it in time.as an example :<url> - this contains a list of products, paginated until page 2000+<url> - this contains a list of products starting with the letter a, paginated to about 30+ pageswww.example.com/products/b - you get the point.also:<url> - a list of most viewed products ( the same products - paginated to 2000+<url> - the same products, paginated to 2000+as you can see there lots and lots of duplicated content.i am trying to fix it. so i am implementing rel=next and prev for the pagination, but i also want to remove some useless pages for example the browse product alphabetically. in order to deindex the example.com/products/a, b, etc.should i:a. eliminate it from internal linking completely and then manually request an url removal for each link from webmasters tools ?b. keep it on the website and use meta robots to noindex these pages? i will have to leave it here untill the crawler gets around and updates all the pages accordingly.c. remove it from website's internal linking but add the meta robots noindex/follow, but instead of manually de-indexing them i should add them to the url sitemap and submit it to google so that the crawler still knows them and crawls them to read the noindex directive... even though they are no longer linked from the website.d. 301 redirect to either the products page or home page. but some many bulk directs to a single page or homepage will cause problems and google can treat them as 404 actually. more info here <url> i were to redirect each one to another page that would be something, but i am trying to remove lots and lots of pages.what would be the logical approach?",
    "present_kp": [
      "redirects",
      "301 redirect",
      "indexing",
      "404"
    ],
    "absent_kp": []
  },
  {
    "text": "code that uses reflection to validate arguments. i wrote an answer to this question on the software engineering se site and was hoping to get it critiqued. (i'm told that it's acceptable to do so).essentially, this code uses reflection to check to ensure that none of the parameters of a method are null and none of the strings are empty or consist only of whitespace. if one of those conditions is violated, it raises an exception on behalf of the caller.the weakness of this code is that it assumes that it's never valid for a string to consist of whitespace or be empty and that none of the arguments can be null.my concerns:is this overly convoluted/difficult to understand?obviously any time you use reflection that's going to entail a performance hit. for the particular system i'm considering using this in, performance isn't a major concern, but if i end up using it in future projects, how much of a performance hit can i expect?overall, is it actually worth using? is this a reasonable application of the don't repeat yourself principle?the code is as follows:public class argumentvalidator{ public static void validatearguments(params object[] methodarguments) { for (int i = 0; i < methodarguments.length; i++) { if (methodarguments[i] == null) { parameterinfo param = getcallingmethodparameterinfo(i); // raise the exception on behalf of the caller // i include the parameter name because that's conventional for this argument in c# throw new argumentnullexception(param.name); } else if (methodarguments[i].gettype() == typeof(string)) { string argcast = methodarguments[i] as string; if (!argcast.trim().any()) { parameterinfo param = getcallingmethodparameterinfo(i); throw new argumentexception(param.name + is empty or consists only of whitespace); } } } } /// <summary> /// get <see cref=parameterinfo/> for a specific parameter from the calling method /// </summary> /// <param name=index>index of the argument</param> /// <returns><see cref=parameterinfo/> for the parameter in question</returns> private static parameterinfo getcallingmethodparameterinfo(int index) { stacktrace trace = new stacktrace(); // get the method that called the original method methodbase info = trace.getframe(2).getmethod(); // get information on the parameter that is null so we can add its name to the exception parameterinfo param = info.getparameters()[index]; return param; }as an example of how this is supposed to be used, here's my unit test for this method (which obviously passes):[testmethod] public void argumentvalidatortests() { // should run without exception runtest(a, b, c); methodinfo info = gettype().getmethod(runtest, bindingflags.nonpublic | bindingflags.instance); bool result = commontests.throwsexception(info, this, typeof(argumentexception), new[] { abc, def, }); assert.istrue(result, didn't throw an argument exception with an empty string); result = commontests.throwsexception(info, this, typeof(argumentexception), new[] { abc, def, }); assert.istrue(result, didn't throw an exception with a string that consisted only of whitespace); result = commontests.throwsexception(info, this, typeof(argumentnullexception), new[] { abc, null, def }); assert.istrue(result); } private void runtest(string a, string b, string c) { argumentvalidator.validatearguments(a, b, c); }the throwsexception method is as follows:internal class commontests{ /// <summary> /// see if a particular method throws the exception we expected /// </summary> /// <param name=method>method to invoke</param> /// <param name=torunon>object to invoke the method on</param> /// <param name=expectedexceptiontype>expected exception</param> /// <param name=args>arguments for the method</param> /// <returns><c>true</c> if the method in question</returns> internal static bool throwsexception(methodinfo method, object torunon, type expectedexceptiontype, params object[] args) { try { method.invoke(torunon, args); } catch (targetinvocationexception e) { return e.innerexception.gettype() == expectedexceptiontype; } // didn't throw an exception at all return false; }}",
    "present_kp": [
      "c#",
      "reflection"
    ],
    "absent_kp": [
      ".net",
      "validation"
    ]
  },
  {
    "text": "visitor pattern in c++ 11. i have referred some class diagram to actually create visitor.#include <iostream>using namespace std; //know should not be used, but for simplicityclass book;class pen;class computer;class icartvisitor{public: virtual int visit(book &) = 0; virtual int visit(pen &) = 0; virtual int visit(computer &) = 0;};class ielement{public: virtual int accept (icartvisitor& cartvisitor) = 0; virtual int getprice () = 0;};class book : public ielement{public: int accept (icartvisitor& cartvisitor) { return cartvisitor.visit(*this); } int getprice () { return 100; }};class pen : public ielement{public: int accept (icartvisitor& cartvisitor) { return cartvisitor.visit(*this); } int getprice () { return 5; }};class computer : public ielement{public: int accept (icartvisitor& cartvisitor) { return cartvisitor.visit(*this); } int getprice () { return 10000; }};class cartvisitor : public icartvisitor{public: //inlining all the functions for simplicity int visit(book & book) { return book.getprice(); } int visit(pen & pen) { return pen.getprice(); } int visit(computer & computer) { return computer.getprice(); }};int main(int argc, char* argv[]){ int total = 0; icartvisitor *cartvisitor = new cartvisitor(); total += cartvisitor->visit(*(new computer())); total += cartvisitor->visit(*(new book())); total += cartvisitor->visit(*(new pen())); cout<<total; return 0;}",
    "present_kp": [
      "c++"
    ],
    "absent_kp": [
      "object oriented",
      "c++11",
      "design patterns"
    ]
  },
  {
    "text": "help understanding the output of stace for application that use anti-debugging technique. i was trying to debug an android app that implement anti-debugging technique.the app encrypts the .so library so i cannot figure much from it .when i attach stace to the app the app crash immediately with the following output open(/proc/self/maps, o_rdonly) = 33read(33, 12c00000-12e01000 rw-p <phone> ..., 1024) = 1024read(33, ted) 74641000-76283000 ---p 0000..., 934) = 934read(33, /dev/ashmem/dalvik-large object ..., 975) = 975read(33, 000000 00:04 389844 /dev/ash..., 999) = 999read(33, 0 0 a9359000-a935b000 r--p 0010..., 988) = 988read(33, badreno_utils.so a93ed000-a93ee0..., 954) = 954read(33, r-xp <phone> b3:10 1004 /..., 1006) = 1006read(33, 0 r-xp <phone> b3:10 1230 ..., 1008) = 1008read(33, 0 rw-p <phone> 00:00 0 a968100..., 1008) = 1008read(33, 3:10 861 /system/fonts/no..., 991) = 991read(33, /system/fonts/mtlmr3m.ttf a9c450..., 975) = 975read(33, taitham-regular.ttf aabae000-aab..., 953) = 953read(33, b000 r--p <phone> b3:10 806 ..., 1011) = 1011read(33, 0 r--p <phone> b3:10 780 ..., 1008) = 1008read(33, ystem/fonts/notosanskhmerui-bold..., 973) = 973read(33, 1 /system/fonts/notosanst..., 984) = 984read(33, <phone> b3:10 846 /syste..., 1001) = 1001read(33, 0 b3:10 793 /system/fonts..., 994) = 994read(33, --p <phone> b3:10 854 /s..., 1005) = 1005read(33, bold.ttf ab118000-ab159000 r--p ..., 954) = 954read(33, b420000 rw-p <phone> b3:10 1270..., 1014) = 1014read(33, 6f000 r--p <phone> b3:1d 520891..., 1012) = 1012read(33, o af003000-af004000 r-xp <phone>..., 947) = 947read(33, 0 b3:1d 520247 /data/dalvik-..., 994) = 994read(33, 390596 /dev/ashmem/dalvik-m..., 987) = 987read(33, ) b24dd000-b24fd000 rw-p <phone>..., 927) = 927read(33, shmem/dalvik-indirect ref table ..., 969) = 969read(33, rw-p <phone> 00:00 0 b3b75000..., 1007) = 1007read(33, ack:18700] b3f8b000-b3f8d000 rw-..., 972) = 972read(33, 7000 rw-p <phone> 00:00 0 b419..., 1011) = 1011read(33, 0 32104 /system/lib/libart...., 988) = 988read(33, 00 r-xp <phone> b3:10 955 ..., 1009) = 1009read(33, ) b5198000-b5298000 rw-p <phone>..., 897) = 897read(33, 0 b3:10 1325 /system/lib/l..., 994) = 994read(33, 0-b53ac000 rw-p <phone> b3:10 1..., 1017) = 1017read(33, td_client.so b580d000-b5811000 r..., 958) = 958read(33, 26000 rw-p <phone> 00:00 0 ..., 1012) = 1012read(33, 8a1000 ---p <phone> 00:00 0 b5..., 1013) = 1013read(33, 00-b5987000 r--p <phone> b3:10 ..., 1018) = 1018read(33, /system/lib/libskia.so b5be..., 980) = 980read(33, 5cd0000 r--p 0003a000 b3:10 1019..., 1014) = 1014read(33, 66a6000-b66ad000 rw-p <phone> 0..., 1023) = 1023read(33, i++.so b683e000-b698c000 r-xp 00..., 957) = 957read(33, m/lib/libnetutils.so b69e9000-b6..., 969) = 969read(33, -b6b13000 r--p 000e2000 b3:10 10..., 1016) = 1016read(33, 146 /system/lib/libgui.so ..., 985) = 985read(33, m/lib/libaudioutils.so b6bc4000-..., 969) = 969read(33, w-p <phone> b3:10 968 /s..., 1005) = 1005read(33, 0 b6c9f000-b6ca3000 r-xp 000000..., 986) = 986read(33, /system/lib/libstlport.so..., 982) = 982read(33, b4000 r--p 000cd000 b3:10 995 ..., 1012) = 1012close(33) = 0mmap2(null, <phone>, prot_read|prot_write, map_private|map_anonymous|map_noreserve, -1, 0) = 0xb3506000mprotect(0xb3506000, 4096, prot_none) = 0clone(child_stack=0xb3603db0, flags=clone_vm|clone_fs|clone_files|clone_sighand|clone_thread|clone_sysvsem|clone_settls|clone_parent_settid|clone_child_cleartid, parent_tidptr=0xb492a188, tls=0xb3603db0, child_tidptr=0xb492a188) = 18808mprotect(0xa09c7000, 698848, prot_read|prot_write|prot_exec) = 0+++ exited with 1 +++i am trying to use library injection and system call hook to bypass the anti-debugging.what i do not understand in the output is how the app detect that a debugger is attached just by opening /proc/self/maps what i know is detecting a debugger usually require reading /poc/self/status file and calling ptrace and fork the other thing that i do not understand is how the app close without a call to exit ,kill or exit_goup",
    "present_kp": [
      "android"
    ],
    "absent_kp": [
      "anti debugging"
    ]
  },
  {
    "text": "why doesn't the free space on the source partition change during mv?. i am running mv to move a directory (which contains many files) from one partition to another. while mv is moving individual files in the directory one by one, i notice that the free space size of the source partition doesn't change, while the free space size of the destination partition is decreasing. why is it working that way, instead of the sum of the free space sizes of the source and destination partitions stay the same?",
    "present_kp": [
      "mv"
    ],
    "absent_kp": []
  },
  {
    "text": "tool for blind users who also have no speech. i'm building an (open source) online tool for users with no speech who are also blind. the program steps through a list of utterances in a female 'thinking' voice, and when one is selected, speaks it in a male 'speaking' voice (switch genders for a female target users). i've written a demo of the 'display' half of the code in javascript and i'm about to write the editing code in python (it will parse a specification and create json). i've never formally learned javascript, and i feel very much like i'm unaware of 'good' practice. i would like some feedback on general coding style (there's lots to change in the gui and other aspects, i'm interested in style and safety). there is a demo here, and the github is here. the main code is below. any feedback welcomed. i'm particularly interested in things that will increase reuse - am i naming things according to expected patterns and so on?window.comscan = window.comscan || {};var speech_voices;if ('speechsynthesis' in window) { speech_voices = window.speechsynthesis.getvoices(); window.speechsynthesis.onvoiceschanged = function() { speech_voices = window.speechsynthesis.getvoices(); };}function think(message) { voiceoutput(message, fiona)}function say(message) { voiceoutput(message, daniel)}function voiceoutput(message, invoice) { var utterance = new speechsynthesisutterance(message); if (utterance.voice == null) { utterance.voice = speech_voices.filter(function(voice) { return voice.name == invoice; })[0]; } window.speechsynthesis.speak(utterance);}function menuitem(inid, inlabel, inlink, inutterance) { //holds the information for a single unit that can be activated. this.id = inid this.label = inlabel this.link = inlink this.utterance = inutterance || inlabel} //end menuitem classfunction pagesiterator(targetgraph) { this.rootnodeid = 0 this.childindex = 0; //initialisation this.graph = targetgraph; //currently a dictionary of node ids to menuitem objects this.currentnode = this.graph[this.rootnodeid] this.backstack = []; //stores breadcrumbs to work a multi-level 'back' button. this.gethighlighteditem = function() { return this.currentnode[this.childindex]; //returns a menuitem } this.gethighlighteditemlabel = function() { return this.gethighlighteditem().label; }; this.gethighlighteditemid = function() { return this.gethighlighteditem().id; }; this.refreshhtml = function() { var listtable = document.getelementbyid('listtable'); listtable.innerhtml = for (child = 0; child < this.currentnode.length; child++) { html = <td> if (child == this.childindex) { html = <td style= \\color:red\\>; } listtable.innerhtml += <tr> + html + this.currentnode[child].label + </tr></td>; } } this.next = function() { this.childindex++; if (this.childindex == this.currentnode.length) { this.childindex = 0; } think(this.currentnode[this.childindex].utterance); this.refreshhtml() } this.jump = function(dest) { this.currentnode = this.graph[dest] this.childindex = 0; //start the new page at the begining this.refreshhtml() //new page } this.processovf = function(dest) { if (dest.indexof(back) != -1) { this.backstack.pop() //this will be the current page we pop off dest = this.backstack[this.backstack.length - 1] //this the the page below that we peek at: if (dest == undefined) { dest = this.rootnodeid } this.jump(dest) return } //a different ovf command alert(stub!); } this.activate = function() { var dest = this.gethighlighteditem().link if (dest == ) { //then it's a speech activatation say(this.gethighlighteditem().utterance) return } if (dest in this.graph) { this.jump(dest) this.backstack.push(dest) } else if (dest.indexof(ovf() != -1) { this.processovf(dest) } else { //some failed linkk alert(stub!); } }} //end board class",
    "present_kp": [
      "javascript",
      "git"
    ],
    "absent_kp": []
  },
  {
    "text": "is there an algorithm to detect race conditions in logic circuits?. i'm writing a logic gate simulator. i would like to prevent user from constructing circuits prone to race condition such as flip-flops, and instead provide them as separate building blocks. is that possible?edit: i've got an idea. i guess that race conditions can only arise from logic circuit outputs directly or indirectly affecting their own inputs. so one way to check their validity would be to compare the truth tables of their inputs and outputs.example one: not gate feeding itself a = !aa | a a | !a--+-- ---+---t | t t | ff | f f | tthe truth tables do not match!example two: sr nor latch!(a || b) = c!(c || d) = b!((!(a || b)) || d) = b // c => !(a || b) a | b | d | !((!(a || b)) || d) b | b---+---+---+-------------------- ---+--- f | f | f | f f | f f | f | t | f f | f f | t | f | t t | t f | t | t | f (wrong!) t | t t | f | f | t (wrong!) f | f t | f | t | f f | f t | t | f | t t | t t | t | t | f (wrong!) t | ti hope you understand what i'm trying to convey. however, i have nothing to back it up, and i struggle to define it into an algorithm, and even if i could, it would have horrible complexity. i will try to refine it tommorow.online truth table generator tool i usededit 2: this is what i found in logisim manual:logisim will not attempt to detect sequential circuits: if you tell it to analyze a sequential circuit, it will still create a truth table and corresponding boolean expressions, although these will not accurately summarize the circuit behavior. (in fact, detecting sequential circuits is provably impossible, as it would amount to solving the halting problem. of course, you might hope that logisim would make at least some attempt - perhaps look for flip-flops or cycles in the wires - but it does not.) as a result, the combinational analysis system should not be used indiscriminately: only use it when you are indeed sure that the circuit you are analyzing is indeed combinational!however, the amount of inputs and outputs here is finite and well defined, as opposed to infinite memory and time resources in the halting problem, so i do not agree that this problem is equivalent to the halting problem.",
    "present_kp": [
      "logic"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "how important it is to fix memory leaks?. i found by valgring that some gtk+ programs leaks memory. how important it is to fix those leaks? i mean, often those programs works very well but on the other hand, one can never be sure if one wants to copy part of the leaking code to some other program. and i'm not sure if the idea of gtk+-programs is to work fast and therefore there are leaks.so if i sometimes find a memory leak in an open source program, should i fix it or are there for example efficiency issues and therefore programmers original idea was to write some small leaking code?",
    "present_kp": [
      "c",
      "memory"
    ],
    "absent_kp": []
  },
  {
    "text": "r plot(surv(), newdata=...) draws same lines many times - why?. i'm new to r and cannot make plotting work as desired. the problem is that r seems to draw the same four lines over and over again, redundantly. the details of the case i'm having are as follows.i have a dataset:> str(dataset)'data.frame': 57641 obs. of 3 variables: $ duration : num 3 8 7 2 4 8 2 2 8 8 ... $ graduated: logi false true true false false true ... $ group : num 651 651 671 671 651 651 651 651 651 651 ...then, i fit a cox proportional hazards regression model to it:survobj <- surv(time = dataset$duration / 2, event = dataset$graduated)model <- coxph(survobj ~ group, data=dataset)next, following this example, i create a frame that would hopefully group the survival functions by the group number:frame <- data.frame(group = dataset$group)> str(frame)'data.frame': 57641 obs. of 1 variable: $ group: num 651 651 671 671 651 651 651 651 651 651 ...there's four groups in the data:> unique(dataset$group)[1] 651 671 652 681using this new frame, i create a fitted survival model:fitobjgrouped <- survfit(model, newdata = frame)finally, i plot the thing:color_set <- rainbow(4)plot(fitobjgrouped, col=color_set)the result has the correct lines, but drawn many times over each other:as you can see, there's two red lines and two blue lines drawn last. they're the correct ones, one for each category, but closer observation reveals that there's a green or other color lines underneath each of them. when converting this to pdf the file size is 273 times larger than what it should be!so the question is: why is r drawing the lines so many many times and how could i achieve correct model fitting and plotting at the same time?can somebody please help me to better understand the r commands i'm using? thanks in advance!",
    "present_kp": [
      "r"
    ],
    "absent_kp": [
      "survival analysis"
    ]
  },
  {
    "text": "are cddl and gpl really incompatible?. wikipedia seems to suggest that cddl and gpl are incompatible, yet no one knows for sure why or how.why and how are the cddl and gpl are incompatible?",
    "present_kp": [
      "gpl",
      "cddl"
    ],
    "absent_kp": [
      "license compatibility"
    ]
  },
  {
    "text": "is it possible to check a client side application identity from server side?. assume there is a web service which is visible publicly but it must be just responsive to a specific client application. is there any mechanism to check client side application identity to prevent disallowed application to access the service?for instance, i have a web service which is called by my ios application. i want to prevent others from calling my web service.regarding the fact that others can decompile my client application and create another one which is working the same as mine, i think the only way to avoid unwanted access to the service is to check application identity on server to ensure the request comes from my own application.is there any robust and secure way to do that?",
    "present_kp": [
      "app",
      "identity"
    ],
    "absent_kp": [
      "security"
    ]
  },
  {
    "text": "passing variables to the sed command,. we have a file containing 6 columns.filedescriptor . descr00001 filedescriptor . descriptivenamefiledescriptor . lstupdnam filedescriptor . lastupdatenamefiledescriptor . locat00001 filedescriptor . location_idfiledescriptor . retailprc filedescriptor . retailpricefiledescriptor . lstupdtime filedescriptor . updtimestampindustrydivision . descr00001 industrydivision . descriptionindustrydivision . divis00001 industrydivision . divisioncodeindustrygroup . descr00001 industrygroup . descriptionindustrygroup . divis00001 industrygroup . division_idall i need to do, is treat first 3 columns seperated by a single space and store it in a variable as single column, and then the next 3 separated by a single space and store it in another variable. then use sed to replace the first variable with the second.i tried the below script but threw errors:#!/bin/bashwhile ifs='' read -r line || [[ -n $line ]];do column2=$(echo -e $line | awk '{print $4, $5, $6}') #column3=$(echo -e $line | awk '{print $3}') column1=$(echo -e $line | awk '{print $1, $2, $3}' ) #echo $column1 #echo $column2 sed s/${column1}/${column2}/g ims_procedures.txtdone < filethe script is not working. the errors i got are:sed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 20: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 22: unterminated 's' commandsed: -e expression #1, char 22: unterminated 's' commandsed: -e expression #1, char 22: unterminated 's' commandsed: -e expression #1, char 23: unterminated 's' commandsed: -e expression #1, char 30: unterminated 's' commandwhat can be done?",
    "present_kp": [
      "sed",
      "awk"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "creating my own php framework. disclaimer: i don't want to start any flame war so there will not be no name of any framework mentioned.i've been using quite many from the existing php frameworks and my experience in each case was similar: everything is nice a the beginning but in the moment you require something non standard you get into lot of problems to fix otherwise simple issues. in case of frameworks following the mvc design pattern there are some issues with the implementation of each layer for example there is a lot of codding used for model and data access with using orm and presentation is not much more than pure phtml. some frameworks use their own wrappers for existing php functionality and in some cases severely limiting original functionality. depending on framework you can have additional problems like lack of documentation, slow or non existent development cycle and last but not least speed.while ago i made my own framework which while doing it's job and being used for few different applications after couple of years more of experience with php doesn't seem to be perfect piece of codding. i could write my own framework and use additional experience i've gathered during these years to make it better on the other hand i'm aware that there is quite many better programmers working on creating/upgrading existing frameworks. so does it make at all nay sense to write my own php framework if there is so many possibilities to choose from?",
    "present_kp": [
      "php",
      "frameworks"
    ],
    "absent_kp": []
  },
  {
    "text": "testing strategy for wrapper class. in my android project i decided to create wrapper around sharedpreferences(which is basically key-value storage) with following interfaceinterface preferences{ public void saveint(int value, string key); public void savestring(string value, string key); public int readint(string key); public string readstring(string key);}implemetation uses android sharedpreferences api, simplified version looks like that:public class sharedprefenceswrapper implements preferences{ private sharedpreferences msharedpreferences; public sharedpreferencesstorage(context context) { msharedpreferences = context.getsharedpreferences(prefs_name, context.mode_private); } public void saveint(int value, string key){ msharedpreferences.edit().putint(key, value).commit(); } //the same for all other public methods}now i want to test sharedpreferenceswrapper class, every public method of preferences class:public class sharedpreferenceswrappertest{ @test public void savesboolean(){ preferences prefs = new sharedpreferenceswrapper(...); prefs.saveint(3, intkey); int savedvalue = prefs.readint(intkey); assertequals(3, savedvalue); }}now, can the test look like that? or should i use sharedpreferences api to check saved values in tests? my concern is that to retrieve the value i will use methods of sharedprefenceswrapper, something doesn't feel right here.",
    "present_kp": [
      "testing"
    ],
    "absent_kp": [
      "java",
      "unit testing",
      "junit"
    ]
  },
  {
    "text": "synchronous shopping hackerrank. i tried this synchronous shopping problem on hackerrank and i had no clue how to approach it. so i looked at the editorial, and i am confused. maybe i misunderstood how dijkstra's single source shortest path algorithm works. this is taken from the editorial:he says the shortest distance to the state $d_{(v, b)}$ denotes the minimum time required to visit shopping center $v$ with fish from the mask $b$ bought.and then he describes two possible ways we might move from one state to another, and after that he says when all the minimal times are calculated....i assume he means, we should have considered all possible ways to obtain fish, after we reach node $n$. all $2^k$ ways. like, we consider 1) we only have the first fish when we reach node $n$2) we only have the second fish...3) we only have the first fish and the second fish..etc..but if we run dijkstra, it will calculate the shortest path from node $1$ to node $n$, but we have to travel a specific path to get from node $1$ to node $n$. and we will only get the fish available along those nodes. how do we calculate all other states? (reaching node $n$ with different sets of fish)",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "graphs",
      "weighted graphs"
    ]
  },
  {
    "text": "gmail search query not returning all today's mails for primary label. say today is 12/12/2014 and i want to search all mails for today only in my primary label in inbox. i type this query in gmail search bar:in: inbox -category:{social promotions updates forums} after: 2014/12/11with this i get all today's emails in my primary label of gmail inbox, except for few auto-generated emails, e.g. amazon.com sending some autogenerated emails etc. please tell me what modification i should do in my query above to get all missing email threads too in search result.",
    "present_kp": [
      "gmail",
      "gmail search"
    ],
    "absent_kp": []
  },
  {
    "text": "how to test code and functionality effectively while working as a freelancer?. i work as an independent developer. i find it difficult to test functionality of a feature and test code. as project goes complex, i loose focus resulting in each feature partially developed. i want to know how to write test cases, manage smooth workflow and handle features effectively and while remain focused?",
    "present_kp": [],
    "absent_kp": [
      "project management",
      "testing",
      "freelancing",
      "workflows"
    ]
  },
  {
    "text": "including open graph meta tags and twitter card tags for seo. i have used these tags before to share some content for user to preview on facebook or twitter before they actually go into the shared link/video. but when i was asked to include these tags only for seo i had this doubt which i can split into two partspart 1: let us assume these tags are included in the head tag of html doc. but there are no like, tweet or share links in the page.a) will these tags then help google to search this page (assuming the page already has title and description meta tag)?b) will these tags help search used within facebook and twitter?part 2:let us assume these tags are included in the head tag of html doc and also there are like or share links in the page.c) will these tags then help google, facebook and twitter to search this page since there will be lot of clicks happening through these like, tweet and share links.",
    "present_kp": [
      "seo",
      "facebook",
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "how to math exact digits if the surroundings are digits?. cat x.txt 62643383279533330288419716grep 333 x.txt 62643383279533330288419716grep 3333 x.txt 62643383279533330288419716grep -w 333 x.txt grep -w 3333 x.txt how to grep for only 333? if i use plain grep 333 x.txt it will output the 3333 too!",
    "present_kp": [
      "grep"
    ],
    "absent_kp": []
  },
  {
    "text": "multiple independent random number streams. having multiple streams of pseudo-random numbers known to be independent and with a uniform distribution i want to do monte carlo simulations in parallel.in other words, one thread will have a full-period independent and uniformly distributed stream of pseudo-random numbers. each thread will consume these numbers in four different functions (a,b,c,d).my concern is about the distribution across threads for each function. thread.1 func_a.1, thread.2 func_a.2... and so on. do i still need to make sure this distribution is indeed uniform across func_a1, func_a2, etc? failing to do so can make my simulation have flaws?in summary,if i start using the pseudo-random numbers in a random fashion, rejection sampling. can i still be sure of the uniform distribution among the different parts?",
    "present_kp": [],
    "absent_kp": [
      "parallel computing",
      "probability",
      "cuda",
      "random number generation"
    ]
  },
  {
    "text": "comparing two strings to see if string 2 is inside string 1. here is what i have to do: write a function scramble(str1,str2) that returns true if a portion of str1 characters can be rearranged to match str2, otherwise returns false.for example:str1 is 'rkqodlw' and str2 is 'world' the output should return true.str1 is 'cedewaraaossoqqyt' and str2 is 'codewars' should return true.str1 is 'katas' and str2 is 'steak' should return false.only lower case letters will be used (a-z). no punctuation or digits will be included. performance needs to be consideredpublic class scramblies { public static boolean scramble(string str1, string str2) { string temp = str1; int count = 0; boolean result = true; for(int i=0 ; i<str2.length() ; i++){ char c = str2.charat(i); if(temp.contains(string.valueof(c))){ temp = temp.replacefirst(string.valueof(c), ); count++; } } if (count == str2.length()){ result = true; } else { result = false; } return result; } }my code works perfectly, but the only problem now is efficiency. i am tested against how long it takes to finish the final test class, which times out. i get this:process was terminated. it took longer than 10000ms to completehow can this code be made more efficient to achieve the same result?",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "java",
      "time limit exceeded"
    ]
  },
  {
    "text": "in my hangman game, one of my functions is correct but messy. i got a ton of helpful tips last time i posted some code, so i thought i would come back to the well.my function is deciding whether or not the secretword has been guessed in my hangman game. i am trying to accomplish this by taking a list, lettersguessed, and comparing it to the char in each index of the string secretword. my code works, but i feel as though it is not optimal nor formatted well.def iswordguessed(secretword, lettersguessed): ''' secretword: string, the word the user is guessing lettersguessed: list, what letters have been guessed so far returns: boolean, true if all the letters of secretword are in lettersguessed; false otherwise ''' chars = len(secretword) place = 0 while place < chars: if secretword[0] in lettersguessed: place += 1 return iswordguessed(secretword[1:], lettersguessed) else: return false return truei tried to use a for loop (for i in secretword:) originally, but i could not get my code to return both true and false. it would only do one or the other, which is how i ended up with the while loop. it seems that while loops are discouraged/looked at as not very useful. is this correct?also, i am wondering if the recursive call is a good way of accomplishing the task.",
    "present_kp": [
      "hangman"
    ],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "permanently setting vim as the $editor for crontab. i am trying to tell my terminal to use vim instead of vi when editing crontab by executing export editor=vim. but closing the terminal and opening a new one just resets the session. how do i change that?",
    "present_kp": [
      "cron"
    ],
    "absent_kp": [
      "bash",
      "environment variables"
    ]
  },
  {
    "text": "why dd reads from output device?. while dding a centos 7 x86_64 dvd image to a usb drive (sdb), i monitored the progress with iostat.it kept alternating between mostly writing to the usb drive:device: tps kb_read/s kb_wrtn/s kb_read kb_wrtnsda 18,00 380,00 28,00 380 28sdb 79,00 16,00 9000,00 16 9000and reading from it hard disk and usb drive simultaneously:device: tps kb_read/s kb_wrtn/s kb_read kb_wrtnsda 53,00 5180,00 0,00 5180 0sdb 1329,00 5316,00 0,00 5316 0there was nothing else going on in the machine and, when dd stopped, the disks became idle.is it some sort of internal checksumming process in dd? anything inherent to usb drives' drivers in linux 3.16.0?",
    "present_kp": [
      "dd"
    ],
    "absent_kp": []
  },
  {
    "text": "performing a background task and managing battery notifications for android. on the main view, all you see is a button to click on that says, start setup. once the user clicks on start setup, a file is read in the background and a progress bar is shown in the main thread. once the setup is complete, a setup complete notification should pop up. after that, some kind of status indicating the battery level or status should display to the user.here are my attempts so far. i've included it in a pastebin. feel free to ask me if you would like to see the views or something else.//main activity.javapackage com.example.patient_device;import android.app.activity;import android.app.progressdialog;import android.content.context;import android.content.intent;import android.database.sqlite.sqlitedatabase;import android.os.asynctask;import android.os.bundle;import android.view.view;import android.widget.button;import java.io.*;public class mainactivity extends activity { //fields private progressdialog progressbar; private context context; /** * called when the activity is first created. */ @override public void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); setcontentview(r.layout.start_setup); //set the context context = this; //initialize the start setup button and add an onclick event listener to the button final button start_setup_button = (button) findviewbyid(r.id.start_setup_button); start_setup_button.setonclicklistener(new view.onclicklistener() { public void onclick(view view) { //executes the asynctask new retrieveinfotask().execute(); //instantiates the intent to launch a new activity intent myintent = new intent(mainactivity.this, retrieveinfoactivity.class); mainactivity.this.startactivity(myintent); } }); } public class retrieveinfotask extends asynctask<void, void, void> { //called on the ui thread to execute progress bar @override protected void onpreexecute() { super.onpreexecute(); progressbar = new progressdialog(context); progressbar.setindeterminate(true); progressbar.setcancelable(false); progressbar.setmessage(mainactivity.this.getstring(r.string.retrieve_info)); progressbar.show(); } //methods that retrieves information from the user device. this is performed in the background thread private void retrieveinfo() { try { //reading the drawable resource line by line string str=; stringbuffer buf = new stringbuffer(); inputstream is = mainactivity.this.getresources().openrawresource(r.drawable.user_info); bufferedreader reader = new bufferedreader(new inputstreamreader(is)); if (is!=null) { while ((str = reader.readline()) != null) { buf.append(str + ); } } is.close(); } catch (exception e) { e.printstacktrace(); } } //doinbackground calls retrieveinfo() to perform action in background @override protected void doinbackground(void... params) { retrieveinfo(); return null; } //when the background task is done, dismiss the progress bar @override protected void onpostexecute(void result) { if (progressbar!=null) { progressbar.dismiss(); } } }}//retrieveinfoactivity.javapackage com.example.patient_device;import android.app.activity;import android.content.broadcastreceiver;import android.content.context;import android.content.intent;import android.content.intentfilter;import android.content.res.resources;import android.os.batterymanager;import android.os.bundle;import android.util.log;import android.widget.textview;import android.widget.toast;public class retrieveinfoactivity extends activity { private static string tag = retrieveinfoactivity; private context context; string filelastsync = 09-18-2014 03:47 pm; @override public void oncreate(bundle savedinstancestate) { context = this; super.oncreate(savedinstancestate); setcontentview(r.layout.retrieve_info); //once the new activity is launched, the setup is complete toast.maketext(getapplicationcontext(), setup complete!, toast.length_long).show(); //gets the 'last synced' string and sets to datetime of the last sync resources resources = context.getresources(); string syncstring = string.format(resources.getstring(r.string.last_sync), filelastsync); //dynamically sets the datetime of the last sync string textview lastsynctextview = ((textview) findviewbyid(r.id.last_sync) ); lastsynctextview.settext(syncstring); //calls registerreceiver to receive the broadcast for the state of battery this.registerreceiver(this.mbatinforeceiver,new intentfilter(intent.action_battery_changed)); } private broadcastreceiver mbatinforeceiver = new broadcastreceiver() { @override public void onreceive(context arg0, intent intent) { //battery level int level = intent.getintextra(level, 0); //dynamically sets the value of the battery level textview batterytextview = ((textview) findviewbyid(r.id.battery) ); batterytextview.settext(battery level: + string.valueof(level)+ %); //if the battery level drops below 25%, then announce the battery is low //todo: add 25 to constants file. if(level < 25) { toast.maketext(getapplicationcontext(), low battery!, toast.length_long).show(); } //plugged in status int plugged = intent.getintextra(batterymanager.extra_plugged, -1); //battery status int status = intent.getintextra(batterymanager.extra_status, -1); //if the device is charging or contains a full status, it's charging boolean ischarging = status == batterymanager.battery_status_charging || status == batterymanager.battery_status_full; //if the device ischarging and plugged in, then show that the battery is charging if(ischarging && plugged == batterymanager.battery_plugged_ac || plugged == batterymanager.battery_plugged_usb) { toast.maketext(getapplicationcontext(), charging.. + string.valueof(level)+ %, toast.length_long).show(); }else{ toast.maketext(getapplicationcontext(), unplugged!, toast.length_long).show(); } } }; @override public void ondestroy() { try { super.ondestroy(); unregisterreceiver(this.mbatinforeceiver); } catch (exception e) { log.e(retrieveinfoctivity.tag, getclass() + releasing receivers- + e.getmessage()); } }}//startsetupactivity.javaimport android.app.activity;import android.content.intent;import android.os.bundle;import android.view.view;import android.widget.button;public class startsetupactivity extends activity { @override public void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); }}//fragmentsactivity.javaimport android.app.fragment;import android.os.bundle;import android.view.layoutinflater;import android.view.view;import android.view.viewgroup;public class fragmentsactivity extends fragment{ @override public view oncreateview(layoutinflater inflater, viewgroup container, bundle savedinstancestate) { return inflater.inflate(r.layout.main, container, false); }}how can i better organize and structure my code? how can i make it cleaner? also, i'm still relatively new to design patterns. should i get a battery manager or a separate battery class right to handle all the battery notifications on the screen?i would like advice on what's traditionally used for battery notifications to go off if the phone is charging or unplugged and if the battery level is too low. should those notifications be done with alert dialogues or toasts?for the fragments activity, i just want to make my view on portrait and landscape mode. am i supposed to extend the fragmentsactivity class in the mainactivity class? i'm confused on how to use fragments in my classes so that the view is visible on portrait and landscape on rotation. any feedback on android lifecycle would be great as well.",
    "present_kp": [
      "java",
      "android"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "trying to use google sheets importhtml() to import a table. it forces content to a date format. i am trying to get a table into a sheet. the table contains data that looks like this:4-0-2this is wins-losses-ties. it comes in as a date. this is the command i use:importhtml(<url> table)this is the site: <url> have tried reformatting things in the sheet, but the damage has been done.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "optimal way to implement very big redirect list in apache2. i have about 6000 urls that need to be redirected after changing the cms. all those urls are stored in a db table together with an id that allows me to tell what is being referenced. using this table i could generate one huge .htaccess with a lot of rewrite rules but i suspect that is very inefficient. what's the best way to go? as far as i can tell there are two options:using a rewritemap where the key is the old url (it contains no id, just text, so it has to be the whole thing). i wonder if having 100-150 char long keys is gonna work well.generating a db table that exactly matches every old/new url pair and calling some small script to make the redirect.(could be summed up as: is a hash map stored in the filesystem more efficient than a indexed db table?)second part of the question. the new urls contain the id of the page being invoked. something like <url> instead i call <url> get a 301 redirect to the correct url. should i bother to generate the exact new url or is it ok to concatenate two redirects? this means either storing just an id or the whole new url.",
    "present_kp": [
      "redirects",
      "apache2",
      "hash"
    ],
    "absent_kp": [
      "mod rewrite"
    ]
  },
  {
    "text": "numerical methods for inverting integral transforms?. i'm trying to numerically invert the following integral transform:$$f(y) = \\int_{0}^{\\infty} y\\exp{\\left[- rac{1}{2}(y^2 + x^2) ight]} i_0\\left(xy ight)f(x)\\;\\mathrm{d}x$$so for a given $f(y)$ i need to approximate $f(x)$where:$f(x)$ and $f(y)$ are real and positive (they are continuous probability distributions)$x,y$ are real and positive (they are magnitudes)i have a very messy and brute force method for doing this at the minute: i define $f(x)$ and the spline over a series of points, the values of the splined points are 'guessed' by random sampling, which yields a predicted $f(y)$. a basic genetic algorithm i wrote up minimises the difference between the predicted and measured $f(y)$ array. i then take the $f(x)$ which the algorithm converges to as my answer for the inversion.this approach works fairly well for some simple cases, but it feels messy to me and not particularly robust.can anyone give me guidance on better ways of solving this problem?thanks for your time & help![x-posted at computerscience]",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "numerical analysis",
      "approximation algorithms",
      "inverse problem"
    ]
  },
  {
    "text": "mkdir foo; svn mv * foo. i often want to do some variant of this idiom:$ mkdir 2010$ svn mv * 2010of course, i get an error because the glob matches 2010 as well:svn: cannot copy path '2010' into its own child '2010/2010'is there a way to replace svn mv * 2010 with a different one-liner that does the right thing?",
    "present_kp": [],
    "absent_kp": [
      "shell",
      "directory",
      "rename",
      "wildcards"
    ]
  },
  {
    "text": "yum is asking for nonexistent updateinfo.xml hashes on the repodata directory. any idea why i need to yum clean dbcache metadata frequently? i am using centos6.6 and it has the epel repo. it frequently fails to get the packages from the mirrors with a 404 error until i clean the yum again. below is a part of the log.trying other mirror.http://mirrors.syringanetworks.net/fedora-epel/6/x86_64/repodata/3a5d63c8e27b2a5b5bf046c71ec05e3710df642c3e13f6e6354bd2b613f3c7e7-updateinfo.xml.gz: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.http://mirror.sfo12.us.leaseweb.net/epel/6/x86_64/repodata/3a5d63c8e27b2a5b5bf046c71ec05e3710df642c3e13f6e6354bd2b613f3c7e7-updateinfo.xml.gz: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.http://mirrors.cat.pdx.edu/epel/6/x86_64/repodata/3a5d63c8e27b2a5b5bf046c71ec05e3710df642c3e13f6e6354bd2b613f3c7e7-updateinfo.xml.gz: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.http://mirrors.tummy.com/pub/fedora.redhat.com/epel/6/x86_64/repodata/3a5d63c8e27b2a5b5bf046c71ec05e3710df642c3e13f6e6354bd2b613f3c7e7-updateinfo.xml.gz: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.http://mirrors.kernel.org/fedora-epel/6/x86_64/repodata/3a5d63c8e27b2a5b5bf046c71ec05e3710df642c3e13f6e6354bd2b613f3c7e7-updateinfo.xml.gz: [errno 14] pycurl error 22 - the requested url returned error: 404 not foundtrying other mirror.this is the repolist output# yum repolistloaded plugins: fastestmirror, presto, securityloading mirror speeds from cached hostfile * base: mirror.solarvps.com * epel: mirror.symnds.com * extras: mirror.metrocast.net * updates: mirror.es.its.nyu.edurepo id repo name statusbase centos-6 - base 6,518epel extra packages for enterprise linux 6 - x86_64 11,745extras centos-6 - extras 38updates centos-6 - updates 1,370repolist: 19,671updates:i use the chef cookbook to install. <url> .. i don't see any special means used to install the repo./var/log/yum.log (shows the plugin that i installed today, after cleaning yum)jul 07 20:42:05 installed: wget-1.12-5.el6_6.1.x86_64jul 23 17:17:12 updated: nginx-filesystem-1.0.15-12.el6.noarchjul 23 17:17:12 updated: nginx-1.0.15-12.el6.x86_64jul 30 21:25:43 installed: yum-plugin-security-1.1.30-30.el6.noarch/etc/yum.conf# this file was generated by chef# do not modify this file by hand.[main]cachedir=/var/cache/yum/$basearch/$releaseverdebuglevel=2distroverpkg=centos-releaseexactarch=1gpgcheck=1installonly_limit=3keepcache=0logfile=/var/log/yum.logobsoletes=1plugins=1/etc/yum.repos.d/epel.repo# this file was generated by chef# do not modify this file by hand.[epel]name=extra packages for enterprise linux 6 - $basearchenabled=1failovermethod=prioritygpgcheck=1gpgkey=<url>",
    "present_kp": [
      "yum"
    ],
    "absent_kp": []
  },
  {
    "text": "can i delete messages from the trash after x days in mutt?. i'd like to use a trash folder in mutt. i know how to create a macro that moves mail to the trash folder instead of deleting. however, i'd also like to automatically delete messages that sit there for seven days (as thunderbird can do).my mail is stored in maildir format. i could create a crontab that deleted files/messages from the trash directory, but it'd have to know when files were transferred. i thought a simple way might be to touch files as they were transferred. then, i could just delete based on modification date. is there a way to do make mutt touch files as it moves them, or is there a better way to delete files periodically from the trash?",
    "present_kp": [
      "mutt"
    ],
    "absent_kp": []
  },
  {
    "text": "is it ok to learn from c# 2002 materials?. i've found some videos that explain c# but it back to c#.net when it is first appeared, if i learn from these videos will i learn something that has been removed from the language? will i miss alot?",
    "present_kp": [
      "c#"
    ],
    "absent_kp": []
  },
  {
    "text": "stabilized dg method and fem space-time discretizations references. can someone give me a good reference on the following 2 topics:(1) analysis of stabilized (e.g streamline artificial diffusion ) discontinuous galerkin (dg) methods for first order pdes(2) finite element space-time discretizationsthanks in advance !",
    "present_kp": [
      "finite element",
      "discontinuous galerkin"
    ],
    "absent_kp": [
      "numerical analysis",
      "reference request",
      "space time galerkin"
    ]
  },
  {
    "text": "can every dcfg be converted to dgnf?. i know you can convert every context-free grammar into greibach normal form grammar.but can i convert every deterministic context-free grammar into deterministic greibach normal form grammar?",
    "present_kp": [],
    "absent_kp": [
      "context free",
      "formal grammars",
      "normal forms"
    ]
  },
  {
    "text": "kali linux postgresql error. i recently installed kali linux and keep getting an error code starting metasploit this is the code [...] starting postgresql 9.1 database server: main[...] error: could not exec /usr/lib/postgresql/9.1/bin/pg_ctl /usr/lib/postgresql/9.1/bin/pg_ctl start -d /var/lib/postgresql/9.1/main -l /var/log/postgresql/postgresql-9.1-main.log -s -[failconfig_file=/etc/postgresql/9.1/main/postgresql.conf: ... failed!failed!would really appreciate a solution been stuck for awhile.",
    "present_kp": [
      "kali linux",
      "postgresql"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a better way to describe brain activity than eeg brain waves. i've been reading about eeg brain waves, which are specific waveforms that are observed on the eeg output, and are usually scored by humans. this concept has been around for quite some time.is there anything newer or better than eeg brainwaves discovered in the recent years? given the rise in commercially available eeg sensors, has any company succeeded at putting forth a way to analyze or quantify the output of these sensors to give some useful information to researchers? i'm thinking of brainwave-processing algorithms. for example in actigraphy, the study of human motion, there are algorithms like if 19 out of 20 minutes of activity are scored as sleep, then the sleep onset is known to happen at the start of the 20 minute window. is there something similar for brainwave or derived metrics?",
    "present_kp": [
      "eeg"
    ],
    "absent_kp": [
      "neurobiology",
      "measurement",
      "neuroimaging"
    ]
  },
  {
    "text": "complete finite automaton to never fail a match but either match original or up until the orginal. suppose i have a finite automaton to match a simple string abc and i built some software around it to not only match the start of a string or a full incoming string, but rather to search through a string and find the first match. as an example consider the string to be 12abcxxx.the naive approach is to start with reading the '1' and trying a transition in the automaton. it fails. so we advance the input and try again, with '2'. fail again. now read 'a', 'b', 'c' nicely transition though the automaton, reach the stop state, store it, read 'x', fail and declare a match for the latest stop state we ran through.if we assume that every 'fail' in this algorithm is inefficient, while transitions through the automaton are fast, an improvement would be to extend the automaton such that it matches either 'abc' or '[^a]+' and mark the different stop states as 'found abc' and 'not found abc'. then '123' would be a match, supposedly much faster then three fails to skip over.but adding '[^a]+' is not the only optimization. we could even add something like '([^a]|a[^b]|ab[^c])+' (which is not completely correct) to the automaton to skip over the non-matching sequences quickly.question: working with a finite automaton that allows to mark stop states with different markers, and given an automaton for a regular expression re, is it possible to complete the automaton such that it implements the quick skip over non-matching substrings as described informally above.if it is possible, what would be the operation to perform either on the regular expression or an nfa or dfa representation? i would expect the result to talk about something like the complement set of the prefix set recognized by the original automaton.question rephrased: reading the first answer i realized that the question is equivalent to the following: given a regular language $l$, is there a regular language $l_p$ that satisfies the following: for all strings $s\\in\\sigma^*$, $l_p$ shall contain the prefix of $s$ that ends just before an $s_x\\in l$ or the complete $s$ if no such substring exists.",
    "present_kp": [],
    "absent_kp": [
      "automata",
      "finite automata"
    ]
  },
  {
    "text": "exclamation points in error messages. what do you think about using exclamation points in error messages? i.e. the address is not valid!.personally, i think it adds nothing, insults the user, and makes the product look like it was written in trs-80 basic by a 12-year-old.",
    "present_kp": [
      "error messages"
    ],
    "absent_kp": []
  },
  {
    "text": "error on enabled probe: syscall::open_nocancel:entry): invalid user access in action #2 at dif. i've the following one-liner to show files opened by process:sudo dtrace -n 'syscall::open*:entry { printf(%s %s,execname,copyinstr(arg0)); }'however i've plenty of repeated errors such as:dtrace: error on enabled probe id 4 (id 946: syscall::open_nocancel:entry): invalid user access in action #2 at dif offset 24dtrace: error on enabled probe id 7 (id 160: syscall::open:entry): invalid user access in action #2 at dif offset 24i'm aware that i can suppress them by redirecting to 2> /dev/null.what these errors means and why they're happening?is it dtrace fault, or some specific process causing that? and how this problem can be addressed?i'm using os x 10.11.2",
    "present_kp": [
      "dtrace"
    ],
    "absent_kp": [
      "kernel",
      "osx"
    ]
  },
  {
    "text": "how to use unit testing?. how to use unit testing?there are a lot of frameworks for different languages, which provide functionality of unit testing. there is a lot of information on how to use each of them technically. just like import to your project this lib, type assert, compile, run and blah-blah-blah. and it all is easy to learn.the place im confused in is how to get it: which test to write, to cover large amount of possible bugs?for example, assume we use jasmine framework for js, and we are to test email validation function.great. our simple code will look like this:describe(email validation test, function() { it(isemailvalid(\\<email>) should be true, function() { expect(isemailvalid(<email>)).tobe(true); });});but actually we have no ideas how does isemailvalid function is written and where can it fail. maybe it works only if we have gmail.com domain? so we should include another one test with any other domain.or maybe it doesn't work if we have some very specific domain, just like warhammerhobbitbanachspace.am? in that case it would be rather difficult to catch a bug. or, even, impossible.or maybe it'll fail if we have more than 42 symbols in the string with email? or maybe it'll fail if we have exactly 9 symbols?and that is only a little amount of examples of places which it would be useful to test. and that is just a simple string validation function...and how can we really test some complex objects then? yeah, i know, it is impossible to test everything. but how then to choose what really should be tested, and what not?are there any books or articles, which explain ... some patterns/techniques/principals of covering the code with useful tests?",
    "present_kp": [
      "testing",
      "unit testing"
    ],
    "absent_kp": [
      "programming practices"
    ]
  },
  {
    "text": "developer friendly wifi sdhc card. there are a few sdhc cards with wifi, but i find it difficult to understand what they can actually do, and even harder to find out how they do it. i would like a card that is developer friendly and lets me access it through an api of some sort. i know that the flashair card has a developers site, but i find the product information lacking for the competition.an example of a simple task could be to automatically download all raw files from the sdhc card and convert them to jpeg on the computer.things that would be interesting to know are:can the card be accessed through open protocols, or do you need a proprietary library?if you need a lib, which platforms are supported?are there licenses or any other restrictions on developing and distributing apps for the card?what capabilities does or doesn't the card have? read, write, access without user interaction through some kind of pairing for example.",
    "present_kp": [
      "wifi"
    ],
    "absent_kp": [
      "memory card"
    ]
  },
  {
    "text": "saving tabular, spreadsheet-like data in a relational database?. i'm hoping this question isn't too broad or too prone to opinionated answers, since i could really use some pointers.i'm trying to come up with a way to persist tabular, spreadsheet-like1, data in a backend. since the data could very well end up being rather fuzzy (not easily identifiable as being identical, even though the user may have intended it to be), i'm having doubts about persisting it in a relational sql database.users will be able to create multiple tables of this kind:+====================================================+| category |+==============================+==========+==========+| item | type a | type b |+==============================+==========+==========+| name | value | value |+------------------------------+----------+----------+| name | value | value |+------------------------------+----------+----------+the data will merely be used for representational purposes, to give an overview of categorized items and there respective type values. no relational business logic between cell-data will be implemented.per table, users will be able to define a certain custom amount of type columns. furthermore, there will not be too many constraints on the permitted cell data, except for the value cells, which will be numeric2. lastly, users will also be able to migrate item rows and type columns between tables.originally, my idea was to persist this in a relational sql database, which, simplified, pretty much comes down to this:category------id pknameitem------id pkcategory_id fk category(id)namesortordertype------id pkcategory_id fk category(id)namesortorderitem_type_value------id pkitem_id fk item(id)type_id fk type(id)valuethe main reasons i'm having starting to have doubts about persisting this in a relational database is that even though a user may intend type a in one table to mean the same as type-a in some other table, i'll never be certain. and since i don't want to restrict the user too much (nor do i want to burden myself with too complicated an interface, like letting users first define a type, which they can then select from a drop-down, for instance, or ask whether they intended type-a to mean the same as type a), i doubt this lends itself particularly well for a relational setup, other than perhaps defining relations about which cells belongs to which tables, etc.if one is to assume aforementioned lenient constraints, does it make sense to look for an alternative persistent storage mechanisms than a relational sql database?if so, could you suggest a particularly well-suited persistence mechanism for this type of data? nosql or xml, perhaps?1) perhaps spreadsheet-like is a bit misleading; it will simply be tables where users will be able to insert scalar values (strings and/or numbers) in cells. nothing more; no formulas, calculations, etc. spreadsheet-like pertains to the fact that users will be able to edit the cell-data inline. that's where the similarity basically ends.2) the numeric constraint isn't actually that important either. it's predominantly mentioned to give a little bit of context.",
    "present_kp": [
      "database",
      "persistence"
    ],
    "absent_kp": [
      "database design"
    ]
  },
  {
    "text": "can i refresh my shell within a shell script?. very new to bash scripting...i am trying to setup a script that starts with a minimal centos 6 install and provisions it for ruby development.#!/bin/bash# add postgresql reporpm -i <url> add nginx repoecho '[nginx]' > /etc/yum.repos.d/nginx.repoecho 'name=nginx repo' >> /etc/yum.repos.d/nginx.repoecho 'baseurl=<url> >> /etc/yum.repos.d/nginx.repoecho 'gpgcheck=0' >> /etc/yum.repos.d/nginx.repoecho 'enabled=1' >> /etc/yum.repos.d/nginx.repo# updateyum update -y# install nginx, postgresql, and ruby dependenciesyum install -y nginx postgresql91-server postgresql91-contrib gcc-c++ patch readline readline-devel zlib zlib-devel libyaml-devel libffi-devel openssl-devel make bzip2 autoconf automake libtool bison piconv-devel sqlite-devel git-core# postgresql post installservice postgresql-9.1 initdbchkconfig postgresql-9.1 on# install rbenv system wide installgit clone git://github.com/sstephenson/rbenv.git /usr/local/rbenv# install ruby-buildgit clone git://github.com/sstephenson/ruby-build.git /usr/local/rbenv/plugins/ruby-build# add rbenv to the pathecho '# rbenv setup - only add rbenv path variables if no single user install found' > /etc/profile.d/rbenv.shecho 'if [[ ! -d ${home}/.rbenv ]]; then' >> /etc/profile.d/rbenv.shecho ' export rbenv_root=/usr/local/rbenv' >> /etc/profile.d/rbenv.shecho ' export path=$rbenv_root/bin:$path' >> /etc/profile.d/rbenv.shecho ' eval $(rbenv init -)' >> /etc/profile.d/rbenv.shecho 'fi' >> /etc/profile.d/rbenv.shchmod +x /etc/profile.d/rbenv.sh# shell needs to be refreshed here# install latest rubyrbenv install 1.9.3-p286# set global rubyrbenv global 1.9.3-p286i am getting a rbenv: command not found error when it gets to the point where it uses rbenv because my shell needs refreshed/restarted for it to recognize the command. how can i accomplish this? thanks.",
    "present_kp": [
      "bash",
      "shell",
      "centos",
      "ruby"
    ],
    "absent_kp": []
  },
  {
    "text": "should i build links to my images?. i know a basic of image seo is that we optimize image tag with alt and title, but i noticed that my specific page get on top with some keywords but my images doesn't. why?how can i improve it?improving onpage, add more h2, h3, internal link, add more content... etc ?put link to images ? ---- may be i create backlink to my images? --- keyword ?should i create more attributes for my image like width =, height =, how about uploading new image to my host or use exist images on others site? which is better?does it affect to my images?thank so much",
    "present_kp": [
      "images",
      "content"
    ],
    "absent_kp": [
      "google image search",
      "image size"
    ]
  },
  {
    "text": "differences between volume, partition and drive. what do these terms mean exactly?partitionvolumedriveon windows, one may say drive c: or partition c:. on linux i'm not sure what should be used for partitions because they don't have a name.",
    "present_kp": [],
    "absent_kp": [
      "hard disk"
    ]
  },
  {
    "text": "proper usages of rooms/namespaces when making a news feed with socket.io. i am working on making a news feed for a piece of software that will have data posted to different hierarchical levels within the software. for example, the software will support multiple organizations, each of which may have multiple teams, with multiple squads under each of those.top level users in the organization may see content from all of the content posted to anywhere in the organization (or any of its teams or squads). medium level users should be able to see content posted to the entire organization, or content only within their own team (and its squads). the lowest level users should see content posted only to the entire organization, or their team, or their specific squad.the database will also differential between 'posts', which can appear on a number of people's feeds and be commented on, and 'notifications' which are indicators for individual users that particular events happened, and must be dismissed by the user.i should also note that at the moment, i am not interested in assigning different weights to posts and only making certain posts appear. i am fine with having everyone see every post relevant to them in reverse chronological order.now, i am planning on using socket.io to make this feed update live. from my understanding socket.io relies on namespaces and rooms to determine. my question is about how to leverage these features in order to make this feed function.from a preliminary glance at it, i can see one of two ways of tackling the problem:option 1: create socket.io namespaces (or perhaps rooms) for each node in the hierarchy of the organization (the organization itself, each team, each squad) and make each client join each of their relevant namespaces (top level users would join every namespace in the entire organization, bottom level users would only join the global organization namespace, their team namespace, and their squad namespace). the user facing feed would be an aggregate of all of the namespaces they are in.the upside of this design is that since there are multiple users per namespace, even though i am writing new posts to the database, i can push posts directly from one client to the others in that namespace. this avoids having to do any database lookups for distributing posts to the other users that are already on the application.option 2: create a socket.io namespace (or again, perhaps room) for each user. then just have every client periodically poll the server for new posts that are relevant to them and should be displayed on their news feed. this option would effectively be an ajax style solution without the overhead of actual ajax calls to the php backend that this application is written in.a sort of variation of this second option may be to still make a namespace for each user, but then when new content is posted, have the posts be pushed directly to other user namespaces. i am not sure if/how this would be possible.i would appreciate it if anyone could give any advice on how to proceed.",
    "present_kp": [],
    "absent_kp": [
      "node.js",
      "websockets"
    ]
  },
  {
    "text": "code behaviour: working object orientated with a database. i'm working on my own php framework for a long while now.right now i'm in a refactoring process.i'm came up with the question what a programmer would excpect what happens when he see following code:// working object orientated with a database.$usergroup = new usergroupmodel();$usergroup->title = 'guest';$usergroup->insert(); // execute sql$user = new usermodel();$user->name = 'peter';$user->usergroupid = $usergroup->usergroupid;// print all usersprint_r($usergroup->users);$user->insert(); // execute sql// print all usersprint_r($usergroup->users);would you expect that $usergroup->users imeditaley contains the reference or after the statement $user->insert();.(currently it is the second one.)the same with an update statement:// lets pretend we got the $usergroup1 and $usergroup2 from the database$user = $usergroup1->users[0];$user->usergroupid = $usergroup2->usergroupid;print_r($usergroup1->users);print_r($usergroup2->users);$user->update();print_r($usergroup1->users);print_r($usergroup2->users);would you expect that $usergroup->users imeditaley contains the changed reference or after the statement $user->update().(currently it is the first one.)because working with new objects and already existing ones behave differently i thought it might could be confusing.my suggestion would be that the reference is updated imeditaley.at the moment references for new objects aren't updated imeditaley because the reference is based on the primary key that doesn't exists yet. it exists after we run insert().maybe i could solve this problem by working internal ids and not database ids.but the real question is, what would you expect what happens (for the references) without reading any documentation?edit@showerheadif i got you right, you would consider this as an better way:$usergroup = new usergroupmodel();$usergroup->name = ...;$usergroup->save(); // runs an insert or update sql statement$user = new usermodel();$user->name = ...;$user->usergroupid = $usergroup->usergroupid;$user->save(); // runs an insert or update sql statementprint_r($usergroup->users); // would be still empty here$usergroup->loadchanges(); // load the changes// now we have the new reference in $usergroup->usersprint_r($usergroup->users);",
    "present_kp": [
      "php"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the case 2 in master theorem?. i am confused about the statement of the master theorem in clrs book.here is the link of the book clrs.in page 94, the theorem, in case 2, states that:if $\\displaystyle f(n)=\\theta(n^{\\log_ba})$, then $t(n) = \\theta(n^{\\log_ba}\\lg n)$.what if $t(n) = t(n/2) + \\theta(\\lg n)$? we have $f(n)=\\theta(\\lg n) eq\\theta(1)$.i found the slides of the clrs book in mit website here where the statement of the theorem looks different in case 2 (page 5). if $\\displaystyle f(n)=\\theta(n^{\\log_ba}\\lg^k n)$, then $t(n) = \\theta(n^{\\log_ba}\\lg^{k+1} n)$.what am i missing here?",
    "present_kp": [
      "master theorem"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "provide data via named pipe. i have a few data files that provide filenames of songs in a proprietary fashion. now i want to convert that data to m3u-files and make that available to all applications. i don't want to use something like a cronjob that generates the m3u-files as that's not as dynamic as i want it to be.therefore, i decided to use named pipes. my scenario looks like this:-rw-rw-rw-+ 1 sjngm sjngm 33929 6. may 12:56 songstore-1.dataprw-r--r-- 1 sjngm sjngm 0 6. may 18:38 songstore-1.data.m3u-rw-rw-rw- 1 sjngm sjngm 7750 6. may 12:56 songstore-2.dataprw-r--r-- 1 sjngm sjngm 0 6. may 18:38 songstore-2.data.m3u:the script to do one run for one file seems to do its job nicely:#/bin/bashfile=$1echo #extm3upaste -d ' ' \\ <(tail -n +4 $file | grep ^#description | sed -e 's/#description /#extinf:0,/') \\ <(tail -n +4 $file | grep ^#service | cut -d ':' -f 11 | sed -e 's/%3a/:/gi')this is the shell-script code that in the end should be stored in ~/.xprofile:cd ~/garage/songstoresls -1 songstore-* | paste - - | while read in pipe; do echo $in... while true; do ~/shell-scripts/convert.sh $in > $pipe done & doneafter running this the loops show up in ps. when i cat one m3u the output appears many more times rather than just once. one songstore-file is actually empty and the output is:$ cat songstore-13.data.m3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u#extm3u$the next time i execute the cat the number of lines is different, but always more than one. the idea is that the cat results in just one display of the content.again, the script itself works when run in a single execution on the command line. the problem must be in connection with the pipes and how i write to (or maybe read from) them.what didn't i understand there and how do i fix it?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "fifo"
    ]
  },
  {
    "text": "assembly summation implementation. i wrote a simple summation program in mars to practice using loops and jump instructions. i feel like this is pretty lightweight and wanted some feedback on possible improvements:lowering instruction countorganizational changesam i correct in assuming this is a do-while loop?# description: summation program implementing a do-while loop# author: evan bechtol .dataprompt: .asciiz enter number to get summation: output: .ascii sum of numbers is: .globl main .textmain: # prompt for input li $v0, 4 la $a0, prompt syscall # read input li $v0, 5 syscall add $s0, $zero, $v0 # begin summation addi $s1, $zero, 1 # $s1 used to store summation, starts at 1 addi $t1, $zero, 1 # $t1 used as counter, starts at 1 jal loop # go to loop # display li $v0, 4 la $a0, output syscall li $v0, 1 add $a0, $zero, $s1 syscall # exit la $v0, 10 syscallloop: addi $t1, $t1, 1 add $s1, $s1, $t1 bne $t1, $s0, loop jr $ra",
    "present_kp": [
      "assembly"
    ],
    "absent_kp": []
  },
  {
    "text": "fun with ubuntu 16.04 and mysql. i want to thank you in advance if you manage to get all the way through this post and give me some ideas. it's a lot. i am on ubuntu 16.04 on a 64bit dell 1820. it is dual boot with windows, and i've been using this setup since 16.04 came out. i have had no use for apache, php, or mysql on this setup until now.i wanted to set up a local wordpress, so i went to a 'one-click' solution called ampps. this thing bundles over 400 programs in a self contained lamp. however, the default version of php was 5.5, which a great many apps (maybe the majority) reported back through the ampps dashboard that they couldn't use. i figured out how to switch it to php 7, whereupon wordpress informed me that:your php installation appears to be missing the mysql extension which is required by wordpress.numerous postings to their support system and forum got me nowhere, so i came here.it turns out ampps default setup:has no php.ini file in either 7.0 or 7.1there are ini files in php 5.3 and 5.5opening the ini files routes through wine, and open in a version of notepad. is that a red flag?so i thought, what the heck, i've got my own mysql and php 7 as part of ubuntu 16.04. and i can install and configure apache. it's been 4 or 5 years, but i've done it. i tried opening mysql directly:error 2002 (hy000): can't connect to local mysql server through socket '/var/run/mysqld/mysqld.sock' (2)that's how i learned that i don't have /var/run/mysqld/mysqld.sock. i don't even have /var/run/mysqld!stumbling blindly around the internet, i found out that i should check /etc/mysql/my.cnf. but this file only had one line in it:!includedir /etc/mysql/conf.d/and all conf.d/mysql.conf has in it is:[mysql]so i put the port and localhost in my.cnf, at which point i got a new fatal error.after restart:malikarumi@tetuoan2:~$ mysqlmysql: [error] found option without preceding group in config file /etc/mysql/my.cnf at line 19!mysql: [error] fatal error in defaults handling. program aborted!malikarumi@tetuoan2:~$port=3306 # this is line 19bind-address=127.0.0.1turns out i had to put [mysql] on the first line of my.cnf. now i was back where i started - nowhere.i decided i would just start over by removing mysql 5.6 and reinstalling. well, that didn't go well either:malikarumi@tetuoan2:~$ sudo apt-get install mysql-serverreading package lists... done''building dependency treereading state information... donethe following packages were automatically installed and are no longer required: libmircommon5 linux-headers-4.4.0-78 linux-headers-4.4.0-78-generic linux-headers-4.4.0-79 linux-headers-4.4.0-79-generic linux-image-4.4.0-78-generic linux-image-4.4.0-79-generic linux-image-extra-4.4.0-78-generic linux-image-extra-4.4.0-79-generic linux-signed-image-4.4.0-78-generic linux-signed-image-4.4.0-79-genericuse 'sudo apt autoremove' to remove them.the following additional packages will be installed: libevent-core-2.0-5 libhtml-template-perl mysql-client-5.7 mysql-client-core-5.7 mysql-server-5.7 mysql-server-core-5.7suggested packages: libipc-sharedcache-perl tinycathe following packages will be removed: mysql-client-core-5.6 mysql-server-core-5.6the following new packages will be installed: libevent-core-2.0-5 libhtml-template-perl mysql-client-5.7 mysql-client-core-5.7 mysql-server mysql-server-5.7 mysql-server-core-5.70 upgraded, 7 newly installed, 2 to remove and 0 not upgraded.need to get 18.3 mb of archives.after this operation, 113 mb of additional disk space will be used.do you want to continue? [y/n] yget:1 <url> xenial-updates/main amd64 mysql-client-core-5.7 amd64 5.7.18-0ubuntu0.16.04.1 [6,340 kb]get:2 <url> xenial-updates/main amd64 mysql-server-core-5.7 amd64 5.7.18-0ubuntu0.16.04.1 [7,566 kb]get:3 <url> xenial-updates/main amd64 mysql-client-5.7 amd64 5.7.18-0ubuntu0.16.04.1 [1,725 kb]get:4 <url> xenial-updates/main amd64 libevent-core-2.0-5 amd64 2.0.21-stable-2ubuntu0.16.04.1 [70.6 kb]get:5 <url> xenial-updates/main amd64 mysql-server-5.7 amd64 5.7.18-0ubuntu0.16.04.1 [2,554 kb]get:6 <url> xenial/main amd64 libhtml-template-perl all 2.95-2 [60.4 kb]get:7 <url> xenial-updates/main amd64 mysql-server all 5.7.18-0ubuntu0.16.04.1 [10.8 kb]fetched 18.3 mb in 24s (746 kb/s)preconfiguring packages ...dpkg: mysql-client-core-5.6: dependency problems, but removing anyway as you requested: akonadi-backend-mysql depends on mysql-client-core-5.7 | virtual-mysql-client-core; however: package mysql-client-core-5.7 is not installed. package virtual-mysql-client-core is not installed. package mysql-client-core-5.6 which provides virtual-mysql-client-core is to be removed.(reading database ... 374021 files and directories currently installed.)removing mysql-client-core-5.6 (5.6.31-0ubuntu0.15.10.1) ...processing triggers for man-db (2.7.5-1) ...selecting previously unselected package mysql-client-core-5.7.(reading database ... 374013 files and directories currently installed.)preparing to unpack .../mysql-client-core-5.7_5.7.18-0ubuntu0.16.04.1_amd64.deb ...unpacking mysql-client-core-5.7 (5.7.18-0ubuntu0.16.04.1) ...processing triggers for man-db (2.7.5-1) ...dpkg: mysql-server-core-5.6: dependency problems, but removing anyway as you requested: akonadi-backend-mysql depends on mysql-server-core-5.7 | virtual-mysql-server-core; however: package mysql-server-core-5.7 is not installed. package virtual-mysql-server-core is not installed. package mysql-server-core-5.6 which provides virtual-mysql-server-core is to be removed.(reading database ... 374022 files and directories currently installed.)removing mysql-server-core-5.6 (5.6.31-0ubuntu0.15.10.1) ...processing triggers for man-db (2.7.5-1) ...selecting previously unselected package mysql-server-core-5.7.(reading database ... 373927 files and directories currently installed.)preparing to unpack .../mysql-server-core-5.7_5.7.18-0ubuntu0.16.04.1_amd64.deb ...unpacking mysql-server-core-5.7 (5.7.18-0ubuntu0.16.04.1) ...selecting previously unselected package mysql-client-5.7.preparing to unpack .../mysql-client-5.7_5.7.18-0ubuntu0.16.04.1_amd64.deb ...unpacking mysql-client-5.7 (5.7.18-0ubuntu0.16.04.1) ...selecting previously unselected package libevent-core-2.0-5:amd64.preparing to unpack .../libevent-core-2.0-5_2.0.21-stable-2ubuntu0.16.04.1_amd64.deb ...unpacking libevent-core-2.0-5:amd64 (2.0.21-stable-2ubuntu0.16.04.1) ...selecting previously unselected package mysql-server-5.7.preparing to unpack .../mysql-server-5.7_5.7.18-0ubuntu0.16.04.1_amd64.deb ...unpacking mysql-server-5.7 (5.7.18-0ubuntu0.16.04.1) ...selecting previously unselected package libhtml-template-perl.preparing to unpack .../libhtml-template-perl_2.95-2_all.deb ...unpacking libhtml-template-perl (2.95-2) ...selecting previously unselected package mysql-server.preparing to unpack .../mysql-server_5.7.18-0ubuntu0.16.04.1_all.deb ...unpacking mysql-server (5.7.18-0ubuntu0.16.04.1) ...processing triggers for man-db (2.7.5-1) ...processing triggers for libc-bin (2.23-0ubuntu9) .../sbin/ldconfig.real: file /usr/local/lib/libqtcore.so is empty, not checked./sbin/ldconfig.real: /lib/x86_64-linux-gnu/libssl.so.1.0.0 is not a symbolic link/sbin/ldconfig.real: /lib/x86_64-linux-gnu/libcrypto.so.1.0.0 is not a symbolic linkprocessing triggers for systemd (229-4ubuntu17) ...processing triggers for ureadahead (0.100.0-19) ...ureadahead will be reprofiled on next rebootsetting up mysql-client-core-5.7 (5.7.18-0ubuntu0.16.04.1) ...setting up mysql-server-core-5.7 (5.7.18-0ubuntu0.16.04.1) ...setting up mysql-client-5.7 (5.7.18-0ubuntu0.16.04.1) ...setting up libevent-core-2.0-5:amd64 (2.0.21-stable-2ubuntu0.16.04.1) ...setting up mysql-server-5.7 (5.7.18-0ubuntu0.16.04.1) ...update-alternatives: using /etc/mysql/mysql.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto moderenaming removed key_buffer and myisam-recover options (if present)insserv: warning: script 'k01ampps' missing lsb tags and overridesinsserv: warning: script 'k01httpd' missing lsb tags and overridesinsserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mysql: service mysql already provided!insserv: exiting now!update-rc.d: error: insserv rejected the script headerdpkg: error processing package mysql-server-5.7 (--configure): subprocess installed post-installation script returned error exit status 1'setting up libhtml-template-perl (2.95-2) ...dpkg: dependency problems prevent configuration of mysql-server: mysql-server depends on mysql-server-5.7; however: package mysql-server-5.7 is not configured yet.'dpkg: error processing package mysql-server (--configure): dependency problems - leaving unconfiguredno apport report written because the error message indicates its a followup error from a previous failure. processing triggers for libc-bin (2.23-0ubuntu9) .../sbin/ldconfig.real: file /usr/local/lib/libqtcore.so is empty, not checked./sbin/ldconfig.real: /lib/x86_64-linux-gnu/libssl.so.1.0.0 is not a symbolic link/sbin/ldconfig.real: /lib/x86_64-linux-gnu/libcrypto.so.1.0.0 is not a symbolic linkprocessing triggers for systemd (229-4ubuntu17) ...processing triggers for ureadahead (0.100.0-19) ...errors were encountered while processing: mysql-server-5.7 mysql-servere: sub-process /usr/bin/dpkg returned an error code (1)malikarumi@tetuoan2:~$ the canonical/ubuntu system referred me to the bug tracker:<url> this issue is considered expired - not fixed - because there's been no activity for 60 days!!!finally, i found out about the command apt-show-versions, ( from here: dpkg won't install any package) so i tried that to see what i could find out:malikarumi@tetuoan2:~$ apt-show-versionsthe program 'apt-show-versions' is currently not installed. you can install it by typing:sudo apt install apt-show-versionsmalikarumi@tetuoan2:~$ sudo apt install apt-show-versions[sudo] password for malikarumi: reading package lists... donebuilding dependency treereading state information... donethe following new packages will be installed: apt-show-versions0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.2 not fully installed or removed.need to get 29.6 kb of archives.after this operation, 163 kb of additional disk space will be used.get:1 <url> xenial/universe amd64 apt-show-versions all 0.22.7 [29.6 kb]fetched 29.6 kb in 0s (44.9 kb/s)selecting previously unselected package apt-show-versions.(reading database ... 309531 files and directories currently installed.)preparing to unpack .../apt-show-versions_0.22.7_all.deb ...unpacking apt-show-versions (0.22.7) ...processing triggers for man-db (2.7.5-1) ...setting up mysql-server-5.7 (5.7.18-0ubuntu0.16.04.1) ...renaming removed key_buffer and myisam-recover options (if present)insserv: warning: script 'k01ampps' missing lsb tags and overridesinsserv: warning: script 'k01httpd' missing lsb tags and overridesinsserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mongod is broken: incomplete lsb comment.insserv: missingrequired-start:' entry: please add even if empty.insserv: missing required-stop:' entry: please add even if empty.insserv: script mysql: service mysql already provided!insserv: exiting now!update-rc.d: error: insserv rejected the script headerdpkg: error processing package mysql-server-5.7 (--configure): subprocess installed post-installation script returned error exit status 1dpkg: dependency problems prevent configuration of mysql-server: mysql-server depends on mysql-server-5.7; however: package mysql-server-5.7 is not configured yet.dpkg: error processing package mysql-server (--configure): dependency problems - leaving unconfiguredsetting up apt-show-versions (0.22.7) ...no apport report written because the error message indicates its a followup error from a previous failure. ** initializing cache. this may take a while **errors were encountered while processing: mysql-server-5.7 mysql-servere: sub-process /usr/bin/dpkg returned an error code (1)malikarumi@tetuoan2:~$ sudo dpkg --auditthe following packages have been unpacked but not yet configured.they must be configured using dpkg --configure or the configuremenu option in dselect for them to work: mysql-server mysql database server (metapackage depending on the latesthe following packages are only half configured, probably due to problemsconfiguring them the first time. the configuration should be retried usingdpkg --configure <package> or the configure menu option in dselect: mysql-server-5.7 mysql database server binaries and system database setupmalikarumi@tetuoan2:~$ sudo dpkg -cthe following packages have been unpacked but not yet configured.they must be configured using dpkg --configure or the configuremenu option in dselect for them to work: mysql-server mysql database server (metapackage depending on the latesthe following packages are only half configured, probably due to problemsconfiguring them the first time. the configuration should be retried usingdpkg --configure <package> or the configure menu option in dselect: mysql-server-5.7 mysql database server binaries and system database setupmalikarumi@tetuoan2:~$ sudo dpkg --configuredpkg: error: --configure needs at least one package name argumenttype dpkg --help for help about installing and deinstalling packages [*];use 'apt' or 'aptitude' for user-friendly package management;type dpkg -dhelp for a list of dpkg debug flag values;type dpkg --force-help for a list of forcing options;type dpkg-deb --help for help about manipulating *.deb files;options marked [*] produce a lot of output - pipe it through 'less' or 'more' !malikarumi@tetuoan2:~$ i could see i already had a --configure error in the output so i didn't run this.unlike the op in that other unix exchange question, i have not (knowingly) mixed oses, and in other respects my os seems to be fine, so i have not tried his solution. it is at this point that i came here to post. suggestions?",
    "present_kp": [
      "ubuntu",
      "mysql"
    ],
    "absent_kp": []
  },
  {
    "text": "computing sum and counting matches in an array. the problem was pretty straightforward and used two simple algorithms from our examples; the one for computing the sum, and the one for counting matches. the array for the problem wasn't provided, but you can easily write a method around it without actually having it, since she gave us the name and type of the array. the code for my solution is this: public class tests { private double[] grades; public int belowaverage() // creates method for finding scores below the mean { double total = 0; for (double element1 : grades) // computes total of array 'grades' { total=total + element1; } double mean = total / grades.length; //uses total and the length of the array to computer the mean int matches = 0; for (double element2 : grades) //uses mean to compute number of grades that are below the mean and { // increases matches for each one that is. if (element2 < mean) {matches++;} } return matches; // returns the number of matches. } }obviously the third line would change if you had the actual array. that was just kind of a placeholder. i tried to notate the code well enough to see where you get the total, then the mean, then compare each one to the mean to get matches that are less and increase your 'matches' variable for each match. i could have used the same 'element' variable for both loops since they're only used within the loops, but for clarity's sake in this example, i named them differently. i put all of these steps together in one method to solve this problem, but if i were going to write this sort of thing 'for real', i would assume it would probably need to calculate much more than just this small task (different averages, highest/lowest, etc.), so i would probably put each step in its own method so it could be used wherever you needed it.can someone comment on this and tell me if i could have done this in another way or an easier way? maybe i could have used arrays.",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "parameterized java types (generics). consider this legacy code:public interface ipersistentcollection { ipersistentcollection cons(object o);}genericized in java, it could become something like this:public interface ipersistentcollection<t> { ipersistentcollection<t> cons(t o);}clearly adding a new item to a mutable java collection shouldn't change the type of the existing collection. but unlike the java collections, cons() returns a completely new, immutable collection, leaving the old collection unchanged, opening the possibility that it could meaningfully take on a different type than the original collection had.obviously, you should be able to cons an object of type ford to a collection of cars and get a collection of cars back (covariance). i think this is covered by the above generic example.if car and train both extended a vehicle class, it would be handy to be able to cons a train to a collection of cars and get a collection of vehicles back (contravariance). how would i even write that? i thought by declaring new bounded type variables, s and e for vehicle and train in this example:// illegal because of <s super t><s super t, e extends s> ipersistentcollection<s> cons(e o);// simpler, but still illegal because java disallows <s super t><s super t> ipersistentcollection<s> cons(s o);if we want to assume that the programmer knows what they are doing, you should be allowed to cons something totally unrelated to a collection and get a collection of objects back. i think this is the extreme case of contravariance, but i'm not sure there is even a name for it (dynamic language maybe?).i think that if #2 were legal, it would cover cases #1 and #3.my questions are:a. to what degree is it possible to do #2 in java?b. is #2 possible/easier in other languages? scala? haskell? ml?c. in theory, a type system that preferred the most specific version of s in example 2 could handle a definition like this. what book can i read about type systems without a phd in math? is types and programming languages by pierce the best place to start?sample code would be appreciated. if i'm using terms like covariance and contravariance incorrectly, i would appreciate being politely corrected.",
    "present_kp": [
      "java",
      "type systems",
      "generics"
    ],
    "absent_kp": [
      "parameters",
      "type safety"
    ]
  },
  {
    "text": "linux doesn't drop fs caches. instead memory starts swapping. i'm quite confused about this behaviour of linux memory caching. total used free shared buffers cachedmem: 15953 14188 1765 64 37 11504-/+ buffers/cache: 2645 13308swap: 2047 1332 715shouldn't have non-cache memory priority against caches? in other words: why is the machine swapping to disk, instead of dropping caches.can i change this behavior? if yes, how?",
    "present_kp": [
      "linux",
      "memory",
      "swap",
      "cache"
    ],
    "absent_kp": [
      "linux kernel"
    ]
  },
  {
    "text": "how to start a process chain from the shell. is it possible and if so how do i:start a /bin/bash process that is not bound to a terminal from a terminal?hence, a shell process that shows up in the process tree asinit -- bash. (shells usually have the process tree structure terminal-emulator-of-your-choosing -- bash)start a /bin/bash process not bound to a terminal that has as its child another process e.g. a browser like firefox from a shell session in a terminal? hence, a shell process with a child that shows up in the process tree as init -- bash -- firefox.it is easy to get init -- firefox directly from the shell via something along the lines of exec firefox & exit or /bin/bash -c firefox & exit.(this question is part of a series of related questions that first enabled me to formulate these questions precisely (cf. how to correctly start an application from a shell and is reparenting from the shell possible?). the three questions have been formulated and discussed partially in the comments of the two former questions but as i see it not been answered. furthermore, they do seem more appropriate as short question in their own right not suited for discussion in comments.)",
    "present_kp": [
      "bash",
      "shell"
    ],
    "absent_kp": [
      "namespace"
    ]
  },
  {
    "text": "getting the smallest snippet from content containing all keywords. this returns the smallest snippet from the content containing all of the given keywords (in any order). this provides the correct solution but i would like to know if it can be made more efficient.import itertools, redef solve(content, keywords): content = content.strip() contentwords = content.split() termposition = {} for term in keywords: index = 0 positions = [] while index is not none: try: index = contentwords.index(term) positions.append(index) contentwords[index] = none except: index = none termposition[term] = positions singlepositions = [] multiplepositions = [] for term in termposition.keys(): if len(termposition.get(term)) == 1: singlepositions.append(termposition.get(term)[0]) else: multiplepositions.append(termposition.get(term)) snippet = content contentwords = content.split(' ') for element in itertools.product(*multiplepositions): templist = list(element) + singlepositions minpos = min(templist) maxpos = max(templist) + 1 if len(' '.join(contentwords[minpos:maxpos])) < len(snippet): snippet = ' '.join(contentwords[minpos:maxpos]) return snippet",
    "present_kp": [],
    "absent_kp": [
      "python",
      "performance",
      "algorithm",
      "strings",
      "clustering"
    ]
  },
  {
    "text": "is predicting (in the limit) computable sequences as hard as the halting problem?. question:is predicting (as defined below) computable sequences as hard as the halting problem?elaboration:predict means successfully predict, which means make only finitely many errors on the task of trying to predict the n-th bit of the sequence given access to the previous n-1 bits (starting from the first bit and going through the entire infinite computable sequence).there's a simple diagonalization argument (due to legg 2006) that for any turing machine predictor p, there's a computable sequence on which it makes infinitely many errors. (construct a sequence that has as its nth term the opposite of what p predicts given the previous n-1 terms in the sequence.) so there is no computable predictor that predicts every computable sequence. a halting oracle would allow construction of such a predictor. but can you show that having such a predictor allows you to solve the halting problem?more elaborationdefinition (legg)a predictor p is a turing machine that tries to predict the n-th bit of a sequence s given access to the previous n-1 bits. if the prediction fails to match the n-th bit of the sequence, we call this a mistake. we will say that p predicts s if p only makes finitely many mistakes on s. in other words, p predicts s if there is some number m in the sequence s.t. for every m>m, p correctly predicts the m-th bit of s given access to the first m-1 bits. formally, we could define a predictor machine as having three tapes. the sequence is entered as input bit-by-bit on one tape, the predictions for the next bit are made on a second tape (the machine can only move right across this tape), and then there is a work tape on which the machine can move in both directions. simple resultsby the above definition, there's a predictor that predicts all the rational numbers. (use the standard zig-zag enumeration of the rationals. start by predicting the 1st rational in the list, if there's a mistake, move to the next rational.). by a similar argument, there's a predictor s.t. given access to n, is able to predict all sequences of kolomogorov complexity less than or equal to n. (run all the n-bit machines in parallel and take the prediction of the machine that halts first. you can only make finitely many errors). citationshane legg 2006http://www.vetta.org/documents/idsia-12-06-1.pdf(not the author of this post)",
    "present_kp": [],
    "absent_kp": [
      "computability"
    ]
  },
  {
    "text": "continuously receive messages async from azure service bus queues. i'd like to get input on my approach of continuously receiving messages from an azure service bus queue using the async part of the library.my main concern being whether its safe to use task.factory.startnew to process the incoming messages and then continue to call the action's to continue receiving new messages.the processor class is started like this:public void start(){ throwifdisposed(); lock (_lockobject) { trace.writeline(string.format(started '{0}' allocation., _projectsettings.name)); _cancellationsource = new cancellationtokensource(); task.factory.startnew(receiveallocationmessages, _cancellationsource.token); }}and then the actual continuous receival of messages from the (azure service bus) queueclient (from the microsoft.servicebus.messaging namespace):private void receivemessage(){ task.run(async () => { //receive a new message async within 1 minute return await _queueclient.receiveasync(timespan.fromminutes(1)); }) .continuewith(t => { if (t.result != null) { //the result is not null so we process the brokered message task.factory.startnew(() => { processmessage(t.result) receivenextmessage(); }, _cancellationsource.token); } else { // continue receiving and processing // new messages until told to stop. receivenextmessage(); } });}private void receivenextmessage(){ if (_cancellationsource.iscancellationrequested == false) { //continue to receive new messages every 1 minute task.delay(timespan.fromminutes(1)) .continuewith(t => receivemessage()); }}when the process is stopped or disposed the stop method is called in order to cancel the cancellationtokensource as shown here:public void stop(){ lock (_lockobject) { using (_cancellationsource) { if (_cancellationsource != null) { _cancellationsource.cancel(); _cancellationsource = null; } } trace.writeline(string.format(stopped '{0}' allocation., _projectsettings.name)); }}does this seem like a reasonable way to go about implementing continuous receival of messages in an async fashion?update: i posted a gist with the code from above polished and put into a class. hopefully improves readability gist of the queue processor class",
    "present_kp": [
      "queue"
    ],
    "absent_kp": [
      "c#",
      "asynchronous"
    ]
  },
  {
    "text": "can not execute restart networking service on ubuntu 14.04. i use ubuntu 14.04 lts, i try type sudo /etc.init.d/networking restart but no output's displayed and no action excuted.",
    "present_kp": [
      "ubuntu"
    ],
    "absent_kp": []
  },
  {
    "text": "how to deal with the automation is easy mindset?. the title says it all. some employees in our company believe that automated tests are easy and that it should take a day to write suites of com and ui tests. what can be done to counter this? note: i'm not asking about how to promote automation. that isn't the problem. automated testing and processes are being promoted and requested all the time here. the issue is that some individuals don't understand that automation is not easy nor is it fast.",
    "present_kp": [
      "automation"
    ],
    "absent_kp": [
      "project management",
      "quality"
    ]
  },
  {
    "text": "assigning read/write privileges for a folder to a user in centos 7. i am logged into a centos 7 server as root. i created a folder /somefolder. i want someusername to be able to write to that folder via scp from a remote computer. what command should i run so that someusername is able to type in scp /some/directory/in/remotepc someusername@centos7server:/somefolder/ and successfully transfer the file?i can guess something like chmod -r u+rw /somefolder, but that is just a guess. and how would i specify which user?",
    "present_kp": [
      "chmod"
    ],
    "absent_kp": [
      "files",
      "permissions",
      "users"
    ]
  },
  {
    "text": "untar only a certain number of files from a large tarball. i have a large tarball that is busy being ftp'd over from a remote system to our local system.i want to know if it is possible to start untarring lets say 50 files at a time so that those files can begin being processed while the transfer takes place.",
    "present_kp": [
      "tar"
    ],
    "absent_kp": []
  },
  {
    "text": "declare: additional attributes do not take effect until subsequent assignments. from bash manual for declare command:when using -a or -a and the compound assignment syntax to create array variables, additional attributes do not take effect until subsequent assignments.what does it mean?i can't figure it out by$ declare -ar arr=([1]=2, [2]=3)$ declare -p arrdeclare -ar arr='([1]=2, [2]=3)'thanks.",
    "present_kp": [
      "bash"
    ],
    "absent_kp": []
  },
  {
    "text": "what is a flat file?. is it a plain text file or binary file or just character file? can someone explain what a flat file actually means?",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "files",
      "filesystems"
    ]
  },
  {
    "text": "google drive remove permission from app after uninstalled. i just installed an app that asked for permission to google drive. i granted the access. now i'm uninstalling the app from my phone, but i'm not sure if the app still has access to my google drive. how do i remove the granted permission? or is it not necessary?",
    "present_kp": [
      "google drive"
    ],
    "absent_kp": [
      "permissions"
    ]
  },
  {
    "text": "is there any way to improve putty on slow connections?. i'm working with putty but have a slow connection to the server.it's not slow everywhere and i don't need to get it faster. there is latency between when i type and when the text is displayed in the terminal.so the question : how to work with putty without the delay between my typing and the text appearing in the terminal. so i found this putty options : local echo and local line edit, but sure i can't use hotkeys with it. i need hotkeys so the subquestion is : how to make a hotkey to enable / disable local echo+line editing.",
    "present_kp": [
      "putty"
    ],
    "absent_kp": [
      "ssh"
    ]
  },
  {
    "text": "edomform - dynamic forms without writing any javascript. i'd like some comments and any suggestions that you have for where to go next with this.i've been working on developing a javascript library that allows for dynamic forms by simply adding some extra html tags and attributes to your form. it's brand new, so it doesn't have a lot of features, but it's based on the idea that you shouldn't need to write a bunch of javascript and have to deal with bugs and stuff just to get your form to have multiple pages or to add new fields when you click a button... stuff like that.all you have to do to make it work is include jquery and this javascript in the page after all the form html....<script type='text/javascript' src='<url> type='text/javascript' src='edomform.js'></script></body>i've got the current javascript in a fiddle with some example html and css, and some basic documentation/guide material in a google doc that you can comment on if you like. any comments and suggestions are welcome.you're also welcome to use this for whatever you want as-is or with any modifications you or anyone comes up with.fiddleedomform//configuration variablesvar config = jquery(edfconfig);function getconfigboolean(attr) { if (config != null) return jquery(config).attr(attr) != undefined;}function getconfigvalue(attr) { if (config != null) return jquery(config).attr(attr);}var noasterisks = getconfigboolean(noasterisks);var addafter = getconfigboolean(addafter);var doactions = getconfigboolean(doactions);var noappend = getconfigboolean(noappend);var requiredmessage = getconfigvalue(requiredmessage);var requiredmessageid = getconfigvalue(requiredmessageid);//edomform variablesvar attrs = jquery(edfvars)[0];var variables = {};if (attrs != null)for (i=0;i<attrs.attributes.length;i++) { variables[attrs.attributes[i].nodename] = attrs.attributes[i].nodevalue;}//function because jquery doesn't have a selector for the name attributefunction getbyname(n) { return document.getelementsbyname(n);}//required fields have the class required_fieldvar required = jquery(.required_field);//message div to display global form messagesvar message = jquery(#message);//reference to the entire form itselfvar form = jquery(#form);//form datajquery(form).data(required_empty,required.length);//add next and back buttonsjquery(.form_page).each(function(i){ jquery(this).prepend('<button type=button class=back>back</button> <button type=button class=next>next</button>');});//next and back buttonsvar pages = jquery(.form_page);var backbuttons = jquery(.back);var nextbuttons = jquery(.next);for (i=0;i<pages.length;i++) { if (i != pages.length-1) { nextbuttons[i].onclick = function() { jquery(this).closest(div).fadeout(); jquery(this).closest(div).nextall(:not(.disabled):first).fadein(); }; } else { jquery(nextbuttons[i]).remove(); } if (i != 0) { backbuttons[i].onclick = function(i) { jquery(this).closest(div).fadeout(); jquery(this).closest(div).prevall(:not(.disabled):first).fadein(); }; } else { jquery(backbuttons[i]).remove(); }}//aliasesfunction getbyalias(a) { return jquery([alias=+a+]);}function hasclass(element, cls) { return (' ' + element.classname + ' ').indexof(' ' + cls + ' ') > -1;}var aliases = jquery(.alias);for (i=0;i<aliases.length;i++) { var alias = jquery(aliases[i]).attr(alias); var original = jquery(.+alias); for (j=0;j<original.length;j++) { if (hasclass(original[j],required_field)) { jquery(aliases[i]).addclass(required_field); } original[j].onchange = aliaschange.bind(null,original[j],aliases[i]); aliases[i].onchange = aliaschange.bind(null,aliases[i],original[j]); }}function aliaschange(o,a) { a.value = o.value; a.onblur();}var radiogroupcounter = 1;jquery(document).ready(function() { //prevent form submission if required fields have not been filled in if (form[0] != null) form[0].onsubmit = function() { var required_fields = document.getelementsbyclassname(required_field); for (i=0;i<required_fields.length;i++) { if (required_fields[i].value == ) { jquery(#+requiredmessageid).html(requiredmessage); return false; } } jquery(#+requiredmessageid).html(); return true; }; //hidden pages function handlehiddenpages() { jquery(.revealer).each(function(i){ var page = jquery(this).attr(page); jquery(this).click(function(){ if (jquery(this).is(:checked)) { jquery(.+page).removeclass(disabled); } else { jquery(.+page).addclass(disabled); } }); }); } handlehiddenpages(); //switchers function handleswitchers() { jquery(.switcher).each(function(x){ var connections = jquery(this).attr(connections); connections = jquery.parsejson(connections); var connectedsections = {}; for (var key in connections) { //if something like a-b if (connections[key].indexof(-) > -1) { var nums = connections[key].split(-); var resultnums = []; for (i=0;i<nums.length;i++) { nums[i] = parseint(nums[i]); } for (i=nums[0];i<=nums[nums.length-1];i++) { resultnums.push(i+); connectedsections[i] = key; } } else { if (connections.hasownproperty(key)) connectedsections[connections[key]] = key; } } jquery(this).change(function(){ for (var key in connectedsections) { jquery(.+connectedsections[key]).hide(); } jquery(.+connectedsections[jquery(this).val()]).show(); }); }); } handleswitchers(); //displayers/hiders function handledisplayers() { jquery(.displayer).each(function(x){ var connected = jquery(this).attr(display); var special = ; var connecteds = []; if (connected.indexof( ) > -1) { connecteds = connected.split( ); var special = connecteds[0]; connected = connecteds[1]; } var name = jquery(this).attr(name); var group = getbyname(name); jquery(group).each(function() { jquery(this).on(click,function() { var button = this; if (jquery(this).attr(display) != null) { if (special == ) { jquery(.+connected).each(function() { jquery(this).show(); }); } else if (special == next) { jquery(.+connected).each(function() { if (button.comparedocumentposition(this) == 4) { jquery(this).show(); return false; } }); } else if (special == prev) { jquery(jquery(.+connected).get().reverse()).each(function(i) { if (button.comparedocumentposition(this) == 2) { jquery(this).show(); return false; } }); } }else { if (special == ) { jquery(.+connected).each(function() { jquery(this).hide(); }); } else if (special == next) jquery(.+connected).each(function() { if (button.comparedocumentposition(this) == 4) { jquery(this).hide(); return false; } }); else if (special == prev) jquery(jquery(.+connected).get().reverse()).each(function(i) { if (button.comparedocumentposition(this) == 2) { jquery(this).hide(); return false; } }); } }); }); }); } handledisplayers(); //findnext function from stackoverflow /** * find the next element matching a certain selector. differs from next() in * that it searches outside the current element's parent. * * @param selector the selector to search for * @param steps (optional) the number of steps to search, the default is 1 * @param scope (optional) the scope to search in, the default is document wide */ $.fn.findnext = function(selector, steps, scope) { // steps given? then parse to int if (steps) { steps = math.floor(steps); } else if (steps === 0) { // stupid case :) return this; } else { // else, try the easy way var next = this.next(selector); if (next.length) return next; // easy way failed, try the hard way :) steps = 1; } // set scope to document or user-defined scope = (scope) ? $(scope) : $(document); // find kids that match selector: used as exclusion filter var kids = this.find(selector); // find in parent(s) hay = $(this); while(hay[0] != scope[0]) { // move up one level hay = hay.parent(); // select all kids of parent // - excluding kids of current element (next != inside), // - add current element (will be added in document order) var rs = hay.find(selector).not(kids).add($(this)); // move the desired number of steps var id = rs.index(this) + steps; // result found? then return if (id > -1 && id < rs.length) return $(rs[id]); } // return empty result return $([]); } //adding new sections function handleadds() { jquery(.add).each(function(x){ var add = jquery(this).attr(add); if (add.indexof( ) > -1) { add = add.split( ); } var to = jquery(this).attr(to); var radiogroup = jquery(this).attr(radiogroup); if (radiogroup != null) radiogroup = radiogroup.split( ); var cpy = jquery(<div />).append(jquery(.+add).clone()).html(); if (to == null) { jquery(this).click(function() { var text = cpy; var counter = radiogroupcounter++; if (radiogroup != null) for (i=0;i<radiogroup.length;i++) { var re = new regexp(radiogroup[i]+\\[\\d\\],g); text = text.replace(re,radiogroup[i]+[+(counter)+]); } if (addafter) jquery(this).after(text); else jquery(this).before(text); handlehiddenpages(); handledisplayers(); handleswitchers(); }); } else { if (to.indexof( ) > -1) { to = to.split( ); } jquery(this).click(function() { var text = cpy; var counter = radiogroupcounter++; if (radiogroup != null) for (i=0;i<radiogroup.length;i++) { var re = new regexp(radiogroup[i]+\\[\\d\\],g); text = text.replace(re,radiogroup[i]+[+(counter)+]); console.log(text); } jquery(#+to).append(text); handlehiddenpages(); handledisplayers(); handleswitchers(); }); } }); } handleadds(); //action tags function handleall() { handlehiddenpages(); handledisplayers(); handleswitchers(); handleadds(); }});required = jquery(.required_field);//loop through required fields, adding the onblur event//so that whenever the user deselects a required field,//if it is blank the asterisk will turn red.for (i=0;i<required.length;i++) { jquery(required[i]).after(<span>*</span>); jquery(required[i]).data(empty,true); required[i].onblur = function() { if (this.value == ) { jquery(this).next().css(color,#f00); } else { jquery(this).next().css(color,#000); } };}",
    "present_kp": [
      "javascript",
      "jquery",
      "html",
      "form",
      "dom"
    ],
    "absent_kp": []
  },
  {
    "text": "wireless network and dhcp wired server. i have an ubuntu server, which automatically connects to a wireless network on startup. this is achieved through /etc/network/interfaces:auto loiface lo inet loopbackauto wlan0iface wlan0 inet dhcppre-up wpa_supplicant [...]post-down sudo killall [...]however, i would like the machine to act also as a dhcp server when somebody plugs in a cable. i installed dhcp3-server, and then configured /etc/network/interfaces by adding:auto eth0iface eth0 inet static address 10.0.0.1 netmask 255.255.255.0 network 10.0.0.0/25 gateway 10.0.0.1however, internet is now unreachable, as the machine tries (me thinks) to connect through eth0 rather than wlan0.how do i configure a machine to have both wireless internet access, and acting as a wired dhcp server?edit: attached requested output.ifconfig -aeth0 link encap:ethernet hwaddr [...] inet addr:10.0.0.1 bcast:10.0.0.255 mask:255.255.255.0 up broadcast multicast mtu:1500 metric:1 rx packets:0 errors:0 dropped:0 overruns:0 frame:0 tx packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:0 (0.0 b) tx bytes:0 (0.0 b) interrupt:17 lo link encap:local loopback [...]wlan0 link encap:ethernet hwaddr [...] inet addr:10.7.0.213 bcast:10.7.255.255 mask:255.255.0.0 inet6 addr: fe80::21c:bfff:fe36:cea7/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:1368 errors:0 dropped:0 overruns:0 frame:0 tx packets:66 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:267437 (267.4 kb) tx bytes:9606 (9.6 kb)rounte -nkernel ip routing tabledestination gateway genmask flags metric ref use iface0.0.0.0 10.0.0.1 0.0.0.0 ug 100 0 0 eth010.0.0.0 0.0.0.0 255.255.255.0 u 0 0 0 eth010.7.0.0 0.0.0.0 255.255.0.0 u 0 0 0 wlan0",
    "present_kp": [
      "ubuntu",
      "dhcp"
    ],
    "absent_kp": [
      "wifi"
    ]
  },
  {
    "text": "how does a sim card work?. i understand that a sim card has memory, and that some or maybe all of them also include microprocessors. they act as peripherals that are more than just flash memory.i would like to be able to read the contents and extract my contacts and messages, for backup, so i bought an el-cheapo sim card reader that plugs into a usb port. but when i plug it in it is as if it isn't even there. so how can i get access to the data?secondly, i understand that they can affect the baseband portion of the cellphone, including frequency of operation and whatever codes are necessary to identify itself (imei) and to access a particular network (t-mobile, at&t, verizen). again, it is clearly more than just flash memory.so my question is, how exactly do they work, and how can i get into my own card?",
    "present_kp": [
      "memory"
    ],
    "absent_kp": [
      "firmware"
    ]
  },
  {
    "text": "connect to kvm instance using virsh when image launched through eucalyptus?. i'm using eucalyptus on ubuntu 10.04 to set up a private cloud. sometimes i'm not able to ssh into the vm instances, and i'd like to be able to connect directly to the console of the vm instance. however, by default, that doesn't seem to work through virsh:$ sudo virsh -c qemu:///system console i-486b085eno console available for domainis there some way to enable this, for example, by changing the way eucalyptus generates the xml file that gets passed to libvirt? here's the libvirt.xml file that eucalyptus generates:$ cat /var/lib/eucalyptus/instances/admin/i-486b085e/libvirt.xml<domain type='kvm'> <name>i-486b085e</name> <os> <type>hvm</type> <kernel>/var/lib/eucalyptus/instances//admin/i-486b085e/kernel</kernel> <initrd>/var/lib/eucalyptus/instances//admin/i-486b085e/ramdisk</initrd> <cmdline>root=/dev/sda1 console=ttys0</cmdline> </os> <features> <acpi/> </features> <memory>262144</memory> <vcpu>1</vcpu> <devices> <disk type='file'> <source file='/var/lib/eucalyptus/instances//admin/i-486b085e/disk'/> <target dev='sda'/> </disk> <interface type='bridge'> <source bridge='eucabr10'/> <mac address='d0:0d:48:6b:08:5e'/> <model type='e1000'/> </interface> <serial type=file> <source path='/var/lib/eucalyptus/instances//admin/i-486b085e/console.log'/> <target port='1'/> </serial> </devices></domain>here's the output of virsh dumpxml:$ sudo virsh dumpxml i-486b085e<domain type='kvm' id='3'> <name>i-486b085e</name> <uuid>3b762376-4de1-f6ac-7327-9df520fa4862</uuid> <memory>262144</memory> <currentmemory>262144</currentmemory> <vcpu>1</vcpu> <os> <type arch='x86_64' machine='pc-0.12'>hvm</type> <kernel>/var/lib/eucalyptus/instances//admin/i-486b085e/kernel</kernel> <initrd>/var/lib/eucalyptus/instances//admin/i-486b085e/ramdisk</initrd> <cmdline>root=/dev/sda1 console=ttys0</cmdline> <boot dev='hd'/> </os> <features> <acpi/> </features> <clock offset='utc'/> <on_poweroff>destroy</on_poweroff> <on_reboot>restart</on_reboot> <on_crash>destroy</on_crash> <devices> <emulator>/usr/bin/kvm</emulator> <disk type='file' device='disk'> <source file='/var/lib/eucalyptus/instances//admin/i-486b085e/disk'/> <target dev='sda' bus='scsi'/> </disk> <interface type='bridge'> <mac address='d0:0d:48:6b:08:5e'/> <source bridge='eucabr10'/> <target dev='vnet0'/> <model type='e1000'/> </interface> <serial type='file'> <source path='/var/lib/eucalyptus/instances//admin/i-486b085e/console.log'/> <target port='0'/> </serial> <console type='file'> <source path='/var/lib/eucalyptus/instances//admin/i-486b085e/console.log'/> <target port='0'/> </console> </devices> <seclabel type='dynamic' model='apparmor'> <label>libvirt-3b762376-4de1-f6ac-7327-9df520fa4862</label> <imagelabel>libvirt-3b762376-4de1-f6ac-7327-9df520fa4862</imagelabel> </seclabel></domain>here's the full kvm command-line that ends up being invoked: /usr/bin/kvm -s -m pc-0.12 -enable-kvm -m 256 -smp 1 -name i-486b085e -uuid 3b762376-4de1-f6ac-7327-9df520fa4862 -nographic -chardev socket,id=monitor,path=/var/lib/libvirt/qemu/i-486b085e.monitor,server,nowait -monitor chardev:monitor -boot c -kernel /var/lib/eucalyptus/instances//admin/i-486b085e/kernel -initrd /var/lib/eucalyptus/instances//admin/i-486b085e/ramdisk -append root=/dev/sda1 console=ttys0 -drive file=/var/lib/eucalyptus/instances//admin/i-486b085e/disk,if=scsi,index=0,boot=on -net nic,macaddr=d0:0d:48:6b:08:5e,vlan=0,model=e1000,name=e1000.0 -net tap,fd=55,vlan=0,name=tap.0 -chardev file,id=serial0,path=/var/lib/eucalyptus/instances//admin/i-486b085e/console.log -serial chardev:serial0 -parallel none -usbnote: cross-posted from serverfault since question migration isn't supported yet.",
    "present_kp": [
      "kvm"
    ],
    "absent_kp": []
  },
  {
    "text": "refactor to reduce code duplication. i have four methods like these (here are only two of them): def checkleft(clickedindex: int): option[int] = { val leftindex = clickedindex - 1 if (leftindex >= 0 && clickedindex % field.width != 0 && isemptycell(leftindex)) some(leftindex) else none } def checkright(clickedindex: int): option[int] = { val rightindex = clickedindex + 1 if (rightindex < field.size && clickedindex + 1 % field.width != 0 && isemptycell(rightindex)) some(rightindex) else none }they all have similar structures. how i can reduce code duplication here?",
    "present_kp": [],
    "absent_kp": [
      "scala"
    ]
  },
  {
    "text": "how can i target specific countries with global site under gtld using sub-directory for each targeted country?. we're building a global platform for a large client who want a range of sites targeting different countries all hosted under a single gtld, so domain.com/uk will be a uk-specific site, domain.com/fr would target france etc. each of these sites will have a different set of language variants e.g. domain.com/fr/en-gb would be an english-language version of the french site.i would like to know how best to inform search engines that these sub-directories are effectively separate regionalised site. are there any tools at my disposal (speaking as a developer rather than a content manager) to ensure, for example, that domain.com/uk appears in search results for people in the uk above other english-language sites e.g. domain.com/us?or am i entirely reliant on content within the sites being interpreted by the search robots? i assume that from the client's perspective, this is what google webmaster tools is for? would that be the primary means to educate google about the regional relevance of the sub-directories of the platform? is there an equivalent for other major search engines?",
    "present_kp": [],
    "absent_kp": [
      "seo",
      "domains",
      "internationalization"
    ]
  },
  {
    "text": "how to explain what code is to my parents?. i am an engineering student in computer science and recently my parents asked me to explain a bit what i do, which is their way of asking what is coding?.they have no idea of what coding is, what languages are, lines of codes etc, and i wanted to explain briefly how it all works. i wanted to explain what a programming language is and how it is used to write algorithms, make computations... to me it seems very logical that the interpreter reads lines of code from top to bottom, understanding the statements of a particular language.i can't find the right words and nice examples to help them understand globally how it works.how can i explain this idea to them?",
    "present_kp": [],
    "absent_kp": [
      "layperson"
    ]
  },
  {
    "text": "execute command on a defined range of directories. is it possible to 'partition' a directory listing - say in to blocks of some number, to perform different actions on each 'range'?for example, lets say i have the following directories inside another folder:$ ls testabc/def/hij/klm/nop/qrs/tuv/wxy/zzz/and i want to perform some action on the first 3 directories, another on the second 3, and so on.my thought was that perhaps a loop across numbers would work, based on the output of something like ls | nl (but before anyone mentions it, i know parsing ls is a no-no!)this obviously doesn't work, but illustrates my point i hope:for dir in 'ls | nl'; do do-something-with ${dir{1..3}} # where $dir has taken on some numerical value linked to the folder) do-something-with ${dir{4..6}} # and so on... do-something-with ${dir{n-3..n}} donethe folders i intend to actually do this on, can be worked on in any order (i.e. the final splits can be totally arbitrary), but they have no logical naming consistency - by which i mean they can't be organised sensibly alphabetically or numerically based on any key within the directory name themselves.",
    "present_kp": [
      "ls"
    ],
    "absent_kp": [
      "bash",
      "indexing"
    ]
  },
  {
    "text": "grep: search and replace full line. the command grep foo myfile.txtprints all matching lines in my file.now i want to replace the full line with another string. how can i do that?",
    "present_kp": [
      "grep"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "find a file in the path without which?. i am (somehow) able to run a script:$ assemble.sh file... [output]but which can't find it:$ which assemble.shwhich: no assemble.sh in (/s/std/bin:/usr/afsws/bin:/opt/sunwspro/bin:/usr/ccs/bin:/usr/ucb:/bin:/usr/bin:/usr/stat/bin:/usr/x11r6/bin:.how is this possible?how can i find where this file is?i'm using bash.",
    "present_kp": [
      "bash",
      "path"
    ],
    "absent_kp": [
      "shell"
    ]
  },
  {
    "text": "integrating ldap and kerberos v to add users via a useradd-like interface. i'm currently trying to set up an integrated kerberos v/ldap system for authentication/authorization. from what i have managed to gather, there are at least two ways to integrate kerberos v with ldap:use ldap as a backend to store kerberos principalsuser kerberos and sasl authentication via gssapi to authenticate to the ldap server (to be able to query and modify the ldap entries using a kerberos ticket)the two options aren't mutually exclusive. the thing is, i would like to make a hybrid of the two: not just use ldap to store kerberos principals, but also make sure that when i add a kerberos principal, it's created with objectclass=posixaccount in order for it to appear as a unix user entry to nss for authorization purposes.to paraphrase, i would like to have to add new user accounts in only one place (viz., the kadmin server) instead of two. is this possible? if so, how?if it's any help, i'm using openldap and mit kerberos on debian wheezy.",
    "present_kp": [
      "kerberos",
      "openldap"
    ],
    "absent_kp": [
      "administration"
    ]
  },
  {
    "text": "why does haskell's built in max function run faster than mine?. i noticed that for some reason, haskell's built in max function (which returns the greatest of two numbers) runs much faster than the one i wrote, even though they are essentially identical.from this site: <url> found that the standard max function is defined as: max x y | x <= y = y | otherwise = xwhich is capable of executingfoldr max 0 [0..<phone>]in 7.6 seconds (my laptop is in super power saving mode)i wrote the exact same function though, and ran it, andfoldr mymax 0 [0..<phone>]took an average of 23.74 secondsthe two functions look identical, except that the built-in max doesn't seem to have a type signature (unless its hidden somewhere.)does anyone know what might be going on here? i seriously doubt that a built in function will run more than three times faster than an identical, user defined one. to me that would be very strange.(when i say that they're identical, i mean literally clones of each other. just to test, i c&p'd it right out of the prelude, and it's still significantly slower.)edit: i thought about it more, and i think it might have something to do with the included functions being pre-compiled, where-as my functions are being interpreted via ghci (which would make sense then). i'll leave this up in case someone has a better answer, but i suspect this to be the cause.(one thing i realized that i don't understand though is why ghci says that's it compiled my code after an edit, but then goes on the say that's it's interpreting it. you don't interpret compiled code do you?)",
    "present_kp": [
      "haskell"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "text style behind an image or pic. there are times that surfers block images just to have a faster browsing(block download images)i would like to have an option when this happen to show a style textwith a large text in colors.so if the user block my images they still can see my main message.",
    "present_kp": [
      "images"
    ],
    "absent_kp": []
  },
  {
    "text": "how to grep thousands of files in a directory for hundreds of strings in a file. i am trying to compose a grep statement and it is killing me. i am also tired of getting the arguments list too long error. i have a file, let's call it subset.txt. it contains hundreds of lines with specific strings such as mo43312948. in my object directory i have thousands of files and i need to copy all the files that contain the strings listed in subset.txt into another directory.i was trying to start with this to just return the matching files from the objects directory.grep -f $(subset.txt) /objects/*i keep getting 'bash: /bin/grep: argument list too long''",
    "present_kp": [
      "grep"
    ],
    "absent_kp": []
  },
  {
    "text": "my shift/ctrl and numlock keys stopped working. my ctrl and right-shift keys are not responding, though they still work in a vmware window. numlock doesn't work. a held-down key does not repeat. clicking in a field in another window does not make that window active.can i clear whatever's making it sick without rebooting?it started (approximately?) when my full-screen vmware workstation instance on desktop 2 was missing and found as a small window on desktop 4. it moved by itself or i accidentally entered a strange command while working on desktop 1?linux mint 17.1 rebeca, standard cinnamon desktop.",
    "present_kp": [
      "numlock"
    ],
    "absent_kp": [
      "x11",
      "keyboard"
    ]
  },
  {
    "text": "remove chromium sync data from google account. i want to sign in to a new installation of chromium with a google account, but i don't want any previously synced data to be downloaded to the browser. how can i delete this data from my google account?",
    "present_kp": [
      "google account"
    ],
    "absent_kp": [
      "synchronization"
    ]
  },
  {
    "text": "find when the file was closed in unix. i know ls -l will give the modified time of file, but it is giving the time when the file was opened, not closed (using ctrl+d or something)please tell me how to find the time of file closed[bash]$datewed may 7 10:33:01 eest 2014[bash]$cat >aaadfadsf#waited 8 mins before closing file (time of closing: 10:41)[bash]$ls -l aa-rw------- 1 orclschd staff 9 may 7 10:33 aa[bash]$datewed may 7 10:41:47 eest 2014[bash]$stat aabash: stat: command not found[bash]$unameaix here i have created a file named aa, the file was created at 10:33 but when i closed the file and i checked the file's modified date it still showed 10:33.but the file creation end date (closed time) is 10:41 .is there is any command in aix to find when the file is closed or can we write any bash script to track the file automatically?",
    "present_kp": [
      "aix"
    ],
    "absent_kp": [
      "files",
      "file metadata"
    ]
  },
  {
    "text": "how are new sessions calculated on a mobile wap website?. on a 2g phone connection while surfing the mobile website if a user receives a call, what happens to the page session? does the session continue or is it considered to be the new session?",
    "present_kp": [
      "mobile",
      "session"
    ],
    "absent_kp": [
      "google analytics",
      "tracking"
    ]
  },
  {
    "text": "creating a terminal device for interprocess communication. i'd like to know how to create a terminal device to simulate a piece of hardware connected through a serial port. basically, tty device with a certain baud rate that can be read from and written to between two processes. from what i understand, a psuedo-terminal is what i'm looking for, and the makedev can apparently make one.i've also found the following set of instructions:su to rootcd /devmkdir ptymknod pty/m0 c 2 0mknod pty/s0 c 3 0ln -s pty/m0 ttyp0ln -s pty/s0 ptyp0chmod a+w pty/m0 pty/s0is there a better way of making pseudo-terminal, or is this pretty much the standard way of make one in the shell?",
    "present_kp": [
      "terminal",
      "tty"
    ],
    "absent_kp": [
      "linux",
      "devices",
      "ipc"
    ]
  },
  {
    "text": "a simple unrolled linked list implementation. i tried to implement an unrolled linked list in c#. i only needed to add things and clear the whole list so i didn't implement ilist<t> (i tried but it was getting too complex, so i postponed it).why i did it?i needed a collection that should be able to handle millions of items and i was getting outofmemoryexceptions when i tried list<t> since it needs sequential memory to hold everything in one array.i tried linkedlist<t> but it was too slow. i don't need to enumerate backwards or expose the node class publicly. i also know the size of blocks that i want to keep my items in, so i wrote this:public sealed class unrolledlinkedlist<t> : ienumerable<t>{ // fields private int _count; private node _firstnode; private node _lastnode; private int _lastnodecount; private int _nodecount; private readonly int _nodesize; // properties public int count { get { return _count; } } // constructors public unrolledlinkedlist(int nodesize) { _nodecount = 1; _nodesize = nodesize; _firstnode = _lastnode = new node(nodesize); } public unrolledlinkedlist() : this(8) { } // fuctions public void add(t item) { if (_lastnodecount == _nodesize) { _lastnode = (_lastnode.next = new node(_nodesize)); _lastnode.items[0] = item; _lastnodecount = 1; _nodecount++; } else _lastnode.items[_lastnodecount++] = item; _count++; } public void clear() { _firstnode = _lastnode = new node(_nodesize); // edit: just added these: _count = 0; _lastnodecount = 0; _nodecount = 1; } public ienumerator<t> getenumerator() { var current = _firstnode; if (current == null) yield break; for (; ; ) { if (current.next == null) { for (int i = 0; i < _lastnodecount; i++) yield return current.items[i]; yield break; } else for (int i = 0; i < _nodesize; i++) yield return current.items[i]; current = current.next; } } system.collections.ienumerator system.collections.ienumerable.getenumerator() { return getenumerator(); } // types private class node { public readonly t[] items; public node next; public node(int size) { items = new t[size]; } }}is there a flaw you can detect?is there any suggestion/optimization you have?do you know a better implementation of an unrolled linked list in c#?do you think this class should implement ilist<t>?if so, can you give some pointers for implementing functions like insert?updated versionit became like this after the answers:public sealed class unrolledlinkedlist<t> : ienumerable<t>{ // fields private int _count; private node _firstnode; private node _lastnode; private int _lastnodecount; private readonly int _nodesize; // properties public int count { get { return _count; } } // constructors public unrolledlinkedlist(int nodesize = 64) { _nodesize = nodesize; _firstnode = _lastnode = new node(nodesize); } // functions public void add(t item) { if (_lastnodecount == _nodesize) { _lastnode.next = new node(_nodesize, item); _lastnode = _lastnode.next; _lastnodecount = 1; } else _lastnode.items[_lastnodecount++] = item; _count++; } public void clear() { _count = 0; _firstnode = _lastnode = new node(_nodesize); _lastnodecount = 0; } public ienumerator<t> getenumerator() { for (var current = _firstnode; current != null; ) { var last = current.next == null ? _lastnodecount : _nodesize; for (var i = 0; i != last; i++) yield return current.items[i]; current = current.next; } } system.collections.ienumerator system.collections.ienumerable.getenumerator() { return getenumerator(); } // types private sealed class node { public readonly t[] items; public node next; public node(int size) { items = new t[size]; } public node(int size, t firstitem) : this(size) { items[0] = firstitem; } }}",
    "present_kp": [
      "c#",
      "collections",
      "linked list"
    ],
    "absent_kp": [
      ".net"
    ]
  },
  {
    "text": "gcc vs clang/llvm -- pros and cons of each. what are the pros and cons of gcc vs clang/llvm?",
    "present_kp": [
      "clang",
      "gcc",
      "llvm"
    ],
    "absent_kp": [
      "compiler"
    ]
  },
  {
    "text": "where do i turn for help with research/publishing?. i have been developing a sat algorithm for a while, and have reached a point where i'd like to share it. i don't know many people in computer science, and i'm not sure exactly where to turn.i'm wondering what resources are available for someone with an algorithm who is considering publishing. i also need help analyzing the runtime and correctness of my algorithm.my major problem is in analyzing the runtime. i need help with a detailed analysis of this. i'm fairly certain that the algorithm is correct, but it would be helpful if someone would verify this as well.so is there anyone who would be willing to analyze my algorithm? additionally, what resources are available for a task like this?",
    "present_kp": [
      "sat"
    ],
    "absent_kp": [
      "soft question",
      "proofs"
    ]
  },
  {
    "text": "what good are the signs '-' (minus) in any linux/unix commands?. possible duplicate:what does \"--\" (double-dash) mean?single dashes - for single-character options, but double dashes -- for words? i was reading the man zip page and i found this examples:[...] using the commandunzip -p backup | tar xf -when [...] for example,tar cf - . | zip | dd of=/dev/nrst0 obs=16kis equivalent totar cf - . | zip - - | dd of=/dev/nrst0 obs=16ki' like know the minus utility of these cases. why two minus signs are written in the third case?",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "oracle linux r6 install error. my oracle linux r6 x64 won't install. after normal install it's just blank screen. after basic video driver options install stuck on waiting for hardware to initialize.... tried with different options runs only with noprobe but no drivers at all (understandably). is there any way to run it normally?spcecs:asus rampage extreme iv extreme - newest bios,intel i7 4930k,graphics: geforce 210",
    "present_kp": [
      "oracle linux"
    ],
    "absent_kp": [
      "rhel",
      "system installation",
      "anaconda"
    ]
  },
  {
    "text": "understanding encoder-decoder sequence-to-sequence model. according to this paper (<url>), [the] rnn can easily map sequences to sequences whenever the alignment between the inputs the outputs is known ahead of time.i know that rnn's are used for sequence processing, which theoretically can include sequence-to-sequence mapping, but why do they need to know the alignment between input and output sequences beforehand?how does using an encoder and decoder setup solve the problem of variable alignment? if the above limitation applies, then the alignment between the input sequence and the intermediate encoding is fixed, and the alignment between the intermediate encoding and the output sequence is fixed. in this case, wouldn't that mean that the alignment of input to output would still be fixed?",
    "present_kp": [],
    "absent_kp": [
      "neural networks",
      "natural language processing"
    ]
  },
  {
    "text": "doesn't ida pro 6.95 support decompiling mips executable?. i am working on a mips binary: elf 32-bit msb executable, mips, mips-ii version 1 (sysv), statically linked, for gnu/linux 2.6.32, buildid[sha1]=76438e9ed749bcfc6e191e548da153d0d3b3ee28, not stripped. ida pro 6.95 (32 bit) disassembles the file pretty well, yet the decompiler gives up: sorry, the current file is not decompilable. doesn't ida pro have decompilation support for mips?",
    "present_kp": [
      "ida",
      "decompilation",
      "mips"
    ],
    "absent_kp": [
      "hexrays"
    ]
  },
  {
    "text": "testing intranet network. this is probably a question already discussed here and there. i'd like to try to gathering here all the information.suppose i'm on a machine connected to a network. this network has access to the internet.i'd like to write a bash script to detect the maximum information possible in order tomap the network around me number of devices connectedtypes of services offered by each deviceknow how many devices i must run through in order to reach the router to the internet (counting hops)latency between each stepstrength of signal if the link between a and b is wireless maximum uplink and downlink speed between two devices on the intraneti don't need the final script, i'd like to get dirty doing this, but i need tips on the right approach. i've got a good knowledge of network theory but really a poor knowledge of the practical side and the best i have come up with is flooding the subnet with pings and trying to reverse engineer the network using it.. rubbish!",
    "present_kp": [],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "to disallow indexing the category and tag listings in a blog. mark wilson says that category and tag listings in a blog should be disallowed in order to prevent duplicate content. i understand this. however, i want to put internal links on keywords in the blog posts to the tag and category pages in order for the readers to find more relevant content.i wonder whether putting those internal links to the category/tag pages which are disallowed in robots.txt is counted as useful from the perspective of seo internal linking?",
    "present_kp": [
      "seo",
      "links",
      "robots.txt"
    ],
    "absent_kp": []
  },
  {
    "text": "installing fedora onto hard drive: error checking storage configuration. i am trying to be able to dual boot my windows laptop. in the setup process, navigating to installation destination -> done with automatically configure partitioning checked, the error message failed to save storage configuration shows for a few seconds, and then is replaced by error checking storage configuration.if instead, i try to go installation destination -> done with 'i will configure partitioning' checked, every option i try for mount point doesn't take. i've tried /, /home, and biosboot. each one displays the message failed to add new device and unable to allocate the requested partition scheme. this is with lvm set as the partitioning scheme.when press to create the mount points automatically, the following error appears:you have not defined a root partition (/), which is required for installation of fedora to continue. you have not created a bootable partition.currently, i have about 88 gib of free space shown, so i don't think the problem is a lack of memory. i'm a little out of my depth here (if that's not obvious already) help please!edit: tl;dr why can't fedora automatically configure partitioning? short of that, what steps do i need to take to create the '/', '/boot', and 'swap' mount points myself?",
    "present_kp": [
      "fedora",
      "mount",
      "partition",
      "windows",
      "dual boot"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the best way to build a static page web site from a json api?. i have a json api that includes some discusssions. i want to build a static html site on another server, pages that are built from data on that api. i am more comfortable using rails than node. the api is done in node. the idea is that i periodically call the json api to get the data, and dynamically build the html pages on the rails server. this way the web pages would be super fast, wouldn't have to call the json api. one technology that looks like it would do the job is <url> but i haven't used it before. anybody done this before and have any suggestions?my preference is to use rails, and heroku.",
    "present_kp": [
      "html",
      "heroku"
    ],
    "absent_kp": [
      "ruby on rails",
      "caching"
    ]
  },
  {
    "text": "how do i make grub's gfx_payload setting permanent?. i've been trying to change the console display resolution on my arch linux distro running on virtualbox with no prevail. in /etc/default/grub, i have the following variables set:gfx_mode=1024x768x32gfx_payload_linux=keepthis correctly causes grub to boot at that resolution and linux even does so for a split second but shortly after, linux reverts back to it's default framebuffer resolution. something like 640x480x32 or something like that.i've tried different resolutions, checked to make sure 1024x768x32 is supported, even tried using the obsolete 'vga' kernel boot parameter. it either does nothing or it works but only temporarily.",
    "present_kp": [
      "boot",
      "grub",
      "resolution"
    ],
    "absent_kp": []
  },
  {
    "text": "have pacmatic wrap pacaur/yaourt wrap powerpill wrap pacman. i have a few preferences in regards to managing packages on manjaro / arch:pacmatic adds safety features when installing packagespacaur provides a consistent interface to both the official and aur packagespowerpill for parallel downloading of packagespacman with /etc/pacman.conf options color and usedelta (for the win)how can i have pacmatic wrap pacaur/yaourt wrapping powerpill wrapping pacman?",
    "present_kp": [
      "manjaro",
      "pacman"
    ],
    "absent_kp": [
      "arch linux",
      "package management"
    ]
  },
  {
    "text": "solving unary constraint satisfaction problem other than branch and bound. i am solving a problem of planning a meal, where i need to fulfill requests such as create a two-dish meal that must have at most 2g of fat, the first dish must have 400kcal and should have at least 10g of protein, and the second dish must have 100kcal by returning a list of dishes from a predefined list. in other words, it takes soft/hard constraints on a meal as a whole and sets of soft/hard constraint on each dish slot as an input, and outputs an assigment of dishes to dish slots.i modelled it as a constraint satisfaction problem with all dish constraints being unary constraints and meal constraints being used for accepting/rejecting a solution as well as ranking. i wrote depth-first branch and bound roughly following [1] (shortly, it constructs depth-first a tree of all possible assignments and prunes branches with a dish violating its constraints) and it works pretty well.(*)the problem is, i need another algorithm for solving that problem and - for reasons i can't change - it needs to be fully deterministic. which is problematic, since:the whole meal planning research focuses on using various flavours of artificial intelligence,the few research papers that don't use ai, use onthologies and rule-based reasoning, but offer no details and constructing such is outside of my time budget and capabilites,all other algorithms i could find for solving constraint satisfaction problem focus on the ones with binary constraints.i have tried to find such algorithm for about two weeks, but found nothing. i feel like i'm missing an obvious solution, but i can't quite put my finger on it.(*) of course, i plan to improve it by appriopriately integrating meal constraints into the search.[1] sundmark, niclas. design and implementation of a constraint satisfaction algorithm for meal planning. (2005).",
    "present_kp": [
      "algorithms",
      "branch and bound",
      "planning"
    ],
    "absent_kp": []
  },
  {
    "text": "making sh script into program. so, my question is: how do you turn a .sh sh into a command line based application? i know it's already executable by using the command ./name.sh, but what if i wanted to be able to execute it just by typing name in the terminal, like would do with a tool downloaded with my system default command for installing an application. is that possible?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "shell script"
    ]
  },
  {
    "text": "how are the logical and mathematical skills of people with adhd?. how does rationality and the logical thought processes of those with and without adhd compare? please explain the source of the differences. are the differences thought to be caused by dopamine, serotonin, or norepinephrine? or is there some other neurological explanation?how do the math skills of those with adhd compare to others? as above, please explain in detail from a biochemical perspective.",
    "present_kp": [
      "adhd"
    ],
    "absent_kp": [
      "cognitive psychology",
      "clinical psychology",
      "neurology",
      "mathematical ability"
    ]
  },
  {
    "text": "an algorithm for counting to grahams number. im trying to come up with an algorithm that performs some action a grahams number of times on a machine with a reasonable amount of memory.i thougth of the way to organize counter suitable for calculating $a{\\uparrow\\uparrow}b$, but got stuck at even smaller problem of counting to $2^a$, where $a$ is a 64-bit integer ($2^{21}$tb needed for storage of such number is above what i assume reasonable).is there some clever technique to count beyond $2{\\uparrow\\uparrow}6$? or is there any conceptual limitations on the counters with a polynomial-bounded memory?",
    "present_kp": [],
    "absent_kp": [
      "space bounded",
      "combinatorics"
    ]
  },
  {
    "text": "linux arch unity not writeable settings. i am running linux arch with kde till yet. now i want to move to unity because of some personal favors. i used the tutorial proposed in the arch wiki for installation (the recommended way using the repositories). <url> ui seems to be running fine, except that i can't change a lot of settings. for example:i can't set an option to the nautilus, to the gnome-terminal, to the compiz config manager. i also can't add a program to my starter. everything gets reset one second after i set an option. so it seems to me like a permissions problem, that i have no write access to my profile configs, but i don't know how to tackle it.",
    "present_kp": [
      "linux",
      "unity"
    ],
    "absent_kp": [
      "arch linux"
    ]
  },
  {
    "text": "block google analytics referral spam from fake lifehacker site. my google analytics shows traffic from russia and shows lifehacker.com as traffic referral. traffic appears throughout the day and it shows no pages visited. any ideas for this issue?just realized, it is actually coming from lifehacer.com (letter not k), which appears to be some sort of analytics spam. how can i block this?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "can't login kali 2.0 after fresh installation. installed new instance of kali 2.0 graphical in virtualbox. created a normal user say user1 and set the password of root as pass123.after installation (no error encountered), tried login into kali 2.0 using normal user user1, can't get in and received wrong password related error.then, tried using root user and password user1 (was set during installation); user root is not recognized in the login window and same only user login window just bounces back",
    "present_kp": [],
    "absent_kp": [
      "kali linux"
    ]
  },
  {
    "text": "minimize reserved space on ext4 volume without large files. i'm creating a small (~4gb) ext4 volume to store mostly text documents, and no files larger than ~200 mb. i estimate the total number of files won't exceed 150,000 (i know because i'm migrating data from a comparable ntfs volume).what parameters should i pass to mkfs.ext4 in order to minimize the reserved space? i've read that -m 0 is not recommended, but this will be a data volume stored on ssds (so fragmentation isn't an issue), not a system partition.",
    "present_kp": [
      "ext4",
      "ssd"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "group array by sums. i have the following code that takes an array, and groups it by the sums of its elements:class array def in_sums_of size, &block block = -> el { el } unless block container = [] each_with_index.inject([]) do |tmp, group| element, idx = group value = block.call(element) sum = tmp.inject(0) { |sum,x| sum + block.call(x) } if sum + value <= size tmp << element else container << tmp if tmp.any? tmp = [element] end container << tmp if idx == length - 1 tmp end container endend[].in_sums_of(0)# => [][1].in_sums_of(1)# => [[1]][1,1].in_sums_of(1)# => [[1], [1]][1,1].in_sums_of(2)# => [[1, 1]][3,2,1].in_sums_of(3)# => [[3], [2, 1]][3,3].in_sums_of(3)# => [[3], [3]][4,3,1].in_sums_of(3)# => [[4], [3], [1]][{v: 1},{v: 2},{v: 2},{v: 3}].in_sums_of(3) do |el| el[:v]end# => [[{:v=>1}, {:v=>2}], [{:v=>2}], [{:v=>3}]]it takes an array and a limit, and puts elements into sub arrays, as long as there is space left, which is limited by size var (3 in the example above).the code works, and is already in production, but i was curious if this is the best approach. i haven't found a rails helper or ruby method that would help with this approach. so any ideas on this?editi've updated the code and added some examples.",
    "present_kp": [
      "ruby",
      "array"
    ],
    "absent_kp": [
      "ruby on rails"
    ]
  },
  {
    "text": "is the term web portal obsolete?. my boss uses the term portal for the project i work on all the time.to me, the word makes me think of yahoo in the late 90s. does the word portal have old-school connotations, or is it just me? do you think it's ok to use it or will it drag our client's perception of the product down into the middle-ages?",
    "present_kp": [],
    "absent_kp": [
      "naming",
      "terminology"
    ]
  },
  {
    "text": "google indexed my home page incorrectly: how can i fix it?. i finished my website and launched it, i think i had a problem with my robots.txt - so i changed it to look like this:03/08/2012# allows all botssitemap: <url> *disallow: /dashboard/when i google my domain.co.za - i get this back: homea description for this result is not available because of this site's robots.txt learn more.you've visited this page 3 times. last visit: 2012/08/15now since i fixed this and added a 301 redirect to redirect mysite.co.za to <url> i would love it if google bot would come do a visit.is there anything i can do to get this fixed?",
    "present_kp": [],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "if i try to monetize free software, what could possibly prevent someone from forking that software and creating a proprietary version?. i've only recently begun to learn about the tensions between free and proprietary software, and i've been very confused by the way that free software can make money.i understand that free software is free as in speech, not as in beer, but if i release an open source program and then try to monetize it, what could possibly prevent someone from forking that software and creating a proprietary version?is the only thing that stops them the investment of other members of the open source community in improving the software?it seems like every improvement free software makes is transparent so a proprietary copycat can make sure they are always up to date with the latest features in the free version, and then add their own features on top of that independently. i'm confused about how free software can survive in serious competition with proprietary software.",
    "present_kp": [
      "free software",
      "proprietary"
    ],
    "absent_kp": []
  },
  {
    "text": "windows service listening for messages from a network. i am new with async task in c# 4.5 and feel insecure about this:i want to create a windows service that listen messages from a network (similar to msmq for example), when a message is received, do stuff not cpu bound (call webservices and rest api) without blocking other messages.i created this console application in order to test the concept:using system;using system.collections.generic;using system.linq;using system.threading;using system.threading.tasks;namespace sandbox{ public class program { static cancellationtokensource cts; static cancellationtoken ct; static taskcompletionsource<bool> maintask; static void main(string[] args) { console.writeline(string.format([{0:000}] start., thread.currentthread.managedthreadid)); cts = new cancellationtokensource(); ct = cts.token; // run inside a new thread, the service will have 3 dedicated threads maintask = new taskcompletionsource<bool>( task.factory.startnew(() => { run(ct); maintask.setresult(true); }, taskcreationoptions.longrunning)); console.writeline(press a key to stop.); console.readkey(); cts.cancel(); // stop the main threads maintask.task.wait(); // wait for tasks to end properly } static list<task> tasks; /// <summary>main loop</summary> static void run(cancellationtoken cancel) { console.writeline(string.format([{0:000}] start loop., thread.currentthread.managedthreadid)); tasks = new list<task>(); int iteration = 0; while (!ct.iscancellationrequested) { string onemsg = waitmessagefromnetwork(); // for the test, randomize duration of async task. iteration += 100; int wait; switch (iteration) { case 200: wait = 1000; break; case 300: wait = 2000; break; case 400: wait = 1500; break; case 500: wait = 1600; break; case 600: wait = 1100; break; case 700: wait = 1200; break; case 800: wait = 1900; break; case 900: wait = 1800; break; case 1000: wait = 800; break; case 1100: wait = 900; break; default: wait=0; break; } if (wait > 0) tasks.add(doworkasync(wait, onemsg)); foreach (task t in tasks.where(x => x.isfaulted)) { console.writeline(t.exception); // log.error(... } tasks.removeall(x => x.iscanceled | x.iscompleted | x.isfaulted); // remove finished tasks // limit asynchronism to 5 tasks for the test, unnecessary ? x in real service ? if (tasks.count > 4) console.writeline(waitany returns {0}., task.waitany(tasks.toarray())); } task.waitall(tasks.toarray()); // if the service stop, wait pending tasks to finish. } static string waitmessagefromnetwork() { thread.sleep(100); // real method will not block the thread return dummy; } /// <summary>do i/o bound stuff : call webservices async and rest api.</summary> static async task doworkasync(int wait, string onemsg) { try { console.writeline(string.format([{0:000}] start {1:0000}., thread.currentthread.managedthreadid, wait)); await task.delay(wait); console.writeline(string.format([{0:000}] end {1:0000}., thread.currentthread.managedthreadid, wait)); } catch(exception ex) { console.writeline(ex); // log.error(... } } }}it works but is it ok to do like this?in my tests, start and end messages are not one the same thread (not a problem in my case), its normal if i understand because a console or service application does not have a synchronizationcontext ?",
    "present_kp": [
      "c#"
    ],
    "absent_kp": [
      "async await"
    ]
  },
  {
    "text": "facebook change from profile into an artist page -> now all friends lost. i changed my facebook profile with 1,300 friends into a facebook page because i am a music artist. facebook said only my friends and the profile picture would be in the page.now that i have changed it, the problem now is that i have 0 likes and all the 1,300 people who listen to my music are lost.how can i solve that problem? did anyone have same experiences?",
    "present_kp": [
      "facebook",
      "friends"
    ],
    "absent_kp": []
  },
  {
    "text": "union grouping in bipartite graphs?. i'm trying to figure out a good (and fast) solution to the following problem:i have two models i'm working with, let's call them players and teams. a player can be on multiple teams and a team can have multiple players). i'm working on creating a ui element on a form that allows a user to select multiple teams (checkboxes). as the user is selecting (or deselecting) teams, i'd like to display the teams grouped by the players.so for examples:if the selected teams have no players that intersect, each team would have its own section. if the user selects two teams and they have the same players, there would be one section containing the names of the two teams and all the players.if team_a has players [1, 2, 4, 5] and team_b has players [1, 3, 5, 6]. there would be the following sections: section_x = [team_a, team_b, 1, 5], section_y = [team_a, 2, 3], section _z = [team_b, 3, 5]i hope that's clear. essentially, i want to find the teams that players have in common and group by that. i was thinking maybe there is a way to do this by navigating a bipartite graph? not exactly sure how though and i might be overthinking it. i was hoping to do this by creating some type of data structure on the server and using it on the client. i would love to hear your suggestions and i appreciate any help you can give!",
    "present_kp": [
      "graphs"
    ],
    "absent_kp": []
  },
  {
    "text": "regular expression over a monoid. i'm looking for the name of the following concept.given a monoid $(m,\\oplus)$, and a finite set of generators $x_1,\\ldots,x_n$. the generators are the alphabets.we define the regular expression on the words formed by the generators. we treat those words just like strings. for words $x$ and $y$, we write $x\\equiv y$ if $x$ and $y$ represent the same element in $m$.if $r$ is a regular expression, we define $l(r)$ to be the set of strings matched by $r$ and $l_m(r)$ as$$l_m(r) = \\{w'|w'\\equiv w,w\\in l(r)\\}$$.i'm interested to know if there exist known literature on $l_m(r)$. many problems related to $l_m(r)$ are undecidable, because the word problem on $m$ might be undecidable. i wonder if $m$ has a decidable word problem, does it imply we can decide if $l_m(r)=l_m(r')$ for 2 regular expressions $r$ and $r'$.",
    "present_kp": [],
    "absent_kp": [
      "formal languages",
      "reference request"
    ]
  },
  {
    "text": "how to understand the lpstartaddress-parameter of the function createthread. i have the following assembly code :.....lea eax, [ebp+threadid]push eax ; lpthreadidpush 0 ; dwcreationflagspush 0 ; lpparameterpush offset startaddress ; lpstartaddresspush 0 ; dwstacksizecall createthread....so, i try to translate it in a c-like pseudocode:dword* lpword eax_lpthreadid = null;dword dwcreationflags;void *lpvoid lpparameter;size_t dwstacksize;lpsecurity attributes lpthreadattributes;handle handle_to_new_thread = createthread(lpthreadattributes, dwstacksize, ..., lpparameter, dwcreationflags, eax_lpthreadid );as you can see, i do not include the 3rd parameter, namely the parameter lpthread_start_routine lpstartaddress, because i have problems understanding it.in this so thread i have read that a lpthread_start_routine is a function pointer defined as:typedef dword (__stdcall *lpthread_start_routine) ( [in] lpvoid lpthreadparameter);that would mean that the 4th parameter lpthreadparameter is a parameter of this. but how can i integrate that information into my pseudo c code program ?i am little bit confused about that. can someone explain it to me? the other attributes/parameters are clear....",
    "present_kp": [
      "assembly",
      "c"
    ],
    "absent_kp": []
  },
  {
    "text": "legendre expansion of $r(x) = f(x)/g(x)$ using a finite number of samples from $f(x)$ and $g(x)$. i have two finite sets of events $\\{x_1, ..., x_n\\}$ and $\\{y_1, ..., y_n\\}$ that are sampled from the pdfs $f(x)$ and $g(x)$, respectively, where $x \\in [-1,+1]$. i want to estimate the legendre expansion of $r(x) = f(x)/g(x)$ using these events. what is the best method? (note that $g(x) eq0$ over $[-1,1]$)",
    "present_kp": [],
    "absent_kp": [
      "numerical analysis",
      "statistics",
      "polynomials"
    ]
  },
  {
    "text": "if you have a piece of logic that needs to be shared between two controllers where do you keep it?. i have a set of single purpose functions that i need in two separate controllers. right now i just have duplicate code and i want to get rid of it. this code is part of the controller and doesn't belong in my service layer. where would you put it?",
    "present_kp": [],
    "absent_kp": [
      "mvc",
      "code smell"
    ]
  },
  {
    "text": "how to turn off google's page preview in search?. how to turn off scripts in google search, in particular the page preview?",
    "present_kp": [
      "google"
    ],
    "absent_kp": [
      "search engine"
    ]
  },
  {
    "text": "in c++ is casting to find bad pointers undefined behavior?. by accident i found that with a polymorphic type using dynamic_cast back to the derived class will throw a 'bad cast' error if the pointer is no longer valid. is this undefined behavior or could this be a way to check for valid pointers without using smart pointers? i'm not really against using smart pointers as they serve a real need, but i dislike the syntax. i don't have anything against templated types but i find smart pointers to bloat the code and i'm not a fan of macro's to try and avoid that bloat. i wish c++ included something in the language syntax itself vs using the template feature but with this question i'm more concerned about what is happening below and if this is a valid and defined way to checking for valid pointers as this gives an exception every time from my tests.#include <string>#include <map>using namespace std;class base{public: virtual ~base(){}};class derived : public base{public: virtual ~derived(){}};class storage{private: map<string, base*> storage;public: void additem(string name, base* base) { if (storage.find(name) == storage.end()) { storage[name] = base; } } template <class t> t& finditem(string name) { if (storage.find(name) != storage.end()) { base* item = storage[name]; return dynamic_cast<t&>(*item); } throw; }};int main(){ storage store; // force 'd' to go out of scope for our test { derived d; store.additem(test, &d); } // this will throw a bad cast exception derived& test = store.finditem<derived>(test); return 0;}",
    "present_kp": [
      "c++"
    ],
    "absent_kp": []
  },
  {
    "text": "visualeditor for mediawiki wiki via node.js on heroku. for small non-wmf wikis on economical shared hosting it might be possible to get extension:visualeditor running without having to upgrade to vps hosting. that is by installing parsoid to run on heroku's node.js.please some advice on how to go about this and what are the risks?",
    "present_kp": [
      "mediawiki",
      "heroku"
    ],
    "absent_kp": [
      "node js"
    ]
  },
  {
    "text": "route -n gives output route: fscanf. if i boot my system and no interface has an ip address i get the above output. however if i give an interface an ip, even if i remove it again, this will disappear. why does this happen?is it that there is some file created that route tries to read?",
    "present_kp": [
      "route"
    ],
    "absent_kp": [
      "bash",
      "shell",
      "networking"
    ]
  },
  {
    "text": "2-player game of battleship (python). i have been working on a 2-player battleship game and have finally got it working, bug free.i'm posting this here to ask you what you think of it. are there any changes that could be made to improve the performance/general layout of the code?if you come across any issues with the code itself, (maybe a bug yet to be found) then i'd be grateful if you could let me know.the game is a fairly simple console-based battleship game, where the players take it in turns to sink a mutual ship that is defined by an x and y coordinate on a 5x5 game board.from random import randintgame_board = []player_one = { name: player 1, wins: 0,}player_two = { name: player 2, wins: 0,}colors = { reset:, red:, blue:, cyan:,}# building our 5 x 5 boarddef build_game_board(board): for item in range(5): board.append([o] * 5)def show_board(board): for row in board: print( .join(row))# defining ships locationsdef load_game(board): print(welcome to battleship!) print(find and sink the ship!) del board[:] build_game_board(board) print(colors['blue']) show_board(board) print(colors['reset']) ship_col = randint(1, len(board)) ship_row = randint(1, len(board[0])) return { 'ship_col': ship_col, 'ship_row': ship_row, }ship_points = load_game(game_board)# players will alternate turns.def player_turns(total_turns): if total_turns % 2 == 0: total_turns += 1 return player_one return player_two# allows new game to startdef play_again(): positive = [yes, y] negative = [no, n] global ship_points while true: answer = input(play again? [y(es) / n(o)]: ).lower().strip() if answer in positive: ship_points = load_game(game_board) main() break elif answer in negative: print(thanks for playing!) exit()# what will be done with players guessesdef input_check(ship_row, ship_col, player, board): guess_col = 0 guess_row = 0 while true: try: guess_row = int(input(guess row:)) - 1 guess_col = int(input(guess col:)) - 1 except valueerror: print(enter a number only: ) continue else: break match = guess_row == ship_row - 1 and guess_col == ship_col - 1 not_on_game_board = (guess_row < 0 or guess_row > 4) or (guess_col < 0 or guess_col > 4) if match: player[wins] += 1 print(congratulations! you sunk my battleship!) print('the current match score is %d : %d (player1 : player2)' % (player_one[wins], player_two[wins])) print(thanks for playing!) play_again() elif not match: if not_on_game_board: print(oops, that's not even in the ocean.) elif board[guess_row][guess_col] == x or board[guess_row][guess_col] == y: print(you guessed that one already.) else: print(you missed my battleship!) if player == player_one: board[guess_row][guess_col] = x else: board[guess_row][guess_col] = y print(colors['cyan']) show_board(game_board) print(colors['reset']) else: return 0begin = input(type 'start' to begin: )while (begin != str('start')): begin = input(type 'start' to begin: )def main(): for turns in range(6): if player_turns(turns) == player_one: print(ship_points) print(player one) input_check( ship_points['ship_row'], ship_points['ship_col'], player_one, game_board ) elif player_turns(turns) == player_two: print(player two) input_check( ship_points['ship_row'], ship_points['ship_col'], player_two, game_board ) if turns == 5: print(this game is a draw.) print(colors['red']) show_board(game_board) print(colors['reset']) print('the current match score is %d : %d (player1 : player2)' % (player_one[wins], player_two[wins])) play_again()if __name__ == __main__: main()",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "python 3.x"
    ]
  },
  {
    "text": "are recursions intrinsically less safe than iterations?. java doesn't have a predefined recursion depth limit. as a result the recursion below (a dummy method that returns the value) throws java.lang.stackoverflowerror after 62844 (with static) and 14002 (without static) iterations.public static int testrecursion(int number) { if (number == 1) { return 1; } else { int result = 1 + testrecursion(number - 1); return result; } }public int testiteration(int number){int result = 0;while (number > 0){ result++; number--; }return result;}i have two concerns:iteration method works correctly for all positive int values, whereas recursion throws an exceptionchanges to a method change the recursion depth at which the exception will be thrown. recursion in java seems like a way to add floating bugs. recursion depth is greater than a magic number? program throws exception. author modified recursive method - allowed recursion depth decreased and an exception is thrown again.recursions are widely used in java. does it mean that recursion limit is rarely reached in practical situations? or are there some general and robust methods to deal with floating recursion depth limit?i've read these questions:how to convert this recursive problem to iterative? line simplification algorithm fails to run due to maximum recursion depth being hitrecursion or while loopswhat are the advantages of recursion compared to iteration?but none of those questions discuss a problem of recursion depth in java.",
    "present_kp": [
      "java",
      "recursion"
    ],
    "absent_kp": []
  },
  {
    "text": "can server break clients' cache settings?. i have disputed a domain name to a cybersquatter that i expect to recover soon. the problem is that the cybersquatter has changed the cache headers and now every user who already visited the site or is going to visit the site until the domain name is given back, can see the same page until 2016.a lot of the traffic of the site comes from google, i will fix that by moving the domain with error 301 and the webmasters tools. but how about those users who access directly to the site? is there any way (i guess not) to break the client's cache settings (even the homepage is cached)?thank you!",
    "present_kp": [
      "cache"
    ],
    "absent_kp": [
      "http headers",
      "cache control"
    ]
  },
  {
    "text": "mysql database connection in the constructor. i'm an absolute beginner in php oop in search of the holy grail of connecting to mysql database once and reusing this connection for the whole site.classes/db.php<?phpdefine('server', 'localhost');define('username', 'root');define('password', 'password');define('database', 'cms');class db { function __construct(){ $connection = @mysql_connect(server, username, password) or die('connection error -> ' . mysql_error()); mysql_select_db(database, $connection) or die('database error -> ' . mysql_error()); }}?>classes/users.php<?phpclass users { function __construct(){ $db = new db(); } public function read(){ $query = mysql_query(select use_id, use_name, use_email from users); while ($row = mysql_fetch_array($query)){ $data[] = $row; } return $data; }}?>users.php<?php require_once('classes/db.php'); ?><?php require_once('classes/users.php'); ?><?php$users = new users();$users = $users->read();?><?phpif ($users) { echo '<ul>'; foreach($users as $user){ echo '<li><a href=mailto:' . $user['use_email'] . '>' . $user['use_name'] . '</a></li>'; } echo '</ul>'; }?>my doubts are mostly on the users class part:function __construct(){ $db = new db();}it seems to be an easy way to have the connection available, but i read somewhere that instantiate the db connection in the constructor is a bad idea. can you explain why, and if there's a better way to have the db connection easily available in every class that needs it?i read a similar question here, but i can't understand the abstraction/holding reference/singleton suggestion from the accepted answer, and the lack of a full practical example doesn't help me.",
    "present_kp": [
      "php",
      "beginner",
      "mysql",
      "constructor"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "gce vm not connecting from terminal but working in web ssh. until before couple of days in mac terminal i was able to connect to gce vm without trouble. now when i tried any vm it is not connecting. same vms are connecting from web ssh ok. does it need to be fixed on mac or vm side? as none of vm is connecting i felt the issue must be in mac side. log didn't display much info, is there anything can be done?gcloud compute --project <projectname> ssh --zone us-central1-b instance-dm-f07a --ssh-flag=-vvvvvopenssh_6.2p2, osslshim 0.9.8r 8 dec 2011debug1: reading configuration data /etc/ssh_configdebug1: /etc/ssh_config line 20: applying options for *debug2: ssh_connect: needpriv 0debug1: connecting to 104.197.95.27 [104.197.95.27] port 22.debug1: connect to address 104.197.95.27 port 22: operation timed outssh: connect to host 104.197.95.27 port 22: operation timed outerror: (gcloud.compute.ssh) [/usr/bin/ssh] exited with return code [255].",
    "present_kp": [],
    "absent_kp": [
      "google cloud"
    ]
  },
  {
    "text": "determining the best way(s) of adding unit tests to a large project that makes good use of stored procedures. we work on a fairly large casino/gaming/wallet/lottery platform. it's a turn-key application that is currently in use by 4 clients, and soon to be much more. i've made some bullet points regarding the architecture below:~130k loc in just c# codeover 500 stored procs, in one of the 5 databases our system uses - because our code is used in regulated environments, the source code is locked for some clients until it is reviewed by a (very expensive) outside agency, so making changes via stored proc is a good balance of keeping both regulators and clients happy. the other databases are not near the complexity of the main database.c# application code, spread out in windows forms, xamarin android, windows services, web apps, sql clr library, class libraries and unit test projectsuses ef6 for data layer, some ad-hoc, some stored procswhile we have some unit tests in place, it's mostly for infrastructure-related stuff. there aren't many tests that test the business features. the other issue is that a lot of the heavy lifting is done in stored procedures. it's come time to add some unit tests in before we start refactoring some of the code, to prevent regressions. what i am looking for is a list of the different ways to go about this. this is what i have come up with so far:we have a test sql server instance that we could set up to clear and repopulate data when starting each test.prosthe clear/reload data script can easily be modified when adding new testsconsthe clear/reload script could get hugetesting could be slow because of clearing/reloading data on each test runwe could use moq to mock the ef6 data context as i have read on soprostesting would be fast as the data would come from c# code and be compiledconsadding test data in c# would take foreveruse mstest to test c# procs that don't use stored procedures, and use redgate's sql test product to test sql procedures by itselfprosunsure. while we own the developer suite of redgate products, we haven't used sql test before.consit's not a true test of the inner workings of the procs in my opinionmake a new override of the ef data context that forcibly loads the databases on the qa server, creates a new sqltransaction on the connection, and when disposed of, calls rollback to dispose of any changes madeprosdoesn't require a lot of modifications to a lot of the internals of the existing code, or refactoringconsrequires that we refactor a bunch of code to take in a database connection rather than allowing it to be created, e.g. make an ioc for getting the database connectionthe plan i have is to get a couple of good tests written, and if a lot of refactoring is not in the cards, have our qa guy learn programming by writing tests based on the examples made while getting it all set up.how should i handle adding unit testing to a large project? how should i handle testing procedures that call stored procedures in a database? what i would like to know is the best way to shim unit tests in without a lot of refactoring. refactoring this code base to decouple the data layer, for some spots, would not be hard, but in other spots, would be tough to do, so the method with the least amount of friction would be best.",
    "present_kp": [
      "c#",
      "unit testing",
      "sql server",
      "stored procedures"
    ],
    "absent_kp": [
      "entity framework"
    ]
  },
  {
    "text": "admin css sidebar template. could i get some feedback on my simple start to an admin template: <url> <div class=wrapper> <div class=left> <a href=#><img src=nav_sprite.jpg class=logo /></a> <ul class=navigation> <li id=dashboard><a href=index.html class=active>dashboard</a></li> </ul> </div> <div class=right> <h1>title</h1> <p>content</p> </div> </div></body></html>css* { margin: 0; padding: 0; border: 0;}li { list-style: none;}a { text-decoration: none}html, body {height: 100%; max-height: 100%; padding:0; margin:0;}.wrapper {display:table; width:100%; height:100%;}.wrapper > div {display:table-cell; vertical-align: top;}.wrapper .left {width:200px; background-color:#34495e}#btn_pri { background-color: 60a0df; color: white;}#btn_sec { background-color: #e74c3c;color:white;}.navigation {}.navigation li {}.navigation li span { display: inline-block; background: url(<url>) no-repeat left center; width: 16px; height: 16px; overflow: hidden; margin-left: 15px; margin-right: 15px;}.navigation li a { display: block; color: white; padding-top: 15px; padding-bottom: 15px; font-family:'helvetica neue', helvetica, arial, sans-serif; font-size: 14px;}.navigation li a:hover { background-color: #495c6d;}.navigation li a.active { background-color: #495c6d}#rss span { background-position: -52px -68px;}#photos span { background-position: -90px -66px;}#links span { background-position: -45px 0;}h1 {font-family: 'helvetica neue', helvetica, arial, sans-serif; font-size: 30px; font-weight: 500;}.logo {height: 50px; margin-bottom: 30px;}.btn { letter-spacing: 1px; font-weight:bold; padding-left: 10px; padding-right: 10px; height: 34px; border-radius:3px; border: 0px; text-transform:uppercase; font-size:12px;}#btn_pri { background-color: #60a0df; color: white;}#btn_sec { background-color: #e74c3c;color:white;}",
    "present_kp": [
      "html",
      "css"
    ],
    "absent_kp": []
  },
  {
    "text": "is logging personally identifiable information a bad practice or violation of law?. i know we all do semi-anonymous logging (server logs, google analytics, etc.). however, on one of our external web applications, we have some non-reproducible errors that the external users report occasionally. i chalk most of them up to a pebkac errors, but i always investigate the problem to see if i have the same problem.while talking to the internal user that manages it, she mentioned that it is too bad that we can't figure out what browser the person is using without having to call them. i told her that actually we can, but normally it is anonymous data that isn't directly linked to a user.i am curious, is this practice frowned upon? actually tracking what browser an identified user is using to fill out our forms and log that information with their data. nothing more than what is logged normally, just linked to a user.thoughts?updated: i thought i could get by without more details about the application and why. this is for a job application... application. i am trying to track down some bugs. we hate to always call the user back and ask what browser they were using and how they got the error. if i link their browser information to their name as they fill out the form it removes one piece of the puzzle and i may be able to track down some of the browser-based errors. the real question is if this is against best practices and/or the law.",
    "present_kp": [
      "logging"
    ],
    "absent_kp": [
      "privacy"
    ]
  },
  {
    "text": "why do people call linux a kernel rather than an os?. why do people refer to linux as a kernel rather than an operating system? to the best of my knowledge, the kernel is one part of the operating system.",
    "present_kp": [
      "linux",
      "kernel"
    ],
    "absent_kp": []
  },
  {
    "text": "simple trial division in javascript. i began programming recently. i am trying to implement a simple trial-division algorithm for finding all primes up to some number (it is much more primitive algorithm than the sieve of eratosthenes). can you please find what's wrong with my code?#range function:range = function (a,b,c){ var range1=[] for (i=a; i<b; i=i+c){ range1.push(i); } return range1;}#the algorithm:n=prompt(n);var numbers=range(2,n,1);var primes=[];for (number in numbers){ var sublist=range(2,number,1); console.log(sublist); for (x in sublist){ if (number%x ===0){ break; } primes.push(number); }}thanks in advance!",
    "present_kp": [
      "javascript"
    ],
    "absent_kp": []
  },
  {
    "text": "changes to server not reflected on website. the disclaimer: i've looked around for this for a while and didn't find anything - i'm guessing it's a common question and i just don't know how to ask it so sorry about this (almost certainly) being a duplicate.ok, here's the problem: so i have a shared server (through arvixe) and i recently updated my site (by renaming some of the files) via ssh: foo.htm -> foo2.htm, index.htm -> index2.htm, etc. when i go to my site the old file is still there (i can type <url> and it works) but the new file is not (<url> doesn't exist). cache could explain the old file loading, but the lack of the new file is baffling (also cleared my cache and tried it on a new computer for sanity checking). this tells me that my server is not working how i think it's working (i.e. making a change on the server makes a change on the site). so the question is, why are my changes not reflected to my site?a brief addendum: this also happened with a wordpress install. i installed using softalicious and when i deleted the wp/ directory in my public_html dir the site still showed up. i figured that this had something to do with the installer doing some behind the scenes thing (though i wasn't totally convinced). i had to uninstall via softalicious to get it to go away.my guess: is this just my server is being reflected to another server for actual site loading? my server's ip is different than when i ping my site.",
    "present_kp": [],
    "absent_kp": [
      "web development",
      "webserver"
    ]
  },
  {
    "text": "open a luks volume as a non-root user?. i'm using cryptsetup to create a luks file-based device to stash information in:# create a file as a containerdd if=/dev/zero of=zulu.bin bs=1024 count=102400# create a keydd if=/dev/urandom bs=1 count=8192 2>/dev/null | \\ base64 | \\ cut -b 1-8192 | \\ tr -d ' ' | \\ gpg2 --output zulu-key.gpg -aser deadbeef# format the file-based devicegpg2 --decrypt zulu-key.gpg | \\ cryptsetup luksformat --iter-time=10000 --hash sha256 \\ --cipher aes-cbc-essiv:sha256 --key-size 256 --key-file - \\ zulu.binthere are a lot of things less than optimal here, namely block-device encryption provides no cryptographic authentication, etc.in any case, i cannot open this device as a non-root user:$ gpg2 --decrypt zulu-key.gpg | \\ cryptsetup open -d - zulu.bin zulucannot initialize device-mapper, running as non-root user.what i essentially need is an entire filesystem that is encrypted but stored in a file. i need to be able to open and close this encrypted filesystem at will and without elevated privileges.i have thought about simply creating a tmpfs or ramfs and then simply dding the device directly piped into gnupg and then i'd get gnupg's encryption, authentication, and non-repudiation, but i'm not sure if this will work.is there a good known way to allocate a filesystem of an arbitrary size as a file that is encrypted at rest via gnupg, can be opened into ram, and then can be again piped into gnupg for encryption to take the device offline again? is it possible to do this as a normal user using fuse?my use case is needing an arbitrarily sized filesystem which is encrypted so that programs writing files to said filesystem need not know about encryption at all; gnupg would handle the encryption when closing the device and writing ciphertext to disk as a file.",
    "present_kp": [
      "gpg",
      "luks"
    ],
    "absent_kp": [
      "dm crypt"
    ]
  },
  {
    "text": "libreoffice missing menus in xfce4. i have linux mint 17.2 64 bit (14.04 base) originally a kde install. i installed xfce4 from repos (4.10.1) and other desktops recently, but libreoffice (4.4.3.2 40m0(build:2) is not showing the menus at the top of the screen after installing libreoffice-gtk. checking an existing working install this package is installed (and not using gtk3).i am baffled what else i need to do to enable the menus. i have tried a clean profile, even a new user with no change in the problem. all i can think of at the moment is i am missing a package. screenshot below",
    "present_kp": [
      "xfce",
      "gtk",
      "libreoffice"
    ],
    "absent_kp": []
  },
  {
    "text": "should i consider microservice as an epic or a project in tfs?. when using tools such as tfs or jira to plan an application made of 10+ microservices, i am concerned should i consider microservice as an epic or as an new project?in tfs when splitting microservices as different projects, the benefit is a separated git repository, but on the other hand it is difficult to plan a single sprint having tasks, stories and bugs from different projects",
    "present_kp": [
      "microservices",
      "jira"
    ],
    "absent_kp": [
      "agile",
      "team foundation server",
      "project planning"
    ]
  },
  {
    "text": "how can i tell if a site uses dofollow or nofollow links?. i would like to solicit links from a small business marketing site. i think it uses nofollow, but its robots tag is <meta name=robots content=all />.how do i tell if it is a dofollow site or nofollow site?",
    "present_kp": [
      "nofollow",
      "dofollow"
    ],
    "absent_kp": []
  },
  {
    "text": "rsync not using --files-from option?. i'm trying to run rsync -a --files-from=~/.rsync_file_list ~/destination and it tells me: rsync error: syntax or usage error (code 1) at options.c(1652) [client=3.0.7]. can anyone enlighten me as to what i'm doing wrong?the file ~/.rsync_file_list just contains a list of file names prefaced with ~/, separated by newlines (though i've also tried listing them all on the same line, with the same result).if i run rsync -a ~/file ~/file2 ~/file3 ~/destination it works just fine. so what am i missing about the --files-from option?",
    "present_kp": [
      "rsync"
    ],
    "absent_kp": []
  },
  {
    "text": "is a properly made website with more content has advantage in seo?. somewhere i was reading about seo and it was noted that for search engines, it is beneficial if a website has:many pages withinlong pages (~pages filled with a lot of content)of course these mean nothing if the given site looks like spam. but if we assume, this isn't the case, and the website is actually filled with a lot of text, on a lot of potentially useful pages (e.g. blogs, wiki sites), then does this mean an advantage in seo?",
    "present_kp": [
      "seo",
      "content"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a way to customize github columns in file list?. right now, it shows:filenamelast commit messagelast commit timeis there a way to include other things, e.g. file size, or to reorder / sort columns?",
    "present_kp": [
      "github"
    ],
    "absent_kp": []
  },
  {
    "text": "netcat not working on linux server running vpn. due to our very remote location and budget restraints my internet connection is limited to cellular 3g / edge. the service provider does not have an option for supplying me with a public ip, so we have managed to work around this by running my linux server through a vpn, with a tunnel to a dedicated ip. an added (temporary) complication is that it is a virtual machine, vmware, soon to be replaced by a physical machine. currently i successfully run a couple gps trackers on this server, they are able to access the server through the public ip through tun0, the tunnel set up by the vpn. i can also access a couple other ip devices located in my local network from the internet, so the setup does work.i need to set up a tcp socket in order to grab data coming from another device. i run $ ncat -l -k -p 8993 and $ netstat -l shows that it is indeed listening on that port.tcp 0 0 *:8993 *:* listentcp6 0 0 [::]:8993 [::]:* listenthe results are that i can connect to this socket with telnet when i access the server through its local adapter eth0 from within my local network (192.168.0.113) but i cannot connect to it using the public ip (tun0). canyouseeme.org also shows that port to be closed. i have the following line in iptables:iptables -a forward -i tun0 -o eth0 -p tcp --syn --dport 8993 -m conntrack --ctstate new -j accepti also put in the following lines to see if it helps to solve anything, but so far no joy.iptables -a forward -i tun0 -o eth0 -m conntrack --ctstate established,related -j acceptiptables -a forward -i eth0 -o tun0 -m conntrack --ctstate established,related -j accepti know i'm missing something small here, since my other devices access the server from the public side with no problem. any help would be greatly appreciated.this is what $ ifconfig shows:eth0 link encap:ethernet hwaddr 00:0c:29:45:c6:83 inet addr:192.168.0.113 bcast:192.168.0.255 mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe45:c683/64 scope:link up broadcast running multicast mtu:1500 metric:1 rx packets:11019 errors:0 dropped:0 overruns:0 frame:0 tx packets:6309 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 rx bytes:<phone> (5.6 mib) tx bytes:<phone> (1.1 mib)lo link encap:local loopback inet addr:127.0.0.1 mask:255.0.0.0 inet6 addr: ::1/128 scope:host up loopback running mtu:65536 metric:1 rx packets:120 errors:0 dropped:0 overruns:0 frame:0 tx packets:120 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 rx bytes:8069 (7.8 kib) tx bytes:8069 (7.8 kib)tun0 link encap:unspec hwaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.212.0.6 p-t-p:10.212.0.5 mask:255.255.255.255 up pointopoint running noarp multicast mtu:1500 metric:1 rx packets:4206 errors:0 dropped:0 overruns:0 frame:0 tx packets:3948 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 rx bytes:<phone> (3.3 mib) tx bytes:392464 (383.2 kib)",
    "present_kp": [
      "linux",
      "iptables",
      "netcat"
    ],
    "absent_kp": []
  },
  {
    "text": "cd to original location when recording session with script command. i have script log.txt in my bash profile; that creates a new sub process and records my entire session to log.txt. when i press cmd+t to open a new terminal usually this will open one in the same directory that the command was called; however, the new script sub process always reverts to the home directory.is there a way to pass the current directory to this script command somehow?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell",
      "pwd",
      "typescript"
    ]
  },
  {
    "text": "sending files over samba with command line. i was wondering if there is a way to use samba to send items to a client machine via the command line (i need to send the files from the samba server). i know i could always use scp but first i was wondering if there is a way to do it with samba. thanks!",
    "present_kp": [
      "command line",
      "samba",
      "scp"
    ],
    "absent_kp": [
      "file transfer"
    ]
  },
  {
    "text": "how does matrix-matrix product scale with multiple cpus?. these days, one can have 64 cores in a single node. i wonder how well the dense matrix-matrix product (sgemm and dgemm) scales with multiple cpus/cores?i tried to find some relevant benchmarks, but couldn't.",
    "present_kp": [
      "matrix"
    ],
    "absent_kp": [
      "linear algebra",
      "parallel computing",
      "blas",
      "benchmarking"
    ]
  },
  {
    "text": "go-back-n arq protocol throughput question. i am an undergraduate studying data coms and networking and this question about go-back-n arq popped up that i am struggling to get my head around and cant find anything similar online. any help at all would be greatly appreciated.the only thing i have at all is that throughput could be defined by (packet bits + overhead)/n. is this at all on the right path?questionconsider the go-back-n arq protocol with n=5 and 4 bits used for sequence numbering. the user data frame is 3000 bits long where 100 bits are overhead for header and error check, etc. the frame transmission rate is 2mbps. assume that the medium does not reorder the frames. the outstanding frames will be retransmitted when the sending window becomes empty. the probability that a data frame would be received without any errors is 0.3.i) what is the effective data transmission rate of this protocol?ii) suppose that at time t, the receiver is waiting for an information frame with binary sequence number 1001. what is the possible sequence number slast in binary inside the senders window at time t? justify your answer.",
    "present_kp": [],
    "absent_kp": [
      "computer networks"
    ]
  },
  {
    "text": "how many types of programming languages are there?. basically, i want to learn lots of programming languages to become a great programmer. i know only a handful to depth and i was hoping someone could elaborate on how many classes or types of programming languages there are. like how you would lump them together if you had to learn them in groups.coming from a java background, i'm familiar with static typing, but i know that in addition to dynamic typing there has to be such variety in available languages that i would love to see a categorical breakdown if possible.",
    "present_kp": [
      "programming languages"
    ],
    "absent_kp": []
  },
  {
    "text": "is it a good idea to document every assumption in code, even if it goes against the standard of the language?. for instance, would this c++ function be a good idea?void dosomething(not_nullptr<mytype> arg){ // stuff}with not_tullptr being a template wrapper for pointers, that will throw an exception if a null value is ever assigned to it. it has the advantage that it finds errors fast, and clearly documents assumptions made directly in the function prototype.the traditional way to do something like this would be:void dosomething(mytype* arg){ assert(arg != nullptr); // stuff}this method accomplishes the goal of finding null errors fast. but it does not itself document that assumption in the prototype. so my question is, is the idea above a good one? it is not the standard way of doing things in the c++ and could of course be expanded to other assumptions.",
    "present_kp": [
      "c++"
    ],
    "absent_kp": []
  },
  {
    "text": "can i put google analytics code on this way?. i have website who have main.html and my full front page is there header,footer all is in this one file main.html, other my pages have separate footer and header, now my question is can i put same google analytics code in this main.html and in header for other pages who is connect with header.html without risk some google penalty ?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "recover an overwritten file. i had a linux plain text document file with close to 100000 lines, a size of 10 mb. i accidentally overwrote the file via python code. but i got an exception in the middle of the code and think the file socket did not get closed properly. the new file has a few new lines (250) ,but the size of the file corresponds to the old one. i was wondering if the old content will still be there within the file and any chances of recovering the same. i tried using testdisk and poked around a little bit. but it did not have any option for working on a particular file or maybe i am doing it wrong. i dont have any expertise in file systems and would really appreciate any pointers on how to proceed. thanks",
    "present_kp": [],
    "absent_kp": [
      "filesystems",
      "data recovery"
    ]
  },
  {
    "text": "could developers learn anything from studying malware?. malware uses interesting techniques for hiding themselves from anti-malware software and more. they can polymorph themselves: practically change the code while it continuing to mean pretty much the same to the executing machine, making antivirus definitions invalid etc.i wonder if there is anything (non-malicious) developers could learn from studying the source of such, or reversing them and studying whatever you get from that process if the source isn't available, that could be useful outside this (dark?) realm.i am not interested in writing malware. (at least not for non-educational purposes) this question isn't meant to be a question about how to write malware or such, but what you could learn from already written malware.also, maybe a bit unethical (i hope not), would there be any gains from writing your own piece of malware, just for better understanding of vulnerabilities/exploits/security, or the underlying operating system?",
    "present_kp": [
      "security"
    ],
    "absent_kp": [
      "learning"
    ]
  },
  {
    "text": "how to copy text from an image in a pdf file?. i can view a pdf image with text using the evince document viewer, however i cannot select the text in the image to copy and paste. how do i copy text from an image in a pdf file?",
    "present_kp": [
      "pdf",
      "text"
    ],
    "absent_kp": [
      "images"
    ]
  },
  {
    "text": "tag dependence approach. i need to add class is_active to all div's when i click on <div id=all-tags> and remove class if i click again. only every div have class is_active then main div (<div id=all-tags>) have class is_active.please tell me if this is ok or not. i need as fast of a solution as possible. i'm also not sure using .each() is a very good idea.i need as fast of a solution as possible. i'm not sure using if .each() is a very good idea.$(#all-tags).click(function() { if ($(this).hasclass(is_active)) { $(.tags_cloud div).each(function() { $(this).removeclass(is_active); }); } else { $(this).addclass(is_active); $(.tags_cloud div).each(function() { $(this).addclass(is_active); }); }});$(.tags_cloud div).click(function() { !$(this).is(#all-tags) ? $(this).toggleclass(is_active) : true; var c = 0; $(.tags_cloud div).each(function() { if ($(this).hasclass(is_active) && !$(this).is(#all-tags)) { // some my code } else if (!$(this).is(#all-tags)) { $(#all-tags).removeclass(is_active); c = 1; } c == 0 ? $(#all-tags).addclass(is_active) : true; })});",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "jquery",
      "html",
      "dom"
    ]
  },
  {
    "text": "no qemu-debootstrap in arch linux. i just installed lxc in arch linux, but the qemu-debootstrap binary seems missing,this command sudo lxc-create -n test -t ubuntu -p /run/shm/1 complains about that.i couldn't find it with either pacman or yaourt.any ideas how to fix that? i have the debootstrap script installed and that works though",
    "present_kp": [
      "arch linux",
      "lxc"
    ],
    "absent_kp": []
  },
  {
    "text": "my google search results use to include a translate this page link alongside each search result. my google search results used to include a translate this page link alongside each search result. this does not appear now and i have tried to find a way to bring back that option for many hours today until i am totally frustrated.i did however find some info on the web that suggests the option is still available. i found the following statement:your results may include a translate this page link when a results page is written in a language different from your interface languagehow can i bring this option back to my devices?",
    "present_kp": [
      "google search"
    ],
    "absent_kp": [
      "google translate"
    ]
  },
  {
    "text": "how to change the default driver used for an external screen. i'm having trouble setting up an external displaylink screen in fedora 20.i've found someone who seems to be having exactly the same problem as me and his solution:if you are using displaylink for the xorg driver module, switch it to fbdev.i'm trying to figure out how to do this. i've been searching around, apparently fedora doesn't use an xorg.conf file anymore as it determines the configuration every time x is started.i've downloaded arandr and looked in the system configs as well, i couldn't find a way to manually assign a driver to this device (dvi-1-0 is the displaylink screen).i tried generating my own xorg.conf as well using xorg :l -configure and get told:fatal server error:(ee) server is already active for display 0i can't seem to be able to generate an xorg.conf. solutions to this problem recommend shutting down my desktop manager, which leads to chaotic results in the following terminal, forcing me to hard-reboot.my question is: how can i assign a specific driver to the external screen, instead of the default one? can this be done without an xorg.conf?i use mate desktop, fedora 20.",
    "present_kp": [
      "xorg",
      "display"
    ],
    "absent_kp": [
      "drivers"
    ]
  },
  {
    "text": "reversing bytcode - trying to work decompiling expression. i'm trying to reverse engineer a proprietary scripting compiled bytecode so i can recover source codes of contractor who has gone.while i worked out the majority of it, i'm trying to work out how to translate expressions back into code. wondering if anyone may have some ideas from the patterns below the sort of logic that might be used to rebuild the equations. in particular how operators may be applied back to the components of the expression.specifically i'm trying to work out how to decompile these two expressions:a = b * c+d/e-fa = b * (c+d)/e-foperation codes ,this was worked out from examples provided below22 04 >2b 04 <32 04 *01 04 +17 04 /55 04 -25 00 and27 00 or26 04 end of statementtype of assignment:3d 40 xx xx = variable xx xx 3d 45 xx xx xx xx = 4 byte number4b xx = one byte value48 xx = one byte value38 40 xx xx = assign result to variable xx xxin this example the variables are:a = 00 00b = 00 04c = 00 08d = 00 0ce = 00 10f = 00 14example:a = 10*20+30/40-50/24b af ; 175 38 40 00 00 ; assign result to aa = 10*b+30/40-50/248 0a ; 103d 40 00 04 ; b 32 04 ; *48 00 ; 001 04 ; +48 19 ; 2555 04 ; -38 40 00 00 ; assign result to aa = b+c3d 40 00 04 ; b3d 40 00 08 ; c01 04 ; +38 40 00 00 ; assign result to aa = b*c3d 40 00 04 ; b3d 40 00 08 ; c32 04 ; *38 40 00 00 ; assign result to aa = b-c3d 40 00 04 ; b3d 40 00 08 ; c55 04 ; -38 40 00 00 ; assign result to aa = b/c3d 40 00 04 ; b3d 40 00 08 ; c17 04 ; / 38 40 00 00 ; assign result to aa = b*c+d-e/f3d 40 00 04 ; b3d 40 00 08 ; c32 04 ; *3d 40 00 0c ; d01 04 ; +3d 40 00 10 ; e3d 40 00 14 ; f17 04 ; /55 04 ; -38 40 00 00 ; assign result to aa = b*c+d/e-f3d 40 00 04 ; b3d 40 00 08 ; c32 04 ; *3d 40 00 0c ; d3d 40 00 10 ; e17 04 ; / 01 04 ; +3d 40 00 14 ; f55 04 ; -38 40 00 00 ; assign result to aa = b*(c+d)/e-f3d 40 00 04 ; b3d 40 00 08 ; c3d 40 00 0c ; d01 04 ; +32 04 ; *3d 40 00 10 ; e17 04 ; /3d 40 00 14 ; f55 04 ; -38 40 00 00 ; assign result to aa = b+c * d3d 40 00 04 ; b3d 40 00 08 ; c 3d 40 00 0c ; d32 04 ; * 01 04 ; +38 40 00 00 ; assign result to aa=(b+c) * d3d 40 00 04 ; b3d 40 00 08 ; c01 04 ; +3d 40 00 0c ; d32 04 ; *38 40 00 00 ; assign result to aa=b+c+d * e3d 40 00 04 ; b3d 40 00 08 ; c01 04 ; +3d 40 00 0c ; d3d 40 00 10 ; e32 04 ; *01 04 ; +38 40 00 00 ; assign result to aa=(b+c+d) * e3d 40 00 04 ; b3d 40 00 08 ; c01 04 ; +3d 40 00 0c ; d01 04 ; +3d 40 00 10 ; e32 04 ; *38 40 00 00 ; assign result to aa=a+b * c+d+e * f3d 40 00 00 ; a3d 40 00 04 ; b3d 40 00 08 ; c32 04 ; *01 04 ; +3d 40 00 0c ; d01 04 ; +3d 40 00 10 ; e3d 40 00 14 ; f32 04 ; *01 04 ; +38 40 00 00 ; assign result to aa=(a+b) * (c+d)+e * f3d 40 00 00 ; a3d 40 00 04 ; b01 04 ; + 3d 40 00 08 ; c3d 40 00 0c ; d01 04 ; + 32 04 ; *3d 40 00 10 ; e3d 40 00 14 ; f32 04 ; *01 04 ; +38 40 00 00 ; assign result to aa=a+b+(c * d)+e3d 40 00 00 ; a3d 40 00 04 ; b01 04 ; +3d 40 00 08 ; c3d 40 00 0c ; d32 04 ; *01 04 ; +3d 40 00 10 ; e01 04 ; + 38 40 00 00 ; assign result to aa=a+b+(c* d *e)+f3d 40 00 00 ; a3d 40 00 04 ; b01 04 ; +3d 40 00 08 ; c3d 40 00 0c ; d32 04 ; *3d 40 00 10 ; e32 04 ; *01 04 ; +3d 40 00 14 ; f01 04 ; +38 40 00 00 ; assign result to aa=b-c3d 40 00 04 ; b3d 40 00 08 ; c55 04 ; -38 40 00 00 ; assign result to aa=b*c+d-e/f3d 40 00 04 ; b3d 40 00 08 ; c32 04 ; *3d 40 00 0c ; d01 04 ; +3d 40 00 10 ; e3d 40 00 14 ; f17 04 ; -55 04 ; /38 40 00 00 ; assign result to aboolean expressions512 < a3d 45 00 00 02 00 ; 5123d 40 00 00 ; variable a2b 04 ; <26 00 ; end of expression00 7e ; ?a>b and b128 or d>1024 or e>1283d 40 00 00 ; a3d 40 00 04 ; b22 04 ; >25 00 ; and00 cc ;3d 40 00 04 ; b3d 40 00 08 ; c2b 04 ; <25 00 ; and00 cc ;3d 40 00 08 ; c4b 80 ; 12822 04 ; >27 00 ; or 00 e8 ;3d 40 00 0c ; d 3d 45 00 00 04 00 ; 102422 04 ; >27 00 ; or 00 e8 ; 3d 40 00 10 ; e4b 80 ; 12822 04 ; >26 00 ; end of expression01 14 ; ?",
    "present_kp": [],
    "absent_kp": [
      "file format"
    ]
  },
  {
    "text": "performance of single-assignment adt oriented code on modern cpus. working in immutable data with single assignments has the obvious effect of requiring more memory, one would presume, because you're constantly creating new values (though compilers under the covers do pointer tricks to make this less of an issue).but i've heard a few times now that the losses there in performance are outweighed by the gains in the way that the cpu (its memory controller specifically) can take advantage of the fact that the memory is not mutated (as much).i was hoping someone could shed some light on how this is true (or if it's not?).in a comment on another post it was mentioned that abstract data types (adt's) have to do with this which made me further curious, how do adts specifically effect the way the cpu deals with memory? this is however an aside, mostly i'm just interested in how purity of language necessarily affects the performance of the cpu and its caches etc.",
    "present_kp": [
      "memory",
      "cpu"
    ],
    "absent_kp": [
      "functional programming",
      "hardware",
      "algebraic data type"
    ]
  },
  {
    "text": "finite differences for incompressible viscous fluid equations. i am working with the equations for incompressible viscous fluid:$$\\partial_t ec{\\omega} + (ec{u}\\cdot abla)ec{\\omega} = u abla^2ec{\\omega}$$$$ abla^2 ec{\\psi} = -ec{\\omega}$$$$ec{u}= abla imes ec{\\psi}$$with an usual notation:$\\omega$ ... vorticity$u$ ... velocity$ u$ ... kinematic viscosity$\\psi$ ... stream functioni need to discretize the system (by means of finite differences). since this is very common tasks, the schemes must be somewhere available, but i was not lucky in googling this time. could you please share a solution?",
    "present_kp": [
      "finite difference"
    ],
    "absent_kp": [
      "pde",
      "navier stokes"
    ]
  },
  {
    "text": "schema.org caption inside article?. ho to use schema.org in the caption of an image?i see that caption is not present in blogposting nor article. i made a search and it seems that it is in imageobject.but if i am inside itemscope article, can i use itemprop=caption? i mean, can i use the code example below?<div itemprop=caption>caption of the image</div>if not, how to use caption inside article or blogposting?<div itemscope itemtype=<url> itemprop=image src=1.png><div>caption of the image</div><h1 itemprop=headline name >title of the post</h1><div itemprop=datepublished content=2016-01-07 >2016-01-07</div><div itemprop=articlebody > <p>this is the body of the post</p></div></div><!-- end schema article -->",
    "present_kp": [
      "schema.org"
    ],
    "absent_kp": [
      "images",
      "microdata"
    ]
  },
  {
    "text": "being root without asking for the password in a shell script. i want to write a script which runs chrome as root without getting password from the users. users should not know the password,they also should not see the password,if they open the script (if the root password is needed to be written into script,we need to encrypt it)how can be possible that ? i checked out this one and it didn't work#!/usr/bin/expect -f right here i need to be rootchrome -p <url> & sleep 4",
    "present_kp": [
      "shell script"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "project euler problem 44: sums and differences of pentagonal numbers. this is my code for solving the pentagonal number problem on project euler:pentagonal numbers are generated by the formula, \\$p_n=n\\dfrac{3n1}{2}\\$. the first ten pentagonal numbers are: 1, 5, 12, 22, 35, 51, 70, 92, 117, 145, ... it can be seen that p4 + p7 = 22 + 70 = 92 = p8. however, their difference, 70 22 = 48, is not pentagonal. find the pair of pentagonal numbers, \\$p_j\\$ and \\$p_k\\$, for which their sum and difference are pentagonal and \\$d = |p_k p_j|\\$ is minimized; what is the value of \\$d\\$?as a beginner, i use the most basic concepts so often that sacrifices efficiency. if i could get some general tips on improving this code that would be awesome.key things i'd like to improve on:how to deal with double for loops when using elements from 2 lists:for x in a: for y in b:and if there are any functions built into python that i could use to instead of the bit of code written.lst = []dic = []test = []final = []for x in range(1, 3010): thing = int((x * (3*x - 1))/2) test.append(thing)test = set(test)for x in range(1, 3001): num = int((x * (3*x - 1))/2) lst.append(num)lst = set(lst)list2 = lstfor x in lst: for y in list2: num = x + y num2 = abs(x - y) dic.append({num: num2})dic = [dict(t) for t in set([tuple(d.items()) for d in dic])]for x in dic: for y in x: if y in test: final.append(x)for x in final: for y in x: if x[y] in test: print(x)",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "performance",
      "programming challenge"
    ]
  },
  {
    "text": "where does samba 4 store user passwords?. where does samba 4 store user passwords? how can i import my password hashes from samba 3 in samba 4?i am using my own ldap server with samba 3, and the password hash is stored within the userpassword attribute of the user entry (passdb backend: ldapsam). however samba 4 uses it own ldap server and shema, and it does not seem to work when i copy this attribute in the samba 4 user entry. how can i store samba 4 passwords within an ldap attribute?",
    "present_kp": [
      "samba",
      "password",
      "ldap"
    ],
    "absent_kp": [
      "login",
      "authentication"
    ]
  },
  {
    "text": "how do you return the k smallest elements of an array using mergesort?. i'd like to create a modified mergesort algorithm to return the k smallest elements of an array. the mergesort algorithm below sorts an unordered array of size n. how do i modify the algorithm so that it returns the k smallest elements of the array?a = [1...n]mergesort (a,p,r) //start with p = 1 and r = a.length if p < r q = floor((p + r)/2) mergesort (a,p,q) mergesort (a,q + 1,r) merge-sort (a,p,q,r)merge-sort (a,p,q,r) n1 = q - p + 1 n2 = r - q let l[1,2,..,n1+1] and r[1,2,..,n2+1] be new arrays for i = 1 to n1 l[i] = a[p + i - 1] for j = 1 to n2 r[j] = a[q + j] l[n1 + 1] = (an infinitely big number) r[n2 + 1] = (an infinitely big number) i = 1 j = 1 for m = p to r if l[i] <= r[j] a[m] = l[i] i = i + 1 else a[m] = r[j] j = j + 1",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "search algorithms",
      "sorting"
    ]
  },
  {
    "text": "html5 doctype & seo. i am trying to get my pages validated using markup validation service on w3c validator.we are getting validation against the xhtml 1.0 strict doctype comes back with the following error: [] there is no attribute data-gidbecause of the following code:<a href=# class=addtocartlink data-gid=202>add to inquiry list</a>we have been advised that we need to use the html5 doctype. we have changed to the above doctype on this page now however the point of this excercise was to make sure the site is clean to help with seo.i would like to use the html5 doctype with html5 markup. here is the question: is there any difference, from seo perspective, between valid html5 or xhtml 1.0 strict? should i try to stay on (valid) xhtml 1.0 strict doctype/markup or is it ok to move to valid html5 doctype/markup?",
    "present_kp": [
      "seo",
      "html5",
      "xhtml",
      "doctype"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the k-sat problem?. first of all i am of course aware of the wikipedia article: <url> i still do not understand exactly what the problem is. to demonstrate that i've tried, i think it is as follows but i am not sure:the problem of checking whether a given boolean equation with k distinct variables is satisfiable.for example, is this an instance of the 3-sat problem?x or y or z",
    "present_kp": [
      "sat"
    ],
    "absent_kp": []
  },
  {
    "text": "which affiliate offer non-standard 250x90 banner ad size?. do you know any affiliate that offers this non-standard banner ad size?",
    "present_kp": [
      "affiliate"
    ],
    "absent_kp": []
  },
  {
    "text": "counting binary, with moving position (turing machine). i'm trying to make a turing machine that will take in a binary string as input x and output the binary representation of the length of x. so m(0110) returns 100, m(<phone>) returns 1010, ect. it also has to have a runtime of o(n).so i can prove that the number of flips (changing a 0 to a 1 or a 1 to a 0) that occur when counting from 1 to n in base 2 approaches 2n as n goes to infinity. meaning it's o(n) in terms of runtime, but i'm not sure how to factor in the movement of the head of the tape that is writing the binary. near as i can tell, the head may have to move at most log(n) place to go from the 1s place to the last power of 2s place. for example, going from 11111 to 000001 requires moving from the 1s to the 64s place, or 6 places. it then has to move back to the ones to create the binary representation for 65. how is this operation as a not o(nlogn)?",
    "present_kp": [
      "counting"
    ],
    "absent_kp": [
      "turing machines"
    ]
  },
  {
    "text": "able to connect to wifi fine in debian w/gnome, but in interface no networks are shown. i'm currently writing this on debian, having connected to my wifi using commands from terminal.however, the networkmanager interface (top-right corner > wi-fi > select network) shows 'no networks'.how can i make it show my network?",
    "present_kp": [
      "debian",
      "wifi",
      "gnome"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "arduino driver for 7 segment display with bit-shift register. this code counts down from 30 to -999 on a 7-segment 4-digit display; it works but i don't know if it is a good way to do it or if it follows best practices. i want to start writing libraries for components that are not specifically made for arduino. this is my first attempt. please tell me if there are any problems with it or if there is some way for me to improve it. i am working on also making it able to show decimals but am not done yet.//this is code to put out any signed integer to a seven segment display using a bit shift register.int number[12] = {80,95,50,22,29,148,144,94,16,28,191,16}; //values 0 through 9 on a 7-segment led display, negative symbol is 10 and subtract 11 from any number to put a decimalint shiftpins[3] = {7,8,9}; // (clock pin, data pin, latch pin)int digitpins[4] = {2,3,4,6}; // (ones, tens, hundreds, thousands)int show[4]; // (thousands, hundreds, tens, ones)void setup(){ pinmode(digitpins[0], output); pinmode(digitpins[1], output); pinmode(digitpins[2], output); pinmode(digitpins[3], output); pinmode(shiftpins[0], output); pinmode(shiftpins[1], output); pinmode(shiftpins[2], output);}void loop(){ print2leds(30-millis()/1000);}void print2leds(int number2show){ if(number2show >= 0){ show[0] = ((int)number2show/1000); show[1] = ((int)number2show%1000)/100; show[3] = (((int)number2show%1000)%100)/10; show[2] = ((((int)number2show%1000)%100)%10); } else { number2show = -(number2show); show[0] = 10; show[1] = ((int)number2show%1000)/100; show[3] = (((int)number2show%1000)%100)/10; show[2] = ((((int)number2show%1000)%100)%10); } showdigit(show[0],digitpins[0]); showdigit(show[1],digitpins[1]); showdigit(show[2],digitpins[2]); showdigit(show[3],digitpins[3]);}void showdigit(int i, int f){ digitalwrite(shiftpins[2], 0); digitalwrite(f, 1); shiftout(shiftpins[1], shiftpins[0], lsbfirst, number[i]); digitalwrite(f, 0); digitalwrite(shiftpins[2], 1);}",
    "present_kp": [
      "c",
      "arduino"
    ],
    "absent_kp": []
  },
  {
    "text": "regular expression matching with string slice in go. i have a slice of strings, and within each string contains multiple key=value formatted messages. i want to pull all the keys out of the strings so i can collect them to use as the header for a csv file. i do not know all potential key fields, so i have to use regular expression matching to find them.here is my code.package mainimport ( fmt regexp)func getkeys(logs []string) []string { // topmatches is the final array to be returned. // midmatches contains no duplicates, but the data is 'key='. // submatches contains all initial matches. // initialregex matches for anthing that matches 'key='. this is because the matching patterns. // cleanregex massages 'key=' to 'key' topmatches := []string{} midmatches := []string{} submatches := []string{} initialregex := regexp.mustcompile('([a-za-z]{1,}\\=)') cleanregex := regexp.mustcompile('([a-za-z]{1,})') // the nested loop for matches is because findallstring // returns []string for _, i := range logs { matches := initialregex.findallstring(i, -1) for _, m := range matches { submatches = append(submatches, m) } } // remove duplicates. seen := map[string]string{} for _, x := range submatches { if _, ok := seen[x]; !ok { midmatches = append(midmatches, x) seen[x] = x } } // this is where i remove the '=' character. for _, y := range midmatches { clean := cleanregex.findallstring(y, 1) topmatches = append(topmatches, clean[0]) } return topmatches}func main() { y := []string{key=value, msg=payload, test=yay, msg=payload} y = getkeys(y) fmt.println(y)}i think my code is inefficient because i cannot determine how to properly optimise the initialregex regular expression to match just the key in the key=value format without matching the value as well.can my first regular expression, initialregex, be optimised so i do not have to do a second matching loop to remove the = character?playground: <url>",
    "present_kp": [
      "regex",
      "go"
    ],
    "absent_kp": [
      "parsing"
    ]
  },
  {
    "text": "extract highest day from time-stamp date within a filename. filename is structured as name$timestamp.extension where:timestamp='date +%y%m%d-%h%m%s'so, if there are following files in a directory:name161214-082211.gzname161202-082211.gzname161220-082211.gzname161203-082211.gzname161201-082211.gzwith the execution of the code/script from your answer, the value 20 should be stored in the variable highest_dayhighest_day = 20thank you for your kind answers in advance!",
    "present_kp": [
      "files"
    ],
    "absent_kp": [
      "bash",
      "shell",
      "sort",
      "timestamps"
    ]
  },
  {
    "text": "can tree be used to list the number of files per level?. as title, i need to look into a particular directory and list the number of files per level. the directory is pretty large, about 10-15 levels deep. for instance, if i have the following:d1||-- d2a (5 files in this directory)| |-- d3a (6 files in this directory)| |-- d3b (7 files in this directory)||-- d2b (1 file in this directory)then it should tell me that level 3 has 13 files and level 2 has 6 files (or 6+13, doesn't matter). can tree accomplish this? i've tried around mixing the options but it does not seem to work.",
    "present_kp": [
      "directory",
      "tree"
    ],
    "absent_kp": [
      "directory structure"
    ]
  },
  {
    "text": "no analog audio with amd e1 - hdmi takes over. i am having problems related to audio settings on my notebook with all distros, since i used ubuntu and xubuntu (14 and 16), kubuntu 16, ubuntu studio (14 and 15), elementary (0.32) and mint (17.3 cinnamon and mate), and all distros showed problems relating to analog audio, since only hdmi works after login (on systems with login sound, the sound works when i login, but a few moments after, analog sound no longer works.my notebook is an acer e1 421 with amd apu, and both analog output and hdmi output seems to use the same audio module, and hdmi, being the 0 card with alsa, only it works.my lspci audiolspci | grep audio00:01.1 audio device: advanced micro devices, inc. [amd/ati] wrestler hdmi audio00:14.2 audio device: advanced micro devices, inc. [amd] fch azalia controller (rev 01)my aplay -laplay -l**** list of playback hardware devices ****card 0: generic [hd-audio generic], device 3: hdmi 0 [hdmi 0]subdevices: 1/1subdevice #0: subdevice #0card 1: generic_1 [hd-audio generic], device 0: cx20584 analog [cx20584 analog]subdevices: 1/1subdevice #0: subdevice #0i even found some workarounds to fix the issue, but i had no luck, since the fix was temporary or things got worse, like removing pulseaudio and lose the volume icons at the task bar...so, is there a way to revert the devices ? it looks like the system is sending audio direct to card 0 (hdmi)so would it be possible to fix it so it can revert device order ?i even found a script to change the device order here (at stackexchange)sound not working when both the sound card and hdmi use the intel hda driver. how to exchange their device loading order?it would look like alias char-major-116 sndalias snd-card-0 snd-hda-intelalias snd-card-1 snd-hda-inteloptions snd cards_limit=2options snd-hda-intel id=sb index=0options snd-hda-intel id=hdmi index=1but i don't know how it would apply on my scenario, and even using a script to revert the order, analog audio does not work at allit shows on the sound config, but testing it show there is no audio, despite, the sound config showing audio activity, there is no sound on the speakers.if there is no way, is there a way to block only the hdmi output ? remember both outputs use the same module, so it's impossible to blacklist the module it self.i saw some people saying about recompiling the kernel with no hdmi support by changing the menu config.if it is possible could some one tell me what i can to do recompile and use a new kernel ? at least how to recompile on mint and elementary, since they are my prefered distros.tks",
    "present_kp": [
      "audio",
      "alsa"
    ],
    "absent_kp": []
  },
  {
    "text": "gathering response from a pagable service. i'm wondering how this code could be improved. i especially don't like the use of mutable buffer but not sure what the best way to get it out cleanly. def find(service: service): traversable[long] = { def loop(lastid: option[long]) (acc: mutable.buffer[long]) (quota: int): traversable[long] = { val response = service.call(lastid.getorelse(-1)) if (response.size() > 0 && quota > 0) { loop(response.last.getid)(acc ++ response)(quota - 1) } else { (acc ++ response).tolist } } loop(none)(mutable.buffer())(3) }",
    "present_kp": [],
    "absent_kp": [
      "scala"
    ]
  },
  {
    "text": "remove disqus hashtags from url. i'm new to disqus and have just added it to my blog site.however, i've noticed that upon disqus loading via javascript, it adds a hashtag to the pages url:why is this? is there a setting to opt-out of it?",
    "present_kp": [
      "disqus"
    ],
    "absent_kp": []
  },
  {
    "text": "how to find pull requests by you on bitbucket?. i can't figure out how to find pull requests made by me on bitbucket.",
    "present_kp": [
      "bitbucket"
    ],
    "absent_kp": []
  },
  {
    "text": "should my program be flawless at release. i'm building a big, very complex piece of open-source software, and it's killing me trying to make what i have as clean as it needs to be.what i want to know is: if there is an undetected flaw in my program and/or my code cleanliness (is that a word?), can that harm my reputation?likewise, is it bad that i've reused code from an already open-source app but have rewritten it my way?thanks.",
    "present_kp": [
      "app"
    ],
    "absent_kp": [
      "open source",
      "source code",
      "clean code"
    ]
  },
  {
    "text": "concurrently iterable poor array list. as i wrote on so, i need an arraylist-like structure allowing just the following operationsget(int index)add(e element)set(int index, e element)iterator()while supporting iterations concurrent with modifications. while i'm waiting for something better, i tried it myself. it was a bit harder than expected, so i used synchronization, which made it easy again. i'm linking to the full code and the test and showing here the relevant part (i.e., everything but the imports)./** * a data structure implementing a tiny subset of list operations and allowing concurrent access. * * see <url> for requirements. */public class concurrentiterable<e> implements iterable<e> { class myiterator extends unmodifiableiterator<e> { @override public boolean hasnext() { return index < size(); } @override public e next() { try { return get(index++); // safe as the array never shrinks. } catch (final indexoutofboundsexception e) { // this is hacky, but better than checking the size upfront, as the size may change. throw new nosuchelementexception(); } } private int index; } /** * the returned iterator may or may not see the changes made after its creation. * the only guarantee in case of concurrent modifications is is that * it sees no garbage provided that the items are immutable. */ @override public iterator<e> iterator() { return new myiterator(); } public synchronized int size() { return size; } @suppresswarnings(unchecked) public synchronized e get(int index) { checkelementindex(index, size); return (e) data[index]; } public synchronized void add(e element) { if (data.length == size) grow(); data[size++] = element; } public synchronized void set(int index, e element) { checkelementindex(index, size); data[index] = element; } private void grow() { data = arrays.copyof(data, newsize(data.length)); } private static int newsize(int oldsize) { int result = oldsize + (oldsize>>3) + 4; // grow by about 1/8 only. if (result-max_array_size > 0) result = max_array_size; // handle overflow. if (result<=oldsize) throw new outofmemoryerror(); return result; } private static final int max_array_size = integer.max_value - 8; // see arraylist. private int size; private object[] data = new object[4];}i'm aware that it's incompatible with the collection or list interfaces, but it's not meant to be general use class (though it may change). i need no additional constructors or other features.concerning spacing and single line conditional statements... yes, i know, i just don't care (my own conventions differ slightly).i'll probably try to re-implement this without synchronization as a challenge.",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "java",
      "concurrency"
    ]
  },
  {
    "text": "how to display only a process and its descendant processes on htop?. i want to monitor only a process and its children processes on htop. filtering on the name of the parent process lists only the parent process, not its children. how do i show the children processes too?",
    "present_kp": [
      "htop"
    ],
    "absent_kp": []
  },
  {
    "text": "make bash's tab completion fill in first match?. is there any way to make bash fill in the first match when i press tab, kind of like the windows command prompt?(it should still display the list of matches, but it should cycle through them when i keep on pressing tab.)i.e. the goal here is to be able to fill in any match with only the tab key, given enough presses -- like in windows.",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "autocomplete"
    ]
  },
  {
    "text": "how can i export calculated fields in cognito forms to excel?. i have a calculated field on my form, however it is not exported when i export to excel.how can i make the calculated fields be part of the export?",
    "present_kp": [
      "cognito forms"
    ],
    "absent_kp": []
  },
  {
    "text": "what's an expat xml parser?. i found the term here: <url> know what a xml parser is.i can't understand; what exactly is an expat xml parser?",
    "present_kp": [
      "xml"
    ],
    "absent_kp": [
      "html",
      "web"
    ]
  },
  {
    "text": "static backlinks vs rotating backlinks?. i'm creating a sort of widget for use on our partners' websites. this widget will contain several links to our site which will help greatly with our backlink building efforts. for the purposes of this question, let's assume that we have 10 different keywords that we'll be targeting.i have two options:generate the backlinks dynamically within the widget. every time the widget loads, one of the 10 keyword phrases is loaded randomly and displayed.generate dynamic backlinks when the widget embed code is created. every time a user accesses our embed code, one of the 10 keyword phrases is loaded randomly and inserted directly into the embed code. every time the widget loads on our partner's site, the same keyword phrase will be used. however, with many partners using the various keyword phrases, all keyword phrases will receive equal coverage. (i suppose this is similar behavior to a 'random posts' widget on a blog)is it better to have a backlink that doesn't change and is the same over a long period of time (option 1), or a backlink that changes slightly every time a page loads (option 2)? or, is there no difference in the long run?from an seo perspective, which approach do you feel is superior?",
    "present_kp": [
      "seo",
      "backlinks"
    ],
    "absent_kp": [
      "google"
    ]
  },
  {
    "text": "cfd for high-detailed turbulence and non-linear waves. what are typical (or promising) techniques and methods in cfd to achieve high-detailed turbulence and non-linear waves interaction? and with active geometry (when bodies interacts with fluid in both ways)?currently i've been recommended sph, but i am very unsure, that sph is smart choice for my task. especially considering my attempts to achieve nice parallel behaviour.also, it would be interesting to see some promising and good papers about some recommended techniques.update on motivation: the reason to write our own code is because there is no high-order discretization with low dissipation and dispersion in most comercial codes. also, software like ansys is known to be not very scalable.",
    "present_kp": [],
    "absent_kp": [
      "fluid dynamics"
    ]
  },
  {
    "text": "agile transformation and its affect on release management. can anyone give me some insight in what happens to traditional release management when an entire enterprise moves into agile?for example, lets say an enterprise operates in a waterfall method, does one big release a month and the systems are tightly integrated.lets say the enterprise moves to agile and the dev teams get restructured to operate in agile. now that the teams are operating on sprints and developing features each sprint, how does the release management team have to change to support the agile teams working in sprints now?",
    "present_kp": [
      "agile",
      "release management"
    ],
    "absent_kp": []
  },
  {
    "text": "a recent approach for subsurface scattering. i read a practical model for subsurface light transport and a rapid hierarchical rendering technique for translucent materials. if i understand correctly, the former does not consider the case when an object is lit behind and we can see the light is going through it.the latter can achieve this but there is a preprocessing stage which is not suitable for my cuda path tracer and i want it to be as natural as possible. so, do you have any paper in mind which is not obsolete or would you suggest me to solve the full radiative transfer equation?",
    "present_kp": [
      "subsurface scattering",
      "cuda"
    ],
    "absent_kp": [
      "raytracing",
      "pathtracing",
      "global illumination"
    ]
  },
  {
    "text": "large replace in xml. okay, so i have this xml file. i need to replace every key value with a value from another file (txt). both files are sorted so line 20 i.e inside the xml <word key=active group=service application value=testvalue1/>within my second file, on line 20 will betestvalue2i am looking for something which will change the value from testvalue1 to testvalue2",
    "present_kp": [
      "cat",
      "xml"
    ],
    "absent_kp": [
      "text processing",
      "scripting"
    ]
  },
  {
    "text": "sound and complete algorithms for boolean satifiability. to my best knowledge, these are the sound and complete algorithms for boolean satisfiabilityvariations of dpll algorithm (e.g. cdcl, look-ahead solvers)stalmarks methodbinary decision diagram (bdd)i am looking for other sound and complete algorithms for boolean satisfiability?",
    "present_kp": [
      "satisfiability"
    ],
    "absent_kp": [
      "3 sat",
      "sat solvers"
    ]
  },
  {
    "text": "why would there be a load of 5 if there are zero processes in the runq?. this doesn't make sense to me, why would there be a load of 5 if there are zero processes in the runq?12:00:01 am runq-sz plist-sz ldavg-1 ldavg-5 ldavg-1512:05:01 am 0 708 5.23 5.14 5.1012:15:01 am 0 708 5.16 5.12 5.0912:25:01 am 0 708 5.07 5.07 5.0812:35:01 am 0 708 5.12 5.08 5.0712:45:01 am 2 708 5.18 5.15 5.0912:55:01 am 1 708 5.05 5.12 5.0901:05:01 am 0 708 5.06 5.08 5.0801:15:01 am 0 708 5.14 5.11 5.09i know iowait is often the culprit for driving up the reported load, but there's very little disk activity,12:00:01 am dev tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util12:05:01 am dev8-0 1.53 0.00 30.61 20.01 0.00 0.34 0.21 0.0312:15:01 am dev8-0 1.32 0.00 25.77 19.51 0.00 0.34 0.10 0.0112:25:01 am dev8-0 1.60 0.00 40.81 25.43 0.00 0.64 0.29 0.0512:35:01 am dev8-0 1.64 0.00 35.76 21.80 0.00 0.73 0.22 0.0412:45:01 am dev8-0 1.33 0.00 25.95 19.51 0.00 0.23 0.12 0.02the box itself is running a django instance and handling about 5 hits/sec.",
    "present_kp": [
      "load"
    ],
    "absent_kp": [
      "kernel"
    ]
  },
  {
    "text": "circle intersection with sweep line algorithm. unfortunately i am still not so strong in understanding sweep line algorithm. all papers and textbooks on the topic are already read, however understanding is still far away. just in order to make it clearer i try to solve as many exercises as i can. but, really interesting and important tasks are still a challenge for me.the following exercise i found in lecture notes of line segment intersection by omnipotent jeff erickson.exercise 2. describe and analyze a sweepline algorithm to determine, given $n$ circles in the plane, whether any two intersect, in $o(n \\log n)$ time. each circle is specied by its center and its radius, so the input consists of three arrays $x[1.. n], y [1.. n]$, and $r[1.. n]$. be careful to correctly implement the low-level primitives.let's try to make a complex thing easier. what do we know about intersection of circles? what analogue can be found with intersection of lines. two lines might intersect if they adjacent, which property two circle should have in order to intersect? let $d$ be the distance between the center of the circles, $r_{0}$ and $r_{1}$ centers of the circles. consider few cases:case 1: if $d > r_{0} + r_{1}$ then there are no solutions, the circles are separate.case 2: if $d < |r_{0} - r_{1}|$ then there are no solutions because one circle is contained within the other.case 3: if $d = 0$ and $r_{0} = r_{1}$ then the circles are coincident and there are an infinite number of solutions.so, it looks like conditions of intersection are ready, of course it may be wrong conditions. please correct if it's so.algorithm. now we need to find something in common between two intersecting circles. with analogue to line intersection, we need to have insert condition and delete condition to event queue. let's say event point are x coordinate of the first and the last points which vertical sweep line touches. on the first point we insert circle to status and check for intersection (3 cases for checking are mentioned above) with nearest circles, on the last point we delete circle from status.it looks like is enough for sweep line algorithm. if there is something wrong, or may be there is something what should be done different, feel free to share your thoughts with us.addendum:i insert a circle when vertical sweep line touches the circle for the first time, and remove a circle from the status when sweep line touches it for the last time. the check for intersection should be done for the nearest previous circle. if we added a circle to status and there was already another circle which we added before and it was still there, therefore the pervious circle was not closed, so there might be an intersection.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "computational geometry"
    ]
  },
  {
    "text": "what is the bias called when listening to the same sound repeatedly?. when people are made to listen to the same sounds repeatedly, it can trigger placebo effects, i.e., they think they've heard something new or different the $ nth $ time around, when in fact they haven't.what is the name of this bias? and are there any research papers on it?i've stumbled across the 'focusing effect' but i don't think that's what i'm looking for",
    "present_kp": [
      "bias",
      "placebo"
    ],
    "absent_kp": [
      "perception",
      "terminology",
      "hearing"
    ]
  },
  {
    "text": "best practices for geolocation. we are writing a flight search engine. we want to pre-fill the departure airport for mobile users with the closest one to their location. to do that, our plan is tofind a list of airports with their latitude/longitude.find the user geolocation using something like html5 geolocation (which asks the user for permission).calculate the distance between the user's location and every airport to find the closest one.fill the departure form.is this a standard way of proceeding? i am a junior programmer and i am not used to this kind of problem. is there any obstacle i should bear in mind while developing my solution? i have the feeling the algorithm to calculate the distance between one point and 300 locations might get a bit heavy.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "optimization"
    ]
  },
  {
    "text": "program synthesis, decidability and the halting problem. i was reading an answer to a recent question, and sort of a strange, ephemeral thought came to mind. my asking this might betray either that my theory chops are seriously lacking (mostly true) or that it's just too early for me to read this site. now, with the disclaimer out of the way...it is a well-known result it computability theory that the halting problem cannot be decided for tms. however, this doesn't exclude the possibility that there exist machines that can solve the halting problem for certain classes of machines (just not all of them).consider the set of all decidable problems. for each problem, there exist infinitely many tms which decide that language. could the following be possible there is a tm that decides the halting problem for a subset $s$ of turing machines; andall decidable problems are decided by at least one turing machine in $s$?of course, finding the turing machine in $s$ may not be computable itself; but we ignore that problem.edit: based on shaull's answer below, it seems that either (a) this idea is too ill-specified to be meaningful or (b) my previous attempt wasn't quite on the mark. as i try to elaborate in the comments to shaull's answer, my intent isn't that we're guaranteed that the input tm is in $s$. what i really meant by my question is whether there could exist such an $s$, such that membership in $s$ is a decidable problem. the program to solve the halting problem for $s$ would, presumably, write invalid input on the tape or something when given an input that it recognizes as not being in $s$. when i formulate it like that, i'm not sure whether this allows us to solve the halting problem or not, or whether rice's theorem applies (is decidability a semantic property of a language w.r.t. rice's theorem?)",
    "present_kp": [
      "turing machines",
      "halting problem"
    ],
    "absent_kp": [
      "undecidability"
    ]
  },
  {
    "text": "how come the design process is so different for web design and gui design?. i had the opportunity to develop applications in several niches:server back-end, desktop clients, and recently a small scale website.once indulged in the website design i am asking myself and youhow come the ui design process is so different? can you point out the differences, and why they originated?once, html was for marking up text and desktop gui was the front-end for doing the real job,but today, why the gui development process is still so different?here are some for a start:desktop: use of explicit layout. (ex: stackpanel in wpf, borderlayout in swing)web: layout is a set of css properties (ex: height/width, margin/padding, float, display..) that are given to each container like element.desktop: isolation of gui components to oo classes, easy reuse.web: components are not reused in html level, they may be reused in dynamic server-side html generation. only css styles may be reused.can you name a few more? and why?why can't they be similar?side note: i have some experience with gwt, it creates a client application that runs in the browser, but why can't i make a webpage (like a blog page) with desktop ui design methods and tools?",
    "present_kp": [
      "web design",
      "ui",
      "gui design"
    ],
    "absent_kp": [
      "user interface",
      "user experience"
    ]
  },
  {
    "text": "quickly finding empty-string producing nonterminals in a cfg. for a given context free language g, we call a nonterminal $a_i$ nullable if $a_i ightarrow^* \\epsilon$, ie we can derive the empty string from $a_i$ after applying a finite number of productions.there is a simple algorithm for determining which nonterminals of a grammar are nullable as can be found here:we start by considering all nonterminals as not nullable. we mark all $a_i$ as nullable if there is a production $a_i ightarrow \\epsilon$. we then loop over all other productions $a_i ightarrow b_1 b_2 \\dots b_k$ excluding productions with a terminal in them, and mark $a_i$ as nullable if all $b_i$ are nullable. we keep doing this loop until we finish a loop without marking any nonterminals as nullable.my problem with this algorithm is that it has a $o(n^2)$ running time: a worst case is for instance $a_1 ightarrow a_2$, $a_2 ightarrow a_3$, $a_3 ightarrow a_4$, ..., $a_{n-1} ightarrow a_n$, $a_n ightarrow \\epsilon$.is there an algorithm for this problem with a better running time than $o(n^2)$?",
    "present_kp": [],
    "absent_kp": [
      "ds.algorithms",
      "fl.formal languages",
      "time complexity"
    ]
  },
  {
    "text": "how does facebook know when to show give a gift?. facebook seems to know when people post good news like about a new baby, graduation, or a new job. if you like or comment on the status, it shows surprise {so-and-so} with a gift. in one case i saw today, the only text for the status was well, it's done! with a picture of his cap & gown, but facebook still knew it was good news and showed the gift suggestion. so how does facebook know when a post is good news?as a follow-up, i noticed several of the comments said congrats or i'm proud of you or just yay! is the good news detector based on comments, or more than that? would it be pretty easy to spoof good news and get a false positive for the gift suggestions?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "mass storage device fails to mount. i bought a device that apparently is meant to be used as mass storage.when plugging it on my linux machine, it doesn't mount and i get those errors:[ <phone>] usb 2-5: new full-speed usb device number 10 using ohci-pci[ <phone>] usb 2-5: new usb device found, idvendor=1b3f, idproduct=30fe[ <phone>] usb 2-5: new usb device strings: mfr=1, product=2, serialnumber=0[ <phone>] usb 2-5: product: usbdevice[ <phone>] usb 2-5: manufacturer: generalplus [ <phone>] usb-storage 2-5:1.0: usb mass storage device detected[ <phone>] scsi host12: usb-storage 2-5:1.0[ <phone>] scsi 12:0:0:0: direct-access generalp lus sd device v2 .0.0 pq: 0 ansi: 2[ <phone>] sd 12:0:0:0: attached scsi generic sg9 type 0[ <phone>] sd 12:0:0:0: [sdi] 32768 512-byte logical blocks: (16.8 mb/16.0 mib)[ <phone>] sd 12:0:0:0: [sdi] write protect is off[ <phone>] sd 12:0:0:0: [sdi] mode sense: 03 00 00 00[ <phone>] sd 12:0:0:0: [sdi] no caching mode page found[ <phone>] sd 12:0:0:0: [sdi] assuming drive cache: write through[ <phone>] sdi:[ <phone>] sd 12:0:0:0: [sdi] attached scsi removable disk[ <phone>] sd 12:0:0:0: [sdi] tag#0 failed result: hostbyte=did_ok driverbyte=driver_sense[ <phone>] sd 12:0:0:0: [sdi] tag#0 sense key : not ready [current] [ <phone>] sd 12:0:0:0: [sdi] tag#0 add. sense: medium not present[ <phone>] sd 12:0:0:0: [sdi] tag#0 cdb: read(10) 28 00 00 00 7f 80 00 00 08 00[ <phone>] blk_update_request: i/o error, dev sdi, sector 32640[ <phone>] sd 12:0:0:0: [sdi] tag#0 failed result: hostbyte=did_ok driverbyte=driver_sense[ <phone>] sd 12:0:0:0: [sdi] tag#0 sense key : not ready [current] [ <phone>] sd 12:0:0:0: [sdi] tag#0 add. sense: medium not present[ <phone>] sd 12:0:0:0: [sdi] tag#0 cdb: read(10) 28 00 00 00 7f 80 00 00 08 00[ <phone>] blk_update_request: i/o error, dev sdi, sector 32640[ <phone>] buffer i/o error on dev sdi, logical block 4080, async page readi'm using a recent kernel:linux 4.5.0-0.bpo.1-amd64 #1 smp debian 4.5.1-1~bpo8+1 (2016-04-20) x86_64 gnu/linuxi have access to a windows laptop. on this machine, i can mount the device and load a file.from linux, using gnome-disk-utility, i see the device but formatting fails.on windows, i can format the device as fat with default options, but even then, it is still unreadable from my linux machine.the device is a wireless doorbell. the usb interface allows the user to load .mp3 files to use as custom ring melodies:[fr] <url>] <url> attempts on another computeri was suggested it may be a hardware compatibility issue, so i'm checking on other computers.kernel:linux 3.16.0-4-amd64 #1 smp debian 3.16.7-ckt25-2 (2016-04-08) x86_64 gnu/linuxlog:[ 211.284009] usb 1-3.4: new full-speed usb device number 5 using ehci-pci[ 211.395905] usb 1-3.4: new usb device found, idvendor=1b3f, idproduct=30fe[ 211.395908] usb 1-3.4: new usb device strings: mfr=1, product=2, serialnumber=0[ 211.395910] usb 1-3.4: product: usbdevice[ 211.395911] usb 1-3.4: manufacturer: generalplus [ 211.436522] usb-storage 1-3.4:1.0: usb mass storage device detected[ 211.436608] scsi10 : usb-storage 1-3.4:1.0[ 211.436697] usbcore: registered new interface driver usb-storage[ 212.439737] scsi 10:0:0:0: direct-access generalp lus sd device v2 .0.0 pq: 0 ansi: 2[ 212.440255] sd 10:0:0:0: attached scsi generic sg2 type 0[ 212.445342] sd 10:0:0:0: [sdb] 32768 512-byte logical blocks: (16.7 mb/16.0 mib)[ 212.448363] sd 10:0:0:0: [sdb] write protect is off[ 212.448367] sd 10:0:0:0: [sdb] mode sense: 03 00 00 00[ 212.451971] sd 10:0:0:0: [sdb] no caching mode page found[ 212.451976] sd 10:0:0:0: [sdb] assuming drive cache: write through[ 212.476600] sdb:[ 212.499568] sd 10:0:0:0: [sdb] attached scsi removable disk[ 212.508188] sd 10:0:0:0: [sdb] device not ready[ 212.508191] sd 10:0:0:0: [sdb] [ 212.508192] result: hostbyte=did_ok driverbyte=driver_sense[ 212.508194] sd 10:0:0:0: [sdb] [ 212.508195] sense key : not ready [current] [ 212.508198] info fld=0x0[ 212.508199] sd 10:0:0:0: [sdb] [ 212.508202] add. sense: medium not present[ 212.508204] sd 10:0:0:0: [sdb] cdb: [ 212.508205] read(10): 28 00 00 00 7f 80 00 00 08 00[ 212.508211] end_request: i/o error, dev sdb, sector 32640[ 212.508214] buffer i/o error on device sdb, logical block 4080[ 212.515687] sd 10:0:0:0: [sdb] device not ready[ 212.515689] sd 10:0:0:0: [sdb] [ 212.515691] result: hostbyte=did_ok driverbyte=driver_sense[ 212.515692] sd 10:0:0:0: [sdb] [ 212.515693] sense key : not ready [current] [ 212.515695] info fld=0x0[ 212.515697] sd 10:0:0:0: [sdb] [ 212.515699] add. sense: medium not present[ 212.515700] sd 10:0:0:0: [sdb] cdb: [ 212.515701] read(10): 28 00 00 00 7f 80 00 00 08 00[ 212.515706] end_request: i/o error, dev sdb, sector 32640[ 212.515708] buffer i/o error on device sdb, logical block 4080edit 2: attempts on yet another computer (old dell latitude)kernel:linux 3.2.0-4-686-pae #1 smp debian 3.2.54-2 i686 gnu/linuxlog:[ 352.816123] usb 1-1: new full-speed usb device number 2 using uhci_hcd[ 352.988140] usb 1-1: new usb device found, idvendor=1b3f, idproduct=30fe[ 352.988152] usb 1-1: new usb device strings: mfr=1, product=2, serialnumber=0[ 352.988160] usb 1-1: product: usbdevice[ 352.988166] usb 1-1: manufacturer: generalplus [ 353.129013] initializing usb mass storage driver...[ 353.130932] scsi2 : usb-storage 1-1:1.0[ 353.131211] usbcore: registered new interface driver usb-storage[ 353.131219] usb mass storage support registered.[ 354.133013] scsi 2:0:0:0: direct-access generalp lus sd device v2 .0.0 pq: 0 ansi: 2[ 354.138372] sd 2:0:0:0: attached scsi generic sg2 type 0[ 354.142948] sd 2:0:0:0: [sdb] 32768 512-byte logical blocks: (16.7 mb/16.0 mib)[ 354.147962] sd 2:0:0:0: [sdb] write protect is off[ 354.147975] sd 2:0:0:0: [sdb] mode sense: 03 00 00 00[ 354.151952] sd 2:0:0:0: [sdb] no caching mode page found[ 354.151966] sd 2:0:0:0: [sdb] assuming drive cache: write through[ 354.172966] sd 2:0:0:0: [sdb] no caching mode page found[ 354.172979] sd 2:0:0:0: [sdb] assuming drive cache: write through[ 354.180090] sdb:[ 354.207968] sd 2:0:0:0: [sdb] no caching mode page found[ 354.207982] sd 2:0:0:0: [sdb] assuming drive cache: write through[ 354.207992] sd 2:0:0:0: [sdb] attached scsi removable disk[ 354.214947] sd 2:0:0:0: [sdb] device not ready[ 354.214956] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.214966] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.214978] info fld=0x0[ 354.214983] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.214996] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f 80 00 00 08 00[ 354.215021] end_request: i/o error, dev sdb, sector 32640[ 354.215033] buffer i/o error on device sdb, logical block 4080[ 354.222946] sd 2:0:0:0: [sdb] device not ready[ 354.222956] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.222966] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.222977] info fld=0x0[ 354.222982] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.222995] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f 80 00 00 08 00[ 354.223019] end_request: i/o error, dev sdb, sector 32640[ 354.223031] buffer i/o error on device sdb, logical block 4080[ 354.229881] sd 2:0:0:0: [sdb] device not ready[ 354.229891] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.229901] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.229913] info fld=0x0[ 354.229918] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.229932] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f0 00 00 08 00[ 354.229955] end_request: i/o error, dev sdb, sector 32752[ 354.229966] buffer i/o error on device sdb, logical block 4094[ 354.237954] sd 2:0:0:0: [sdb] device not ready[ 354.237964] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.237975] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.237986] info fld=0x0[ 354.237991] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.238004] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f0 00 00 08 00[ 354.238027] end_request: i/o error, dev sdb, sector 32752[ 354.238039] buffer i/o error on device sdb, logical block 4094[ 354.259868] sd 2:0:0:0: [sdb] device not ready[ 354.259878] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.259888] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.259899] info fld=0x0[ 354.259905] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.259918] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.259941] end_request: i/o error, dev sdb, sector 32760[ 354.259952] buffer i/o error on device sdb, logical block 4095[ 354.267948] sd 2:0:0:0: [sdb] device not ready[ 354.267960] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.267970] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.267981] info fld=0x0[ 354.267987] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.268000] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.268057] end_request: i/o error, dev sdb, sector 32760[ 354.268068] buffer i/o error on device sdb, logical block 4095[ 354.276948] sd 2:0:0:0: [sdb] device not ready[ 354.276958] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.276968] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.276981] info fld=0x0[ 354.276986] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.277001] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.277025] end_request: i/o error, dev sdb, sector 32760[ 354.277036] buffer i/o error on device sdb, logical block 4095[ 354.283870] sd 2:0:0:0: [sdb] device not ready[ 354.283880] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.283890] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.283902] info fld=0x0[ 354.283907] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.283921] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.283944] end_request: i/o error, dev sdb, sector 32760[ 354.283955] buffer i/o error on device sdb, logical block 4095[ 354.291935] sd 2:0:0:0: [sdb] device not ready[ 354.291946] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.291955] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.291967] info fld=0x0[ 354.291972] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.291985] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.292040] end_request: i/o error, dev sdb, sector 32760[ 354.292052] buffer i/o error on device sdb, logical block 4095[ 354.298935] sd 2:0:0:0: [sdb] device not ready[ 354.298945] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.298955] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.298967] info fld=0x0[ 354.298972] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.298985] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.299008] end_request: i/o error, dev sdb, sector 32760[ 354.299018] buffer i/o error on device sdb, logical block 4095[ 354.305937] sd 2:0:0:0: [sdb] device not ready[ 354.305947] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.305956] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.305968] info fld=0x0[ 354.305973] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.305986] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.306009] end_request: i/o error, dev sdb, sector 32760[ 354.313934] sd 2:0:0:0: [sdb] device not ready[ 354.313943] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.313953] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.313964] info fld=0x0[ 354.313969] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.313982] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f c0 00 00 08 00[ 354.314005] end_request: i/o error, dev sdb, sector 32704[ 354.320935] sd 2:0:0:0: [sdb] device not ready[ 354.320945] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.320954] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.320966] info fld=0x0[ 354.320971] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.320984] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f0 00 00 08 00[ 354.321007] end_request: i/o error, dev sdb, sector 32752[ 354.328938] sd 2:0:0:0: [sdb] device not ready[ 354.328948] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.328958] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.328969] info fld=0x0[ 354.328974] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.328988] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.329011] end_request: i/o error, dev sdb, sector 32760[ 354.335860] sd 2:0:0:0: [sdb] device not ready[ 354.335870] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.335880] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.335892] info fld=0x0[ 354.335897] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.335910] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.335934] end_request: i/o error, dev sdb, sector 32760[ 354.343928] sd 2:0:0:0: [sdb] device not ready[ 354.343938] sd 2:0:0:0: [sdb] result: hostbyte=did_ok driverbyte=driver_sense[ 354.343948] sd 2:0:0:0: [sdb] sense key : not ready [current] [ 354.343959] info fld=0x0[ 354.343965] sd 2:0:0:0: [sdb] add. sense: medium not present[ 354.343978] sd 2:0:0:0: [sdb] cdb: read(10): 28 00 00 00 7f f8 00 00 01 00[ 354.344001] end_request: i/o error, dev sdb, sector 32760lspci:00:00.0 host bridge: intel corporation 82845 845 [brookdale] chipset host bridge (rev 04)00:01.0 pci bridge: intel corporation 82845 845 [brookdale] chipset agp bridge (rev 04)00:1d.0 usb controller: intel corporation 82801ca/cam usb controller #1 (rev 02)00:1e.0 pci bridge: intel corporation 82801 mobile pci bridge (rev 42)00:1f.0 isa bridge: intel corporation 82801cam isa bridge (lpc) (rev 02)00:1f.1 ide interface: intel corporation 82801cam ide u100 controller (rev 02)00:1f.5 multimedia audio controller: intel corporation 82801ca/cam ac'97 audio controller (rev 02)00:1f.6 modem: intel corporation 82801ca/cam ac'97 modem controller (rev 02)01:00.0 vga compatible controller: advanced micro devices [amd] nee ati rv200 [mobility radeon 7500]02:00.0 ethernet controller: 3com corporation 3c905c-tx/tx-m [tornado] (rev 78)02:01.0 cardbus bridge: texas instruments pci1420 pc card cardbus controller02:01.1 cardbus bridge: texas instruments pci1420 pc card cardbus controller",
    "present_kp": [],
    "absent_kp": [
      "usb drive",
      "removable storage"
    ]
  },
  {
    "text": "free software to run questionnaire based experiments. i am looking for free software to build experiments that do not heavily rely on accurate timing (where i use psychopy and heard a lot of good things about opensesame) but more on an easy way to implement different types of items and response options.that is, for example, an experiment which starts in presenting some texts to the participants, then some questions contingent on this text and on what participants entered before (potentially more than one question per page with different response options) followed by some standard questionnaires. how would you implement such a study?background and motivationi used to do such things using medialab which unfortunately is proprietary software. however, implementing items and questionnaires was easy. you could program a simple html page (even using variables and placeholders) using html forms and medialab would present this page using ie engine in fullscreen and collect the responses. those responses could then be used or handed over to directrt for response time experiments.currently i am using psychopy to control the screen and data collection and code all questionnaires and such stuff per hand using wxpython. it works, but designing questionnairs in wxpython is a lot less handy and more difficult than programming html pages with html forms and definitely nothing for people not too profficient in coding. any ideas or hints would be really appreciated.note that i read what's the best program for creating computer based psychology experiments under os x?, but my question concerns specific implementations. furthermore, i work on windows 7.",
    "present_kp": [
      "software"
    ],
    "absent_kp": [
      "methodology",
      "experimental psychology"
    ]
  },
  {
    "text": "root password is asked for anything after dist-upgrade. i'm using debian stretch and today i did apt-get upgrade && apt-get dist-upgrade. after that, nearly every action is started to ask root password, including external monitor plug/unplug, usb harddisk mount, suspend, etc...why is that? how can i trace this issue?",
    "present_kp": [
      "debian",
      "upgrade"
    ],
    "absent_kp": [
      "authorization"
    ]
  },
  {
    "text": "does tdd make defensive programming redundant?. today i had an interesting discussion with a colleague.i am a defensive programmer. i believe that the rule a class must ensure that its objects have a valid state when interacted with from outside the class must always be adhered to. the reason for this rule is that the class does not know who its users are and that it should predictably fail when it is interacted with in an illegal manner. in my opinion that rule applies to all classes.in the specific situation where i had a discussion today, i wrote code which validates that the arguments to my constructor are correct (e.g. an integer parameter must be > 0) and if the precondition is not met, then an exception gets thrown. my colleague on the other hand believes that such a check is redundant, because unit tests should catch any incorrect uses of the class. additionally he believes that defensive programming validations should also be unit tested, so defensive programming adds much work and is therefore not optimal for tdd.is it true that tdd is able to replace defensive programming? is parameter validation (and i don't mean user input) unnecessary as a consequence? or do the two techniques complement each other?",
    "present_kp": [
      "tdd",
      "defensive programming"
    ],
    "absent_kp": []
  },
  {
    "text": "what happened to +1?. in the last week the google chrome extension for +1-ing a webpage was changed, and the +1 functionality was removed. now users can only post to google+, but cannot give an anonymous +1. many users are unhappy (including me):my google+ profile now contains only posts, no +1's. i am afraid that google is getting rid of the +1 system altogether, which is a big loss for me. i love being able to give helpful/cool pages a +1, and seeing the +1 count for helpful/popular pages. i don't want to post every single page i find useful, as that would completely flood my google+ profile.google's developer documentation still refers to a +1 button, but the button does not appear to store +1 counts.the strange thing about this is that i am unable to find any sort of announcement or explanation for this radical change in behavior. can anyone point me to an official announcement or explanation regarding this change of behavior? i would also like to know if i will be able to retrieve my +1 data, which goes back several years.",
    "present_kp": [
      "google"
    ],
    "absent_kp": [
      "google plus"
    ]
  },
  {
    "text": "vim not loading color scheme file at all. i have exactly same two centos 6 boxes. trying to install vim and enable color scheme file.same thing, same vim versions used but the color scheme works in one machine and not in other.here are info:# vim --versionvim - vi improved 7.4 (2013 aug 10, compiled jul 24 2015 02:23:23)...... +syntax# cat ~/.vimrcfiletype plugin indent onsyntax oncolor termschool# ll ~/.vim/colors/termschool.vimeverything are exactly same on both server. but the color scheme file is working on one but not on another one.here is what's happening:when i edit a file using vim, it always falls into default scheme. (so it shows default colors)when i remove the color scheme file ~/.vim/colors/termschools.vim, then the vim shows error message. (so, that means vim still looks for the color scheme file, which is correct manner)but when i put the file back again, nothing happens but the default color are loaded again.i'm very confused now. any advice please?",
    "present_kp": [
      "centos",
      "vim",
      "colors"
    ],
    "absent_kp": []
  },
  {
    "text": "how to prevent end-date shift when changing start-date in google calendar?. any time i change the starting date of an event for example by extending it with an extra day (e.g. from 5th of july to 4th of july) the ending date gets shifted accordingly (e.g. 10th of july to 9th of july), assuming that the event itself has a fixed lenght instead of assuming that the timespan changes. the same happens with ending date changes.i think it is reasonable to have this behaviour for time changes of events, assuming that a standard meeting is 2 hours for google, but the same does not hold for multiple-day-events for me. is there any way to change the behaviour for such events?",
    "present_kp": [
      "google calendar"
    ],
    "absent_kp": []
  },
  {
    "text": "adding vector functionality to ti calculators. although ti-83/84 calculators support multiple data types, such as real numbers, complex numbers, 1d and 2d lists, fuctions, etc., there is no data type for vectors. this program is my attempt to take the sequence three sequence functions (u v w), which are rarely used for their intended function, and transform them into two-dimensional vectors that can be expressed in terms of i and j.in addition to adding vectors in terms of i and j, which can be operated on by most functions (including + - * / ^ and many more), functions have been added to determine (1) the angle between vectors, (2) the dot product of two vectors, and (3) the magnitude of a vector. the use of angle( has been altered to return the angle between to vectors, e.g. by angle(u,v. also, * is now dot product (so uv is still implicit multiplication, but u*v is dot product). finally, to get the magnitude of a vector, instead of absolute value notation ||u||, which only works with mathprint, you should use brackets, for example, [u].prgmvectorsclrhome1->iwhile 1 {e->k input ,str3 i+str3iansk prgmq ans->str3 ?->str4 if 2<length(str3 sub(str3,2,2->str4 str3+ji prgmq if instring(u=v=w=,str4 i+sub(ans,4,length(ans)-3 if str4=u= ans->u if str4=v= ans->v if str4=w= ans->w ans+angle(cos(cos(abs(list(angle({ prgmr if i[=sub(ans,1,2) and ]i=sub(ans,length(ans)-1,2 then expr(sub(ans,3,length(ans)-4 real(sqrt(ansconj(ans prgms end if instring(ans,* then ans+*, prgmr expr({+ans prod(real(ans))+prod(imag(ans prgms end expr(ans->k if elk(1 ans(1->k imag(ans if ans then prgms ans->str4 real(k prgms ans+i++str4+j if 0i=sub(ans,1,2 sub(ans,4,length(ans)-3 ans++~- prgmr disp sub( ,1,16-length(ans))+ans else disp k endend-> represents the arrow (0x04), represents 0x81, ~ represents negation (0xb0), and l represents the list token (0xeb).also, prgmvectors calls on three subprograms. prgms converts a real number to a string, prgmr replaces the first instance of one string with another, and prgmq replace all instances of one string with another. they are shown below:prgmqansstr9instring(ans,~sub(str9,ans,length(str9)-ans+1str8str9prgmrrepeat str9=ans+str8ans+str8str9prgmrendprgmransstr0instring(ans,~zinstring(str0,~,ans+1yinstring(sub(str0,1,z-1),sub(str0,z+1,ans-z-1xsub(str0,1,-1+instring(str0,~if xsub(str0,1,x-1)+sub(str0,y+1,length(str0)-y)+sub(str0,x+length(sub(str0,z+1,y-z-1)),z-x-length(sub(str0,z+1,y-z-1prgms{0,ans->l2{0,1->l1linreg(ax+b) r6equ>string(r6,str1sub(str1,1,length(str1)-3",
    "present_kp": [],
    "absent_kp": [
      "coordinate system",
      "ti basic"
    ]
  },
  {
    "text": "creating image thumbnails and serving from own server. i would like to display some images on my website. this website got indexed content from different websites. it display content in a way that you have image, short description and link to website where this image and description come from.my question is, can i create thumbnails from pictures which are crawled and show it from my server or should i refer to image from external server or is it illegal?",
    "present_kp": [
      "legal"
    ],
    "absent_kp": []
  },
  {
    "text": "smallest possible universal combinator. i am looking for the smallest possible universal combinator, measured by the number of abstractions and applications required to specify such a combinator in the lambda calculus. examples of universal combinators include:size 23: f.f(fs(kkki))ksize 18: f.f(fs(kk))ksize 14: f.fksksize 12: f.fs(xyz.x)size 11: f.fskwhere s = xyz.xz(yz) of size 6 and k = xy.x of size 2 are the combinators of the sk combinator calculus. the first 4 examples are described in this paper.my questions are:are there any universal combinators that are smaller in size?what is the smallest possible universal combinator?edit: see also <url> which has azbc.bc(a(y.c)).",
    "present_kp": [
      "lambda calculus"
    ],
    "absent_kp": [
      "lo.logic",
      "computability",
      "universal computation",
      "combinatory logic"
    ]
  },
  {
    "text": "basic slot machine game. i have been learning php and wanted to see if i could make a very simple slot machine game. everything works, but i'm sure this is not the best way to do this. please let me know how you would do this and what i can do to improve.<?php$num1 = rand(1, 5);$num2 = rand(1, 5);$num3 = rand(1, 5);$result = $num1.' | '.$num2.' | '.$num3;// read points from file$filename = 'points.txt';$handle = fopen($filename, 'r');$current = fread($handle, filesize($filename));fclose($handle);if ($num1 == $num2 && $num2 == $num3) {$status = '<big>you are a winner!</big>';$add_points = $current + 10;// add points to file$handle = fopen($filename, 'w');$current_points = fwrite($handle, $add_points);fclose($handle);} else {$status = 'please try again!';}?><html><head><title>slot machine game!</title></head><body><center><big><?php echo $result; ?></big></center><br /><br /><center><big><?php echo $status; ?></big></center><br /><br /><center><big><?php echo 'you have <strong>'.$current.'</strong> points!'; ?></big></center></body></html>",
    "present_kp": [
      "php",
      "game"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "sed to match pattern between matching curly braces. from a pattern such as[string 1]{string 2}i want to extract string 2, the string between the last pair of matching curly braces -- that is delete [string 1] and the open { and close }. my attempt below breaks when there is a additional [, ] pairs in either string 1 or string 2.desired output:the desired output from the script below begins with foo and ends with a digit:foo bar 1foo bar 2foo[3]{xyz} bar 3foo $sq[3]{xyz}$ bar 4foo $sq[3]{xyz}$ bar 5foo $sq[3]{xyz}$ bar 6foo $sq[3]{xyz}$ bar 7foo $sq[3]{xyz}$ bar 8'foo $sq[abc]{xyz}$ bar 9'foo $sq[abc]{xyz}$ bar 10'assumptions:parameter to removeinitialsquarebraces always begins with a [ and ends with a }.the opening [ for string 1 will have a matching ] at the point where the opening { begins for string 2.platform:macos 10.9.5script#!/bin/bashfunction removeinitialsquarebraces { #extracted_text=$(\\ # echo $1 \\ # | sed 's/^\\[.*\\]//' \\ # | sed 's/{//' \\ # | sed 's/}$//' \\ # ) extracted_text=$(\\ echo $1 \\ | sed 's/.*[^0-9]\\]{\\(.*\\)}//' \\ ) echo ${extracted_text}}removeinitialsquarebraces '[]{foo bar 1}'removeinitialsquarebraces '[abc]{foo bar 2}'removeinitialsquarebraces '[]{foo[3]{xyz} bar 3}'removeinitialsquarebraces '[]{foo $sq[3]{xyz}$ bar 4}'removeinitialsquarebraces '[goo{w}]{foo $sq[3]{xyz}$ bar 5}'removeinitialsquarebraces '[goo[3]{w}]{foo $sq[3]{xyz}$ bar 6}'removeinitialsquarebraces '[goo[3]{w} hoo[3]{5}]{foo $sq[3]{xyz}$ bar 7}'removeinitialsquarebraces '[goo[3]{w} hoo[3]{5}]{foo $sq[3]{xyz}$ bar 8}'removeinitialsquarebraces '[goo[3]{w} hoo[xyz]{5}]{foo $sq[abc]{xyz}$ bar 9}'removeinitialsquarebraces '[goo[3]{w} hoo[xyz]{uvw}]{foo $sq[abc]{xyz}$ bar 10}'exit 0",
    "present_kp": [
      "sed"
    ],
    "absent_kp": [
      "osx",
      "regular expression",
      "escape characters"
    ]
  },
  {
    "text": "winscp idisposable wrapper. i have written a simple wrapper for winscp in c#. i have written it to simplify sftp connections i will needing to perform. public class winscpconn : idisposable{ //private fields private sessionoptions sessionoptions; private transferoptions transferoptions; private session session; //public properties public bool issessionopen { get { return session.opened; } } public winscpconn(string hostname, string username, string password) { sessionoptions = new sessionoptions(); sessionoptions.protocol = protocol.sftp; sessionoptions.hostname = hostname; sessionoptions.portnumber = 22; sessionoptions.password = password; sessionoptions.username = username; sessionoptions.timeout = new timespan(0, 3, 0); sessionoptions.giveupsecurityandacceptanysshhostkey = true; transferoptions = new transferoptions(); transferoptions.transfermode = transfermode.binary; try { session = new session(); session.executablepath = properties.settings.default.winscppath; } catch (sessionlocalexception) { throw; } } public void open() { try { if (session.opened == false) { session.open(sessionoptions); } } catch (sessionremoteexception) { throw; } } public transferoperationresult sendfile(string sourcefile, string destfile) { transferoperationresult result; try { result = session.putfiles(sourcefile, destfile, false, transferoptions); return result; } catch (sessionremoteexception) { throw; } } public void createdirectory(string folderpath) { try { if (!session.fileexists(folderpath)) { session.createdirectory(folderpath); } } catch (sessionremoteexception) { throw; } } public void close() { if (session.opened == true) { session.dispose(); } } public void dispose() { close(); } }it would be used as follows: using (winscpconn conn = new winscpconn(host, username, password)) { conn.open(); conn.createdirectory(/path/); conn.sendfile(@c: ile.txt,/path/file.txt); }my questions are as follows:how is my exception handling?is there too much going on in the constructor?",
    "present_kp": [
      "c#",
      "wrapper"
    ],
    "absent_kp": [
      ".net"
    ]
  },
  {
    "text": "how to get vimchat to work in linux. i added bundle 'throughnothing/vimchat'to my ~/.vimrc file and ran :plugininstall. that all ran fine, then i added an account and password to the ~/.vim/bundle/vimchat/config file like this:user@domain = passwordwhen i run vim and type :vimchat (after restarting) i get this message:e492: not an editor command: vimchatclearly the installation somehow failed, but i'm a bit at a loss on how to diagnose this. the installation seemed to go fine!i'm using vim 7.4",
    "present_kp": [
      "vim"
    ],
    "absent_kp": []
  },
  {
    "text": "ssh timeout to everywhere after a fresh rhel7 install. [user@desktop ~]$ ssh root@foobar...$ sudo su -[you have new mail]root@foobar:/home/root # cd /etc root@foobar:/etc # connection to 1.2.3.4 closed by remote host.connection to 1.2.3.4 closed.[user@desktop ~]$ after installing rhel7 to my desktop (it was rhel6 before and it worked perfectly). question: no matter where i ssh, it will always say, connection closed by remote host. a few seconds after login.. why?? before fresh install it worked perfectly. update: 1) what happens if you run telnet yourhost 22. -> i did and telnet didn't closed the connection!update#2: [user@desktop applications]$ ssh -vvv useronserver@servernameopenssh_6.6.1, openssl 1.0.1e-fips 11 feb 2013debug1: reading configuration data /home/user/.ssh/configdebug1: /home/user/.ssh/config line 1: applying options for dee1*debug1: /home/user/.ssh/config line 7: applying options for dee1*debug1: /home/user/.ssh/config line 18: applying options for *debug1: reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 56: applying options for *debug1: /etc/ssh/ssh_config line 67: applying options for *debug2: ssh_connect: needpriv 0debug1: connecting to servername [1.2.3.4] port 22.debug1: connection established.debug3: incorrect rsa1 identifierdebug3: could not load /home/user/.ssh/id_rsa as a rsa1 public keydebug1: identity file /home/user/.ssh/id_rsa type 1debug1: identity file /home/user/.ssh/id_rsa-cert type -1debug1: identity file /home/user/.ssh/id_dsa type -1debug1: identity file /home/user/.ssh/id_dsa-cert type -1debug1: identity file /home/user/.ssh/id_ecdsa type -1debug1: identity file /home/user/.ssh/id_ecdsa-cert type -1debug1: identity file /home/user/.ssh/id_ed25519 type -1debug1: identity file /home/user/.ssh/id_ed25519-cert type -1debug1: enabling compatibility mode for protocol 2.0debug1: local version string ssh-2.0-openssh_6.6.1debug1: remote protocol version 1.99, remote software version openssh_6.0debug1: match: openssh_6.0 pat openssh* compat 0x04000000debug2: fd 3 setting o_nonblockdebug3: load_hostkeys: loading entries for host servername from file /home/user/.ssh/known_hostsdebug3: load_hostkeys: found key type rsa in file /home/user/.ssh/known_hosts:822debug3: load_hostkeys: loaded 1 keysdebug3: order_hostkeyalgs: prefer hostkeyalgs: <email>,<email>,ssh-rsadebug1: ssh2_msg_kexinit sentdebug1: ssh2_msg_kexinit receiveddebug2: kex_parse_kexinit: <email>,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1debug2: kex_parse_kexinit: <email>,<email>,ssh-rsa,<email>,<email>,<email>,<email>,<email>,<email>,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,ssh-dssdebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,<email>,<email>,<email>,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,<email> kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,<email>,<email>,<email>,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,<email> kex_parse_kexinit: <email>,<email>,<email>,<email>,<email>,<email>,<email>,<email>,<email>,hmac-md5,hmac-sha1,<email>,<email>,hmac-sha2-256,hmac-sha2-512,hmac-ripemd160,<email>,hmac-sha1-96,hmac-md5-96debug2: kex_parse_kexinit: <email>,<email>,<email>,<email>,<email>,<email>,<email>,<email>,<email>,hmac-md5,hmac-sha1,<email>,<email>,hmac-sha2-256,hmac-sha2-512,hmac-ripemd160,<email>,hmac-sha1-96,hmac-md5-96debug2: kex_parse_kexinit: none,<email>,zlibdebug2: kex_parse_kexinit: none,<email>,zlibdebug2: kex_parse_kexinit: debug2: kex_parse_kexinit: debug2: kex_parse_kexinit: first_kex_follows 0 debug2: kex_parse_kexinit: reserved 0 debug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1debug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256debug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,<email> kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,<email> kex_parse_kexinit: hmac-md5,hmac-sha1,<email>,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,<email>,hmac-sha1-96,hmac-md5-96debug2: kex_parse_kexinit: hmac-md5,hmac-sha1,<email>,hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,<email>,hmac-sha1-96,hmac-md5-96debug2: kex_parse_kexinit: none,<email> kex_parse_kexinit: none,<email> kex_parse_kexinit: debug2: kex_parse_kexinit: debug2: kex_parse_kexinit: first_kex_follows 0 debug2: kex_parse_kexinit: reserved 0 debug2: mac_setup: setup hmac-md5debug1: kex: server->client aes128-ctr hmac-md5 nonedebug2: mac_setup: setup hmac-md5debug1: kex: client->server aes128-ctr hmac-md5 nonedebug1: kex: ecdh-sha2-nistp256 need=16 dh_need=16debug1: kex: ecdh-sha2-nistp256 need=16 dh_need=16debug1: sending ssh2_msg_kex_ecdh_initdebug1: expecting ssh2_msg_kex_ecdh_replydebug1: server host key: rsa censoreddebug3: load_hostkeys: loading entries for host servername from file /home/user/.ssh/known_hostsdebug3: load_hostkeys: found key type rsa in file /home/user/.ssh/known_hosts:822debug3: load_hostkeys: loaded 1 keysdebug3: load_hostkeys: loading entries for host 1.2.3.4 from file /home/user/.ssh/known_hostsdebug3: load_hostkeys: found key type rsa in file /home/user/.ssh/known_hosts:801debug3: load_hostkeys: loaded 1 keysdebug1: host 'servername' is known and matches the rsa host key.debug1: found key in /home/user/.ssh/known_hosts:822debug1: ssh_rsa_verify: signature correctdebug2: kex_derive_keysdebug2: set_newkeys: mode 1debug1: ssh2_msg_newkeys sentdebug1: expecting ssh2_msg_newkeysdebug2: set_newkeys: mode 0debug1: ssh2_msg_newkeys receiveddebug1: ssh2_msg_service_request sentdebug2: service_accept: ssh-userauthdebug1: ssh2_msg_service_accept receiveddebug2: key: /home/user/.ssh/id_rsa (0x7fe5faa58140),debug2: key: created by sasgui (0x7fe5faa589f0),debug2: key: id_rsa (0x7fe5faa59040),debug2: key: /home/user/.ssh/id_dsa ((nil)),debug2: key: /home/user/.ssh/id_ecdsa ((nil)),debug2: key: /home/user/.ssh/id_ed25519 ((nil)),debug1: authentications that can continue: publickey,password,keyboard-interactivedebug3: start over, passed a different list publickey,password,keyboard-interactivedebug3: preferred gssapi-keyex,gssapi-with-mic,publickey,keyboard-interactive,passworddebug3: authmethod_lookup publickeydebug3: remaining preferred: keyboard-interactive,passworddebug3: authmethod_is_enabled publickeydebug1: next authentication method: publickeydebug1: offering rsa public key: /home/user/.ssh/id_rsadebug3: send_pubkey_testdebug2: we sent a publickey packet, wait for replydebug1: server accepts key: pkalg ssh-rsa blen 148debug2: input_userauth_pk_ok: fp censoreddebug3: sign_and_send_pubkey: rsa censoreddebug1: authentication succeeded (publickey).authenticated to servername ([1.2.3.4]:22).debug1: channel 0: new [client-session]debug3: ssh_session2_open: channel_new: 0debug2: channel 0: send opendebug1: requesting <email> entering interactive session.debug1: remote: forced command.debug1: remote: forced command.debug2: callback startdebug1: requesting authentication agent forwarding.debug2: channel 0: request <email> confirm 0debug2: fd 3 setting tcp_nodelaydebug3: packet_set_tos: set ip_tos 0x10debug2: client_session2_setup: id 0debug2: channel 0: request pty-req confirm 1debug1: sending environment.debug3: ignored env xdg_vtnrdebug3: ignored env ssh_agent_piddebug3: ignored env xdg_session_iddebug3: ignored env guestfish_initdebug3: ignored env hostnamedebug3: ignored env imsettings_integrate_desktopdebug3: ignored env gpg_agent_infodebug3: ignored env vte_versiondebug3: ignored env termdebug3: ignored env shelldebug3: ignored env xdg_menu_prefixdebug3: ignored env histsizedebug3: ignored env gjs_debug_outputdebug3: ignored env windowiddebug3: ignored env qtdirdebug3: ignored env qtincdebug3: ignored env gjs_debug_topicsdebug3: ignored env imsettings_moduledebug3: ignored env qt_graphicssystem_checkeddebug3: ignored env userdebug3: ignored env ls_colorsdebug3: ignored env ssh_auth_sockdebug3: ignored env session_managerdebug3: ignored env usernamedebug3: ignored env gnome_disable_crash_dialogdebug3: ignored env guestfish_ps1debug3: ignored env pathdebug3: ignored env maildebug3: ignored env desktop_sessiondebug3: ignored env qt_im_moduledebug3: ignored env pwddebug1: sending env xmodifiers = @im=ibusdebug2: channel 0: request env confirm 0debug1: sending env lang = en_us.utf8debug2: channel 0: request env confirm 0debug3: ignored env gdm_langdebug3: ignored env kdedirsdebug3: ignored env guestfish_outputdebug3: ignored env pd_socketdebug3: ignored env gdmsessiondebug3: ignored env histcontroldebug3: ignored env xdg_seatdebug3: ignored env homedebug3: ignored env shlvldebug3: ignored env gnome_desktop_session_iddebug3: ignored env xdg_session_desktopdebug3: ignored env lognamedebug3: ignored env qtlibdebug3: ignored env dbus_session_bus_addressdebug3: ignored env lessopendebug3: ignored env windowpathdebug3: ignored env pdhostdebug3: ignored env xdg_runtime_dirdebug3: ignored env displaydebug3: ignored env qt_plugin_pathdebug3: ignored env xdg_current_desktopdebug3: ignored env guestfish_restoredebug3: ignored env xauthoritydebug3: ignored env oldpwddebug3: ignored env _debug2: channel 0: request shell confirm 1debug2: callback donedebug2: channel 0: open confirm rwindow 0 rmax 32768debug2: channel_input_status_confirm: type 99 id 0debug2: pty allocation request accepted on channel 0debug2: channel 0: rcvd adjust 2097152debug2: channel_input_status_confirm: type 99 id 0debug2: shell request accepted on channel 0censored - motd here - censored$ sudo su -[you have new mail]root@servername:/home/root # datefri apr 15 10:39:22 utc 2016root@servername:/home/root # debug1: channel 0: free: client-session, nchannels 1debug3: channel 0: status: the following connections are open: #0 client-session (t4 r0 i0/0 o0/0 fd 4/5 cc -1)connection to servername closed by remote host.connection to servername closed.transferred: sent 4240, received 4440 bytes, in 217.5 secondsbytes per second: sent 19.5, received 20.4debug1: exit status -1[user@desktop applications]$",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": []
  },
  {
    "text": "making usb drives readonly on an specific usb port or for an user account. i have a multiseat machine and the second seat has usb access from a signle port by hub (a keyboard and a mouse are connected to it).i need make all storages drives that is connected to to this hub be read-only.this seat logins only by one user account. how can i make a usb port read-only for one account or one port (without makeing problem for input devices that are connected it that port)? i'm using ubuntu 12.04thanks",
    "present_kp": [
      "usb",
      "usb drive",
      "readonly"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "linux deepin language switcher - making it smoother like in ubuntu. i installed the latest linux deepin 2014.2 distro. it's a chinese distro based on ubuntu 14.04.the os is great, but there's one annoying flaw - when switching language, there appears a transparent switcher, and you need to switch again to actually make the change happen. it looks like this:this is incredibly annoying. i already tried asking around the deepin forum but i got no help there. can anyone help me fix this myself? i'd like to have something similar to ubuntu's behavior (switches immediately)",
    "present_kp": [
      "deepin"
    ],
    "absent_kp": [
      "locale",
      "desktop environment"
    ]
  },
  {
    "text": "installing and compiling log4cpp on debian. how to install log4cpp framework package stored locally as tar.gz, and which file from that package to use for bulding. i read some articles on internet, but i'm getting stucked at this part:./configuremakemake checkmake installcan someone please explain me how to install and build app from tar.gz?thanks",
    "present_kp": [
      "debian",
      "cpp"
    ],
    "absent_kp": [
      "linux",
      "software installation"
    ]
  },
  {
    "text": "'first_name' vs 'name_first' for grouping similar sql columns. when creating a table with similar bits or data such as names. is it preferred to have the column name prefixed with a common value?consider a table to store user information. looking at the columns related to the users name they may be structured as follows:titlefirst_namemiddle_namelast_namewould it not be better to style all columns relating to the users name with 'name' (as shown below) leading to more consistent naming patterns?name_titlename_firstname_middlename_last",
    "present_kp": [
      "sql"
    ],
    "absent_kp": [
      "naming standards"
    ]
  },
  {
    "text": "how do i add a widget to the header area of the 'twenty fourteen' wp theme?. i would like to add a widget to the header area (above the main menu) of the wordpress twenty fourteen theme. ideally this would cut down the size of the header image from the full width to half, with the other half of the area holding the new widget.i am not well versed in php, css, java, or any other useful stuff like that, so the more simple the solution, the better.i've not been able to locate a plug-in which achieves this outcome, but a plugin would certainly be my preferred way of doing this, as i can then easily do it across multiple sites if required.",
    "present_kp": [
      "wordpress",
      "theme"
    ],
    "absent_kp": [
      "web development",
      "website design"
    ]
  },
  {
    "text": "mutation and crossover in a genetic algorithm with real numbers. how exactly are mutation and cross-over applied in the context of a genetic algorithm based on real numbers (as opposed to just bits)? i think i understood how those two phases are applied in a canonical context where chromosomes are strings of bits of a fixed length, but i'm not able to find examples for other situations. what would those phases look like on the domain of real numbers?",
    "present_kp": [],
    "absent_kp": [
      "genetic algorithms",
      "genetic programming"
    ]
  },
  {
    "text": "reducing multiple satisfiability to normal sat. i have to prove the np-completeness of the following set:quadruple-sat:={f is formula in cnf|f has at least 4 satisfying interpretations}my idea so far has been to reduce the problem to the normal sat by constructing a new formula, copying the original formula 4 times and using a new set of literals in every copy, then adding clauses to ensure that the 4 sets of literals are pairwise differently interpreted (there is at least 1 literal which is flipped). such a formula is easy to find, i'm unable to get it to cnf though.i might also be on the completely wrong track on this one, if you know another np-complete problem this could be reduced to more easily, that would be great as well.",
    "present_kp": [
      "satisfiability"
    ],
    "absent_kp": [
      "complexity theory",
      "logic"
    ]
  },
  {
    "text": "comment on interface class and implemented class both? or interface class only?. now i'm commenting on both on interface class and implemented class.but sometimes, i feel it's unnecessary commenting both.so i want to hear from pros which is a better way? commenting on both? or only on interface class?example)/** * google analytics service interface */interface igoogleanalyticsservice { /** * track an event * * @param { string } category category-name * @param { string } action action-name * @param { string } label * @param { number } value */ trackevent(category: string, action: string, label?: string, value?: number): void;}/** * google analytics service */class googleanalyticsservice implements igoogleanalyticsservice { /** * track an event * * @param { string } category category-name * @param { string } action action-name * @param { string } label * @param { number } value */ trackevent(category: string, action: string, label: string = null, value: number = null) { this.$window.ga.trackevent(category, action, label, value); }}",
    "present_kp": [],
    "absent_kp": [
      "coding style"
    ]
  },
  {
    "text": "transfer google tasks to google reminders. i have a couple of tasks in the old-style google tasks calendar. i'd like to transfer them to (and start using) the new reminders feature.is there a way for me to do that without cutting and pasting from one to the other?",
    "present_kp": [
      "google tasks"
    ],
    "absent_kp": [
      "google calendar",
      "google calendar reminders"
    ]
  },
  {
    "text": "finding groups of ip addresses in a file. i have a file with groups of ip addresses. the file looks like this:london:1.1.1.0-1.1.1.200172.25.2.0-172.25.2.100germany:2.2.2.0-2.2.2.100192.168.1.0-192.168.1.200172.25.2.0-172.25.2.200so when i search for an ip address (./program.sh 172.25.2.32 ) the output should be london and germany.",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "text processing"
    ]
  },
  {
    "text": "are there apps for [near] real-time collaborative programming in javascript?. i'd like to take part in, or host an event where i collaboratively code something with a small group of people in geographically dispersed locations.is there a web app like jsbin.com or jsfiddle that allows near-real-time editing and code sharing? i'm thinking of the sort of editing you see in google docs spreadsheets, where the cursors and editing of other people editing the spreadsheet are shown to the other editors/viewers in near-real-time.",
    "present_kp": [],
    "absent_kp": [
      "collaboration"
    ]
  },
  {
    "text": "what is signal 0 in a trap command?. i'm following this guide on how to set up passwordless ssh authentication with ssh-agent.to start up ssh-agent the author recommends the following code in .bash_profile:sshagent=/usr/bin/ssh-agentsshagentargs=-sif [ -z $ssh_auth_sock -a -x $sshagent ]; then eval '$sshagent $sshagentargs' trap kill $ssh_agent_pid 0fii don't understand why it is trapping signal 0. according to man 7 signal there is no such signal.is this just a typo or bug or does this really achieve something?",
    "present_kp": [
      "bash",
      "trap"
    ],
    "absent_kp": [
      "signals"
    ]
  },
  {
    "text": "should my project provide precompiled binaries?. inspired by source code or binaries? how important is this?many of the larger, more widely used, floss projects provide both source distributions and ready-to-install binary images. this seems especially common when one of the target operating systems is windows (presumably on the assumption most users don't have a compiler installed).what are the advantages to doing so?what are the disadvantages?",
    "present_kp": [
      "distribution",
      "binaries"
    ],
    "absent_kp": []
  },
  {
    "text": "game of life component in react. i have been learning webdevelopment at freecodcamp and have therefore been writing a lot of javascript by myself. they have a code-review chatroom, but the people in that chatroom seem to review the final product and not the code itself. so, i am searching for some constructive criticism about the structure and style of my code.the code shown below is a class from a game of life game as part of the freecodecamp course and does work. it is written in javascript and uses react. there is more code for this project, but i don't think it is necessary to show all of the code, for you to critique my code structure and style. if it the rest of the code is required i can of course post it as well.class gameoflife extends component { constructor(props) { super(props) this.togglegamestate = this.togglegamestate.bind(this); this.stepgame = this.stepgame.bind(this); this.squareclicked = this.squareclicked.bind(this); this.cleargrid = this.cleargrid.bind(this); this.generaterandomgrid = this.generaterandomgrid.bind(this); this.togglespeed = this.togglespeed.bind(this); this.state = { cellrows: generaterandomcelldistribution({height: 50, width: 50}), size: {height:50, width:50}, gamestate: 'playing', speed: 1, generation: 0 }; } componentdidmount() { this.setstate({gamtestate: 'playing', interval: setinterval(this.stepgame, 200/this.state.speed)}); } togglegamestate() { var newstate = this.state.gamestate === 'playing' ? 'paused' : 'playing'; if(newstate === 'playing') { this.setstate({gamestate: newstate, interval: setinterval(this.stepgame, 200/this.state.speed)}); } else { this.setstate({'gamestate': newstate}); clearinterval(this.state.interval); } } squareclicked(row, column) { var cellrows = this.state.cellrows.slice(); var newstate = cellrows[row][column].state === 'alive' ? 'dead' : 'alive'; cellrows[row][column] = {state: newstate}; this.setstate({cellrows: cellrows}); } generaterandomgrid() { this.setstate({cellrows: generaterandomcelldistribution(this.state.size), generation: 0}) } cleargrid() { this.setstate({cellrows: getblankcellrows(this.state.size), generation: 0}); } togglespeed(){ var newspeed = this.state.speed < 4 ? this.state.speed+1 : 1; clearinterval(this.state.interval); this.setstate({speed: newspeed, interval: setinterval(this.stepgame, 200/newspeed)}); } stepgame() { var newcellrows = getblankcellrows(this.state.size); var currentcellrows = this.state.cellrows.slice(); var aliveneighbours = getaliveneighbours(currentcellrows); for(var i = 0; i < currentcellrows.length; i++) { for(var q = 0; q < currentcellrows[i].length; q++) { newcellrows[i][q].state = getnewstate(currentcellrows[i][q].state, getaliveneighbours(currentcellrows, i, q)); } } this.setstate({cellrows: newcellrows, generation: this.state.generation + 1}); } render(){ return( <div> <div classname=ui-container> <button classname=button-theme onclick={this.togglegamestate}>{this.state.gamestate === 'playing' ? 'pause' : 'start'}</button> <button classname=button-theme onclick={this.cleargrid}>clear grid</button> <button classname=button-theme onclick={this.generaterandomgrid}>random</button> <button classname=button-theme onclick={this.togglespeed}>speed: {this.state.speed}x</button> <div classname=generation-indicator>generation: {this.state.generation}</div> </div> <grid gamestate={this.state.gamestate} size={this.state.size} cellrows={this.state.cellrows} squareclicked={this.squareclicked} /> </div> ); }}",
    "present_kp": [
      "javascript",
      "game of life"
    ],
    "absent_kp": [
      "ecmascript 6",
      "react.js"
    ]
  },
  {
    "text": "how can i justify software testing to management?. i work for a small company (less than 200 employees) whose software group only makes up a small part of our staff (4 employees, occasionally with a few contractors). the four of us have been making strides in transitioning to better practices, and one of the next logical steps is to improve our testing.as anyone who has done any meaningful tests knows, testing takes a lot of time - and at my company, it takes too much time to justify to management, so we generally do what little we do on the sly. i don't think this is serving us well, as we keep coming up against otherwise avoidable problems when we ship under-tested software.i would like to be able to come to management with a justification for hiring a dedicated software test engineer (someone who can both write automated tests and perform manual ones). are there any good published studies that show the benefits of adding such a position to a small company? where can i find information about costs associated with the position? i plan on doing a little number crunching on our own history, but having some external sources to point to would help bolster my case.",
    "present_kp": [
      "testing",
      "management"
    ],
    "absent_kp": []
  },
  {
    "text": "disable daylight saving time in debian linux. i do not want my system to use daylight saving time.root@ali-debserver:~# cat /etc/timezoneasia/tehranroot@ali-debserver:~# cat /etc/default/rcs## /etc/default/rcs## default settings for the scripts in /etc/rcs.d/## for information about these variables see the rcs(5) manual page.## this file belongs to the initscripts package.# delete files in /tmp during boot older than x days.# '0' means always, -1 or 'infinite' disables the feature#tmptime=0# spawn sulogin during boot, continue normal boot if not used in 30 seconds#sulogin=no# do not allow users to log in until the boot has completed#delaylogin=no# be more verbose during the boot process#verbose=no# automatically repair filesystems with inconsistencies during boot#fsckfix=noi could not solve this problem permanently with ntp or tzdate. how do i disable daylight saving time?",
    "present_kp": [
      "linux",
      "time",
      "timezone"
    ],
    "absent_kp": []
  },
  {
    "text": "safe to delete system.map-* files in /boot?. i'm experimenting with generating some custom kernels using genkernel.however, each iteration leaves a file in /boot called system.map-genkernel-<arch>-<version>.is it safe to rename and/or delete the system.map-* files?",
    "present_kp": [
      "kernel",
      "boot"
    ],
    "absent_kp": [
      "linux",
      "gentoo"
    ]
  },
  {
    "text": "calculating sum of values in each child of dictionary for qtreeview. there is data stored in json file with the following structure:goods_data = {year : {month : {day : {01 : {name : some item, price : 10.01, category : root | first | sub first | twice sub first, 02 : {name : another item, price : 10.99, category : root | first | sub first} }}}}}the task is to fill a qtreeview in which categories must have tree structure (the first column). the second column must contain the total sum of purchases and percentage of the year for current category. the other columns are suppose to contain the total sum for each month for the current category.the script i have written does what it is supposed to do but it takes too much time for the given data.i understand that i include too many iterations inside each iteration, but i don't know the other way to do it. i think there is no reason to put all data that is being used, so i just have included the simplified dictionary.how can i do it in more efficient and pythonic way?#!/usr/bin/env python -tt# -*- coding: utf-8 -*-#from pyside.qtgui import *from pyqt5.qtgui import *from pyqt5.qtcore import *from pyqt5.qtwidgets import *from pyqt5.qtcore import pyqtslotimport timeimport typesimport jsonimport sysreload(sys)sys.setdefaultencoding('utf8')from datetime import datetimeimport collectionsimport operatorimport sipsip.setapi('qvariant', 2)goods_data = {2015 : {09 : { 01 : { 1 : { name : red apples, price : 10.01, category : food and grocery | fruit and vegetables | fruit | apples }, 2 : { name : green apples, price : 10.99, category : food and grocery | fruit and vegetables | fruit | apples } }, 15 : { 1 : { name : blue apples, price : 10.01, category : food and grocery | fruit and vegetables | fruit | apples }, 2 : { name : black apples, price : 10.99, category : food and grocery | fruit and vegetables | fruit | apples }} }, 10 : { 01 : { 1 : { name : oranges, price : 10, category : food and grocery | fruit and vegetables | fruit | oranges }, 2 : { name : oranges, price : 10, category : food and grocery | fruit and vegetables | fruit | oranges } }, 15 : { 1 : { name : oranges, price : 10, category : food and grocery | fruit and vegetables | fruit | oranges }, 2 : { name : apples, price : 10, category : food and grocery | fruit and vegetables | fruit | apples }} } } }#gj = 'goods.json'#with open(gj) as f: #goods_data = json.load(f)@pyqtslot(float, float) def percentage(part,whole): if whole>0: return 100.00* float(part)/float(whole) else: return 0@pyqtslot(float, float) def perc_diff(prev,curr): return((float(curr)-prev)/abs(prev))*100.00@pyqtslot(dict, dict) def update(d, u): ''' returns updated dictionary (initial dict, updating dict) ''' for k, v in u.iteritems(): if isinstance(v, collections.mapping): r = update(d.get(k, {}), v) d[k] = r else: d[k] = u[k] return dclass mainframe(qwidget): def __init__(self): #super(mainframe, self).__init__(parent) qwidget.__init__(self) self.statusbar = qstatusbar() self.expences_cat_tree_stat = qtreeview() self.expences_cat_tree_stat.setautoexpanddelay(0) self.expences_cat_tree_stat_model = qstandarditemmodel() self.expences_cat_tree_stat.setmodel( self.expences_cat_tree_stat_model ) mainwindow = qvboxlayout(self) mainwindow.addwidget(self.expences_cat_tree_stat) mainwindow.addwidget(self.statusbar) self.statusbar.showmessage(ready) self.setlayout(mainwindow) self.stat_cat_tree = self.load_stat_cat_tree(goods_data, self.expences_cat_tree_stat_model) @pyqtslot(qobject, dict, qobject, dict, int, qstandarditemmodel) def treecatstat(self, children, parent, cat_dict, year, model): for child in sorted(children): child_item = qstandarditem(child) data_row = list([child_item]) # adding items without data to the row for i in range(model.columncount()): data_row.append(qstandarditem()) parent.appendrow(data_row) # creating the path varforpath = child_item.parent() list_for_path = list([child_item.text()]) while varforpath.parent() is not none: list_for_path.append(varforpath.text()) varforpath = varforpath.parent() cat_path_str = str() cat_path_str = ' > '.join(reversed(list_for_path)) self.statusbar.showmessage(cat_path_str) # iterating categories for sbct in sorted(cat_dict): cat_tot_year = float() # if iterated category starts with path created from item if sbct.startswith(cat_path_str): # iterating months for i in range(2, model.columncount()): cat_tot_month = float() # inside each month iterating categories for kpd in sorted(cat_dict): # if iterated category inside the month starts with path from item if kpd.startswith(cat_path_str): # iterating month of categories that starts with path from item for mm in sorted(cat_dict[kpd][year]): # if name of the month from header matches name of the month from dictionary if model.headerdata(i, qt.horizontal) == qdate.fromstring(mm, m).tostring(mmmm): # iterating dates of month for dd in sorted(cat_dict[kpd][year][mm]): # iterating numbers of purchases for ii in sorted(cat_dict[kpd][year][mm][dd]): # iterating names of purchases for itn in sorted(cat_dict[kpd][year][mm][dd][ii]): cat_tot_month += cat_dict[kpd][year][mm][dd][ii][itn]['sum'] cat_tot_year += cat_dict[kpd][year][mm][dd][ii][itn]['sum'] model.setdata(model.indexfromitem(data_row[i]), cat_tot_month) model.setdata(model.indexfromitem(data_row[1]), cat_tot_year) whole = float(data_row[1].text()) # adding percentage to months for val in range(2, model.columncount()): part = model.indexfromitem(data_row[val]).data() str_out = str() if part is not none: part = float(part) if part > 0: perc_str = format(percentage(part, whole), .2f) str_out = str(format(part, .2f)) + ( + perc_str + %) model.setdata(model.indexfromitem(data_row[val]), str_out ) if isinstance(children, types.dicttype): self.treecatstat(children[child], child_item, cat_dict, year, model) @pyqtslot(qobject, dict, qstandarditemmodel) def load_stat_cat_tree(self, data, model): start=time.clock() res = dict() ch_y = 2015 tree = self.expences_cat_tree_stat exp_cat_tree_header = list([year / category, total]) month_perc_item_list = list() overall_spent = float() prev_month_perc =float() one_month_sum_list = list() cat_dict = dict() initial_dict_creation_time_start = time.clock() for yy in sorted(data): year_item = qstandarditem(yy) one_year_sum = float() for mm in sorted(data[yy]): date = qdate.fromstring(mm, m) chosenmonth = date.tostring(mmmm) month_item = qstandarditem(chosenmonth) one_month_sum = float() for dd in sorted(data[yy][mm]): one_day_sum = float() day_str = qdate.fromstring(dd + + mm + + yy, dd mm yyyy) day_str_out = day_str.tostring(d, dddd) day_item = qstandarditem(day_str_out) day_item.settooltip(day_str.tostring(d.mm.yy, dddd)) for ii in sorted(data[yy][mm][dd]): item_pr = float(data[yy][mm][dd][ii][price]) item_name=data[yy][mm][dd][ii][name] #item_descr=data[yy][mm][dd][ii][descr] item_cat = data[yy][mm][dd][ii][category].replace(|, >) path = item_cat if path not in cat_dict: cat_dict[path] = {yy: {mm: {dd: {ii: {item_name: {sum: item_pr} }}}}} else: if yy not in cat_dict[path]: cat_dict[path][yy] = {} if mm not in cat_dict[path][yy]: cat_dict[path][yy][mm] = {} if dd not in cat_dict[path][yy][mm]: cat_dict[path][yy][mm][dd] = {} if ii not in cat_dict[path][yy][mm][dd]: cat_dict[path][yy][mm][dd][ii] = {} if item_name not in cat_dict[path][yy][mm][dd][ii]: cat_dict[path][yy][mm][dd][ii][item_name] = {sum: item_pr} if path: d = t = {} # t is my temporary dictionary for i in path.split( > ): t[i] = {} t = t[i] dct = update(res,d) else: dct = res one_month_sum += float(item_pr) one_year_sum += float(item_pr) if one_month_sum > 0: exp_cat_tree_header.append(month_item.text()) one_month_sum_list.append( float(one_month_sum)) initial_dict_creation_time_end = time.clock() initial_dict_creation_time_diff = str(initial_dict_creation_time_end - initial_dict_creation_time_start) print initial dict creation time for + yy + -> + initial_dict_creation_time_diff if one_year_sum > 0: year_row_list = [year_item, qstandarditem(str(format(one_year_sum, .2f)))] for tm in one_month_sum_list: year_row_list.append(qstandarditem(str(format(tm, .2f)) + ( + format(percentage (tm, one_year_sum), .2f) + %) )) self.expences_cat_tree_stat_model.appendrow(year_row_list) model.sethorizontalheaderlabels(exp_cat_tree_header) self.treecatstat(res, year_item, cat_dict, yy, model) tree.expandall() c = 0 while c < len(exp_cat_tree_header): tree.resizecolumntocontents(c) c=c+1 tree.collapseall() item_to_expand = year_item tree.setexpanded(model.indexfromitem(item_to_expand), true) tree.scrollto(model.indexfromitem(item_to_expand)) end = time.clock() #print %.2gs % (end - start) print calculations:, str(end - start) self.statusbar.showmessage(calculations: + str(end - start))if __name__ == __main__: app = qapplication(sys.argv) main = mainframe() main.show() main.move(app.desktop().screen().rect().center() - main.rect().center()) sys.exit(app.exec_())",
    "present_kp": [
      "python",
      "dictionary",
      "pyqt"
    ],
    "absent_kp": [
      "performance",
      "beginner"
    ]
  },
  {
    "text": "why does this programs speed not increase?. this is the program i was given, it searches a large array for a max value:import java.util.date;import java.util.random;class findmax { private static final int n = 256 * 1024 * 1024; public static void main(string args[]) { assert(n > 0); int array[] = new int [n]; assert(array != null); random random = new random(new date().gettime()); for (int i = 0; i < n; i++) { array[i] = random.nextint(); } date start = new date(); int max = array[0]; for (int i = 1; i < n; i++) { if (array[i] > max) { max = array[i]; } } date end = new date(); system.out.println(max: + max); system.out.println(time in msec: + (end.gettime() - start.gettime())); }}i am to increase the speed by having multiple threads each search part of the array. this is what i did:import java.util.date;import java.util.random;class findmax extends thread{ private static final int n = 256 * 1024 * 1024; static int array[] = new int [n]; static int max = array[0]; int start, end; public void run(){ for (int i = this.start; i < this.end; i++) { if (array[i] > max) { max = array[i]; } } } public findmax(int q, int u){ this.start=q; this.end=u; } public static void main(string args[]) { assert(n > 0); int ts = integer.parseint(args[0]); assert(array != null); random random = new random(new date().gettime()); for (int i = 0; i < n; i++) { array[i] = random.nextint(); } date start = new date(); thread t[] = new thread[ts]; int eacht = (256 * 1024 * 1024)/ts; for( int p=0; p<ts;p++){ t[p] = new findmax(0+p*eacht, (eacht-1)+p*eacht); t[p].start(); } date end = new date(); system.out.println(max: + max); system.out.println(time in msec: + (end.gettime() - start.gettime())); }}the problem is that is has the opposite effect. the more threads (taken from command line argument) the longer the program takes to run. why is this doing the exact opposite of increasing the programs speed with increased threads created?",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "multithreading"
    ]
  },
  {
    "text": "how to install a newer version of mysql workbench than is available in my distro's repos. i am trying to install a version of mysql workbench that is newer than what is available to me through the regular debian repos.i started by adding testing, unstable and experimental repos, but even they don't have the version i'm looking for (6.3.6).so i tried following these instructions here, i added the mysql repo, ran apt-get update and am getting unable to locate package mysql-server-communityi can, and have installed the mysql-workbench package, but the instructions explicitly state to use the community version. the version i have installed now is 6.2.3.also, my mysql server version is 5.5.46 and i would rather not upgrade it as we are developing with that version.so what gives? i should point out that i am running debian 8 and am using the deb section of the linked instructions.",
    "present_kp": [
      "apt",
      "mysql"
    ],
    "absent_kp": [
      "repository"
    ]
  },
  {
    "text": "permanently disable built-in bluetooth and use usb. after 5 years my laptop is in perfect condition (still).but my built-in bluetooth is not what it used to be (thanks to the extensive use of it) and fails to load at boot pretty much.because of extensive use i opted to buy a 10 dollar bluetooth stick which took over the job of the built-in one.however, the built-in one is mostly not on but sometimes it still gives a spark. at that times it's sometimes really annoying because it just screws my settings and overwrites several things.my question: how can i make sure the built-in bluetooth is permanently disabled while the usb-device is still able to send my audio/pointing devices/... through.system: linux mint 18 (base: ubuntu 16.04)lsusb-output:jeroen@laptop ~ $ lsusbbus 002 device 002: id 5986:02ac acer, inc bus 002 device 001: id 1d6b:0002 linux foundation 2.0 root hubbus 004 device 002: id 138a:0018 validity sensors, inc. fingerprint scannerbus 004 device 001: id 1d6b:0001 linux foundation 1.1 root hubbus 001 device 001: id 1d6b:0002 linux foundation 2.0 root hub(built-in bt) bus 003 device 004: id 0a5c:21b4 broadcom corp. bcm2070 bluetooth 2.1 + edr(usb-bt) bus 003 device 006: id 0a12:0001 cambridge silicon radio, ltd bluetooth dongle (hci mode)bus 003 device 001: id 1d6b:0001 linux foundation 1.1 root hubbus 008 device 001: id 1d6b:0003 linux foundation 3.0 root hubbus 007 device 001: id 1d6b:0002 linux foundation 2.0 root hubbus 006 device 001: id 1d6b:0003 linux foundation 3.0 root hubbus 005 device 001: id 1d6b:0002 linux foundation 2.0 root hubupdate: test output(as requested by dirkt)jeroen@laptop ~ $ sudo hcitool devdevices: hci0 00:1b:dc:0f:73:5d hci1 cc:52:af:a8:71:b5## plugged out the usb-bt donglejeroen@laptop ~ $ sudo hcitool devdevices: hci1 cc:52:af:a8:71:b5## plugged in the usb-bt donglejeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: no hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: nojeroen@laptop ~ $ sudo rfkill block 5jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: no hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: nojeroen@laptop ~ $ sudo rfkill block 6jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: yes hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: nojeroen@laptop ~ $ sudo rfkill block 8jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: yes hard blocked: no8: hci0: bluetooth soft blocked: yes hard blocked: nojeroen@laptop ~ $ sudo rfkill unblock 8jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: no hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: nojeroen@laptop ~ $ sudo rfkill unblock 6jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: no hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: nojeroen@laptop ~ $ sudo rfkill unblock 5jeroen@laptop ~ $ sudo rfkill list0: phy0: wireless lan soft blocked: no hard blocked: no1: brcmwl-0: wireless lan soft blocked: no hard blocked: no4: hp-wifi: wireless lan soft blocked: no hard blocked: no5: hp-bluetooth: bluetooth soft blocked: no hard blocked: no6: hci1: bluetooth soft blocked: no hard blocked: no8: hci0: bluetooth soft blocked: no hard blocked: no",
    "present_kp": [
      "usb",
      "bluetooth"
    ],
    "absent_kp": [
      "drivers"
    ]
  },
  {
    "text": "how to install & run collectd on solaris 10 x86. i am trying to install and run collectd on solaris 10 x86. i downloaded the solaris x86 version of the installer. installed using pkd_add command and chose the default folders. now i am trying to run the daemon, but it doesn't seem to work. here is the problem / error:bash-3.00# sbin/collectdbash: sbin/collectd: cannot execute binary file",
    "present_kp": [
      "solaris"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "is this language recursively enumerable?. let $p=\\{l \\mid \\exists w\\in \\sigma^* s.t. w\\in l \\wedge orall z>w\\colon z\\in l\\}$ . now denote $l=\\{\\langle m angle \\mid l(m) \\in p \\}$.that is, $l$ is the set of all tms $m$ s.t. there exists a $w\\in \\sigma^*$ s.t. $w$ is accepted by $m$ and for each $z>w$, $z$ is accepted by $m$ as well. i am trying to find out whether $l$ is in $re$ or not.i can easily show that $l$'s complement is $ otin re$ using rice's theorem. but here, if using rice's theorem, i can only show that $l otin r$, but i have no guarantee over $re$. i thought about using reduction - either to prove $l\\in re$ or to disprove, but none came about. i thought about using $l_{acc}$ or its complement, $l_{\\sigma^*}$, but could not come up with an idea that will work for either direction of the reduction.could someone assist?",
    "present_kp": [],
    "absent_kp": [
      "computability",
      "turing machines",
      "reductions",
      "undecidability"
    ]
  },
  {
    "text": "delivery algorithm - find shortest paths. given -a center(lat=x,lng=y) 'c' from which a delivery boy makes a roundtrip. a delivery boy has a bag which may contain at the most 10boxes to deliver. a set of points di (lat=xi,lng=yi) around 'c'where the delivery has to be done. d=number of di & 1<=d<=10 each di either belongs to time window(30 minutes) w1 or w2 where w1 issomething like 11-30 am to 12 pm and w2 like 12 pm to 12-30 pmeach delivery has to meet an sla (service level agreement). eg- if the order o1 at drop point d1 belongs to w1 then it must be delivered within w1 window.task - find the shortest time path such that the delivery boy meets sla for maximum number of orders. the best path is the one where sla is met for all orders..i think it will be better if i start with a couple of variations.. use these variations in dry runs and gather some data for each of the variations..what i am looking for - any other cues/variations that i can use.. the greedy approach is already up and running. i am gathering real time data to measure its performance..clarificationsif sla's can't be met, do the deliveries still need to be made? - yes, in those cases the best algorithm will be the one with minimum sla breaches..followed by minimum time..are there algorithm constraints/metrics (i.e. execution speed, memory used,etc) that must be considered? - speed - not so much an issue - even if it takes 1 minute to run algo its ok, memory - it may take upto 0.5 gb.. also if it turns out to be very compute intensive.. i can buy a new machine for running this algo..will you need to scale up beyond the relatively small inputs stated - no. the delivery boys capacity is fixed. it may at the most become 15 (from 10 earlier)",
    "present_kp": [
      "shortest path"
    ],
    "absent_kp": [
      "algorithms",
      "greedy algorithms"
    ]
  },
  {
    "text": "wordpress.com to self-hosted wordpress blog. i have been writing articles on the wordpress.com blog, now i am looking to move it to self-hosted wordpress blog but i wonder:should i move all my articles on the new blog or just put an article on my last blog that more articles will be posted on my new blog?if i move all articles on my new blog, i am not sure about how google will react to it because there are articles with good number of visitors, won't this be seo-un-friendly because i am not sure but google will re-create page reputation stuff, etc or those articles will have same popularity even if i move elsewhere?what are the implications and side-effects in moving from wordpress.com blog to self-hosted wordpress blog?",
    "present_kp": [
      "seo",
      "google",
      "wordpress"
    ],
    "absent_kp": [
      "domains"
    ]
  },
  {
    "text": "table model code style. this is my table model code style:public class mymodel extends defaulttablemodel {static vector data = new vector();static vector column = new vector();connection conn;statement statement;resultset result;public mymodel() {super(data, column);try { conn = drivermanager.getconnection(...); statement = conn.createstatement(); result = statement.executequery(select * from table); int col = result.getmetadata().getcolumncount(); for (int i = 1; i <= col; i++) { column.add(result.getmetadata().getcolumnname(i)); } while (result.next()) { vector newrow = new vector(col); for (int i = 1; i <= col; i++) { newrow.add(result.getstring(i)); } data.add(newrow); }} catch (sqlexception e) { e.printstacktrace();} }// create methods for remove and add and edit a jtable selected row}//my gui class that show jtable on ownis this best way?what is this way problems?any idea to be better?",
    "present_kp": [],
    "absent_kp": [
      "java",
      "swing",
      "jdbc"
    ]
  },
  {
    "text": "c++11 factory pattern with lambdas. anonymous functions are one of the best features of c++11. they make everything so beautiful! however, one can get carried away and start overusing them.this code calls a function that reads through a file and invokes a callback everytime that something matches a regex. since i read two different files but i want callbacks only to differ for a constant, i chose this lambda-returning-lambda factory pattern.auto callback_factory = [&] (ipmarkertype start, ipmarkertype stop) -> std::function<void(ipnode<t>&)>{ return [&,start,stop](ipnode<t> & node){ markers.push_back(ipmarker<t>(node.ip, start)); markers.push_back(ipmarker<t>(node.ip.network_ones(node.prefix), stop)); };};read_regexp<t>(c:\\path\\to\\file1.txt, regex, callback_factory(ipm_a_open,ipm_a_close));read_regexp<t>(c:\\path\\to\\file2.txt, regex, callback_factory(ipm_b_open,ipm_b_close));callbacks are really local just to the calling function, so i think that external functor would not be justified. on the other hand, this code smells a lot to me, so i would like to hear your comments.",
    "present_kp": [
      "c++",
      "c++11",
      "lambda"
    ],
    "absent_kp": [
      "design patterns"
    ]
  },
  {
    "text": "converting $eta$-bit integer to a decimal representation in $\\theta(m(eta) \\log eta)$. the following problem is from clrs (31.1-13, page 933, 3rd edition):give an efficient algorithm to convert a given $eta$-bit (binary) integer to a decimal representation. argue that if multiplication or division of integers whose length is at most $eta$ takes time $m(eta)$, then we can convert binary to decimal in time $(m(eta)\\log eta)$. (hint: use a divide-and-conquer approach, obtaining the top and bottom halves of the result with separate recursions.)by a simple divide and conquer (by dividing $eta$-bit integer into two $eta/2$-bit integers), i obtain the recurrence $t(eta) = 2t(eta/2) + m(eta)$. however, how to argue that it is $o(m(eta) \\log eta)$? my attempt: i think the result relies on $m(eta)$. if $m(eta) = \\theta(eta)$, then $t(eta) = \\theta(m(eta)\\log eta)$. but, if, for example, $m(eta) = o(eta)$ or $m(eta) = \\omega(eta^2)$, you may not obtain $t(eta) = \\theta(m(eta)\\log eta)$.according to the hint, it seems that we should use different recursions to obtain $o(m(eta)\\log eta)$ and $\\omega(m(eta) \\log eta)$, respectively. but how?",
    "present_kp": [
      "recursion",
      "divide and conquer"
    ],
    "absent_kp": [
      "algorithm analysis",
      "asymptotics",
      "recurrence relation"
    ]
  },
  {
    "text": "deterministic turing machine with infine tape in both directions. consider a deterministic turing machine $d$ which has an infinite tape in both directions. we don't have exact information about it; what we know is that its alphabet is $\\{a, b, c\\}$ and there are at least three states $q_1, q_s, q_f$ where $q_s$ is the start state, $q_f$ is the final state. at some step of the computation, all the tape is blank except one cell containing the symbol $a$, the state is $q_1$ and the head is currently at a blank cell.i need to write states and transitions that will guarantee to enter to final state from state $q_1$ but i have difficulties since $d$ is both deterministic and with infinite tape in both directions.",
    "present_kp": [],
    "absent_kp": [
      "turing machines"
    ]
  },
  {
    "text": "linux file system that ages off older files when partition is full. i am wondering if there is a file system equivalent to a round-robin database, which for a fixed size, ages off the oldest files. it is pretty easy to implement with a simple cron job, which i have, but i assume it is a problem many people have and there is perhaps something better. i wish to set a fixed-size partition, or pool, in which older files are automatically removed, or aged-off, when the pool is full. a type of circular-buffer that would use the space left by the oldest file for the new ones, whilst preserving file integrity.my cron solution compares disk usage to a threshold and recursively removes the oldest file until disk usage is again under the threshold. it is not perfect because one can't guarantee the threshold is low enough that it isn't overtaken between two cron iterations. it also doesn't maximize the use of the storage space because of the threshold value which tends to be predictive in nature (how much can i fill in one minute, between two iterations of crond). two shortcomings i am hoping to improve upon.i am looking for a more elegant solution, akin to how the round-robin database (<url>) handles this transparently, but for file systems.",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "what's the difference between the 'tree -l 1 /' with 'tree -l 1'?. in linux i use the tree command to show the directory construction.if i use tree -l 1 / in root directory:[root@localhost /]# tree -l 1 // a.out bin -> usr/bin boot dev etc home lib -> usr/lib lib64 -> usr/lib64 media mnt opt proc root run sbin -> usr/sbin srv sys tmp usr varbut if i use tree -l 1:[root@localhost /]# tree -l 1. a.out bin -> usr/bin boot dev etc home lib -> usr/lib lib64 -> usr/lib64 media mnt opt proc root run sbin -> usr/sbin srv sys tmp usr varyou can see there is . and / difference, i don't know if there is more deep meaning, can't be only the . and / looks like, alright?",
    "present_kp": [
      "linux",
      "tree"
    ],
    "absent_kp": []
  },
  {
    "text": "could an artificial neural network algorithm be expressed in terms of map-reduce operations?. could an artificial neural network algorithm be expressed in terms of map-reduce operations? i am also interested more generally in methods of parallelization as applied to anns and their application to cloud computing. i would think one approach would involve running a full ann on each node and somehow integrating the results in order to treat the grid like a single entity (in terms of input/output and machine learning characteristics.) i would be curious even in this case what such an integrating strategy might look like.",
    "present_kp": [],
    "absent_kp": [
      "parallel computing",
      "artificial intelligence",
      "neural networks"
    ]
  },
  {
    "text": "eav - is it really bad in all scenarios?. i'm thinking to use eav for some of the stuff in one of the projects, but all questions about it in stackoverflow end up to answers calling eav an anti pattern.but i'm wondering, if is it that wrong in all cases? let's say shop product entity, it has common features, like name, description, image, price, etc., that take part in logic many places and has (semi)unique features, like watch and beach ball would be described by completely different aspects. so i think eav would fit for storing those (semi)unique features?all this is assuming, that for showing product list, it is enough info in product table (that means no eav is involved) and just when showing one product/comparing up to 5 products/etc. data saved using eav is used.i've seen such approach in magento commerce and it is quite popular, so may be there are cases, when eav is reasonable?",
    "present_kp": [],
    "absent_kp": [
      "database design",
      "data structures",
      "anti patterns"
    ]
  },
  {
    "text": "understanding this graphical depiction of a radial-basis function network. let $f$ be a radial-basis function network:$$f(x) = \\sum_{i=1}^n a_i p( \\lvert \\lvert b_i x - c_i \\lvert \\lvert)$$from artificial intelligence for human beings, the following depicts $f$:in the concrete example of this diagram, it seems that $n = 3$ (i.e., there are $3$ rbfs).question 1: how is it possible that there are multiple outputs on the right of this diagram coming from multiple summations? in particular, there are 3 summations producing 3 outputs. but shouldn't there just be 1 summation producing 1 output? are the second and third summations coming from a different set of rbfs than the first summation?the textbook continues:because multiple summations exist, you can see the development of a classification problem. the highest summation specifies the predicted class. a regression problem indicates that the model will output a single numeric value.question 2: here, does the highest summation refer to the very top output 1 in the diagram? or does it refer to the largest summation in the numerical sense?question 3: where in the equation for $f$ above is the $bias$ (depicted in the diagram as $bias (1)$) represented?",
    "present_kp": [],
    "absent_kp": [
      "neural networks"
    ]
  },
  {
    "text": "base64 encoded e-mails and compression. i sent an e-mail which included almost 2500 characters of text and one attached 60kib png file. this text included number 185 eight times. however, after the e-mail was encoded to base64 and sent, i'm able to find only three mtg1(mtg1 is 185 in base64 encoding) strings from e-mail source. how to explain this? according to e-mail header, content type is text/plain; charset=utf-8 and content transfer encoding is base64.",
    "present_kp": [
      "base64"
    ],
    "absent_kp": [
      "email"
    ]
  },
  {
    "text": "samba 4 nt acl on win7. global task: there are domain groups, using one global share for all users. these groups have to see file objects which have access set only to their groups. for example, user1 in group1 and group2 have to see folders and files with acls set to group1 or group2 , but no others. this is solved by acl ofc.software: samba-4.3.5 as ad member (fileshare) running in openvz container on proxmox ve (pve-manager/3.4-6/102d4547 kernel: 2.6.32-39-pve). hardware node has enabled acl support for /var/lib/vz. /etc/pve/nodes/vmid.conf has domain controllers are also samba. mount_opts=rw,acl,user_xattr,realtimesmb.conf: [global] workgroup = mds security = ads realm = mds.local netbios name = msrv server role = auto encrypt passwords = yes auth methods = winbind log level = 0 vfs:1 idmap config * : backend = rid idmap config * : range = 300000-400000 idmap config * : base_rid = 0 idmap config * :schema_mode = rfc2307 idmap_ldb:use rfc2307 = yes winbind nss info = rfc2307 winbind trusted domains only = no winbind use default domain = yes winbind enum users = yes winbind enum groups = yes winbind refresh tickets = yes max log size = 1000 syslog = 1 passdb backend = tdbsam obey pam restrictions = yes vfs objects = acl_xattr #acl_xattr:ignore system acls = yes map acl inherit = yes store dos attributes = yes unix password sync = yes load printers = no show add printer wizard = no disable spoolss = yes printcap name = /dev/null os level = 1 case sensitive = no hide unreadable = yes log writeable files on exit = yes deadtime = 600 ea support = yes#======================= share definitions =======================[m]comment = mailbrowseable = yespath = /opt/mguest ok = noread only = nocreate mask = 0777directory mask = 0777strict sync = yessync always = yesinherit permissions = yesinherit acls = yesinherit owner = yesinherit permissions = yesacl group control = yesacl map full control = yesveto files = /.snap/quota*/recycler/*.vmx/autorun.inf/hide files = .recyclevalid users = +mdsll mdsdminadmin users = +mds\\it mdsdministrator mdsdminhide unreadable = yesvfs objects= full_audit, recyclefull_audit:facility=local5full_audit:priority=noticefull_audit:prefix = %m(%i)|%ufull_audit:success = write rename unlink mkdir rmdirfull_audit:failure = write rename unlink mkdir rmdirrecycle:repository = .recyclerecycle:keeptree = yesrecycle:maxsize = 104857600recycle:exclude = ~$*,*.tmp,*.bakaccess based share enum = yesmap acl inherit = yeseverything seems ok: acls are present, i can modify them. user1 from group1 sees his folder and no others. but the problem is next: when i adding group2 to user1 groups he can see appropriate files or folders (that belongs to group2) only when he logouts and logins back on his pc. not on the fly. tested on windows 7 pcs.disconnecting share and mapping it back, restarting samba fileserver doesn't help. only logout-login.what's wrong?",
    "present_kp": [
      "acl",
      "openvz"
    ],
    "absent_kp": [
      "samba4"
    ]
  },
  {
    "text": "remove leading characters in filename up to a certain pattern. suppose i have files named:93162-117352 - may 24, 2017 345 pm_16_163_student.csvi want to rename it to be:16_163_student.csvhow do i do this with rename?",
    "present_kp": [
      "rename"
    ],
    "absent_kp": [
      "linux",
      "filenames",
      "wildcards"
    ]
  },
  {
    "text": "what is meant by an oracle separation between classes $\\mathsf{bpp}$ and $\\mathsf{bqp}$?. in these notes about quantum computation by scott aronson, he explains that the computation classes $\\mathsf{bpp}$ is contained in $\\mathsf{bqp}$, but that they are not equal, andso, the bottom line is that we get a problem -- simon's problem -- that quantum computers can provably solve exponentially faster than classical computers. admittedly, this problem is rather contrived, relying as it does on a mythical black box for computing a function f with a certain global symmetry. because of its black-box formulation, simon's problem certainly doesn't prove that $\\mathsf{bpp} eq \\mathsf{bqp}$. what it does prove that there exists an oracle relative to which $\\mathsf{bpp} eq \\mathsf{bqp}$. this is what i meant by formal evidence that quantum computers are more powerful than classical ones.what does he mean by an oracle separation?my understanding of an oracle for a turing machine is one that solves the halting problem. surely that can't be the case here?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "quantum computing",
      "oracle machines"
    ]
  },
  {
    "text": "i need to bind (join) data in google sheets. i'm looking for a way to accomplish data binding (join data) in google sheets. i have two sheets (a = form responses and b = report w/notes). i need data from sheeta to be moved into sheetb. sheetb needs to bind (join) imported data from sheeta with manually entered data in sheetb. sheeta = from responses(a)date (b)fname (c)lname (d)id#1-2-17 tod smith <phone>-3-17 jen jones <phone>-5-17 bob craft 345678sheetb = report w/notes- in reverse chronological order(a)date (b)fname (c)lname (d)id# (e)notes1-5-17 bob craft 345678 good kid1-2-17 tod smith 123456 always late1-3-17 jen jones 234567 very helpfuli need the notes column data to bind to the data in columns a-d when a new record is submitted into sheeta and imported into sheetb, the data in column (e)notes moves down and remains properly aligned with the student data. sheetb = report w/notescurrent outcome when new record is submitted (a)date (b)fname (c)lname (d)id# (e)notes 1-7-17 new kid 456789 good kid 1-5-17 bob craft 345678 always late 1-2-17 tod smith 123456 very helpful 1-3-17 jen jones 234567 you'll see the new student info is imported into sheetb, but the notes in (e)notes are not properly aligned with their student.sheetb = report w/notesdesired outcome when new record is submitted (a)date (b)fname (c)lname (d)id# (e)notes 1-7-17 new kid 456789 1-5-17 bob craft 345678 good kid 1-2-17 tod smith 123456 always late 1-3-17 jen jones 234567 very helpfulyou'll see the new student info is imported into sheetb, and it has been automatically 'moved' down a row so it stays properly aligned with the appropriate student.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "what happens when thread is created. when working on linux what happens when a thread is created? it is a separate execution flow. does each thread have their own code section? personally i don't think threads would be able to share code section even if it's the same section. say if the number of threads being created is dynamic. how is the memory allocated for each thread? will the memory foot print, especially code section, increase as threads are created?",
    "present_kp": [
      "threads"
    ],
    "absent_kp": []
  },
  {
    "text": "udev systemd swap dependency boot upgrade kali linux. my laptop is intel pentium cpu compaq cq57 32bit.i run kali linux rolling version 4.8.0. during upgrade a power blackout occurred. on rebooting, the boot process gets stuck at a start job is running for udev kernel device manager. after 1min 30 sec of unsuccessful run, it outputs dependency failure on swap. the partition is /dev/sda5. i append rw init=/bin/bash to my kernel and hit ctrl+x at my grub2 menu. it boots to shell root@(none):. i try to run dpkg --configure -a to solve package issues. boot still fails at the same stage.i examine my fstab to cross check uuid for my swap n disks with the output of blkid. they match. i run free command and swap space is 0 0. i run swapon to mount it. free outputs the 3.7gb size. i reboot again. it fails again.i perform fdisk -d to delete the partition. create it again and perform mkfs.ext4 on it. mkswap and swapon. paste the new uuid in fstab. reboot still fails at the same stage. commenting out the line doesnt help either. is there a solution to this where i dont lose my documents?",
    "present_kp": [
      "boot",
      "systemd",
      "kali linux",
      "udev"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the relationship between scope and namespaces in python?. in many resources i found scope and namespaces are used interchangeably, which seems a bit confusing since they mean different things. scope defines the region of the code where a name is available.the legb rule defines the way names are looked up.namespace is a place where you look up names.then i read:names are bind to a namespace according to where they are assigned... (which i believe is the deal with scopes in lexical scoping).functions add an extra namespace layer to your programs [ref.] (don't they add a extra local scope?)all the names assigned inside a function definition are put in the local scope (thenamespace associated with the function call).global scopethat is, a namespace in which variables created (assigned) at the top level of the module file live.*all of the quotes are from learning python 5th edition ch17are namespaces in python the way scopes are implemented? are they the same thing? can anyone enlighten me?",
    "present_kp": [
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "prng for generating numbers with n set bits exactly. i'm currently writing some code to generate binary data. i specifically need to generate 64-bit numbers with a given number of set bits; more precisely, the procedure should take some $0 < n < 64$ and return a pseudo-random 64-bit number with exactly $n$ bits set to $1$, and the rest set to 0.my current approach involves something like this:generate a pseudorandom 64-bit number $k$.count the bits in $k$, storing the result in $b$.if $b = n$, output $k$; otherwise go to 1.this works, but it seems inelegant. is there some kind of prng algorithm which can generate numbers with $n$ set bits more elegantly than this?",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "information theory",
      "coding theory",
      "pseudo random generators"
    ]
  },
  {
    "text": "registering single letter domain, selling subdomains?. i am about to purchase x.yz or a.bc (not those, but same lengths). i want to sell subdomains like rst.x.yz to the public, and would be able to run my own dns servers for it. is there a system (ipanel or something, preferably free) that i can do this automatically, where the user purchases a domain and enters the ip to point it to (i am not hosting files) and have it create instantly? i am really trying to avoid the paypal api as not to spend time re-inventing what could possibly exist already.do you think i should just stick with cpanel and let users make their own accounts and be touted a reseller ?other questions:1) should i run my own dns servers as a backend to this?2) how much to charge, and for one-time fee, monthly, or yearly?3) should i stick with redirects, or actually handle the dns?",
    "present_kp": [
      "domains",
      "dns",
      "paypal"
    ],
    "absent_kp": []
  },
  {
    "text": "why are emails from a google group getting automatically deleted by gmail?. i subscribe to emails from a google group. i noticed the other day that i felt like i hadn't gotten any emails about it in a while, so i went onto googlegroups.com and saw that there were many new threads in the group. i went back to my gmail and searched for the [xyz] that prefixes every subject line from this group, and lo and behold, there they all were in the trash. i can now see the emails come in to airmail and sit in the inbox for a few seconds before the gmailbot gets a hold on them and deletes them. i have no filters set up for these emails, and no filters at all with instructions to delete anything. the messages are not being marked as spam; they're simply getting dumped directly into the trash. why does gmail trash these messages automatically?",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "google groups"
    ]
  },
  {
    "text": "how to manage time for studying while working?. i've been programming 8 years for a company. we build business intelligence software systems. since i thought working is learning, i've always studied in terms of what i was doing at the company while working for 60 hours per week. these days, however, i am looking for a new company for employment, i can see that thought was a dumb idea because i frequently fail in job interviews mainly due to lack of knowledge on the other areas. of course, i am still willing to improve myself and am really trying. but while working that much of time per week, i can't find good amount of study time to catch up.i don't think i am the only one to concern about this so i would like to ask how you guys find time to study for your career? how many hours do you assign to studying other areas? am i missing some time management skills?",
    "present_kp": [
      "time management"
    ],
    "absent_kp": [
      "training"
    ]
  },
  {
    "text": "google analytics: what is not set under network domain. i'm looking at google analytics. when i view network domain i see a lot of (not set). what does that mean in terms of the user's network? i'm expecting to see wireless providers, too (e.g., verizon, sprint, etc.), but don't. are wireless providers not captured?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "easily create xml within powershell. the purpose of this powershell function is to make it simpler to output xml in a given format. for my use case, that xml did not have a schema associated, so i've not implemented any namespace logic; though suspect that could be easily added.codeadd-type -assemblyname 'system.xml.linq'function create-xmlelement { [cmdletbinding(defaultparametersetname = 'byxmlnodes')] param ( [parameter(mandatory = $true, valuefrompipelinebypropertyname = $true, position = 0)] [string]$name , [parameter(mandatory = $false, valuefrompipelinebypropertyname = $true, parametersetname = 'byxmlnodes', position = 1)] [system.xml.linq.xobject[]]$childobjects , [parameter(mandatory = $false, valuefrompipelinebypropertyname = $true, parametersetname = 'byvalue', position = 1)] [object]$value ) process { (new-object -typename 'system.xml.linq.xelement' -argumentlist ([system.xml.linq.xname]$name), $value, $childobjects) }}function create-xmlattribute { #just use a function for this as there's nothing clever required [cmdletbinding()] param ( [parameter(mandatory = $true, valuefrompipelinebypropertyname = $true)] [string]$name , [parameter(mandatory = $true, valuefrompipelinebypropertyname = $true)] [string]$value ) process { (new-object -type 'system.xml.linq.xattribute' -argumentlist ([system.xml.linq.xname]$name), $value) }}example usageset-alias -name 'x<>' -value 'create-xmlelement' #added aliases to avoid over cluttering the below definitionsset-alias -name 'x@' -value 'create-xmlattribute' #hopefully that makes the code a little easier to read #i had gone with cxe and cxa, but then figured this notation may be clearer (though possibly risky / more confusing for some?)( x<> 'root' @( (x@ 'attribute1' 'attribute''s value'), (x<> 'hello' 'valuex'), (x<> 'hello2' ( x<> 'adate' (get-date) )) )).tostring()outputthe above example produces this xml:<root attribute1=attribute's value> <hello>valuex</hello> <hello2> <adate>2017-06-09t16:09:27.<phone>+01:00</adate> </hello2></root>",
    "present_kp": [
      "xml",
      "powershell"
    ],
    "absent_kp": []
  },
  {
    "text": "combine arrays and preserve ordering - but prioritize one array's ordering over another. i have two arrays and i want to combine them both in a manner similar to this:arr1 = 1a, 1b, 1carr2 = 2a, 2b, 2carr1.zip(arr2).flatten(1)# => [1a, 2a, 1b, 2b, 3b, 3c]that is, put each arr2 element right after the arr1 element sharing an index.since arr1 elements come before their arr2 counterparts, arr1 can be considered 'prioritized' in this example.the prioritization could be switched by instead using arr2.zip(arr1).in both these cases, the priority has a binary state. either arr1 elements always come before their arr2 counterparts or vice versa. this can be visualized in a graph:y axis: percentage of added nodes that are arr1x axis: percent completion of arr2 iteration 100% | | 75% | | 50% | x x x x x | 25% | | 0% | ------------------------- 0% 25% 50% 75% 100%what if i wanted the graph's mean to be 50% and to have it increase in a linear fashion like so:y axis: percentage of added nodes that are arr1x axis: percent completion of arr2 iteration 100% | x | 75% | x | 50% | x | 25% | x | 0% | x ------------------------- 0% 25% 50% 75% 100%i ended up writing this code: # merges two arrays, ordering the results based on a 'priority' between 0 and 1 # if the priority is 0, then the results will include 100% original array # if the priority is 1, then the results will contain 50% original array # for example: # input: 0.5, [1,2,3], [4,5,6] # step 1: 1:0 odds in favor of array 1 # step 2: 1:1 tie # step 3: 1:0 odds in favor of array 2 # possible results: [1, 2, 6] and [1, 5, 6] are equally likely # # @param priority_amt [float] a number between 0 and 1. # represents the percentage of the result array that comes from # array_to_be_merged # @param original_array [array] will be at least 50% of the result # @param array_to_be_merged [array] # @return [array] def priority_merge(priority_amt, original_array, array_to_be_merged) original_array = original_array.clone array_to_be_merged = array_to_be_merged.clone original_array_original_length = original_array.length.to_f priority_amt = priority_amt.to_f results = [] swapped_priority = nil original_array.each_index do |index| results << original_array.shift percent_completed_through_iteration = 2 * (index.to_f / original_array_original_length) calculated_priority_for_run = 2 * priority_amt * percent_completed_through_iteration if calculated_priority_for_run > 0.5 if swapped_priority.nil? original_array, array_to_be_merged = array_to_be_merged, original_array end swapped_priority = 1.0 - calculated_priority_for_run calculated_priority_for_run = swapped_priority end priority_case_did_pass = priority_run_result(calculated_priority_for_run) results << array_to_be_merged.shift if priority_case_did_pass end return results end # @param success_pct [float] the percentage of times this method will return true # if called with the same argument # @return [boolean] def priority_run_result(success_pct) rand(100) < (success_pct * 100.0) endhere's a usage example:arr1 = 'a'.upto('z').map { |c| 1-#{c} }arr2 = arr1.map { |str| str.gsub(1, 2) }result = priority_merge(0.5, arr2, arr1)print #{result} # => [2-a, 2-b, 2-c, 2-d, 2-e, 2-f, 2-g, 1-a, 2-h, 1-b, 2-i, 1-c, 1-d, 2-j, 1-e, 2-k, 1-f, 1-g, 1-h]# verifying that the result is 50% composed of the second array:pct_is_arr1 = result.select { |str| str.include?(1) }.count.to_f / result.count.to_fputs pct_is_arr1# => 0.42105263157894735running it again shows pct_is_arr1 == 0.5714285714285714, so it's clearly staying close to 50% as expected.since i don't have a lot of practice with algorithms, i'm wondering how this looks and if my logic makes sense.",
    "present_kp": [
      "algorithm",
      "array"
    ],
    "absent_kp": [
      "ruby"
    ]
  },
  {
    "text": "p2/p0 and p2/(p1+p0) finite elements for stokes and darcy equations. typically i have seen p2/p1 elements used for stokes equation, but i want to use p2/(p1+p0) and p2/p0 elements because i want to ensure local mass conservation. when i say p2/(p1+p0), i simply mean the concatenation of the basis for p1 and p0 separately.i ran simple problems in fenics with both element pairs and while the velocity works great in both cases (i.e., element-wise conservative), the pressure does get a little screwed up. i have been told mixed opinions about using anything with piecewise constants for pressure. i have heard that p2/p0 is not lbb stable for 3d elements (however, i fail to see this happening because i do not get node-to-node spurious oscilliations) although this could potentially explain why my pressure looks screwed up. i have also heard that p2/p0 should be doable in 3d (hence p2/(p1+p0) should work as well).so i guess my question is, theoretically are p2/p0 and/or p2(p1+p0) elements stable and usable for 3d stokes and darcy problems?",
    "present_kp": [
      "finite element"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the downside of having many inodes?. too few inodes can result in you not being able to store anymore files. what is the the downside of having many inodes ? (more than default)",
    "present_kp": [
      "inode"
    ],
    "absent_kp": [
      "debian"
    ]
  },
  {
    "text": "repurpose mysql as a mutex. my application needs to perform an operation once every 10 minutes, but that operation is triggered many times more frequently. occasionally it is triggered three or four times a second in different processes, and that's the main thing i want to avoid.it's django, and at first i used the django.core.cache feature, but i am still getting more than one worker performing the operation simultaneously.i have redis also, and know that watch and multi can be used to prevent race conditions, but the django-redis library doesn't support them.this is my solution; please comment on how well (or not) it prevents multiple workers (processes) from performing the operation simultaneously:have a mysql table with fields when and uuid and just a single row starting with both nulls.when a worker is told to start the operation, it quits early if when is less than 10 minutes ago.otherwise, generate a uuid and store it in the table, updating when to now() in the same query.then, select the row and quit early if uuid doesn't match the one just generated.otherwise continue with the operationthis relies on mysql enforcing the order of reads and writes and enforcing that only one query access the row at once, which may be invalid assumptions.any alternative ways of keeping celery processes from running a task simultaneously would be just as helpful.",
    "present_kp": [
      "mysql",
      "django"
    ],
    "absent_kp": [
      "concurrency"
    ]
  },
  {
    "text": "dynamically adding controls to a form in a winforms project. i have created this function in my detailsscreen.cs, but i have no idea if this is the correct file to put this kind of code in, or if coding it this way is the correct approach. i know that it works because i have tested it.my application generates a questionnaire based on selected (cyber security) standards. i have a form detailsscreen, which requires the user to fill in some details such as name, company, etc. they also need to select from a checkedlist (questionstandardinput), the question standard they wish to use in this interview. for each selected standard, two answer standards need to be selected from two drop down lists (maturity answer standard and compliance answers standard).therefore, i need to be able to dynamically add labels and comboxes for each question standard. i asked because most code concerning label font etc. is placed in .designer.cs files instead of the .cs files. but i need certain logic from the .cs file in order to properly format the controls, which is why i put it in here.// load answer input according to the number of questions standards selected.private void questionstandardinput_mouseup(object sender, mouseeventargs e){ questionlabels.clear(); maturityinput.clear(); complianceinput.clear(); selectionpanel.controls.clear(); foreach (var item in questionstandardinput.checkeditems) { label qs_label = new label(); qs_label.location = new point(0, 0 + (questionlabels.count * 115)); qs_label.font = new font(arial, 12f, fontstyle.regular); qs_label.size = new size(150, 18); qs_label.text = item.tostring(); questionlabels.add(qs_label); this.selectionpanel.controls.add(qs_label); label m_label = new label(); m_label.location = new point(0, 0 + (questionlabels.count * 115 + 35)); m_label.font = new font(arial, 12f, fontstyle.regular); m_label.size = new size(150, 18); m_label.text = maturity standard; this.selectionpanel.controls.add(m_label); label c_label = new label(); c_label.location = new point(0, 0 + (questionlabels.count * 115 + 70)); c_label.font = new font(arial, 12f, fontstyle.regular); c_label.size = new size(170, 18); c_label.text = compliance standard; this.selectionpanel.controls.add(c_label); combobox m_input = new combobox(); m_input.location = new point(170, 0 + (questionlabels.count * 115 + 35)); m_input.font = new font(arial, 12f, fontstyle.regular); m_input.size = new size(200, 22); m_input.dropdownstyle = comboboxstyle.dropdownlist; maturityinput.add(m_input); this.selectionpanel.controls.add(m_input); combobox c_input = new combobox(); c_input.location = new point(170, 0 + (questionlabels.count * 115 + 70)); c_input.font = new font(arial, 12f, fontstyle.regular); c_input.size = new size(200, 22); c_input.dropdownstyle = comboboxstyle.dropdownlist; complianceinput.add(c_input); this.selectionpanel.controls.add(c_input); initializematuritystandardinput(m_input); initializecompliancestandardinput(c_input); } this.saveassessmentbutton.location = new point(235, 0 + (questionlabels.count * 115)); this.selectionpanel.controls.add(saveassessmentbutton); }",
    "present_kp": [
      "winforms"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "how can i check what version of the vi editor i have?. how can i check what version of the vi editor i have? what's the best way to upgrade it or install vim on solaris?",
    "present_kp": [
      "vim",
      "solaris",
      "vi"
    ],
    "absent_kp": []
  },
  {
    "text": "running a given command after each change in a file. i would love to hear some comments on this small script, which (i hope) reduces repetitive tasks such as page refreshing, compilation and so on to minimum.# -*- coding: utf-8 -*-# author: jacek 'sabr' karolak (<email>)# watch [files] for change, and after every change run given [command]### example watchdog script: safari.py# #!/usr/bin/env python# # -*- coding: utf-8 -*-## from loop import loop## if __name__ == __main__:# loop([osascript, -e, tell application safari# do javascript window.location.reload() in front document# end tell]).run()# eof## make safari.py executable (chmox +x safari.py) or use it with python.# python safari.py files_to_watch# whenever files_to_watch change, refresh safari in background :-)#__all__ = [loop]import argparse, subprocessfrom os import getcwd, listdir, statfrom os.path import existsfrom time import sleepclass loop(object): def __init__(self, cmd): self._command = cmd self._files_to_watch = {} def _watchdog(self): '''check wheter any file in self._files_to_watch changed, if so fire self._command''' check_file = lambda f: stat(f).st_mtime files = self._files_to_watch any_file_changed = false while true: # check each file for st_mtime change (modification) for f in files.keys(): actual_mtime = check_file(f) if not files[f] == actual_mtime: any_file_changed = f files[f] = actual_mtime if any_file_changed: # run command print('file: '{}' changed since last check.'\\ .format(any_file_changed)) any_file_changed = false subprocess.call(self._command) # sleep before next check sleep(0.5) def _set_files_to_watch(self, files): '''process args files wheter they exists and include current directory content if requested.''' if '.' in files: files.remove('.') # combine all other given files with current working directory # content, without dot files files += [f for f in listdir(getcwd())\\ if not f.startswith('.')] # make f list unique files = set(files) # check rights (in order to perform system stat) and wheter they exist for f in files: if not exists(f): msg = 'file '{}' does not exists, or i don't\\ have access rights.'.format(f) raise ioerror(msg) # save files to watch in instance variable self._files_to_watch = dict.fromkeys(files) # set modification times for file_key in self._files_to_watch.keys(): self._files_to_watch[file_key] = stat(file_key).st_mtime def run(self): '''parses command line arguments, processes files list, and fires watchdog.''' parser = argparse.argumentparser(description='checkes wheter given \\ files change, when they do, runs given command.') parser.add_argument('files', metavar='f', type=str, nargs='+',\\ help='list files to process, if you add . in list it will\\ watch also all non dot files in current dir.\\ if you want to have all non dot files and some dot ones use:\\ .file1 .file2 .file2 . .file3 it will combine specified dot\\ files and all others.') args = parser.parse_args() self._set_files_to_watch(args.files) print('started watching...') self._watchdog()if __name__ == '__main__': pass",
    "present_kp": [
      "python",
      "file"
    ],
    "absent_kp": []
  },
  {
    "text": "second step of a funnel higher than first step in google analytics. i have a problem with the funnels in google analytics.so i have a e-commerce website that i want to track the user path to a purchase.i want ga to track if a user goes trough these steps [item page] [purchase] [checkout].i thought this could be done by funnels and my setup currently now consist of:step 1: [item page] (required)step 2: [purchase]goal: [checkout]but when i go to the funnel visualization report the following shows.[item page] visits: 150[purchase page] visits: 170[checkout] visits: 32how can the [purchase page] be higher than the [item page]?i searched the internet over, and found something called horizontal funnels but this doesn't show the correct numbers, again the purchase and checkout steps are higher than the item page.so somehow it doesn't need step 1, to fulfill the funnels/goals.what am i doing wrong?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": [
      "tracking",
      "goal tracking"
    ]
  },
  {
    "text": "language that embraces mutable state?. there seems to be a trend towards immutable objects, and pure functional programming. while i recognize the benefits, i find it hard to apply these principles to gui programming, for example. but i also find classical imperative languages with mutable objects lacking. i was wondering whether there is a language or system that embraces mutable state, and makes it especially easy to work with.below are some features i would consider to be designed around mutability:the ability to hook up events and get a change notification for any variable. it would make it very easy to write guis and mvc applications. and you could just make a list<myobject>, and stuff it into a list widget, and with a bit of configuration it would manage your list for you, no manual listview.insert() etc..a type system that considers state. for example, if i pass a car into a function that requires a working one, the compiler should try to proove that car.broken == false. if it can't proove it, it won't compile, and i have to ensure it (by putting the code in an if block, or setting it manually to false).a take on concurrency that makes sense for mutable objects. for example an atomic statement, that guarantees that certain statements are run together, using transactions or locks. the goal is not performance, but ease of use and gui responsiveness. i should be able to manipulate data and the gui from any thread, using atomic {step1; step2} to ensure invariants.i'm not looking for a system with these exact features, but one written in a similar spirit. the closest i've seen to this is c#/.net with its data binding features.gtk+ has custom listmodels that keep a gtktreeview in like with your data without manual inserts/updates. android has listadapters which are similar. i haven't found a thread-safe gui, but you can get pretty close with a liberal use of invoke() in c#/winforms, or gobject_idle_add in gtk+. are there any systems like what i describe? or research material, references, etc.?",
    "present_kp": [],
    "absent_kp": [
      "language design",
      "immutability"
    ]
  },
  {
    "text": "enabling additional executable binary formats fails. on ubuntu 14.04, after doing do-release-upgrade -d several systems failed like dbus, network-manager, sound card etc.. i am logged into terminal instead of x.looking at the /var/log/boot.log i managed to fix all failed services except the line enabling additional executable binary formats. what is the purpose of it and how do i debug it?",
    "present_kp": [
      "ubuntu",
      "boot"
    ],
    "absent_kp": []
  },
  {
    "text": "compiling riofs, can't compile with support to --force-head-requests. i am on debian jessie, compiling the last master with a gcc 4.8 and some higher versions for some of the required libs, required libs are :glib >= 2.22fuse >= 2.7.3libevent >= 2.0libxml >= 2.6libcrypto >= 0.9libmagic (optional: --with-libmagic=path)everything goes smooth, configure stage drops no error, neither make. but i can't use --force-head-requests because it is not compiled in to the binary ( the option does not show when executing the binary --help )when trying to make a symlink after mounting the bucket, i get failed to create symbolic link function not implemented. this is the project in github : <url> this some backward lib incompatibility issue ?",
    "present_kp": [
      "debian",
      "compiling"
    ],
    "absent_kp": []
  },
  {
    "text": "how to access my instagram account?. i created my instagram account through my facebook account and i have been using it to log in instagram. then, i lost access to my instagram account when i replaced the app.i tried logging in with my facebook account and the response was that they are not linked. instead, it created another account and now i cannot access my previous account.",
    "present_kp": [
      "instagram"
    ],
    "absent_kp": []
  },
  {
    "text": "list of recently modified files of a specified user in whole disk?. one of my colleague is suddenly getting sick seriously and i need to finish his part, so knowing what he is working on most recently would be useful...for example, if i want to see the most recent files bob has worked on(or in other words, he modified them most recently) and then sort them by the time. is there an easy way to do this?",
    "present_kp": [
      "time"
    ],
    "absent_kp": [
      "find"
    ]
  },
  {
    "text": "disable colours on terminal and ssh. my local linux machine has coloured terminal output like this;when i ssh to a pfsense/bsd box it changes the colours like this;even when i ssh from to a machine that doesn't have a coloured local terminal output, and ssh from there to this pfsense/freebsd box it enables coloured output, and starts producing unwanted coloured output/is there something i can change locally so that when i ssh to the pfsense box from either my local machine or via an intermediary machine, my client will ignore the remote colour settings. ideally i want to stay in black and white, two tone standard background and text colour only?",
    "present_kp": [
      "ssh",
      "terminal"
    ],
    "absent_kp": [
      "colors"
    ]
  },
  {
    "text": "when would you choose *not* to update a third-party library to a newer version?. using third party libraries for productivity gains in software development is common. unfortunately, along with the library's functionality we also import its bugs. some of them get fixed in subsequent releases. so, to upgrade or not to upgrade, this is the question. i am interested in learning from experiences when upgrading to a newer version of the library was desirable, but after a cost/benefit analysis the conclusion was that upgrading was not a good solution in the grand scheme of things. i am interested in finding out what forces influence the decision towards not upgrading.",
    "present_kp": [
      "libraries",
      "third party libraries"
    ],
    "absent_kp": [
      "software updates",
      "maven",
      "3rd party"
    ]
  },
  {
    "text": "figure out the emitted keycode for fn+f6. on my lenovo ideapad yoga 2 pro on windows, there is a function available fn+f6 that should turn the touchpad on and off (i would like to map the correct key to the script here on askubuntu).but on linux, it doesn't work.how can i find out the event keycode that it emmits when i press this combination?i tried showkey -a, showkey -k and xev which both shows most keys codes when pressed, but at fn+f6 they stay quiet. the other fn+f1-f5 show output, only f6 doesn't, although it works on windows. what other alternatives are there to xev and showkey?the only hint i found so far is:grep touchpad /usr/include/linux/input.h#define key_touchpad_toggle 0x212 /* request switch touchpad on or off */#define key_touchpad_on 0x213#define key_touchpad_off 0x214source: comment in <url> with link to this articlemaybe someone has an idea?",
    "present_kp": [
      "touchpad"
    ],
    "absent_kp": [
      "key mapping"
    ]
  },
  {
    "text": "what does because il offers no instructions to manipulate registers, it is easy for people to create new languages mean?. i am reading clr via c# and came across this sentence in the first chapter and i did not understand what exactly it meant.full line here:because il offers no instructions to manipulate registers, it is easy for people to create new languages and compilers that produce code targeting the clr.what does it mean?i ventured a guess that it means il is a bit low level, but not too low so that it is easy to create languages on top of it.",
    "present_kp": [
      "c#",
      "clr"
    ],
    "absent_kp": []
  },
  {
    "text": "how to disable set -x?. for some debugging purposes i enabled the command set -x. now the output of my bash is like this: $ ls+ ls --color=autocertificates desktop documents downloads dropbox ...how can i disable set -x so i won't see stuff like + ls --color=auto?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": []
  },
  {
    "text": "sourcing bashrc file fails with ssh -t. ssh -vvv -f /home/me/.ssh/config serva -t source ~/.bashrcthis is the output i get when i use -vvv flag:debug1: authentication succeeded (publickey). debug1: channel 0: new [client-session] debug3: ssh_session2_open: channel_new: 0 debug2: channel 0: send open debug1: requesting <email> debug1: entering interactive session. debug3: wrote 128 bytes for a total of 2413 debug2: callback start debug2: client_session2_setup: id 0 debug2: channel 0: request pty-req confirm 1 debug1: sending command: source ~/.bashrc debug2: channel 0: request exec confirm 1 debug2: fd 3 setting tcp_nodelay debug2: callback done debug2: channel 0: open confirm rwindow 0 rmax 32768 debug3: wrote 400 bytes for a total of 2813 debug2: channel_input_status_confirm: type 99 id 0 debug2: pty allocation request accepted on channel 0 debug2: channel 0: rcvd adjust <phone> debug2: channel_input_status_confirm: type 99 id 0 debug2: exec request accepted on channel 0 debug1: client_input_channel_req: channel 0 rtype exit-status reply 0 debug1: client_input_channel_req: channel 0 rtype <email> reply 0 debug2: channel 0: rcvd eow debug2: channel 0: close_read debug2: channel 0: input open -> closed debug2: channel 0: rcvd eof debug2: channel 0: output open -> drain debug2: channel 0: obuf empty debug2: channel 0: close_write debug2: channel 0: output drain -> closed debug2: channel 0: rcvd close debug3: channel 0: will not send data after close debug2: channel 0: almost dead debug2: channel 0: gc: notify user debug2: channel 0: output drain -> closed debug2: channel 0: rcvd close debug3: channel 0: will not send data after close debug2: channel 0: almost dead debug2: channel 0: gc: notify user debug2: channel 0: gc: user detached debug2: channel 0: send close debug2: channel 0: is dead debug2: channel 0: garbage collecting debug1: channel 0: free: client-session, nchannels 1 debug3: channel 0: status: the following connections are open: #0 client-session (t4 r0 i3/0 o3/0 fd -1/-1 cfd -1) debug3: channel 0: close_fds r -1 w -1 e 6 c -1 debug3: wrote 32 bytes for a total of 2845 debug3: wrote 64 bytes for a total of 2909 the server side log has the following message: sshd[18763]: received disconnect from ...i am using centos 6.4editmy original question was flawed. sorry about that. what i wanted to execute bash shell with the rc file i wanted (~/.bashrc_temp) and then execute something else. i think prompt_command is the recommended option it seems like, or having the command executed within ~/.bashrc_temp itself, which is less than ideal, but i can probably put some conditional statements.",
    "present_kp": [
      "ssh",
      "bashrc"
    ],
    "absent_kp": []
  },
  {
    "text": "what are some great resources for mastering apache administration?. i've been working with apache for a couple years now and am comfortable with basic administration and configuration. however, i'd really like to increase my skill set from basic administration to being a true apache wizard. what are some must read books, mailing lists, feeds, etc. for someone looking to increase their overall skill level with apache?",
    "present_kp": [
      "apache"
    ],
    "absent_kp": []
  },
  {
    "text": "understanding the concept of arguments and parameters. in the third last paragraph at page number 26 of the ebook the c programming language the author(s) say,we will generally use parameter for a variable named in the parenthesized list in a function. the terms formal argument and actual argument are sometimes used for the same distinction.and in the hard copy of the book that i am having, on the second last paragraph of page number 25 the author(s) say, we will generally use parameter for a variable named in the parenthesized list in a function definition, and argument for the value used in a call of the function. the terms formal argument and actual argument are sometimes used for the same distinction.if i understand it correctly, it means whatever the value(or variable) is used in the call of a function, that is called argument. and whatever is written in the paranthesis of the definition of a function, that is called parameter. e.g. in the following code:#include<stdio.h>int func(int j){ return j; }main() { int k=5; printf(the argument = %d, func(k)); } the parameters are declared by the line int func(int j). the argument given, through which main() and func(int j) communicate is k.now, on the page number 30 of the book(both, the ebook and the hard copy) the authors state, main and getline communicate through a pair of arguments and a returned value. in getline, the arguments are declared by the line int getline(char s[], int lim);as i understand, char s[] and int lim are parameters, because they are written in the definition of the function getline, not in the call of that function, so my question is, why have the authors used the word argument in the second paragraph of page number 30?",
    "present_kp": [
      "c",
      "parameters",
      "definition"
    ],
    "absent_kp": [
      "declarations"
    ]
  },
  {
    "text": "find first unique char in string. i intentionally avoided python tools which would make this even more trivial. i would like to be reviewed on efficiency, style, and obviously if there is a bug i would like to know.def unique_char(s): ''' find first non-repeated char in a string ''' mydict = {} first = len(s) for c in s: if c in mydict.keys(): mydict[c] += 1 else: mydict[c] = 1 if 1 in mydict.values(): for k,v in mydict.items(): if v == 1: if s.index(k) < first: first = s.index(k) return s[first] return(false)",
    "present_kp": [
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "easily moving both direction of time during a rebase. after i have written some commits, i very often git rebase -i over them, in order to test them, if necessary split them, take parts form one commit and squash them to another, more appropriate one.but there is a problem. say, today i am hunting for a bug, that 5 recent commits are causing. i rebase interactively on the last known to work (bear with me, not using git bisect for a reason). the next commit introduces the bug, but is a big mess some unrelated code. so i git reset head~ and then form several internally logical commits.here is the problem. i do not know which is the first problematic commit. so i select edit for all commits when rebasing. after i am done with the problematic commit, i have a couple of commits in the past, that i would like to test further.currently, i do git rebase --continue many times, until the rebase is complete, and then rebase interactively again. this has a few problems:it is tedious. at the very least, i would like a command that rebases to the top of the branch, skipping all edit declared commits.neverending merges. i need to merge often, and would prefer to first do the meaningful job of splitting the original commit, and only after that git commit --ammend the latter commits in order to be compatible with the edited hystory.tl;dr;how can i achieve this bi-directional traversal on a branch, while at the same time, creating, removing and amending commits? or is this workflow conceptually wrong?",
    "present_kp": [
      "git"
    ],
    "absent_kp": []
  },
  {
    "text": "an alternative to the object paradigm. i've been playing around with an alternative to the standard object-oriented paradigm for modeling data, and i would like to know if there is any research or already existing systems along the same lines. let me briefly explain my ideas.what i call the object-oriented paradigm goes something like this. objects are representations of physical entities or concepts. an object can consist of components (other objects), and have various attributes and methods (member functions). for example, a car can be represented by an object having four wheels, a gas pedal, a steering wheel, and various methods for driving around. moreover, each object is part of a type (or class), defined as a set of objects having the same kinds of attributes and methods (like the class of all cars). importantly, these attributes and methods are in some sense an integral part of the object; the object is composed of its parts. so the car objects represents the whole physical thing, including all its parts and its behavior. (i'm sure this stuff is very familiar to you.)now, for various reasons i'm considering a fundamentally different view, which we might call the network-oriented paradigm. in this view, objects do not exist. instead, each physical entity or concept is represented by one indivisible atom, which by itself carries no information. instead, all the information about the entity --- its attributes and methods --- are encoded as links to other atoms. for example, a car atom would have links to four wheel-atoms, one gas pedal atom, one steering wheel atom, and to various methods for driving cars around. the key difference is that, in this network view, these atoms that are connected to the car atom are not part of the car. there is no sharp boundary defining what is part of or inside an entity, only links connecting atoms to provide them with attributes and behavior. moreover, atoms are not typed, at least not in the usual object-as-instance-of-class sense. any atom can connect to many other atoms, resulting in a kind of network (hence the name). i think this view is more flexible in various ways; for example, one can easily create a version of a car with three wheels by simply removing one of the links, without having to redesign an entire class hierarchy. and i also like it better for philosophical reasons :)question: does anyone know of an existing system or language, or theoretical papers where something like this has been explored? i haven't found anything similar in the literature when googling, but i'm not a theoretical computer scientist (i work in computational biology) so i just might not know where to look. i'm experimenting with a network-oriented system like this on my spare time, mostly for fun, but i also think data modeling along these lines would be more useful in my field than the object-oriented tools we have now.",
    "present_kp": [],
    "absent_kp": [
      "modelling",
      "object oriented"
    ]
  },
  {
    "text": "permissions confusion when executing binaries via script. ls -al /home/dmsinst1/sqllib/adm/db2start-r-sr-sr-x 1 root dmsiadm1 93613 jun 26 14:14 /home/dmsinst1/sqllib/adm/db2start ls -al /home/bpminst1/sqllib/adm/db2start-r-sr-sr-x 1 root bpmiadm1 93613 jun 26 14:15 /home/bpminst1/sqllib/adm/db2startgroups dmsinst1dmsinst1 : dmsiadm1groups bpminst1bpminst1 : bpmiadm1so, when running the following script as root:#!/bin/bashsu bpminst1 -c /home/bpminst1/sqllib/adm/db2startsu dmsinst1 -c /home/dmsinst1/sqllib/adm/db2starti get:[root@dmsnl857-vm ~]# ./startall.sh sql1092n the requested command or operation failed because the user id does not have the authority to perform the requested command or operation. user id: bpminst1.06/29/2017 09:16:03 0 0 sql1063n db2start processing was successful.sql1063n db2start processing was successful.the second command is apparently executed without errors. update: with set -x[root@dmsnl857-vm ~]# ./startall.sh + echo 'starting bpm db2 instance ... 'starting bpm db2 instance ... + su bpminst1 -c /home/bpminst1/sqllib/adm/db2startsql1092n the requested command or operation failed because the user id does not have the authority to perform the requested command or operation. user id: bpminst1.+ echo 'starting dms db2 instance ... 'starting dms db2 instance ... + su dmsinst1 -c /home/dmsinst1/sqllib/adm/db2start06/29/2017 09:44:13 0 0 sql1063n db2start processing was successful.sql1063n db2start processing was successful.",
    "present_kp": [
      "permissions",
      "db2"
    ],
    "absent_kp": [
      "shell",
      "binary"
    ]
  },
  {
    "text": "how do you handle minor change in source code causing discontinuity in version tree?. for instance, i have a file with poor indentation (at least incoherant with the rest of the project).if i correct the indentation and commit, there will be a serious change in the file at a certain point in time, causing the diffs between versions before and after that serious change to be hard to read.how do you handle that king of minor logical modification causing major diffs ?",
    "present_kp": [],
    "absent_kp": [
      "version control",
      "code quality"
    ]
  },
  {
    "text": "i want to be a developer (website and web application) and want to choose asp.net as a programming lang. i want to be a developer (website and web application) and want to choose asp.net as a programming lang.i am currently an intermediate web designer. my friend told me that there are many things in asp.netmy question is i am interested in website and web application developmentis there any specific thing i have to learn to be a web developer or i have to learn the whole. also, what does a developer has to do? key skills if he choose asp.net?thanks :)",
    "present_kp": [],
    "absent_kp": [
      "web development",
      "language",
      "recommendations"
    ]
  },
  {
    "text": "is interaction more powerful than algorithms?. i've heard the motto interaction is more powerful than algorithms from peter wegner. the basis of the idea is that a (classical) turing machine cannot handle interaction, that is, communication (input/output) with the outside world/environment.how can this be so? how can something be more powerful than a turing machine? what is the essence of this story? why is it not more well known?",
    "present_kp": [],
    "absent_kp": [
      "computability",
      "computation models"
    ]
  },
  {
    "text": "can't determine why exit code is not being logged. weird one, so the following will not log bash exit code...#!/usr/bin/env bashoutput_path=${project_root:-$pwd}/npm-install-output.lognpm --loglevel=warn --progress=false install > ${output_path} 2>&1 &&export node_path=${node_path}:~/.suman/node_modules &&node $(dirname $0)/test.js &&exit=$? &&echo && # newlineecho bash exit code => $? &&exit ${exit}if i remove one && after the node command like so:#!/usr/bin/env bashoutput_path=${project_root:-$pwd}/npm-install-output.lognpm --loglevel=warn --progress=false install > ${output_path} 2>&1 &&export node_path=${node_path}:~/.suman/node_modules &&node $(dirname $0)/test.js # <<<<< removed && charsexit=$? &&echo && # newlineecho bash exit code => $? &&exit ${exit}then the node process will exit with a non-zero code, but then bash says:bash exit code => 0both of these are not giving correct results, there is something wrong with my code. i want to capture the correct exit code of the node process, and i want to print it out! what could be wrong?",
    "present_kp": [
      "bash",
      "exit"
    ],
    "absent_kp": [
      "shell script",
      "return status"
    ]
  },
  {
    "text": "how to remove language parameter from url in google webmaster tools. there is a section named url parameters for dealing changes in url structure, recently i remove language code from url, how can i notify google about that?<url> to <url>",
    "present_kp": [],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "can rsync resume after being interrupted?. i used rsync to copy a large number of files, but my os (ubuntu) restarted unexpectedly. after reboot, i ran rsync again, but from the output on the terminal, i found that rsync still copied those already copied before. but i heard that rsync is able to find differences between source and destination, and therefore to just copy the differences. so i wonder in my case if rsync can resume what was left last time?",
    "present_kp": [
      "rsync"
    ],
    "absent_kp": []
  },
  {
    "text": "confused about piping commands from find to commandx?. i have a script, run.sh, that looks like this:#!/bin/bashfiles=$(find corpus/ -type f)for i in $filesdo ./individual.sh $idoneit runs without problem.i want to do away with the run script by piping each file from find to ./individual.i would think that i could just do:find corpus/ -type f | ./individual.shbut in trying that it just pipes in a file with file name (leading to an error).what is the proper syntax for this?",
    "present_kp": [
      "find",
      "pipe"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "how to test web apps with microsoft login on local network. i'm making a web app for mobile that needs to rely on microsoft authentication.so i registered the app under <url> and it works fine when i allow <url> as redirect uri.however, this means i can only test it on the local computer browser, and not from a different device (which is kinda needed when developing for mobile). when i try to replace the localhost with the local ip-address of the server, ms doesn't want to allow it due to special characters in the url.the app eventually needs to be published, but it's currently way too early for that.is there a possibility to test this on a mobile device now?",
    "present_kp": [
      "authentication",
      "microsoft"
    ],
    "absent_kp": [
      "ip address",
      "registration"
    ]
  },
  {
    "text": "how do i look up nic handles for whois?. sometimes, i look up the whois for an ip address, and only see nic handles listed.how do i look up those handles directly using the command line whois client? i've tried whois <nic-handle> but that doesn't work. i see that there is a -t option, but for the life of me can't figure out what type i should put for a nic handle.better yet, is there a way to have each nic handle listed by whois automatically looked up as part of the original query?",
    "present_kp": [
      "whois"
    ],
    "absent_kp": []
  },
  {
    "text": "4-bit input, 5-bit output, logical right shift by 2, which is the correct set of 5 output bits?. suppose i have the following inputs:11101111if i perform a logical right shift by 2 on each, are the 5-bit outputs these:0011100111or these:0111001111if it's neither, then i'd appreciate an explain why and what i've done wrong!",
    "present_kp": [],
    "absent_kp": [
      "boolean algebra"
    ]
  },
  {
    "text": "extract row if both column values appear in a single column from a separate file. i need help with awk. i have two tab-separated files:file 1123 456135 567234 478file 2123 notimportant notimportant2456 notimportant notimportant2987 notimportant notimportant2135 notimportant notimportant2234 notimportant notimportant2478 notimportant notimportant2i need to extract lines from file1 if both entries in a single row are present in file2's first column. so the output file should be like:output123 456234 478i previously used this awk command to extract rows if only the first column of file1 matched 1st column of file2awk 'fnr==nr{a[$1];next}($1 in a){print}' file2 file1but i don't know how to expand it. any advice would be appreciated!",
    "present_kp": [
      "awk"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "which resolutions should i make a favicon in?. i understand that you can create a favicon.ico with multiple resolutions embedded.which resolutions should your average website support? why?edit: performance should be a consideration. i want to keep the favicon around 1k to stay inline with these recommendations: <url>",
    "present_kp": [
      "performance",
      "favicon"
    ],
    "absent_kp": []
  },
  {
    "text": "how to search outlook.com deleted mail?. how can i search within my deleted emails in outlook.com? (or, for that matter, live.com.) advanced search allows searches of folders but the deleted folder is not an option.i am sweeping old retailer emails but want to ensure that no account, order, or shipping emails land in the trash. yes, i know about marking as important, but want to double-check the process.",
    "present_kp": [
      "outlook.com"
    ],
    "absent_kp": []
  },
  {
    "text": "how to make my linux-2.6.24.4 to identify a hard disk with serial mode on intel 3201 mainboard. how to make my linux-2.6.24.4 to identify a sata hard disk on an intel 3201 mainboard?i have pre-load modules libata.ko ahci.ko scsi_mod.ko sd_mod.ko, but it doesn't work on intel 3210 mainboard. on an intel 5000p mainboard it works.any modules i should to load for support intel 3210 sata hard disk support?",
    "present_kp": [
      "sata"
    ],
    "absent_kp": []
  },
  {
    "text": "unable to chown recursively. i'm using this command:chown root:www-data /var/www/example.com -r but i get an error message that the directory is not listed. what is wrong?",
    "present_kp": [
      "chown"
    ],
    "absent_kp": [
      "linux",
      "ubuntu"
    ]
  },
  {
    "text": "why is resolv.conf emptied every time i dis/connect from the internet in debian?. i'm using debian 9.1 with kde and i noticed that resolv.conf gets cleared every time i disconnect or connect to the internet. why is that? why doesn't it keep its contents?if its contents (at least partly?) depend on the connection-settings or the network or router connected to then shouldn't it keep the contents and only change them if necessary?shouldn't all changes to it be authorized explicitly by the user?another reason for why that is problematic is that it's hard to keep track and log changes to the file otherwise.",
    "present_kp": [
      "debian",
      "resolv.conf"
    ],
    "absent_kp": []
  },
  {
    "text": "how is /proc/net files getting populated in linux/unix?. i'm working on a network monitor for linux, without packet sniffing. i'm planning to read the network statistics and related data from /proc/net files.i know that /proc is the mount point of process file system which is a virtual file system that reflects the kernel internal data structure.i like to know how is it populated and is it possible to read the os internals directly.",
    "present_kp": [
      "proc"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "hateoas vs frontend app gui. i've just found hateoas. i think i kind of understand what is stands for, but something is not clear to me. there is nowhere to be found how can i create the consuming client in html. i can imagine that for some links i will generate buttons, for others there will be hyperlinks. this can so far be done.but how to create the gui to be independent. i meanhow to create the gui pages in a generic way (layout cannot be part of the api)how to describe data i.e form definition, table content, client will not know how the data looks like(for html it is reasonable human can interpret them correctly)how to limit data(user cannot access some fields)i'm expecting still to have a lot of logic in the front end. is it even possible to create generic + good looking front end?",
    "present_kp": [
      "hateoas"
    ],
    "absent_kp": []
  },
  {
    "text": "set the preference for sending packages through an specific network device. i have sl 6.3 installed on two machines. machine a is a workstation and has two interface eth0 and wlan0. using eth0, it is connected to machine b (public facing server) with static ip address. both connect to the internet through their respective wlan0 interface.the problem is when the workstation is connected to the server, it sends all the packets including those of the internet to eth0 and therefore fails. to use the internet on workstation, i need to disconnect eth0 and if i do so then my ssh connection (over eth0)to the server hangs!is there someway, i can compel my workstation to send internet packets to wlan0 irrespective of the connection state of eth0.",
    "present_kp": [],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "choose a terminal emulator from java. i am writing a platform independent java console tool and within which will have to execute some commands in separate independent terminal at runtime.however, i need to know which terminal should i be using gnome-terminal or xterm. i.e. the one available on that particular system.since there are many different linux variants are available. i want to support at least the most obvious ones.normally in java system.getproperty(os.name) returns linux but it doesn't tell you if its ubuntu or any other linux varient. so it is difficult to know which terminal to start at runtime. whether gnome-terminal or xterm or if there is anything else as well that i don't know.working sets:in windows:cmd /c start java -jar jartool argumentsin ubuntu:gnome-terminal --execute java -jar jartool argumentsorxterm -e java -jar jartool argumentsalso just for additional information,i am using runtime.getruntime().exec(args or commands) to start terminal from java program at runtime.",
    "present_kp": [
      "java",
      "terminal emulator"
    ],
    "absent_kp": []
  },
  {
    "text": "intentionally incorrect use of language features, specifically ref in c#, as a hint to colleagues. i recently came across a piece of code something like this (roughly c#):public bool validatestuff(ref arraylist listoferrors, stuff thingstovalidate){ if (!thingstovalidate.isvalid() ) { errors.add(new error!); }}arraylist errors = [];bool valid = validatestuff(ref errors, stufftovalidate);the key thing is the ref keyword - there is no need to use that keyword given the functionality here, and when i asked why it was there i was told that it had only been added as a kind of warning that the errors parameter is manipulated by the method, it's not purely used as input.this immediately seemed wrong to me (ref has a purpose, and here it is not being used according to its purpose), but the idea of forcing (since you have to use ref when calling the method) a reminder of slightly counter-intuitive usage seemed reasonable, and i couldn't immediately think of a better way, apart from liberal use of comments. what do you think?extra credit: how could this method be better? perhaps by simply returning a new list of errors which is added to the main list in the calling code? by providing two methods, one for the test and one for the errors? or is it fine as it is?",
    "present_kp": [
      "c#",
      "comments"
    ],
    "absent_kp": [
      "syntax"
    ]
  },
  {
    "text": "yum update baseurl error. i am new centos, i tried to install openssh usingyum -y install openssh-server openssh-clientswhich resulted in loaded plugins: fastestmirror, refresh-packagekit, securityloading mirror speeds from cached hostfilecould not retrieve mirrorlist <url> error was14: pycurl error 6 - couldn't resolve host 'mirrors.rpmfusion.org'error: cannot find a valid baseurl for repo: rpmfusion-freei tried yum clean all did not helpyum update --disablerepo=rpmfusion shows loaded plugins: fastestmirror, refresh-packagekit, security error getting repository data for rpmfusion, repository not found",
    "present_kp": [
      "yum",
      "repository",
      "centos"
    ],
    "absent_kp": []
  },
  {
    "text": "what keeps the cerebrospinal fluid circulating? is it pumped by something?. what keeps the cerebrospinal fluid circulating? is it pumped by something?this picture from wikipedia seems to indicate that it pulsates as though it is pumped:",
    "present_kp": [],
    "absent_kp": [
      "physiology",
      "neuroanatomy"
    ]
  },
  {
    "text": "difference between printf and echo in bash. what is the difference between the printf function in bash and the echo function?specifically, running:echo blah >/dev/udp/localhost/8125did not send the blah command to the server listening on 8125, whereasprintf blah >/dev/udp/localhost/8125sent the data. does printf send an extra eof at the end of its output?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": []
  },
  {
    "text": "are @live.co.uk and @live.com the same microsoft/windows live/mail/outlook.com/skydrive account?. are @live.co.uk and @live.com the same microsoft/windows live account?for example:email sent to an address at @live.co.uk arrive in the same mailbox as @live.com ?do @live.co.uk and @live.com share the same skydrive?i would prefer if they did share the same account. but if not:i can use either the global/generic top level domain (gtld - live.com) as the main account and have the country code top level domain (cctld - live.co.uk) as a linked account for emails as i think that it is possible to setup microsoft web mail/hotmail/outlook.com to fetch mail from other accountsthe skydrive entitlement with live.co.uk could not be linked to the live.comlet me know your answer to 1. and your response to my suggestion in 2",
    "present_kp": [
      "windows live"
    ],
    "absent_kp": [
      "account management",
      "windows live mail",
      "onedrive"
    ]
  },
  {
    "text": "what causes a copy/paste in terminal to sometimes execute the command?. when you paste some command in terminal, it will sometimes automatically execute the command (just like if the enter key was pressed), sometimes not. i've been using linux for ages, pasted thousands of commands in various consoles on many distros, and i am still unable to tell if the command i'm about to paste will be executed automatically or not. what triggers this behavior?",
    "present_kp": [
      "terminal",
      "command"
    ],
    "absent_kp": [
      "clipboard"
    ]
  },
  {
    "text": "shadow mapping errors. i recently started to create a shadow mapping system in opentk.i ran into a problem: the depthtexture is always completly white -> no depth. even if the color from the shader is changed (i know it shouldn't effect anything.).here is my shadow mapper class:class shadowmapper{ static int framebuffer = 0; static int depthtexture; static readonly int shadowmapresolution = 1024; static shadowshader shader; public static void init() { shader = new shadowshader(); framebuffer = gl.genframebuffer(); gl.bindframebuffer(framebuffertarget.framebuffer, framebuffer); depthtexture = gl.gentexture(); gl.bindtexture(texturetarget.texture2d, depthtexture); gl.teximage2d(texturetarget.texture2d, 0, pixelinternalformat.depthcomponent16, shadowmapresolution, shadowmapresolution, 0, pixelformat.depthcomponent, pixeltype.float, (intptr)null); gl.texparameter(texturetarget.texture2d, textureparametername.texturemagfilter, (int)texturemagfilter.nearest); gl.texparameter(texturetarget.texture2d, textureparametername.textureminfilter, (int)textureminfilter.nearest); gl.texparameter(texturetarget.texture2d, textureparametername.texturewraps, (int)texturewrapmode.clamptoedge); gl.texparameter(texturetarget.texture2d, textureparametername.texturewrapt, (int)texturewrapmode.clamptoedge); gl.framebuffertexture(framebuffertarget.framebuffer, framebufferattachment.depthattachment, depthtexture, 0); gl.drawbuffer(drawbuffermode.none); console.writeline(gl.checkframebufferstatus(framebuffertarget.framebuffer) == framebuffererrorcode.framebuffercomplete); gl.bindframebuffer(framebuffertarget.framebuffer, 0); } public static void render(dictionary<texturedmodel, list<entity>> entities, light sun) { matrix4 depthprojectionmatrix = matrix4.createorthographic(-10, 10, -10, 10); matrix4 depthviewmatrix = matrix4.lookat(sun.position, sun.tolookposition, new vector3(0, 1, 0)); gl.bindtexture(texturetarget.texture2d, 0); gl.bindframebuffer(framebuffertarget.framebuffer, framebuffer); gl.viewport(0, 0, shadowmapresolution, shadowmapresolution); gl.enable(enablecap.depthtest); gl.clear(clearbuffermask.depthbufferbit); shader.start(); foreach (texturedmodel model in entities.keys) { rawmodel rawmodel = model.model; gl.bindvertexarray(rawmodel.vaoid); gl.enablevertexattribarray(0); foreach (entity entity in entities[model]) { matrix4 depthmodelmatrix = maths.createtransformationmatrix(entity.position, entity.rotationx, entity.rotationy, entity.rotationz, entity.scale); matrix4 depthmvp = depthprojectionmatrix * depthviewmatrix * depthmodelmatrix; shader.loadmvpmatrix(depthmvp); gl.drawelements(primitivetype.triangles, rawmodel.vertexcount, drawelementstype.unsignedint, 0); } } gl.disablevertexattribarray(0); gl.bindvertexarray(0); gl.disable(enablecap.depthtest); shader.stop(); gl.bindframebuffer(framebuffertarget.framebuffer, 0); gl.viewport(0, 0, window.instance.width, window.instance.height); } public static int depthtexture { get { return depthtexture; } }}and my vertex/fragment shaders: vertex shader: #version 330 core// input vertex data, different for all executions of this shader.in vec3 vertexposition_modelspace;// values that stay constant for the whole mesh.uniform mat4 depthmvp;void main(){gl_position = depthmvp * vec4(vertexposition_modelspace,1);}fragment shader: #version 330 core // ouput data out float fragmentdepth; out vec4 out_colour; void main(){ // not really needed, opengl does it anyway fragmentdepth = gl_fragcoord.z; out_colour = vec4(1.0, 0.0, 0.0, 0.0); }any help?",
    "present_kp": [
      "opengl",
      "shader",
      "shadow"
    ],
    "absent_kp": []
  },
  {
    "text": "how to put lessons learned, good practices, etc into the work flow. as the title states it, i would like to get some suggestions about putting knowledge into action.we have many additional requirements that concern: coding practices feature development (all of them or only a subset), process, etc. the problem is that we have problems with introducing those practices into new projects and i want to help developers and reviewers to remember about it, but i don't want them to have everything just in theirs heads, but rather in some kind of a database that they can use easily.the list of practices is already defined in excel. i would like all team members to apply these practices in their work but i don't know how make those information easy to find. when developer starts working on a feature he should be able to easily find all practices that he should use in these feature.to be clear with what i mean, i'm showing some examples of information we have to apply:(new design request) every feature must output logs (and it must not contain any sensitive data);(new design request) every feature has to have a flag in the configuration that allows to disable it;(good practice) always update docs when feature is ready;(retrospective feedback) qa must test only on release package (not in debug mode);(retrospective feedback) make stress tests for every new feature implemented;(lead's task) write release notes after each sprint that includes tasks completed and open bugs;(design usage) every event from abcstoremanager must be disconnected after being invoked;(design usage) try-catch every event.invoke() call;i thought for a while about a wiki, but it's no good, because it doesn't support tagging/categories or querying and i'm afraid that everybody would ignore it (people must know exactly where to look).my question can be summed up as how can i improve communication to our developers about the required development methodologies and practices listed above in an easy way?remarks:this question is not about security issues or code smells per-se;i'm not looking for any heavy process (like rup) or any process for that matter, which forces you to go step by step. preferably i am looking for an agile approachdaniel figueroa has suggested adding additional requirements to the definition of done. and it seems like a good way. but the problem is that some features have, for instance, 20 additional requirements (all gui features), some 10 (all server requests), etc. i would like to have this stuff aggregated in a one place and just use links (see: 'gui feature' );",
    "present_kp": [],
    "absent_kp": [
      "programming practices",
      "development process",
      "specifications"
    ]
  },
  {
    "text": "usb tethering iphone 5. i'm having trouble tethering my iphone 5 with my linux mint maya (with xfce) computer. it works as a wifi hotspot but not with the usb cable. when i connect it the phone asks whether it should trust the computer. i say yes but i can't find a wired connection. if choose edit connections (by right-clicking the the wifi signal icon) i see there is a wired connection that says last used 5 minutes ago.if i run idevicepair unpair i get this message: error: device 0deb4ead2a1af3dc107310d70a58a43b7d70295e is not paired with this host am i missing something?",
    "present_kp": [
      "iphone"
    ],
    "absent_kp": []
  },
  {
    "text": "name for function in big o but not in little o?. let $f(n) = o(g(n))$, but not $f(n) = o(g(n))$. that's a nice property, because it means that we cannot replace $g(n)$ with a substantially smaller function. is there a name for this choice of $g(n)$? obviously this covers more cases than just $f(n) = \\theta (g(n))$. it requires the existence of $c > 0$ such that $f(n)\\geq cg(n)$ for infinitely many $n$.",
    "present_kp": [],
    "absent_kp": [
      "terminology",
      "asymptotics"
    ]
  },
  {
    "text": "how does g+ hangout screen sharing work?. i'm curious if it's using html5 or if there's a plugin/extension required to run it. anyone have ideas on how this works, and if there's any known implementations of it outside of g+?",
    "present_kp": [],
    "absent_kp": [
      "google hangouts"
    ]
  },
  {
    "text": "what is the difference between ' and ?. i tried to create a text file in a bash script.the echo command spans multiple lines and has some double quotes .#!/bin/bash echo blabla bla bla bla blabla bla bla bla bla blaand so on and so onbla blablu bla bla bla bla bla bla > /root/bin/blathere are many double quotes in echo command that is undesirable.and i did #!/bin/bash echo 'blabla bla bla bla blabla bla bla bla bla blaand so on and so onbla blablu bla bla bla bla bla bla' > /root/bin/blai wondered if there are any difference between double quote and single quote 'which one has higher priority? is it just the fact that they are visually different?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell script",
      "quoting"
    ]
  },
  {
    "text": "using prolog to implement authorization rules. i'm working on a user management pseudoframework in php, and i'm trying to implement fine-grained rule-based authorization. i'm using a combination of sql and condition-checking functions written in php right now, but i'm not completely satisfied. it works, but it is not very elegant and suffers from some limitations.prolog is turing-complete, so it occurs to me that any arbitrary authorization rules could be implemented this way. for example:in_group(alice,admin).in_group(alice,user).in_group(bob,user).in_group(carlos,admin).in_group(carlos,user).allowed(delete_user,x,y):- in_group(x,admin), not(in_group(y,admin)).this basically says only allow user x to delete user y if x is an admin and y isn't.my questions are basically:will issues in scalability still arise in modern prolog implementations?how would these issues be complicated by the way that people typically use web applications?what are the risks of compromising security due to the unintended consequences of some prolog constructs?how difficult will this make it for people without a prolog background to modify authorization rules? the above example looks straightforward to me, but what if there are thousands of rules?if prolog isn't the best idea for this situation, are there other logic programming languages that might be better suited?i read this post: why aren't rule engines written in prolog?, but that question seems to be about rules engines in general, not authorization rules specifically.",
    "present_kp": [
      "php",
      "authorization",
      "prolog",
      "rules engine"
    ],
    "absent_kp": [
      "web development"
    ]
  },
  {
    "text": "what's the best approach to achieve two-way communication with tidtcpserver and tidtcpclient?. i'm a newbie in delphi and i'm trying to create a client/server application using indy. i want to have a server that is capable not only of receiving messages and streaming, but also sending data to clients at any given time. the clients must have same capabilities. i built a prototype app using tidtcpserver and tidtcpclient and it's working within my test environment, but since i'm new on delphi and have no prior experience with tcp programming, i'm not sure if this is the best way of doing it. the communication between server and client occurs when someone (server or clients) sends a command (string) to the other side. if the command is to send a file then first the send_file string is sent and then a stream containing the file.for the server to receive a file, it instructs the client (via string command) to ask for the file: server sends rcv_file to client which reads the command and sends a send_file string command to server and then the actual file via streaming right after.server //==============================================================================// server execute procedure//==============================================================================procedure tfrmmain.tcpserverexecute(acontext: tidcontext);var cmd: string; date: tdatetime; timestamp: string; stream: tmemorystream;begin cmd := acontext.connection.iohandler.readln; date := now; timestamp := formatdatetime('yyyymmdd_hhmmss', date); if cmd = 'send_file' then begin try stream := tmemorystream.create; try acontext.connection.iohandler.readstream(stream, -1, false); stream.position := 0; stream.savetofile(extractfilepath(application.exename) + ' ecv_test' + timestamp + '.dat'); except on e: exception do showmessage('error loading file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end; end else if cmd = 'recv_file' then begin try stream := tmemorystream.create; try stream.loadfromfile(extractfilepath(application.exename) + 'test.dat'); stream.position := 0; acontext.connection.iohandler.writeln('send_file'); acontext.connection.iohandler.write(stream, 0, true); except on e: exception do showmessage('error sending file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end; end;end;//==============================================================================// server send file button//==============================================================================procedure tfrmmain.btnsendfileclick(sender: tobject);var list: tlist; ip: string; i: integer; context: tidcontext; stream: tmemorystream;begin // lvwpclist is a listview on my form... // do i need to use tthread.queue to safety access this component? ip := gstack.resolvehost(lvwpclist.selected.caption); try list := tcpserver.contexts.locklist; for i := 0 to list.count - 1 do begin context := tidcontext(list[i]); if context.connection.socket.binding.peerip = ip then begin context.connection.iohandler.writeln('send_file'); try stream := tmemorystream.create; try stream.loadfromfile(extractfilepath(application.exename) + 'test.dat'); stream.position := 0; context.connection.iohandler.write(stream, 0, true); except on e: exception do showmessage('error sending file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end; break; end; end; finally tcpserver.contexts.unlocklist; end;end;//==============================================================================// server get file button//==============================================================================procedure tfrmmain.btngetfileclick(sender: tobject);var list: tlist; ip: string; i: integer; context: tidcontext;begin ip := gstack.resolvehost(lvwpclist.selected.caption); try list := tcpserver.contexts.locklist; for i := 0 to list.count - 1 do begin context := tidcontext(list[i]); if context.connection.socket.binding.peerip = ip then begin context.connection.iohandler.writeln('recv_file'); // after send the string command 'recv_file', the server // will receive the actual file sending by client on the execute event... break; end; end; finally tcpserver.contexts.unlocklist; end;end;//==============================================================================client //==============================================================================procedure threadactionstart;var threadaction: tthreadaction;begin threadaction := tthreadaction.create(true); threadaction.freeonterminate := true; threadaction.priority := tpnormal; threadaction.start;end;//==============================================================================procedure tthreadaction.execute;var cmd: string; date: tdatetime; timestamp: string; stream: tmemorystream;begin while frmmain.idtcpclient.connected do begin try cmd := frmmain.idtcpclient.iohandler.readln; tthread.queue( nil, procedure begin frmmain.lstmessages.items.add(cmd); end ); date := now; timestamp := formatdatetime('yyyymmdd_hhmmss', date); if cmd = 'send_file' then begin try stream := tmemorystream.create; try frmmain.idtcpclient.iohandler.readstream(stream, -1); stream.position := 0; stream.savetofile(extractfilepath(application.exename) + ' ecv_test' + timestamp + '.dat'); except on e: exception do showmessage('error loading file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end; end else if cmd = 'recv_file' then begin try stream := tmemorystream.create; try stream.loadfromfile(extractfilepath(application.exename) + 'test.dat'); stream.position := 0; frmmain.idtcpclient.iohandler.writeln('send_file'); frmmain.idtcpclient.iohandler.write(stream, 0, true); except on e: exception do showmessage('error sending file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end; end; except showmessage('error reading from server'); end; end;end;//==============================================================================procedure tfrmmain.btngetfileclick(sender: tobject);begin frmmain.idtcpclient.iohandler.writeln('recv_file');end;//==============================================================================procedure tfrmmain.btnsendfileclick(sender: tobject);var stream: tmemorystream;begin try frmmain.idtcpclient.iohandler.writeln('send_file'); stream := tmemorystream.create; try stream.loadfromfile(extractfilepath(application.exename) + 'test.dat'); stream.position := 0; frmmain.idtcpclient.iohandler.write(stream, 0, true); except on e: exception do showmessage('error sending file: ' + e.classname + ' - ' + e.message); end; finally stream.free; end;end;//==============================================================================procedure tfrmmain.formcreate(sender: tobject);begin try idtcpclient.host := '192.168.0.20'; idtcpclient.port := 4545; idtcpclient.connect; except showmessage('connection error'); end;end;//==============================================================================procedure tfrmmain.idtcpclientconnected(sender: tobject);begin try threadactionstart; except showmessage('error - thread not started'); end;end;//==============================================================================i would like to know if i'm on the right way, any advice or tips will be helpful.",
    "present_kp": [
      "delphi"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "an executable has two processes and is launched twice on two different terminals how to make the processes identify their roles. i have to write a c code which will contain two processes. and its executable will be launched twice on two different terminals. both processes will know whats their role. one terminal will show result of one process and second terminal will show result of second process.if i make two threads to create these two process can some one help me out that how both processes will recognize their role when launched on terminals?",
    "present_kp": [],
    "absent_kp": [
      "programming"
    ]
  },
  {
    "text": "does a web application have to live in a browser to be called a web application?. does a web application have to live in a browser to be called a web application? or is a thin client that uses a web service for most of it's functionality a web applicaiton?",
    "present_kp": [],
    "absent_kp": [
      "web applications"
    ]
  },
  {
    "text": "count cars passing in opposite directions. the problem comes from codility, whose coding problems i'm starting to enjoy as their evaluation criteria really looks at runtime. task descriptiona non-empty zero-indexed array a consisting of n integers is given. the consecutive elements of array a represent consecutive cars on a road.array a contains only 0s and/or 1s:0 represents a car traveling east, 1 represents a car traveling west. the goal is to count passing cars. we say that a pair of cars (p, q), where 0 p < q < n, is passing when p is traveling to the east and q is traveling to the west.for example, consider array a such that: a[0] = 0 a[1] = 1 a[2] = 0 a[3] = 1 a[4] = 1 we have five pairs of passing cars: (0, 1), (0, 3), (0, 4), (2, 3), (2, 4).write a function: def solution(a)that, given a non-empty zero-indexed array a of n integers, returns the number of passing cars.the function should return 1 if the number of passing cars exceeds 1,000,000,000. for example, given: a[0] = 0 a[1] = 1 a[2] = 0 a[3] = 1 a[4] = 1 the function should return 5, as explained above. assume that: n is an integer within the range [1..100,000]; each element of array a is an integer that can have one of the following values: 0, 1. complexity: expected worst-case time complexity is \\$o(n)\\$; expected worst-case space complexity is \\$o(1)\\$, beyond input storage (not counting the storage required for input arguments). elements of input arrays can be modified.solutioni've tried my hand at 2 different solutions, one where i delete elements from the array but that was slower than my first pass like this:def solution(a) results = 0 a.each_with_index do |el, i| if el == 0 j = i while j <= a.size-1 results += 1 if a[j] != 0 j += 1 end end return -1 if results > <phone> end resultsendi understand why this is \\$o(n^2)\\$, but i'm unsure how to make this faster.",
    "present_kp": [],
    "absent_kp": [
      "performance",
      "algorithm",
      "ruby"
    ]
  },
  {
    "text": "tester-developer communication. while a lot is written about developer-developer, developer-client, developer-team manager communications, i couldn't find any text which gives guidelines about tester-developer communication and relation.whether testers and developers are separate teams or in the same one (in my case, i am a lone tester in an agile development project), i have the belief that how testers are perceived is extremely important in order for testing to be well-accepted, and to serve its goal in enhancing the quality of the project (for example, they should not be viewed as a police force).any advices, or studies about how a tester should communicate with developers?update: thank you all for your answers. they all confirmed what i had in mind. as for now, my team was very receptive of my role and we ended up making real progress. i could have chosen more than one as the answer but i had to make my decision.",
    "present_kp": [
      "communication",
      "testers"
    ],
    "absent_kp": []
  },
  {
    "text": "find the ip from which a person tried to reset gmail password. yesterday i received 2 sms from my gmail account. somebody tried to login to my account. he/she tried to use sms to reset my password. can anybody tell me how to find the ip from which the attacker sent the password recovery sms?i didn't get any email from the gmail team. i could easily login with my previous password after the attack.",
    "present_kp": [
      "gmail",
      "password recovery"
    ],
    "absent_kp": [
      "ip addresses"
    ]
  },
  {
    "text": "permissions help?. so i've set up a wordpress site on my server. the problem i'm having is that wordpress creates new folders to sort content uploaded from the dashboard by day. but, somehow the server doesn't have permission to create new folders. how can i set the permissions so that the server will have full creation/read/write permissions in the directory?also, how can i set it so that the server will automatically have the same permissions over any future subdirectories created in wordpresses's folder?",
    "present_kp": [
      "permissions",
      "wordpress"
    ],
    "absent_kp": [
      "raspberry pi",
      "raspbian"
    ]
  },
  {
    "text": "recover software raid5 data. some days ago i found that the partition related to my raid 5 wasn't mounted. i examined my disks and i got:mdadm --examine /dev/sd{a,b,c,d}1mdadm: no md superblock detected on /dev/sda1./dev/sdb1: magic : a92b4efc version : 1.2 feature map : 0x0 array uuid : 87fdc598:a995d0f7:41123bcf:e2760aeb name : itake:0 (local to host itake) creation time : tue aug 28 17:44:52 2012 raid level : raid5 raid devices : 4 avail dev size : <phone> (931.32 gib 1000.00 gb) array size : <phone> (2793.96 gib 3000.00 gb) used dev size : <phone> (931.32 gib 1000.00 gb) data offset : 2048 sectors super offset : 8 sectors unused space : before=1968 sectors, after=648 sectors state : clean device uuid : db15e0ad:ef9f28be:de5e5a5a:f929ebb9 update time : sun sep 11 00:00:26 2016 checksum : 700e7a14 - correct events : 6141 layout : left-symmetric chunk size : 512k device role : active device 1 array state : aa.a ('a' == active, '.' == missing, 'r' == replacing)/dev/sdc1: magic : a92b4efc version : 1.2 feature map : 0x0 array uuid : 87fdc598:a995d0f7:41123bcf:e2760aeb name : itake:0 (local to host itake) creation time : tue aug 28 17:44:52 2012 raid level : raid5 raid devices : 4 avail dev size : <phone> (931.32 gib 1000.00 gb) array size : <phone> (2793.96 gib 3000.00 gb) used dev size : <phone> (931.32 gib 1000.00 gb) data offset : 2048 sectors super offset : 8 sectors unused space : before=1968 sectors, after=648 sectors state : clean device uuid : f3c74ca8:076e5078:305ad83b:159f048d update time : sun sep 4 00:08:53 2016 checksum : d9306794 - correct events : 5896 layout : left-symmetric chunk size : 512k device role : active device 2 array state : aaaa ('a' == active, '.' == missing, 'r' == replacing)/dev/sdd1: magic : a92b4efc version : 1.2 feature map : 0x0 array uuid : 87fdc598:a995d0f7:41123bcf:e2760aeb name : itake:0 (local to host itake) creation time : tue aug 28 17:44:52 2012 raid level : raid5 raid devices : 4 avail dev size : <phone> (931.32 gib 1000.00 gb) array size : <phone> (2793.96 gib 3000.00 gb) used dev size : <phone> (931.32 gib 1000.00 gb) data offset : 2048 sectors super offset : 8 sectors unused space : before=1968 sectors, after=648 sectors state : clean device uuid : 4b376772:29ca4f41:342d39df:877fece0 update time : sun sep 11 00:00:26 2016 checksum : 639ce9a5 - correct events : 6141 layout : left-symmetric chunk size : 512k device role : active device 3 array state : aa.a ('a' == active, '.' == missing, 'r' == replacing) so i thought that only sda was damaged and i could recover the information. i bought a new disk and now i saw that it wasn't sda only but sdc as well. i wonder if there is any chance of try to repair any of two disks to try to recreate and recover the information before replace both...i leave here some useful information about the errors, if you need something else please let me knowcat /proc/mdstatpersonalities : [raid6] [raid5] [raid4]unused devices: <none> cat /var/log/syslognov 11 09:16:59 itake kernel: [ 18.230695] sd 0:0:0:0: [sda] unhandled sense codenov 11 09:16:59 itake kernel: [ 18.230698] sd 0:0:0:0: [sda] result: hostbyte=did_ok driverbyte=driver_sensenov 11 09:16:59 itake kernel: [ 18.230703] sd 0:0:0:0: [sda] sense key : medium error [current] [descriptor]nov 11 09:16:59 itake kernel: [ 18.230708] descriptor sense data with sense descriptors (in hex):nov 11 09:16:59 itake kernel: [ 18.230711] 72 03 11 04 00 00 00 0c 00 0a 80 00 00 00 00 00nov 11 09:16:59 itake kernel: [ 18.230721] 00 00 08 08nov 11 09:16:59 itake kernel: [ 18.230726] sd 0:0:0:0: [sda] add. sense: unrecovered read error - auto reallocate failednov 11 09:16:59 itake kernel: [ 18.230734] sd 0:0:0:0: [sda] cdb: read(10): 28 00 00 00 08 08 00 00 08 00nov 11 09:16:59 itake kernel: [ 18.230744] end_request: i/o error, dev sda, sector 2056nov 11 09:16:59 itake kernel: [ 18.230796] buffer i/o error on device sda1, logical block 1nov 11 09:16:59 itake kernel: [ 18.230881] ata1: eh complete...nov 11 09:16:59 itake kernel: [ 104.221334] sd 2:0:0:0: [sdc] unhandled sense codenov 11 09:16:59 itake kernel: [ 104.221337] sd 2:0:0:0: [sdc] result: hostbyte=did_ok driverbyte=driver_sensenov 11 09:16:59 itake kernel: [ 104.221342] sd 2:0:0:0: [sdc] sense key : medium error [current] [descriptor]nov 11 09:16:59 itake kernel: [ 104.221347] descriptor sense data with sense descriptors (in hex):nov 11 09:16:59 itake kernel: [ 104.221350] 72 03 11 04 00 00 00 0c 00 0a 80 00 00 00 00 00nov 11 09:16:59 itake kernel: [ 104.221360] 74 70 68 00nov 11 09:16:59 itake kernel: [ 104.221365] sd 2:0:0:0: [sdc] add. sense: unrecovered read error - auto reallocate failednov 11 09:16:59 itake kernel: [ 104.221372] sd 2:0:0:0: [sdc] cdb: read(10): 28 00 74 70 68 00 00 01 d0 00nov 11 09:16:59 itake kernel: [ 104.221381] end_request: i/o error, dev sdc, sector 1953523712nov 11 09:16:59 itake kernel: [ 104.221431] buffer i/o error on device sdc, logical block 244190464nov 11 09:16:59 itake kernel: [ 104.221482] buffer i/o error on device sdc, logical block 244190465nov 11 09:16:59 itake kernel: [ 104.221524] buffer i/o error on device sdc, logical block 244190466nov 11 09:16:59 itake kernel: [ 104.221567] buffer i/o error on device sdc, logical block 244190467nov 11 09:16:59 itake kernel: [ 104.221608] buffer i/o error on device sdc, logical block 244190468nov 11 09:16:59 itake kernel: [ 104.221649] buffer i/o error on device sdc, logical block 244190469nov 11 09:16:59 itake kernel: [ 104.221690] buffer i/o error on device sdc, logical block 244190470nov 11 09:16:59 itake kernel: [ 104.221731] buffer i/o error on device sdc, logical block 244190471nov 11 09:16:59 itake kernel: [ 104.221772] buffer i/o error on device sdc, logical block 244190472nov 11 09:16:59 itake kernel: [ 104.221813] buffer i/o error on device sdc, logical block 244190473nov 11 09:16:59 itake kernel: [ 104.221897] ata3: eh completenov 11 09:16:59 itake kernel: [ 107.652344] ata3.00: exception emask 0x0 sact 0x7 serr 0x0 action 0x0nov 11 09:16:59 itake kernel: [ 107.652389] ata3.00: irq_stat 0x40000008nov 11 09:16:59 itake kernel: [ 107.652429] ata3.00: failed command: read fpdma queuednov 11 09:16:59 itake kernel: [ 107.652474] ata3.00: cmd 60/08:00:d8:69:70/00:00:74:00:00/40 tag 0 ncq 4096 innov 11 09:16:59 itake kernel: [ 107.652476] res 41/40:00:d8:69:70/00:00:74:00:00/40 emask 0x409 (media error) <f>nov 11 09:16:59 itake kernel: [ 107.652559] ata3.00: status: { drdy err }nov 11 09:16:59 itake kernel: [ 107.652598] ata3.00: error: { unc }nov 11 09:16:59 itake kernel: [ 107.654733] ata3.00: configured for udma/133nov 11 09:16:59 itake kernel: [ 107.654754] ata3: eh complete...nov 11 09:16:59 itake kernel: [ 137.768972] sd 0:0:0:0: [sda] add. sense: unrecovered read error - auto reallocate failednov 11 09:16:59 itake kernel: [ 137.768979] sd 0:0:0:0: [sda] cdb: read(10): 28 00 00 00 08 08 00 00 08 00nov 11 09:16:59 itake kernel: [ 137.768989] end_request: i/o error, dev sda, sector 2056nov 11 09:16:59 itake kernel: [ 137.769067] ata1: eh completenov 11 09:16:59 itake kernel: [ 137.779624] md: md0 stopped.nov 11 09:16:59 itake kernel: [ 138.630989] ata3.00: exception emask 0x0 sact 0x3 serr 0x0 action 0x0nov 11 09:16:59 itake kernel: [ 138.631035] ata3.00: irq_stat 0x40000008nov 11 09:16:59 itake kernel: [ 138.631076] ata3.00: failed command: read fpdma queuednov 11 09:16:59 itake kernel: [ 138.631121] ata3.00: cmd 60/08:00:40:68:70/00:00:74:00:00/40 tag 0 ncq 4096 innov 11 09:16:59 itake kernel: [ 138.631123] res 41/40:00:40:68:70/00:00:74:00:00/40 emask 0x409 (media error) <f>nov 11 09:16:59 itake kernel: [ 138.631206] ata3.00: status: { drdy err }nov 11 09:16:59 itake kernel: [ 138.631245] ata3.00: error: { unc }nov 11 09:16:59 itake kernel: [ 138.633417] ata3.00: configured for udma/133nov 11 09:16:59 itake kernel: [ 138.633443] ata3: eh completenov 11 09:16:59 itake kernel: [ 138.637684] md: bind<sdc1>nov 11 09:16:59 itake kernel: [ 138.637896] md: bind<sdd1>nov 11 09:16:59 itake kernel: [ 138.638139] md: bind<sdb1>nov 11 09:16:59 itake kernel: [ 138.638173] md: kicking non-fresh sdc1 from array!nov 11 09:16:59 itake kernel: [ 138.638180] md: unbind<sdc1>nov 11 09:16:59 itake kernel: [ 138.640178] md: export_rdev(sdc1)nov 11 09:16:59 itake kernel: [ 138.640178] md: export_rdev(sdc1)nov 11 09:16:59 itake kernel: [ 138.708065] raid6: int64x1 1355 mb/snov 11 09:16:59 itake kernel: [ 138.776062] raid6: int64x2 1504 mb/snov 11 09:16:59 itake kernel: [ 138.844062] raid6: int64x4 1284 mb/snov 11 09:16:59 itake kernel: [ 138.912061] raid6: int64x8 1109 mb/snov 11 09:16:59 itake kernel: [ 138.980085] raid6: sse2x1 2124 mb/snov 11 09:16:59 itake kernel: [ 139.048065] raid6: sse2x2 3413 mb/snov 11 09:16:59 itake kernel: [ 139.116061] raid6: sse2x4 4022 mb/snov 11 09:16:59 itake kernel: [ 139.116064] raid6: using algorithm sse2x4 (4022 mb/s)nov 11 09:16:59 itake kernel: [ 139.116302] async_tx: api initialized (async)nov 11 09:16:59 itake kernel: [ 139.116471] xor: automatically using best checksumming function: generic_ssenov 11 09:16:59 itake kernel: [ 139.136056] generic_sse: 6183.000 mb/secnov 11 09:16:59 itake kernel: [ 139.136059] xor: using function: generic_sse (6183.000 mb/sec)nov 11 09:16:59 itake kernel: [ 139.137667] md: raid6 personality registered for level 6nov 11 09:16:59 itake kernel: [ 139.137671] md: raid5 personality registered for level 5nov 11 09:16:59 itake kernel: [ 139.137674] md: raid4 personality registered for level 4nov 11 09:16:59 itake kernel: [ 139.137936] bio: create slab <bio-1> at 1nov 11 09:16:59 itake kernel: [ 139.137960] md/raid:md0: device sdb1 operational as raid disk 1nov 11 09:16:59 itake kernel: [ 139.137964] md/raid:md0: device sdd1 operational as raid disk 3nov 11 09:16:59 itake kernel: [ 139.138427] md/raid:md0: allocated 4280kbnov 11 09:16:59 itake kernel: [ 139.138551] md/raid:md0: not enough operational devices (2/4 failed)nov 11 09:16:59 itake kernel: [ 139.138628] raid conf printout:nov 11 09:16:59 itake kernel: [ 139.138630] --- level:5 rd:4 wd:2nov 11 09:16:59 itake kernel: [ 139.138634] disk 1, o:1, dev:sdb1nov 11 09:16:59 itake kernel: [ 139.138637] disk 3, o:1, dev:sdd1nov 11 09:16:59 itake kernel: [ 139.139106] md/raid:md0: failed to run raid set.nov 11 09:16:59 itake kernel: [ 139.139146] md: pers->run() failed ...nov 11 09:16:59 itake kernel: [ 139.139523] md: md0 stopped.nov 11 09:16:59 itake kernel: [ 139.139532] md: unbind<sdb1>nov 11 09:16:59 itake kernel: [ 139.156130] md: export_rdev(sdb1)nov 11 09:16:59 itake kernel: [ 139.156158] md: unbind<sdd1>nov 11 09:16:59 itake kernel: [ 139.168118] md: export_rdev(sdd1)...smartctl -a /dev/sdasmartctl 6.5 2016-01-24 r4214 [x86_64-linux-3.2.0-4-amd64] (local build)copyright (c) 2002-16, bruce allen, christian franke, <url> start of information section ===model family: samsung spinpoint f3device model: samsung hd103sjserial number: s246j1kz410348lu wwn device id: 5 0024e9 0034ebb37firmware version: 1aj10001user capacity: 1,000,203,804,160 bytes [1.00 tb]sector size: 512 bytes logical/physicalrotation rate: 7200 rpmform factor: 3.5 inchesdevice is: in smartctl database [for details use: -p show]ata version is: ata8-acs t13/1699-d revision 6sata version is: sata 2.6, 3.0 gb/slocal time is: fri nov 11 11:17:00 2016 cetsmart support is: available - device has smart capability.smart support is: enabled=== start of read smart data section ===smart overall-health self-assessment test result: passedgeneral smart values:offline data collection status: (0x00) offline data collection activity was never started. auto offline data collection: disabled.self-test execution status: ( 121) the previous self-test completed having the read element of the test failed.total time to complete offlinedata collection: ( 9300) seconds.offline data collectioncapabilities: (0x5b) smart execute offline immediate. auto offline data collection on/off support. suspend offline collection upon new command. offline surface scan supported. self-test supported. no conveyance self-test supported. selective self-test supported.smart capabilities: (0x0003) saves smart data before entering power-saving mode. supports smart auto save timer.error logging capability: (0x01) error logging supported. general purpose logging supported.short self-test routinerecommended polling time: ( 2) minutes.extended self-test routinerecommended polling time: ( 155) minutes.sct capabilities: (0x003f) sct status supported. sct error recovery control supported. sct feature control supported. sct data table supported.smart attributes data structure revision number: 16vendor specific smart attributes with thresholds:id# attribute_name flag value worst thresh type updated when_failed raw_value 1 raw_read_error_rate 0x002f 100 100 051 pre-fail always - 784 2 throughput_performance 0x0026 252 252 000 old_age always - 0 3 spin_up_time 0x0023 070 069 025 pre-fail always - 9385 4 start_stop_count 0x0032 099 099 000 old_age always - 1225 5 reallocated_sector_ct 0x0033 252 252 010 pre-fail always - 0 7 seek_error_rate 0x002e 252 252 051 old_age always - 0 8 seek_time_performance 0x0024 252 252 015 old_age offline - 0 9 power_on_hours 0x0032 100 100 000 old_age always - 30077 10 spin_retry_count 0x0032 252 252 051 old_age always - 0 11 calibration_retry_count 0x0032 252 252 000 old_age always - 0 12 power_cycle_count 0x0032 100 100 000 old_age always - 212191 g-sense_error_rate 0x0022 252 252 000 old_age always - 0192 power-off_retract_count 0x0022 252 252 000 old_age always - 0194 temperature_celsius 0x0002 064 052 000 old_age always - 21 (min/max 11/48)195 hardware_ecc_recovered 0x003a 100 100 000 old_age always - 0196 reallocated_event_count 0x0032 252 252 000 old_age always - 0197 current_pending_sector 0x0032 100 100 000 old_age always - 2198 offline_uncorrectable 0x0030 252 252 000 old_age offline - 0199 udma_crc_error_count 0x0036 200 200 000 old_age always - 0200 multi_zone_error_rate 0x002a 100 100 000 old_age always - 64223 load_retry_count 0x0032 252 252 000 old_age always - 0225 load_cycle_count 0x0032 100 100 000 old_age always - 1244smart error log version: 1no errors loggedsmart self-test log structure revision number 1num test_description status remaining lifetime(hours) lba_of_first_error# 1 short offline completed: read failure 90% 30077 2056# 2 extended offline completed: read failure 90% 30077 2056smart selective self-test log data structure revision number 0note: revision number not 1 implies that no selective self-test has ever been run span min_lba max_lba current_test_status 1 0 0 completed_read_failure [90% left] (0-65535) 2 0 0 not_testing 3 0 0 not_testing 4 0 0 not_testing 5 0 0 not_testingselective self-test flags (0x0): after scanning selected spans, do not read-scan remainder of disk.if selective self-test is pending on power-up, resume after 0 minute delay.smartctl -a /dev/sdcsmartctl 6.5 2016-01-24 r4214 [x86_64-linux-3.2.0-4-amd64] (local build)copyright (c) 2002-16, bruce allen, christian franke, <url> start of information section ===model family: western digital greendevice model: wdc wd10ezrx-00a8lb0serial number: wd-wmc1u5433779lu wwn device id: 5 0014ee 657f09173firmware version: 01.01a01user capacity: 1,000,204,886,016 bytes [1.00 tb]sector sizes: 512 bytes logical, 4096 bytes physicaldevice is: in smartctl database [for details use: -p show]ata version is: ata8-acs (minor revision not indicated)sata version is: sata 3.0, 6.0 gb/s (current: 3.0 gb/s)local time is: fri nov 11 11:17:08 2016 cetsmart support is: available - device has smart capability.smart support is: enabled=== start of read smart data section ===smart overall-health self-assessment test result: passedgeneral smart values:offline data collection status: (0x85) offline data collection activity was aborted by an interrupting command from host. auto offline data collection: enabled.self-test execution status: ( 0) the previous self-test routine completed without error or no self-test has ever been run.total time to complete offlinedata collection: (12960) seconds.offline data collectioncapabilities: (0x7b) smart execute offline immediate. auto offline data collection on/off support. suspend offline collection upon new command. offline surface scan supported. self-test supported. conveyance self-test supported. selective self-test supported.smart capabilities: (0x0003) saves smart data before entering power-saving mode. supports smart auto save timer.error logging capability: (0x01) error logging supported. general purpose logging supported.short self-test routinerecommended polling time: ( 2) minutes.extended self-test routinerecommended polling time: ( 148) minutes.conveyance self-test routinerecommended polling time: ( 5) minutes.sct capabilities: (0x30b5) sct status supported. sct feature control supported. sct data table supported.smart attributes data structure revision number: 16vendor specific smart attributes with thresholds:id# attribute_name flag value worst thresh type updated when_failed raw_value 1 raw_read_error_rate 0x002f 200 200 051 pre-fail always - 6787 3 spin_up_time 0x0027 139 137 021 pre-fail always - 4041 4 start_stop_count 0x0032 096 096 000 old_age always - 4454 5 reallocated_sector_ct 0x0033 171 171 140 pre-fail always - 1262 7 seek_error_rate 0x002e 200 200 000 old_age always - 0 9 power_on_hours 0x0032 054 054 000 old_age always - 33859 10 spin_retry_count 0x0032 100 100 000 old_age always - 0 11 calibration_retry_count 0x0032 100 100 000 old_age always - 0 12 power_cycle_count 0x0032 100 100 000 old_age always - 145192 power-off_retract_count 0x0032 200 200 000 old_age always - 31193 load_cycle_count 0x0032 170 170 000 old_age always - 90973194 temperature_celsius 0x0022 119 104 000 old_age always - 24196 reallocated_event_count 0x0032 001 001 000 old_age always - 819197 current_pending_sector 0x0032 198 198 000 old_age always - 326198 offline_uncorrectable 0x0030 200 200 000 old_age offline - 0199 udma_crc_error_count 0x0032 200 200 000 old_age always - 0200 multi_zone_error_rate 0x0008 200 200 000 old_age offline - 80smart error log version: 1ata error count: 11 (device log contains only the most recent five errors) cr = command register [hex] fr = features register [hex] sc = sector count register [hex] sn = sector number register [hex] cl = cylinder low register [hex] ch = cylinder high register [hex] dh = device/head register [hex] dc = device command register [hex] er = error register [hex] st = status register [hex]powered_up_time is measured from power on, and printed asddd+hh:mm:ss.sss where dd=days, hh=hours, mm=minutes,ss=sec, and sss=millisec. it wraps after 49.710 days.error 11 occurred at disk power-on lifetime: 33842 hours (1410 days + 2 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 60 b0 a8 d7 e1 error: unc 96 sectors at lba = 0x01d7a8b0 = 30910640 commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- c8 00 60 a0 a8 d7 e1 08 17d+13:32:19.391 read dma ef 10 02 00 00 00 a0 08 17d+13:32:19.391 set features [enable sata feature] ec 00 00 00 00 00 a0 08 17d+13:32:19.390 identify device ef 03 46 00 00 00 a0 08 17d+13:32:19.390 set features [set transfer mode]error 10 occurred at disk power-on lifetime: 33842 hours (1410 days + 2 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 60 c8 a8 d7 e1 error: unc 96 sectors at lba = 0x01d7a8c8 = 30910664 commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- c8 00 60 a0 a8 d7 e1 08 17d+13:32:11.498 read dma ef 10 02 00 00 00 a0 08 17d+13:32:11.498 set features [enable sata feature] ec 00 00 00 00 00 a0 08 17d+13:32:11.497 identify device ef 03 46 00 00 00 a0 08 17d+13:32:11.497 set features [set transfer mode]error 9 occurred at disk power-on lifetime: 33842 hours (1410 days + 2 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 60 a8 a8 d7 e1 error: unc 96 sectors at lba = 0x01d7a8a8 = 30910632 commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- c8 00 60 a0 a8 d7 e1 08 17d+13:32:07.412 read dma c8 00 08 98 a8 d7 e1 08 17d+13:32:07.412 read dmaerror 8 occurred at disk power-on lifetime: 33841 hours (1410 days + 1 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 08 48 f9 80 e1 error: unc 8 sectors at lba = 0x0180f948 = 25229640 commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- c8 00 08 48 f9 80 e1 08 17d+13:12:31.938 read dma ef 10 02 00 00 00 a0 08 17d+13:12:31.938 set features [enable sata feature] ec 00 00 00 00 00 a0 08 17d+13:12:31.937 identify device ef 03 46 00 00 00 a0 08 17d+13:12:31.937 set features [set transfer mode]error 7 occurred at disk power-on lifetime: 33841 hours (1410 days + 1 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 08 48 f9 80 e1 error: unc 8 sectors at lba = 0x0180f948 = 25229640 commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- c8 00 08 48 f9 80 e1 08 17d+13:12:29.429 read dma c8 00 b8 48 f5 80 e1 08 17d+13:12:29.410 read dmasmart self-test log structure revision number 1num test_description status remaining lifetime(hours) lba_of_first_error# 1 extended offline completed: read failure 90% 33858 384848# 2 short offline completed: read failure 80% 33857 1951525160smart selective self-test log data structure revision number 1 span min_lba max_lba current_test_status 1 0 0 not_testing 2 0 0 not_testing 3 0 0 not_testing 4 0 0 not_testing 5 0 0 not_testingselective self-test flags (0x0): after scanning selected spans, do not read-scan remainder of disk.if selective self-test is pending on power-up, resume after 0 minute delay.editi cloned sda disk using:ddrescue -d -f -r3 /dev/sda /dev/sde ddrescue.logfilegnu ddrescue 1.19initial status (read from logfile)rescued: 1000 gb, errsize: 4096 b, errors: 3current statusrescued: 1000 gb, errsize: 4096 b, current rate: 0 b/s ipos: 1052 kb, errors: 3, average rate: 0 b/s opos: 1052 kb, run time: 3.13 m, successful read: 3.13 m agobut the cloned disk sde says as well: mdadm: no md superblock detected on /dev/sde1. could i recover those superblocks?",
    "present_kp": [
      "raid",
      "mdadm",
      "software raid"
    ],
    "absent_kp": [
      "hard disk",
      "data recovery"
    ]
  },
  {
    "text": "installing column unix utility on windows. i would like to be able to use the bsd unix utilities: column, join and paste in my cygwin installation. it seems that they are not available, or i cannot find them. is there a way to install them so i can use them on windows?",
    "present_kp": [
      "utilities",
      "cygwin"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "type inference + overloading. i'm looking for a type inference algorithm for a language i'm developing, but i couldn't find one that suits my needs because they usually are either: la haskell, with polymorphism but no ad-hoc overloading la c++ (auto) in which you have ad-hoc overloading but functions are monomorphicin particular my type system is (simplifying) (i'm using haskellish syntax but this is language agnostic):data type = int | double | matrix type | function type typeand i've got an operator * which has got quite some overloads:int -> int -> int(function int int) -> int -> intint -> (function int int) -> (function int int)(function int int) -> (function int int) -> (function int int)int -> matrix int -> matrix intmatrix int -> matrix int -> matrix int(function (matrix int) (matrix int)) -> matrix int -> matrix intetc... and i want to infer possible types for(2*(x => 2*x))*6(2*(x => 2*x))*{{1,2},{3,4}}the first is int, the second matrix int.example (that doesn't work):{-# language overlappinginstances, multiparamtypeclasses, functionaldependencies, flexiblecontexts, flexibleinstances, undecidableinstances #-}import qualified preludeimport prelude hiding ((+), (*))import qualified preludenewtype wint = wint { unwrap :: int }liftw f a b = wint $ f (unwrap a) (unwrap b)class times a b c | a b -> c where(*) :: a -> b -> cinstance times wint wint wint where(*) = liftw (prelude.*)instance (times a b c) => times a (r -> b) (r -> c) wherex * g = \\v -> x * g vinstance times (a -> b) a b wheref * y = f ytwo = wint 2six = wint 6test :: winttest = (two*(\\x -> two*x))*sixmain = undefined",
    "present_kp": [
      "type inference"
    ],
    "absent_kp": [
      "type theory"
    ]
  },
  {
    "text": "simple for loop script to build out ipv6 subnet. i am trying to use nmap to scan a /119 ipv6 network. (512 addresses). before i do this i want to generate a file that will populate all of the ip addresses in that range. the network info is as follows:network 2607:f4a0:3:0:250:56ff:feac:3c00prefix length 119network range 2607:f4a0:0003:0000:0250:56ff:feac:3c00- 2607:f4a0:0003:0000:0250:56ff:feac:3dffso i set my script up like this:[root@ns1 ~]# for i in {1..512}; do printf 2607:f4a0:3:0:250:56ff:feac:3c00%x $i >> ipv6.txt; donewhat i expect to see in the file are 512 addresses that are within the range above. however what i see instead is this:2607:f4a0:3:0:250:56ff:feac:3c0012607:f4a0:3:0:250:56ff:feac:3c0022607:f4a0:3:0:250:56ff:feac:3c0032607:f4a0:3:0:250:56ff:feac:3c0042607:f4a0:3:0:250:56ff:feac:3c0052607:f4a0:3:0:250:56ff:feac:3c0062607:f4a0:3:0:250:56ff:feac:3c0072607:f4a0:3:0:250:56ff:feac:3c0082607:f4a0:3:0:250:56ff:feac:3c0092607:f4a0:3:0:250:56ff:feac:3c00a2607:f4a0:3:0:250:56ff:feac:3c00b2607:f4a0:3:0:250:56ff:feac:3c00c2607:f4a0:3:0:250:56ff:feac:3c00d2607:f4a0:3:0:250:56ff:feac:3c00e2607:f4a0:3:0:250:56ff:feac:3c00f2607:f4a0:3:0:250:56ff:feac:3c00102607:f4a0:3:0:250:56ff:feac:3c00112607:f4a0:3:0:250:56ff:feac:3c00122607:f4a0:3:0:250:56ff:feac:3c00132607:f4a0:3:0:250:56ff:feac:3c00142607:f4a0:3:0:250:56ff:feac:3c00152607:f4a0:3:0:250:56ff:feac:3c00162607:f4a0:3:0:250:56ff:feac:3c00172607:f4a0:3:0:250:56ff:feac:3c00182607:f4a0:3:0:250:56ff:feac:3c00192607:f4a0:3:0:250:56ff:feac:3c001a2607:f4a0:3:0:250:56ff:feac:3c001b2607:f4a0:3:0:250:56ff:feac:3c001cwhen i go to run nmap i get errors:nmap -pn -st -p 22 -6 -il ipv6.txt > ipv6uperrors:failed to resolve given ipv6 hostname/ip: 2607:f4a0:3:0:250:56ff:feac:3c00200. note that you can't use '/mask' or '[1-4,7,100-]' style ranges for ipv6.how can i fix this?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "shell script",
      "scripting"
    ]
  },
  {
    "text": "why programs often fail to run when started by 'daemon'?. i do daemon -f -i ./some_gui_program - it starts.i do daemon -i ./some_gui_program - nothing visible happens.why i can't start gui programs detached on linux this way? what's the use of daemon's -f option if it changes behaviour that much?",
    "present_kp": [
      "linux",
      "gui",
      "daemon"
    ],
    "absent_kp": []
  },
  {
    "text": "is there such a thing as control logic complexity classes?. i am currently reading the paper on the computational complexity of algorithms by j. hartmanis and r. e. stearns ( <url> )it includes a proof that any $t$-computable sequence is also $\\lceil kt ceil$-computable, where $k$ is a computable, positive real number, $t$ a time-function and $\\lceil kt ceil$ denotes the smallest integer $m$ such that $m \\ge kt$.the proof idea is to use a (multitape) tm that has a head that can read 2 symbols at once, while storing internally the symbol to the left and right of that head, so that the new tm can simulate 2 steps of a normal (multitape) tm in only once step. by doing the same trick on the new tm using induction, one can prove 1/2k speed-up. i have two questions, which revolve around the same thing: first of all, can i extend this idea and use a head so large that reads the entire input at once? that would require to save a super-constant number of symbols internally in the tm. would that be a violation of the model?reflecting to my first question, whatever the answer is : are there complexity classes that restraint the tm's control logic somehow? e.g. allowing up to a specific number of states or for a specific structure of the automaton?",
    "present_kp": [
      "complexity classes"
    ],
    "absent_kp": [
      "cc.complexity theory"
    ]
  },
  {
    "text": "is it mandatory to have a variable in awk's first statement?. i am having some hard time with awk today. if i try to do:df|awk '{print $2; $some=$2; print $some}'it works as expected and i get the size of the disks twice but if i do:df|awk '{$some=$2; print $some}'i just get blank lines. why is this happening? something is maybe wrong in my understanding but why the usage of a field mandatory for subsequent fields to work? i also tried doing:df|awk '{print hello; $some=$2; print $some}'and i got some hello, each separated by a newline. where is $some=$2 lost?my df command outputs:filesystem 1k-blocks used available use% mounted on/dev/sda5 384<phone> <phone> 88% /udev <phone> 4 <phone> 1% /devtmpfs 768744 984 767760 1% /run",
    "present_kp": [
      "awk"
    ],
    "absent_kp": [
      "ubuntu",
      "mawk"
    ]
  },
  {
    "text": "selective time machine backup deletion. time machine is a useful backup service for mac, but deleting multiple backups is cumbersome. this script allows mass deletion of unwanted backups while allowing specified important backups to remain.i recently ran out of space on an external drive i was using as a time machine backup location, and though there were several old backups i didn't need any more, there were a few specific backups i needed to preserve. since backup deletion through time machine's ui is clunky and limited to individual deletions, i looked around for a script to do what i needed. after not finding a perfect match, i wrote this.i have been considering posting this elsewhere so people in my situation could benefit from it, but since i have no experience with bash or the nitty-gritty of time machine backups, i wanted to make sure i wasn't missing anything obvious that could potentially cause someone to lose data.i've tested it pretty thoroughly on my setup (osx 10.10.5 with a single time machine archive on an external, non-time-capsule drive), but i'm new to this and shouldn't disseminate code dealing in such a sensitive area without being sure it's (reasonably) bulletproof.#!/bin/bashsudo_command=sudo bash $(cd $(dirname $0) && pwd)/$(basename ${bash_source[0]})while [[ $# -gt 0 ]]do option_name=$1 case $option_name in #this many backups will be deleted -a|--amount-to-delete) shift amount_of_backups_to_delete=$1 ;; #the default is to delete oldest to newest -n|--newest-to-oldest) delete_newest_to_oldest=true ;; #test run -t|--test-run) test_run=true ;; #print help -h|--help) echo this script deletes a certain amount of time machine backups that are no longer needed. if there are important backups you never want to delete, add them to the saved_backup_names array in this file. echo options echo -a (--amount-to-delete) <n> echo this required option specifies how many backups should be deleted. n should be an integer greater than 0 or ll\\ to delete all unwanted backups. echo -n (--newest-to-oldest) echo this optional option changes the delete order from the default of oldest to newest. echo -t (--test-run) echo this optional option runs the entire script as normal but substitutes the \\delete\\ verb of the deletion command with a fake verb so the deletions do not occur. echo this is the closest you can get to seeing what will happen without actually performing the deletes. echo echo example usage echo $sudo_command -a 4 -t echo $sudo_command -a all --newest-to-oldest exit ;; *) #unrecognized option echo '$option_name' is not a valid option. ;; esac #move to the next option shiftdoneif [[ $euid -ne 0 ]]then echo you must run this as root. use this command: echo $sudo_command $@ exitfi#if --amount-to-delete wasn't provided, exitif [[ -z $amount_of_backups_to_delete ]]then echo missing required option: --amount-to-delete <n> exitfi#if --newest-to-oldest wasn't provided, set the flag to falseif [[ -z $delete_newest_to_oldest ]]then delete_newest_to_oldest=falsefi#if --test-run wasn't provided, set the flag to falseif [[ -z $test_run ]]then test_run=falsefi#array of backup names for backups that will not be deleted#if there is a benchmark backup that should never be deleted by this script, add it to this arraysaved_backup_names=( 2014-05-17-094303 2014-06-15-093106 2014-06-29-133847 2015-01-02-145324 2015-02-18-103203 2015-07-25-001743 2015-09-12-123932 2015-12-12-025214 2016-12-16-044517)#get an array of absolute paths to all remaining backupsall_backup_paths=($(/usr/bin/tmutil listbackups))if [[ $amount_of_backups_to_delete == all ]]then amount_of_backups_to_delete=${#all_backup_paths[@]}elif [[ $amount_of_backups_to_delete -lt 1 ]]then echo --amount-to-delete must be > 0 exitfi#build an array of paths to the backups that will be deleted so the list can be approved by the useramount_of_backups_added=0for ((i = 0; i < ${#all_backup_paths[@]} && $amount_of_backups_added < $amount_of_backups_to_delete; i++))do #offset index from the last item if the newest backups should be deleted first index=$i if [[ $delete_newest_to_oldest = true ]] then index='expr ${#all_backup_paths[@]} - 1 - $index' fi backup_name=$(basename ${all_backup_paths[$index]}) able_to_delete=true for name in ${saved_backup_names[@]} do #if the current backup trying to be deleted is in the list of saved names, don't delete it if [[ $name == $backup_name ]] then able_to_delete=false fi done if [[ $able_to_delete = true ]] then ((amount_of_backups_added++)) to_delete_backup_paths+=(${all_backup_paths[$index]}) fidone#print a list of the protected and to-be-deleted backups and prompt for confirmationconfirmation_message=i have reviewed the deletion list.echo these backups are protected. they will not be deleted.echo --------------------------------------------------------------------------------for name in ${saved_backup_names[@]}do echo $namedoneechoecho these backups will be deleted.echo --------------------------------------------------------------------------------for backup_path in ${to_delete_backup_paths[@]}do basename $backup_pathdoneechoread -p enter \\$confirmation_message\\ sans quotes to start the deletion. echoif [[ $reply == $confirmation_message ]]then for ((i = 0; i < ${#to_delete_backup_paths[@]}; i++)) do date=$(date) echo [$date] starting deletion for ${to_delete_backup_paths[$i]} if [[ $test_run = true ]] then sudo time /usr/bin/tmutil this_is_a_test_run ${to_delete_backup_paths[$i]} else sudo time /usr/bin/tmutil delete ${to_delete_backup_paths[$i]} fi date=$(date) echo [$date] finished doneelse echo the confirmation message didn't match, so nothing was deleted.fi",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "macos"
    ]
  },
  {
    "text": "can i reset my banned songs list?. in last.fm, is it possible to clear my total list of banned songs so that they are not banned anymore?at the moment it's about 8 pages and that's something you don't want to reset song by song.",
    "present_kp": [
      "last.fm"
    ],
    "absent_kp": []
  },
  {
    "text": "setting up a wireless to ethernet bridge. i am trying to set up a temporary network using the following hardware[wireless router]))) )) ) [laptop] ----- [desktop] ^wifi (debian) ^ethernet ^(3com audrey)looking around online, i found what might be two solutions:1) on the laptop (running debian) set up a nat using iptablesor2) use parproutedi've read online that the first solution won't work because there are problems translating addresses because of the difference in mac addresses between the eth0 and wlan0 connections, so i'm leaning toward the 2nd. what i want to know is:would either of these methods be better than the other, (and/or should i use a different approach)?is there an easy way to back up my settings in case i screw something up?",
    "present_kp": [
      "debian",
      "wifi"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "managing large number of app.config files. we have many windows services and web apps which all rely on a lot of common settings. currently we use just appsettings as needed and they are referenced by key. some of the settings are app specific and only know by the app team while others are environment specific and only know by the deployment team. also we have issues when we have to make a change to common setting necessitating the change 100s of files and restarting all corresponding services. with the great variety of settings there are duplicates ones that are no longer used and many that don't mean the same thing to different applications. to solve the problem i had a two fold idea one we would write a custom config sections group for the company with custom config sections for each app and one for common. the common section would be able to accessed by a wcf service and validate that all of its settings are the current settings. my question is am i reinventing the wheel are there any good frameworks/projects/products that are designed to manage many many configurations files in a distributed environment, and if not is the approach i have decided take a reasonable one.",
    "present_kp": [
      "deployment",
      "configuration"
    ],
    "absent_kp": [
      ".net",
      "configuration management"
    ]
  },
  {
    "text": "duplicate content for e-commerce site. i am trying to look for a solution for my client's e-commerce site which has close to 15k products. my client is about to launch a brand new e-commerce site built on shopify. the issue is, all the product description of the website is taken from their various suppliers. how do i go about this? what are the solutions i should look into? client is willing to change the description eventually, however, he does not want to wait till the description is changed for all the products, quite obvious. blocking the search engine from crawling these products would be a good idea? should i place dnf (do not follow)? i need a solution which is not as much time consuming, hence, connonicalisation would be out of the equation. your suggestions/solutions would be much appreciated.thanks in advance.regards",
    "present_kp": [
      "duplicate content"
    ],
    "absent_kp": [
      "seo",
      "google search console",
      "search engines",
      "ecommerce"
    ]
  },
  {
    "text": "markdown: how to syntax-highlight bold and italic in different color than normal text?. text marked as__bold__ or _italic_ appears in the same color as normal text.headings and code do show up in different colors, so vim correctly recognizes the file as markdown.this is no matter what colorscheme i use.is it possible to make text marked as bold or italic in markdown, highlighted in their own colors?p.s. i'm using a full vim install (not vim-tiny) version 7.4 on xubuntu linux.this is what it looks like. while the previous lines show that headings etc. work, line 22-26 contain text that should have been highlighted differently than the default - this is in :colorscheme default but it doesn't work in others either",
    "present_kp": [],
    "absent_kp": [
      "syntax highlighting",
      "filetype markdown"
    ]
  },
  {
    "text": "set alignment of numeric columns when columnating data. i use column -t to format data for easy viewing in the shell, but there seems to be no option to specify column alignment (e.g. align to the right).any bash one-liners to do it? i have arbitrary number of columns.",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "utilities",
      "table"
    ]
  },
  {
    "text": "method to return a hibernate session. can this method be improved?:public static session gethibernatesession() throws sqlexception{ synchronized(dbsessionmutex){ if(session == null || !session.isopen()){ session = hibernateutil.getsessionfactory().opensession(); } else{ final sessionfactoryimplementor sessionfactoryimplementation = (sessionfactoryimplementor) session.getsessionfactory(); final connectionprovider connectionprovider = sessionfactoryimplementation.getconnectionprovider(); try{ final connection conn = connectionprovider.getconnection(); if(conn.isclosed()){ session.close(); session = hibernateutil.getsessionfactory().opensession(); } else{ conn.close(); } } catch(exception e){ logger.error(exception: , e); session.close(); session = hibernateutil.getsessionfactory().opensession(); } } } return session;}",
    "present_kp": [
      "hibernate"
    ],
    "absent_kp": [
      "java",
      "jdbc"
    ]
  },
  {
    "text": "udisks2 doesn't clean up mount points on shutdown. if i shut down my computer while a device that was mounted by udisks is still mounted, the folder where it was mounted still remains.if i then mount that device again later, a '1' will be appended to the name (or higher numbers if the lower numbers are taken).the owner of these empty folders is root; owner has rwx permissions, the rest has none.i'm running arch linux with xfce4 as desktop manager.my udisks version is 2.1.7-1i configured udisks to mount the devices in /media using these instructions: <url> there anything i can do to fix this so the folders will be removed on shutdown?my problem is similar to this problem, with the difference being in which situation it occurs:make udisks2 clean up stale mount points?. this appered to be a bug in udisks (solved by now). should i report my situation as a bug too?edit:this only applies to shared mounts.if i remove the rule that makes mounts shared by default the cleaning up is done properly.",
    "present_kp": [
      "arch linux",
      "udisks"
    ],
    "absent_kp": []
  },
  {
    "text": "how to check if a the language represented by a dfa is finite. i am studying regular languages and d fa. i have implemented d fa in java. i have to write a function which tells if the language represented by a d fa is finite or not.i need a method or algorithm to do so. what i have already figured out is that if the d fa has loops in it then it can possibly recognize infinite words.",
    "present_kp": [
      "dfa"
    ],
    "absent_kp": []
  },
  {
    "text": "iteratively minimizing the function. consider the problemegin{equation}\\min_{x\\in x, y \\in y} f(x,y)\\end{equation}can i solve the problem by iteratively solving the following two sub problems?egin{equation}x_{k+1} = rg\\min_{x\\in x} f(x,y_k)\\end{equation}egin{equation}y_{k+1} = rg\\min_{ y \\in y} f(x_k,y)\\end{equation}if yes, is there any books/papers talking about this kind of approach?thanks",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "optimization"
    ]
  },
  {
    "text": "takes in two sorted lists and outputs a sorted list that is their union. write a function that takes in two sorted lists and outputs a sorted list that is their unioncould anyone help me to improve this code and make it more user-friendly? we are not supposed to use any built-in python functions, but rather develop our own efficient algorithms.def answer(list1, list2): len1 = len(list1) len2 = len(list2) final_list = [] j = 0 k = 0 for i in range(len1+len2): if k == len1: final_list.append(list2[j]) j += 1 continue if j == len2: final_list.append(list1[k]) k += 1 continue if list1[k] < list2[j]: final_list.append(list1[k]) k += 1 else: final_list.append(list2[j]) j += 1 return final_listprint answer([1, 2 , 17, 18, 100], [3, 3, 4, 5, 15, 19, 20, 101])",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "performance",
      "sorting",
      "mergesort"
    ]
  },
  {
    "text": "time duration formatting in google spreadsheets. a couple issues here: i have a formula that is trying to determine if a time duration (ex 7:51) is greater than or less than a baseline duration value. when typing the formula i have to put the baseline number in quotations ex =if(b3=sb,if(and(i3<13:01,j3>49,k3>49,l3>5,m3<12:01),p,f) otherwise the formula thinks i'm referring to a range of cells. doing it this way doesn't produce an error but the formula doesn't work correctly in that no matter if the time entered is less than or greater than the baseline, the same result is produced.i can make the formula work by inputting the data without a colon and separating the min:sec with a period instead, but i'm just not happy doing things this way. i want to be able to enter the data using the true format which is min:sec. i feel like the answer here is within the way the cell is formatted to display the data, but i've tried many many options and none of them seem to do the trick. i have zero experience with script editing either so that's another avenue that has not been explored, nor do i even know what capabilities that could unlock.",
    "present_kp": [
      "google spreadsheets",
      "duration"
    ],
    "absent_kp": [
      "formulas"
    ]
  },
  {
    "text": "how does one become a leader in a team of programmers?. what skills, knowledge and talents should a junior programmer aim to obtain in order to be qualified to become a team leader?",
    "present_kp": [
      "team leader"
    ],
    "absent_kp": [
      "project management",
      "teamwork"
    ]
  },
  {
    "text": "project euler 11: largest product in a grid, python3. project euler #11what is the greatest product of four adjacent numbers in the same direction (up, down, left, right, or diagonally) in the 2020 grid?i've seen some of the solutions of the problem and although they are in python3, my solution has some differences. pylint rates it 7.27/10 and i will add docstring eventually. some of the lines are too long(104/100) and fl is not a good name for a file and i agree.the main issues are comparing product and product_temp and calculating the sum for a diagonal from down left to upper right is inconsistent with the calculating the other products.the code: #!/bin/env python3https://projecteuler.net/problem=11in a 20x20 matrix iterate over all the rows, columns,diagonals(left up -> down right, down left -> upper right)and find the largest product of 4 numbers in the same directiondef list_ints(): with open('./textfiles/grid2020.txt') as fl: array = [[int(x) for x in line.split()] for line in fl] return arraydef biggest_product(): grid = list_ints() product = 0 product_temp = 0 col = 20 row = 20 for i in range(row): for j in range(col): #for row if i + 3 < 20: product_temp = grid[i][j] * grid[i + 1][j] * grid[i + 2][j] * grid[i + 3][j] if product < product_temp: product = product_temp #for column if j + 3 < 20: product_temp = grid[i][j] * grid[i][j + 1] * grid[i][j + 2] * grid[i][j + 3] if product < product_temp: product = product_temp #for diagonal from upper left to down right if i + 3 < 20 and j + 3 < 20: product_temp = grid[i][j] * grid[i + 1][j + 1] * grid[i + 2][j + 2] * grid[i + 3][j + 3] if product < product_temp: product = product_temp #another loop from the other diagonal #diagonal left to upeer right for i in range(20, -1, -1): for j in range(20): if i + 3 < 20 and j - 3 >= 0: product_temp = grid[i][j] * grid[i + 1][j - 1] * grid[i + 2][j - 2] * grid[i + 3][j - 3] if product < product_temp: product = product_temp return productif __name__ == '__main__': print(biggest_product())edit: now i see the comments for calculating row and col comments are reversed.",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "algorithm",
      "programming challenge",
      "python 3.x"
    ]
  },
  {
    "text": "decidable languages. a recursive (decidable) language is defined as a language for which there exists an algorithm deciding if a string is or not in the language that terminates for every possible input. the question is, does there exist a programming language/grammar/something that is able to represent all and only the algorithms that are a decider? i.e. all the possible programs that terminate, and not others?",
    "present_kp": [],
    "absent_kp": [
      "formal languages"
    ]
  },
  {
    "text": "how can i tell a running process to disregard sighup?. possible duplicate:how can i close a terminal without killing the command running in it? i have a very low-end server running debian squeeze that i occasionally ssh to. the system tends to be slow, e.g. running apt-cache search might take half a minute. occasionally i find that i can't wait for a process to complete (i'm on my laptop and need to go somewhere).if i had originally started the process with nohup or inside screen, this would be no problem. but how can i get an already running process to continue despite my logging off?",
    "present_kp": [
      "nohup"
    ],
    "absent_kp": [
      "logout"
    ]
  },
  {
    "text": "how to measure team productivity in agile project environment?. are there any techniques other than velocity? what are pros and cons of using those from your experience?",
    "present_kp": [
      "productivity",
      "agile"
    ],
    "absent_kp": []
  },
  {
    "text": "update is telling me my package system is broken - the instruction to fix it doesn't work - what to do?. i am using linux mint 12 and currently have the mate desktop running. the icon in the upper right showed their were updates. tried to do it and it said that the package system is brokencheck if you are using third party repositories. if so disable them, since they are a common source of problems. furthermore run the following command in a terminal: apt-get install -fthe details are: the following packages have unmet dependencies:mint-artwork-gnome: depends: gtk2-engines-clearlooks but it is a virtual package depends: mint-backgrounds-lisa but it is not installedsudo apt-get install -f gives this output:reading package lists... done building dependency tree reading state information... donecorrecting dependencies... done the following extra packages will be installed: mint-backgrounds-lisa the following new packages will be installed: mint-backgrounds-lisa 0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded. 4 not fully installed or removed. need to get 0 b/3,003 kb of archives. after this operation, 3,265 kb of additional disk space will be used. do you want to continue [y/n]? y (reading database ... 482703 files and directories currently installed.) unpacking mint-backgrounds-lisa (from .../mint-backgrounds-lisa_1.1_all.deb) ... dpkg: error processing /var/cache/apt/archives/mint-backgrounds-lisa_1.1_all.deb (--unpack): trying to overwrite '/usr/share/gnome-background-properties/linuxmint-lisa.xml', which is also in package mint-artwork-kde 2.0.1 dpkg-deb: error: subprocess paste was killed by signal (broken pipe) errors were encountered while processing: /var/cache/apt/archives/mint-backgrounds-lisa_1.1_all.deb e: sub-process /usr/bin/dpkg returned an error code (1)if i try and install the latest version of chromium by double-clicking the deb file is says:gdebi-gtk broken dependenciesyour system has broken dependencies. this application cannot continue until this is fixed. to fix it run 'gksudo synaptic' or 'sudo apt-get install -f' in a terminal window.if i run 'gksudo synaptic' synaptic comes up and says:(as superuser) you have 1 broken package on your system!use the broken filter to locate it.the broken filter shows:synaptic broken installed version latest version description mint-artwork-gnome 2.6.20 2.6.20 default artwork for linux minttrying to reinstall the above package gives:an error occurredthe following details are provided:e: /var/cache/apt/archives/mint-backgrounds-lisa_1.1_all.deb: trying to overwrite '/usr/share/gnome-background-properties/linuxmint-lisa.xml', which is also in package mint-artwork-kde 2.0.1one easy solution is probably to not run mate with linux mint (this is my first try), but just wondering if this is fixable.",
    "present_kp": [
      "linux mint",
      "upgrade",
      "dpkg"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i close the shell buffer? prefferbly under a certain condition.. i have written a python script that is doing some checks for a latex file and then compiles it. i call it upon saving the file using the following line:autocmd bufwritepost * !~/.vim/latex_compiler.py <afile> how can i close the terminal buffer upon certain condition?",
    "present_kp": [
      "autocmd",
      "terminal"
    ],
    "absent_kp": []
  },
  {
    "text": "best 3g usb modem for reverse engineering?. my idea is to automate the process of keeping in touch with my server in a portable and internet independent manner. the most optimal solution in my case is an sms gateway/relay because i travel a lot and i want to eliminate the situation when i do not have internet access (wifi or sim). the 3g usb modem is the best solution because i can keep it in my home wall plate, and the little ones cost around 7 euro (huawei k4305) in my town.my problem is that i didn't found a custom firmware with a web shell integrated to build the php file that request the information from my server api and send via sms to my mobile number. (i don't want online sms gateways like smsglobal)is there a binwalk / firmware mod kit friendly fw version or projects related to this? my knowledge in reverse engineering is poor. thank you for your attention and time!",
    "present_kp": [
      "firmware",
      "usb"
    ],
    "absent_kp": [
      "hardware"
    ]
  },
  {
    "text": "namespace by topic or by purpose?. the project i'm working on has quite a few classes. these classes can be grouped in two different ways. i'm trying to decide which grouping is best as for namespacing. currently i a set of user facing classes that look like:jamjarhoneyjarpeanutbutterjaretc...these are all similar in that they all inherit from spreadablejar, each spreadable prefix could be considered a 'topic' within in the project. i also have a set of objects relating to these topics, each topic usually has a set of constant definitions and message classes associated with it so i end up with a bundle of files such as:jamdefinitionspeanutbutterspreadmessagehoneydefinitionsjamremovemessageetc...i can think of two ways to organise these files:by topicfirst level is namespace, second is class/file name.jamjardefinitionsremovemessageetc...honeyjardefinitionsetc...peanutbutterjardefinitionsspreadmessageetc...this seems tidy (removes duplicated names) and is useful to the user of the library but means that all the jar files look the same in the project structure, and each jar class no longer has a descriptive name. it also means that related objects are grouped together so they will not need to scope into each others namespacesby purposejarsjamjarhoneyjarpeanutbutterjardefinitionsjamdefinitionshoneydefinitionspeanutbutterdefinitionsmessagesjamremovemessageetc...this way is clear to the user if they know that they need to use jars (the rest of the objects won't be needed by external users) and it separates the large number of messages and the separate definitions files from the main functionality, but now the jars will need to scope into the other namespaces for their own definitions and messages and the file naming becomes more awkward. the 'jar' from jamjar can't really be removed because the class is not just 'jam'.what is the best approach here? am i missing some obvious solution or error in my structure?",
    "present_kp": [
      "naming",
      "project structure",
      "namespace"
    ],
    "absent_kp": []
  },
  {
    "text": "which option of ls should be used for understanding metadata changes?. how can one find the latest time of metadata changes to a file?let's say i changed the ownership of a file and then i did ls -l. it still shows the latest file changes. but i want to see the time that i changed the ownership.",
    "present_kp": [
      "ls"
    ],
    "absent_kp": []
  },
  {
    "text": "strange refresh issue with chromium on gentoo. my system is gentoo 64bit, with kde4. i have installed chromium and have been using it for a long time without any problem. but recently, i noticed a strange issue. for example, in a text box, if i type hello, only hell will be displayed. the last o will be displayed only if i do something that could cause page update, like scroll up/down, hover my mouse over a link. this problem also happens with other input controls. i have tried to re-emerge the package, but it does not fix this problem. i really have no idea how to trouble this issue. there's no error log at all.",
    "present_kp": [
      "kde",
      "gentoo"
    ],
    "absent_kp": [
      "chrome"
    ]
  },
  {
    "text": "segment tree implementation. i'm learning segment trees and their implementation. for the purpose, i tried solving the problem on codechef.full code heremy tree implementation is as follows: #include <bits/stdc++.h>#define _max (1<<17)#define max (_max<<1)using namespace std;struct node{ int tails; int heads; void merge(node &a,node &b) // merge two nodes { tails=a.tails+b.tails; heads=a.heads+b.heads; } void createleaf() // creates a leaf { tails=1; heads=0; }};node st[max]; // segment tree st/* res is the node storing the result information for range [l,r] is present in st[idx] query is required for range [u,v] */void query(node &res,int l,int r,int u,int v,int idx){ if(l==u && r==v) { res=st[idx]; return; } else { int mid=(l+r)/2; if(mid>=v) query(res,l,mid,u,v,2*idx); else if(mid<u) query(res,mid+1,r,u,v,2*idx+1); else{ node left,right; query(left,l,mid,u,mid,2*idx); // left child is 2*idx query(right,mid+1,r,mid+1,v,2*idx+1); // right child is 2*idx+1 res.merge(left,right); } }}void init(int idx,int l,int r) // initialises the tree{ if(l==r) { st[idx].createleaf(); return; } else { int mid=(l+r)/2; init(2*idx,l,mid); init(2*idx+1,mid+1,r); st[idx].merge(st[2*idx],st[2*idx+1]); }}/* updates the value of a single node. when we flip the coins, no. of heads and tails get swapped */void updatevalue(node &a) { swap(a.tails,a.heads); }/* updates the node st[idx] and all the nodes descending the node st[idx] st[idx] stores information for range [l,r] */void update(int l,int r,int idx){ if(l==r) // returns as soon as we reach a leaf node { updatevalue(st[idx]); return; } else { updatevalue(st[idx]); int mid=(l+r)/2; update(l,mid,2*idx); // updates left child update(mid+1,r,2*idx+1); // updates right child }}/* range to be updated is [u,v] st[idx] stores information for range [l,r] */void updaterange(int l,int r,int u,int v,int idx){ if(u<=l && r<=v) { update(l,r,idx); // as soon as required node is found, update the node and all its descendant return; } else { int mid=(l+r)/2; if(mid>=v) updaterange(l,mid,u,v,2*idx); else if(mid<u) updaterange(mid+1,r,u,v,2*idx+1); else { updaterange(l,mid,u,mid,2*idx); updaterange(mid+1,r,mid+1,v,2*idx+1); } st[idx].merge(st[2*idx],st[2*idx+1]); }}int main(){ ios_base::sync_with_stdio(false); cin.tie(null); int n,q,x,y,z; node res; cin>>n>>q; init(1,0,n-1); /* st[1] stores information for [0,n-1] */ while(q--) { cin>>x>>y>>z; if(x==1) { query(res,0,n-1,y,z,1); cout<<res.heads<< ; } else { updaterange(0,n-1,y,z,1); } } return 0;}i've read many online sources and applied the segmented tree to the best of my knowledge, however my implementation is shown slow in accordance with time constraints for the problem. please tell where my code is lacking. i feel my range update is a slow function but i can't find any method to speed it up as when we flip a coin, we have to update all ranges having that coin. any better implementation for range update or query is welcomed.",
    "present_kp": [
      "c++",
      "tree"
    ],
    "absent_kp": [
      "algorithm",
      "interval"
    ]
  },
  {
    "text": "setting up a redirect from '<url>' to '<url>. hopefully someone can give me a roadmap to get this done.i run a self-hosted wordpress blog athttp://www.example.comwhich has numerous posts/links such as <url> am now planning in moving to a new domain, <url>.i would like to move my content into mysite.com as follows:<url> sense is that a 301 redirect will not suffice and wonder if changes elsewhere (htaccess?) are needed to make this move without screwing up my pagerank (currently 5).any ideas or suggestions? my server is lamp.thanks for helping!",
    "present_kp": [
      "wordpress",
      "htaccess",
      "blog",
      "301 redirect"
    ],
    "absent_kp": [
      "redirects"
    ]
  },
  {
    "text": "script load two arguments. i have perl script which need two arguments, for example:./perlscript 0001 192.168.100.200but i need run this script more time (40x)../perlscript 0003 192.168.100.202./perlscript 0061 192.168.100.205./perlscript 0061 192.168.100.206.........i need insert arguments automaticly after perlscript and how to do it?load from file or create array?",
    "present_kp": [
      "perl"
    ],
    "absent_kp": [
      "linux",
      "bash",
      "scripting",
      "variable"
    ]
  },
  {
    "text": "what is the preferred way to install new versions of software?. i have installed ubuntu server 10.10 and now i want to install some software like postgresql, nginx and php. but what is the preferred way to get the latest stable version of the software?e.g i tried with sudo apt-get install postgresql but that installed version 8.4 of postgresql but 9.0.1 is the latest version.i have had this issue before with nginx. the solution was then to download the sourcefiles and compile the latest version which took some time. later a friend told me that wasn't a preferred way to install software.any recommendations?",
    "present_kp": [
      "ubuntu",
      "install",
      "apt",
      "version"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "what is the difference between wikipedia and new world encyclopedia?. what is the difference between wikipedia and new world encyclopedia?and what is the point of having another version of wikipedia-like site?related:what exactly is the new world encyclopedia? at yahoo",
    "present_kp": [
      "wikipedia"
    ],
    "absent_kp": []
  },
  {
    "text": "can the csv format be defined by a regex?. a colleague and i have recently argued over whether a pure regex is capable of fully encapsulating the csv format, such that it is capable of parsing all files with any given escape char, quote char, and separator char. the regex need not be capable of changing these chars after creation, but it must not fail on any other edge case.i have argued that this is impossible for just a tokenizer. the only regex that might be able to do this is a very complex pcre style that moves beyond just tokenizing.i am looking for something along the lines of:... the csv format is a context free grammar and as such, it is impossible to parse with regex alone ...or am i wrong? is it possible to parse csv with just a posix regex?for example, if both the escape char and the quote char are , then these two lines are valid csv:this is a test.,and he said,what will be, will be., to which i replied, surely not!,moving on to the next field here...",
    "present_kp": [
      "parsing",
      "csv"
    ],
    "absent_kp": [
      "regular expressions"
    ]
  },
  {
    "text": "implementation of custom config section. i recently wrote my first custom config section. i have a collection of index files, each has a path and a savetime: internal class searchconfigsection : configurationsection{ static configurationproperty s_indexcollection; static configurationpropertycollection s_propertycollection; static opensearchconfigsection() { s_indexcollection = new configurationproperty(indexcollection, typeof(indexcollection), null, configurationpropertyoptions.none); s_propertycollection = new configurationpropertycollection(); s_propertycollection.add(s_indexcollection); } protected override configurationpropertycollection properties { get { return s_propertycollection; } } public indexcollection indexcollection { get { return (indexcollection)base[s_indexcollection]; } }}internal class indexcollection : configurationelementcollection{ #region static fields static configurationpropertycollection s_properties; #endregion #region constructors static indexcollection() { s_properties = new configurationpropertycollection(); } public indexcollection() { } #endregion #region override public override configurationelementcollectiontype collectiontype { get { return configurationelementcollectiontype.basicmap; } } protected override string elementname { get { return index; } } protected override configurationpropertycollection properties { get { return s_properties; } } protected override configurationelement createnewelement() { return new indexinformation(); } protected override object getelementkey(configurationelement element) { return (element as indexinformation).path; } #endregion #region indexer public indexinformation this[int index] { get { return (indexinformation)base.baseget(index); } set { if (base.baseget(index) != null) { base.baseremoveat(index); } base.baseadd(index, value); } } #endregion #region modify public void add(indexinformation element) { base.baseadd(element); } public void remove(string path) { base.baseremove(path); } public void remove(indexinformation element) { base.baseremove(getelementkey(element)); } public void clear() { base.baseclear(); } public void removeat(int index) { base.baseremoveat(index); } public string getkey(int index) { return (string)base.basegetkey(index); } #endregion}internal class indexinformation : configurationelement{ #region static fields static configurationproperty s_path; static configurationpropertycollection s_properties; static configurationproperty s_savetime; #endregion #region constructor static indexinformation() { s_path = new configurationproperty(path, typeof(string), null, configurationpropertyoptions.isrequired); s_savetime = new configurationproperty(savetime, typeof(datetime), null, configurationpropertyoptions.isrequired); s_properties = new configurationpropertycollection(); s_properties.add(s_path); s_properties.add(s_savetime); } #endregion #region properties protected override configurationpropertycollection properties { get { return s_properties; } } public string path { get { return (string)base[s_path]; } set { base[s_path] = value; } } public datetime savetime { get { return (datetime)base[s_savetime]; } set { base[s_savetime] = value; } } #endregion}here is the app.config file:<?xml version=1.0 encoding=utf-8 ?><configuration><configsections><section name=searchconfig type=configuration.searchconfigsection,searchwindowsclient /></configsections><searchconfig><indexcollection><index path=c:\\index.xml savetime= /></indexcollecetion><searchconfig/></configuration>",
    "present_kp": [
      "configuration"
    ],
    "absent_kp": [
      "c#",
      ".net"
    ]
  },
  {
    "text": "do deep learning algorithms represent ensemble-based methods?. shortly about deep learning (for reference):deep learning is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in data by using a deep graph with multiple processing layers, composed of multiple linear and non-linear transformations.various deep learning architectures such as deep neural networks, convolutional deep neural networks, deep belief networks and recurrent neural networks have been applied to fields like computer vision, automatic speech recognition, natural language processing, audio recognition and bioinformatics where they have been shown to produce state-of-the-art results on various tasks.my question:can deep neural networks or convolutional deep neural networks be viewed as ensemble-based method of machine learning? or it is different approaches?",
    "present_kp": [
      "neural networks",
      "machine learning",
      "deep learning"
    ],
    "absent_kp": [
      "convolutional neural networks"
    ]
  },
  {
    "text": "-calculus : what is the most efficient in memory representation of functions?. i would like to compare performance of function encoded (church's / scott's) vs classically encoded (assembler / c) data structures.but before i do that i need to know how efficient is / can be function representation in memory. the function can be of course partially applied (aka closure).i am interested in both the current encoding algorithm popular functional languages (haskell, ml) use and also in the most efficient one that can be achieved.bonus point : is there such encoding that maps function encoded integers to native integers (short, int etc in c). is it even possible? i value efficiency based on performance. in other words the more efficient the encoding is the less it influences performance of computation with functional data structures.",
    "present_kp": [],
    "absent_kp": [
      "lambda calculus",
      "functional programming"
    ]
  },
  {
    "text": "how to monitor network connectivity between the ports in different windows server?. i have a application hosted from one server which listens on to a specific port and listens to a service on a another server in a different port .seeing error log between xyz application hosted on xx.xx.xx.xx and a service hosted on xx.xx.32.32now need to monitor network connectivity between this servers to see if there are any network drops.error says : an error occurred while receiving the http response to <url>",
    "present_kp": [
      "windows"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "how to avoid device names from being truncated to 16 characters in /dev/disk/by-label?. i have already read this post about how /dev/disk/by-label/ is filled with symlinks to the system drives.i am using kde, and dolphin file manager shows all those drives with those 16-char names, it lets me to rename them, but it only works until the next reboot.i want to know how to avoid names from being truncated to exactly 16 characters if possible.",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "hard disk"
    ]
  },
  {
    "text": "register machine code for fibonacci numbers. i am not sure whether this is the right place to ask this question.i would like to write a register machine code which when given an input of n in register1, returns (also in register 1) the nth fibonacci number. the fibonacci numbers are0 (the 0th), 1 (the 1st), 1 = 0 + 1 (the 2nd), etc. i tried to write few lines of the codes, but unable to do the recursive property of fibonacci sequence. here is my code:let a, b, c be registers.(-a; 2,-)(+c; 1)(-c; 4,-)(+b; 5)(+a; 3)i know that the fifth line is wrong but have no idea how to fix it. and i want to code to be as simple as possible (i.e. with fewest instructions). thanks in advance.",
    "present_kp": [],
    "absent_kp": [
      "programming languages",
      "recurrence relation",
      "recursion"
    ]
  },
  {
    "text": "i want to be seen offline on facebook. i am seen online by people although i turn off my chat ability. they keep sending me massages and it's quite annoying. what can i do for that?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "access to ttyusb0 as normal user. i am trying to access a serial device, which is attached as: /dev/ttyusb0.crw-rw---- 1 root dialout 188, 0 nov 29 15:45 ttyusb0for that i created a new udev rule:subsystem==tty, attr{idvendor}==1a86, attr{idproduct}==7523, symlink+=ttypwm0, mode=0666so i get the following file:lrwxrwxrwx 1 root root 7 nov 29 15:45 ttypwm0 -> ttyusb0if i try to access it with echo, i get the following message. the same problem is with sudo:$echo hello >> ttypwm0bash: ttypwm0: permission deniedmy question is: how can i access this file as normal user? i need to run a program with access granted to it.i don't to add my account to dialout, because i know there is a way without doing this security hole.i have a device of salaelogic. for this device, there is a script:subsystem==usb, env{devtype}==usb_device, attr{idvendor}==0925, attr{idproduct}==3881, mode=0666subsystem==usb, env{devtype}==usb_device, attr{idvendor}==21a9, attr{idproduct}==1001, mode=0666subsystem==usb, env{devtype}==usb_device, attr{idvendor}==21a9, attr{idproduct}==1003, mode=0666subsystem==usb, env{devtype}==usb_device, attr{idvendor}==21a9, attr{idproduct}==1004, mode=0666subsystem==usb, env{devtype}==usb_device, attr{idvendor}==21a9, attr{idproduct}==1005, mode=0666subsystem==usb, env{devtype}==usb_device, attr{idvendor}==21a9, attr{idproduct}==1006, mode=0666with this rule(s), i can start the program and access the device without any other action needed.the same i would like to achieve.... but how?",
    "present_kp": [
      "tty"
    ],
    "absent_kp": [
      "terminal",
      "serial console"
    ]
  },
  {
    "text": "are there mistakes in reading file?. i've recently made a test. there were four tasks. one of them was to improve following code:public class foofileprocessor{ public void processfile(string filename) { stream filestream = file.openread(filename); console.writeline(readallcontent(filestream)); filestream.close(); } public string readallcontent(stream stream) { streamreader streamreader = new streamreader(stream); return streamreader.readtoend(); }}what i've suggested:try{ using (streamreader sr = new streamreader(testfile.txt)) { string line = sr.readtoend(); console.writeline(line); }}catch (exception e) { console.writeline(the file could not be read:); console.writeline(e.message);}please, review my code and show all mistakes you've seen.",
    "present_kp": [
      "stream"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "google message about 404 errors, should i be worried?. i realize this is a topic which has been discussed to infinity, and there are some great posts to be found on here regarding 404 problems.i read this post, and while very informative it did not answer my specific question so forgive me for opening yet another 404 question.ok, so the general consensus is that 404 errors generally does not harm your site regardless of the number...i get that!however, i know google places a great deal of emphasis on user-experience. now when i get messages like this from google, i start to get a bit panicky...googlebot for smartphones identified a significant increase in the number of urls on <url> that return a 404 (not found) error. if these pages exist on your desktop site, showing an error for mobile users can be a bad user experience. this misconfiguration can also prevent google from showing the correct page in mobile search results. if these urls don't exist, no action is necessary.now my primary concern here is the fact that they say this can be bad for user experience...or am i interpreting this incorrectly?i should also mention that the primary reason behind the 404 errors is because i get these weird social details at the end of each of my urls like this one which adds my twitter handle to the end of the url for some bizarre reason:tag/tutorials/<email> i be concerned about the above?i realise the message says if the url does not exist you don't have to do anything, well it doesn't exist, but it also does in the fact that it is a page on my site, just without the twitter handle at the end?confused...head spinning...should i be worried?",
    "present_kp": [
      "google",
      "404"
    ],
    "absent_kp": [
      "seo",
      "google search console"
    ]
  },
  {
    "text": "how to log into a single ssh host without passphrase?. i usually have to access a couple of remote and local ssh hosts, this works perfectly, i actually want to have to type in the passphrase every time.however, there's a single ssh host on my local network that i have to log into a lot more frequently than the rest. security is not much of a problem with this one in particular, although connecting without keys is out of the question. is there any kind of configuration which would allow me to not enter the passphrase for this single ssh host?i hope i'm not asking something that doesn't even make sense...thank you.edit: i apologize for not clarifying, every server and my client are running linux, there's no other os involved in any way.",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "openssh"
    ]
  },
  {
    "text": "cognito form quit sending to my e-mail. i've been using my cognito form since the beginning of august and it has been sending me notifications to my e-mail up until this morning. i only have 108 submissions. why would it stop notifying me? btw- i've checked my junk mail just in case it started being marked as spam but it's not going there either.",
    "present_kp": [],
    "absent_kp": [
      "cognito forms"
    ]
  },
  {
    "text": "aimbot for open-source fps game assault cube. i am actually quite new to c++, although i have previously programmed in java. do you see any ways i can improve readability, maintainability and performance, and make it more object-oriented?/* control + 0 = enable aimbot*/#include stdafx.h#include <math.h>const float pi = 3.14159265358979f;/* * i am using int* as if it were the same thing as int**, int***, etc. * another more elegant looking method is to use int as if it were int*, int**, etc * but it is more prone to undefined behaviour and i am more likely to get away with the first method. * see: <url> getclosestpointer(int** basepointer, int offsets[], int levels) { for (int i = 0; i < levels; i++) { basepointer = (int**) (*basepointer + offsets[i] / sizeof(int)); } return (int*) basepointer;}/* [player base] = a [a + 34] = x [a + 38] = y [a + 3c] = z [a + 40] = crosshair x [a + 44] = crosshair y [a + f4] = hp [a + 154] = grenades*/int playerbasexoffsets[] = { 0x34 };int playerbaseyoffsets[] = { 0x38 };int playerbasezoffsets[] = { 0x3c };int playerbasecxoffsets[] = { 0x40 };int playerbasecyoffsets[] = { 0x44 };int playerbasehpoffsets[] = { 0xf4 };int playerbaseammooffsets[] = { 0x368, 0x14, 0 };int playerbasegrenadesoffsets[] = { 0x154 };typedef struct player { int** basepointer; float* xpointer; float* ypointer; float* zpointer; float* cxpointer; float* cypointer; int* hppointer; int* ammopointer; int* grenadespointer; player() { } player(int** baseptr) { basepointer = baseptr; xpointer = (float*) getclosestpointer(basepointer, playerbasexoffsets, sizeof(playerbasexoffsets) / sizeof(playerbasexoffsets[0])); ypointer = (float*) getclosestpointer(basepointer, playerbaseyoffsets, sizeof(playerbaseyoffsets) / sizeof(playerbaseyoffsets[0])); zpointer = (float*) getclosestpointer(basepointer, playerbasezoffsets, sizeof(playerbasezoffsets) / sizeof(playerbasezoffsets[0])); cxpointer = (float*) getclosestpointer(basepointer, playerbasecxoffsets, sizeof(playerbasecxoffsets) / sizeof(playerbasecxoffsets[0])); cypointer = (float*) getclosestpointer(basepointer, playerbasecyoffsets, sizeof(playerbasecyoffsets) / sizeof(playerbasecyoffsets[0])); hppointer = getclosestpointer(basepointer, playerbasehpoffsets, sizeof(playerbasehpoffsets) / sizeof(playerbasehpoffsets[0])); ammopointer = getclosestpointer(basepointer, playerbaseammooffsets, sizeof(playerbaseammooffsets) / sizeof(playerbaseammooffsets[0])); grenadespointer = getclosestpointer(basepointer, playerbasegrenadesoffsets, sizeof(playerbasegrenadesoffsets) / sizeof(playerbasegrenadesoffsets[0])); }} player;player players[32] = { };/* pythagorean's theorem (flavour for 3d) */float getdistancebetween(player one, player two) { return sqrt( (*(one.xpointer)-*(two.xpointer))*(*(one.xpointer)-*(two.xpointer)) + (*(one.ypointer)-*(two.ypointer))*(*(one.ypointer)-*(two.ypointer)) + (*(one.zpointer)-*(two.zpointer))*(*(one.zpointer)-*(two.zpointer)) );}int getnumberofplayers() { return *((int*) ((uint) getmodulehandlew(0) + 0xe4e10));}player* getclosesttarget() { float smallestdistance; int index = -1; for (int i = 1; i < getnumberofplayers(); i++) { if (*(players[i].hppointer) > 0) { float tempdistance = getdistancebetween(players[0], players[i]); if (index == -1 || tempdistance < smallestdistance) { smallestdistance = tempdistance; index = i; } } } if (index == -1) { return null; } else { return &players[index]; }}/* gets the crosshair horizontal angle in degrees. */float getcx(player me, player target) { float deltax = *(target.xpointer) - *(me.xpointer); float deltay = *(me.ypointer) - *(target.ypointer); if (*(target.xpointer) > *(me.xpointer) && *(target.ypointer) < *(me.ypointer)) { return atanf(deltax/deltay) * 180.0f / pi; } else if(*(target.xpointer) > *(me.xpointer) && *(target.ypointer) > *(me.ypointer)) { return atanf(deltax/deltay) * 180.0f / pi + 180.0f; } else if(*(target.xpointer) < *(me.xpointer) && *(target.ypointer) > *(me.ypointer)) { return atanf(deltax/deltay) * 180.0f / pi - 180.0f; } else { return atanf(deltax/deltay) * 180.0f / pi + 360.0f; }}/* gets the crosshair vertical angle in degrees. */float getcy(player me, player target) { float deltaz = *(target.zpointer) - *(me.zpointer); float dist = getdistancebetween(me, target); return asinf(deltaz/dist) * 180.0f / pi;}int main() { bool aimbotenabled = false; player* closesttargetpointer = null; // [base + df73c] = player 1 base players[0] = player((int**) ((uint) getmodulehandlew(0) + 0xdf73c)); int** extraplayersbase = *((int***) ((uint) getmodulehandlew(0) + 0xe5f00)); while (true) { // [base + e5f00] = a // [a + 0,4,8...] = player 2/3/4... base for (int i = 0; i < getnumberofplayers() - 1; i++) { players[i + 1] = player(extraplayersbase + i * 4 / sizeof(int*)); } if (getasynckeystate(vk_control) && getasynckeystate('0')) { aimbotenabled = !aimbotenabled; sleep(500); } if (aimbotenabled) { closesttargetpointer = getclosesttarget(); if (closesttargetpointer != null) { *(players[0].cxpointer) = getcx(players[0], *closesttargetpointer); *(players[0].cypointer) = getcy(players[0], *closesttargetpointer); } } sleep(10); }}dword winapi main(lpvoid lpparam) { main(); return s_ok;}bool apientry dllmain(hmodule hmodule, dword ul_reason_for_call, lpvoid lpreserved) { if (ul_reason_for_call == dll_process_attach) { disablethreadlibrarycalls(hmodule); createthread(null, 0, &main, null, 0, null); } return true;}",
    "present_kp": [
      "c++",
      "ai"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "linux or unix online practice environment. i want to learn linux or unix, but i don't want to install on my machine. is there any site or any other way to practice linux online?",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "learning"
    ]
  },
  {
    "text": "arch won't boot into grub on hp elitebook, but does everywhere else. so this is not my first time setting up arch on a system. but for some reason this here is not working. i have an hp elitebook 2560p, i already had fedora 22, ubuntu, centos and other linux distros on it before (meaning that grub did boot before). this time around i wanted to switch the distro to arch, so i went about it the way the manual on the archulinix suggested. however, arch doesn't boot up on my laptop, well, the screen is just black (so something must've happened). i tried swapping the harddrive onto another computer (acer one and my desktop) it booted up fine with no issues. because, the screen turned black, i assumed it's something with the drivers, so i tried both hooking it up to another screen and installing the drivers. that didn't work either. i'm not sure what files to post here, so please request them and i will post them here. i'm just not getting why it's not working for me. the computer specs are as they are out of the box, with the one difference that i use an ssd harddrive.",
    "present_kp": [
      "boot",
      "grub"
    ],
    "absent_kp": [
      "arch linux",
      "grub2"
    ]
  },
  {
    "text": "what happens when you rsync without a destination?. to make the story short, i did an rsync:rsync -avp <email>/tmp/and i forgot to put in my source directory...i really meant to run:rsync -avp /tmp/ <email>/tmp/it printed a bunch of files, but i don't know where it copied them because i didn't specify a destination. does anyone know what happened? i did an ls on the current folder, but i didn't find anything.",
    "present_kp": [
      "rsync"
    ],
    "absent_kp": [
      "linux",
      "file copy"
    ]
  },
  {
    "text": "problem when i shutdown the system or reboot with linux mint 18.1 kde. anytime i try to shutdown or reboot the system, desktop and everything is closed but this appear: the system is blocked and i'm obliged to shutdown the notebook manually with the button, i have fear that with doing this anytime i will break the system.solutions?info: notebook: hp 15-ba054nlchipset: amd a10-9600p radeon r5, 10 compute cores 4c+6g ram: 16gb ddr4 sdram os: linux mint 18.1 kde 64 bitkernel: 4.4.0-92-generickde plasma: 5.8.7",
    "present_kp": [
      "linux mint",
      "kde",
      "shutdown",
      "reboot"
    ],
    "absent_kp": [
      "amd graphics"
    ]
  },
  {
    "text": "class responsibilities oop design. i'm having some questions on creating a design for simple approval workflow. some arbitrary thing (itemtoapprove) needs approval process. approval process begins with creating approvalroute which contains several approval steps (approvalstep). itemtoapprove goes sequentially through all steps until gets status approved. on each step there are several approvers with equal priority. if one approver approves item, step becomes approved.public class approvalroute{ private linkedlist<approvalstep> _approvalsteps; private approvalstep _currenstep; public bool? approved { get; private set; } public void approve(approver approver) { // ... some cheks if already approved etc _currentstep.approve(approver); if (_currentstep.approved == true) { movetonextstep(); // changes _currentstep } if (allstepsapproved()) { approved = true; } }}public class approvalstep{ public bool? approved { get; private set; } private list<approver> _approvers; public approvalstep(list<approver> approvers) { _approvers = approvers; } public void approve(approver approver) { if (_approvers.contains(approver)) { approved = true; } }}public class itemtoapprove{ public bool? approved { get; private set; } private approvalroute _approvalroute; public void startapprovalworkflow(approvalroute route) { _approvalroute = route; } public void approve(approver approver) { _approvalroute.approve(approver); if (_approvalroute.approved == true) { approved = true; } }}public class approver{ public string name { get; private set; } public approver(string name) { name = name; } // ... ovveriding equals etc}so some console client would be like this var itemtoapprove = new itemtoapprove(); var aprovalroute = new approvalroute(new approvalstep(new list<approver> { new approver(one), new approver(neo), }); itemtoapprove.startapprovalworkflow(aprovalroute); while (itemtoapprove.approved == null) { console.write(your name: ); string approvername = console.readline(); itemtoapprove.approve(new approver(approvername)); }i thik this design has some smell because calling approve delegates further down to approvalstep. the second smell i feel more naturally call approve on approver passing itemtoapprove// ....var approver = new approver();approver.approve(itemtoapprove);what do you think?",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "object oriented",
      "classes"
    ]
  },
  {
    "text": "how do you determine your hourly rate?. in pricing a service or product it is general practice to not merely charge for the effort spent and the costs involved + margin but from the value delivered down. as an independent consultant, how do you set the price of your work? what is the process of determining your hourly rate as an independent software developer? if you have one, what is your hourly rate and how did you arrive at that figure? what factors would you take into account. is the process of setting a hourly rate only based on balancing demand with supply so that supply (you and your time) doesn't get overwhelmed? when are the good times to raise your rates? are there projects in which you have had to charge higher than other projects? if so, please cite examples.do you change your hourly rate based on what kind of development you are doing? (for example, .net programming more, and lesser for php programming)do you set hourly rates based on what type of business the client is? if so how?if you know of any relevant articles or material on the topic of charging for programming services, please post the same.",
    "present_kp": [
      "business",
      "pricing"
    ],
    "absent_kp": [
      "freelancing"
    ]
  },
  {
    "text": "simple tic-tac-toe game in react.js. i'm relatively new to react and attempted to create a simple tic-tac-toe game. would be great if i could get some feedback on this. again, at this point using only react (no redux).main.js - main file which adds our app component to the domimport react from 'react';import reactdom from 'react-dom';import app from './container/app';document.addeventlistener('domcontentloaded', function() { reactdom.render( react.createelement(app), document.getelementbyid('mount') );});app.js - root component that contains the board and dashboard. one specific question i had here was: when i receive the reset() event from my dashboard app, what's the best practice on how i can end up triggering the reset() of board?import react, { component } from 'react';import board from './board'import dashboard from './dashboard'export default class app extends component { constructor(props) { super(props) this.state = { winner: '' } } reset() { console.log('how do i pass reset to board...?') } haswinner(winner) { this.setstate({ winner: winner }) } render() { return ( <div> <board rows={3} cols={3} haswinner={this.haswinner.bind(this)} /> <dashboard winner={this.state.winner} reset={this.reset.bind(this)} /> </div> ) }}board.js - board component that contains cell components! please ignore the checkwinner() method for the purpose of this review.import react, { component } from 'react';import cell from './cell'import styles from '../css/board.css'export default class board extends component { constructor(props) { super(props) let board = this.createboard(); this.state = { board: board, currentplayer: 'x' } } createboard() { let board = new array(this.props.rows); for ( var row = 0 ; row < this.props.rows ; row++ ) { board[row] = new array(this.props.cols); board[row].fill(''); }; return board; } checkwinner() { // todo: please add correct winner algo! return this.state.board[0][0]; } drawboard() { let board = []; for ( let i = 0 ; i < this.props.rows ; i++ ) { for ( let j = 0 ; j < this.props.cols ; j++ ) { var id = i + '' + j; board.push( <cell key={id} id={id} play={this.play.bind(this)} value={this.state.board[i][j]} /> ); } } return board; } reset() { let board = this.createboard(); this.setstate({ board: board, currentplayer: 'x' }) } play(ij) { let i = ij[0]; let j = ij[1]; let board = this.state.board; board[i][j] = this.state.currentplayer; this.setstate({ board: board, currentplayer: this.state.currentplayer==='x'?'o':'x' }) let winner = this.checkwinner(); if ( winner != '' ) { this.props.haswinner(winner); this.reset(); } } getclassname() { return styles.board } render() { return ( <div classname={this.getclassname()}> {this.drawboard()} </div> ) }}cell.js - cell componentimport react, { component } from 'react';import styles from '../css/cell.css'export default class cell extends component { constructor(props) { super(props) } getclassname() { return styles.emptycell } play() { if ( this.props.value === '' ) this.props.play(this.props.id) } render() { return ( <div onclick={this.play.bind(this)} classname={this.getclassname()}> {this.props.value} </div> ) }}dashboard.js - component to show winner and contains a reset button.import react, { component } from 'react'export default class dashboard extends component { constructor(props) { super(props) } render() { const winner = this.props.winner ?<h1>and the winner is: {this.props.winner}</h1> :<p></p> return ( <div> {winner} <input type=button value=reset onclick={this.props.reset} /> </div> ) }}",
    "present_kp": [
      "react.js"
    ],
    "absent_kp": [
      "javascript",
      "tic tac toe"
    ]
  },
  {
    "text": "restoring symmetry in certain combinatorial bijections?. i'm interested in two 'natural bijections' that involve labeled forests and young tableaux. let me give the definition for labeled forests. by this, we mean a pair $\\cal{f} = (f,f)$ where $f$ is an $n$-vertex forest, and $f$ is a labeling of its nodes from $1$ to $n$. we say that:$\\cal{f}$ is standard if $f$ is bijective,$\\cal{f}$ is sorted if the numbering is increasing along each root-to-leaf path,$\\cal{f}$ is subexcedant if for each node $u$, $f(u)$ is at most the number of nodes of the subtree rooted at $u$.let $t_n,o_n,u_n$ denote the sets arising from these three cases, for a fixed size $n$. it is not too difficult to show the existence of a bijection $sort_n : t_n ightarrow o_n imes u_n$, which implies a well-known 'hook length' formula due to knuth. one unpleasant aspect of this bijection lies in its assymetry: we would like to get a pair of similar objects in order to get extra symmetry properties (e.g. what would happen if we switch the two objects and then apply the reverse bijection?)therefore, i'm asking naively if you think that the symmetry could be restored by considering more general structures. i'm not optimistic on this question though: there might be a positive but difficult answer that so far eludes me. a side remark: this bijection $sort_n$ already enjoys some interesting symmetry properties in connection with the schtzenberger involution, but we would need something stronger to get an interesting algebraic object (possibly a hopf algebra?)",
    "present_kp": [
      "algebra",
      "symmetry"
    ],
    "absent_kp": [
      "co.combinatorics"
    ]
  },
  {
    "text": "jargon for when your site's bandwidth quota is eaten up by traffic from a backlink in a popular blog?. this happens every now and then on the web. charlie has a personal blog where they posts about technical stuff. one day a popular site finds about their posts, and decides to do an article on it, linking to the source, of course.the incoming traffic eats up charlie's provider's bandwidth quota, and is taken down by the provider.is there a term for this unavailability of a site due to unexpected traffic from suddenly being famous?",
    "present_kp": [
      "availability"
    ],
    "absent_kp": [
      "backlinks",
      "high traffic",
      "terminology"
    ]
  },
  {
    "text": "efficient generic type conversion between numeric types in f#. it's easy to write a function that adds two ints in f#:let add x y = x + yactually, it's the same as:let add (x:int) (y:int): int = x + yif you need to make it generic so that it can take arguments of other type than int,you should use inline keyword:> let inline add x y = x + y;;val inline add : x: ^a -> y: ^b -> ^c when ( ^a or ^b) : (static member ( + ) : ^a * ^b -> ^c)then you can pass values of any type that has the + operator to add:> add 1 2;;val it : int = 3> add 1l 2l;;val it : int64 = 3l> add 1i 2i;;val it : system.numerics.biginteger = 3 however, it's not easy to write a generic function if you have to useliterals in the middle of an expression:> let inline inc x = x + 1;; val inline inc : x:int -> intx always evaluates to be of int since the literal 1 is of int. it would be cool if you could write something like the following pseudo-code:let inline inc (x:^t) = x + (1 :> ^t)in order to do so, f# provides numericliteralx (where x should be replaced with g, n, z, ...):module numericliteralg = let inline fromzero() = languageprimitives.genericzero let inline fromone() = languageprimitives.genericone let inline fromint32 n = let one = fromone() let zero = fromzero() let iinc = if n > 0 then 1 else -1 let ginc = if n > 0 then one else -one let rec loop i g = if i = n then g else loop (i + iinc) (g + ginc) loop 0 zero now you can make the inc function generic as follows:> let inline inc x = x + 1g;;val inline inc : x: ^a -> ^c when ( ^a or ^b) : (static member ( + ) : ^a * ^b -> ^c) and ^b : (static member get_one : -> ^b)the obvious deficiency with numericliteralx, however, isfromint32 can be horribly slow for a large number. for example, if you writea function that divides a number by <phone>:let inline dividebymillion x = x / 1000000gthe loop in fromint32 executes <phone> times!here i propose a better approach that has no such performance hit:type bigintcast = bigintcast with static member inline (=>) (bigintcast, x: int) = bigint x static member inline (=>) (bigintcast, x: uint32) = bigint x static member inline (=>) (bigintcast, x: int64) = bigint x static member inline (=>) (bigintcast, x: uint64) = bigint x static member inline (=>) (bigintcast, x: bigint) = x static member inline (=>) (bigintcast, x: single) = bigint x static member inline (=>) (bigintcast, x: double) = bigint x static member inline (=>) (bigintcast, x: decimal) = bigint x static member inline (=>) (bigintcast, x: byte[]) = bigint xtype numericcast = numericcast with static member inline (=>) (numericcast, _: sbyte) = sbyte static member inline (=>) (numericcast, _: byte) = byte static member inline (=>) (numericcast, _: int16) = int16 static member inline (=>) (numericcast, _: uint16) = uint16 static member inline (=>) (numericcast, _: int) = int static member inline (=>) (numericcast, _: uint32) = uint32 static member inline (=>) (numericcast, _: int64) = int64 static member inline (=>) (numericcast, _: uint64) = int64 static member inline (=>) (numericcast, _: nativeint) = nativeint static member inline (=>) (numericcast, _: unativeint) = unativeint static member inline (=>) (numericcast, _: single) = single static member inline (=>) (numericcast, _: double) = double static member inline (=>) (numericcast, _: decimal) = decimal static member inline (=>) (numericcast, _: bigint) = (=>) bigintcastlet inline (^>) t x = (numericcast => x) tnow the inc function can be written as:> let inline inc x = x + (1 ^> x);;val inline inc : x: ^a -> ^c when ( ^a or ^b) : (static member ( + ) : ^a * ^b -> ^c) and (numericcast or ^a) : (static member ( => ) : numericcast * ^a -> int -> ^b) 1 ^> x reads cast 1 to the same type as x.the results are the same as before:> inc 1;;val it : int = 2> inc 1l;;val it : int64 = 2l> inc 1i;;val it : system.numerics.biginteger = 2type safety is enforced by the compiler:> inc 1;; inc 1;; ^^^c:\\users\\junyoung\\appdata\\local\\temp\\stdin(8,1): error fs0043: no overloads match for method 'op_equalsgreater'. the available overloads are shown below (or in the error list window).possible overload: 'static member numericcast.( => ) : numericcast:numericcast * x: ^t -> ('a -> 'a) when ^t : (static member get_one : -> ^t)'. type constraint mismatch. the type string is not compatible with type 'a ... snip ...in summary, it's easy to use, fast and type-safe. choose any three. :-)what do you think?the original idea of using an operator trick came from here.",
    "present_kp": [
      "f#"
    ],
    "absent_kp": [
      "generics",
      "casting"
    ]
  },
  {
    "text": "user roles array vs string. i'm working on a meanjs project. the user roles are set as an array:roles = ['admin', 'user', 'manager'];why not just set it like this?role = 'admin'why is the convention of an array used rather than just setting a role value as a string?",
    "present_kp": [],
    "absent_kp": [
      "frameworks",
      "user interface",
      "authorization"
    ]
  },
  {
    "text": "is there a 'cp' like command for verifying data and removing files?. i have some photo files on my phone, and i am backing them up to an external drive. (everything is mounted on a linux laptop.)i have copied the files, when i should really have mv'ed them.however, since i have done this, i would like to verify the data copied correctly for each file, and then remove the file from my phone if the file was copied without error.so what i am really looking for is a cp or mv like command which:copies the file if it does not exist on the destinationverifies the data between source and destination (after copying if the file did not already exist)if both files are binary identical, remove the file from the sourcei thought i might be able to do this with rsync, but i have had a look through the various delete-like options and none of them matched delete the file on the source, rather these options delete files before/after/during(?) on the destination instead.",
    "present_kp": [
      "files"
    ],
    "absent_kp": [
      "backup",
      "file copy",
      "verification"
    ]
  },
  {
    "text": "boot process stops at [ok] reached target graphical interface. os - apricity osde - gnome 3.22i wasn't able to launch any applications, so i decided to reboot my laptop and now i have this problem.i have included some information below which might be of use.note- i have not modified my nvidia drivers and neither have i performed a complete or partial system upgrade for at least a weak before this happened.there are no errors to be found in my xorg log. here's the output of systemctl status gdm.serviceloaded:loaded (usr/lib/systemd/system/gdm.service; enabled; vendor preset: disabled)active: active(running) since tue 2016-11-01 00:40:35 ist; 44s ago main pid: 626 (gdm)tasks: 3 (limit: 4915)cgroup: /system.slice/gdm.service /usr/bin/gdmnov 01 00:40:44 apricity-lap gdm[626]: child process -794 was already dead.nov 01 00:40:44 apricity-lap gdm[626]: child process 778 was already dead.nov 01 00:40:44 apricity-lap gdm[626]: unable to kill session worker process.nov 01 00:40:44 apricity-lap gdm[626]: gdmdisplay: display lasted 0.545465 seconds.nov 01 00:40:44 apricity-lap gdm[626]: child process -824 was already dead.nov 01 00:40:44 apricity-lap gdm[626]: child process -808 was already dead.nov 01 00:40:44 apricity-lap gdm[626]: unable to kill session worker process.nov 01 00:40:44 apricity-lap gdm[626]: gdmdisplay: display lasted 0.528677 seconds.nov 01 00:40:44 apricity-lap gdm[626]: gdmlocaldisplayfactory: maximum number of x display failures reached: check x server log for errors.nov 01 00:40:44 apricity-lap gdm[626]: child process -854 was already dead.so, what exactly has gone wrong?",
    "present_kp": [
      "gnome"
    ],
    "absent_kp": [
      "arch linux",
      "gnome3"
    ]
  },
  {
    "text": "run apriori algorithm in python 2.7. i have a dataframe in python by using pandas which has 3 columns and 80.000.000 rows.the columns are: {event_id,device_id,category}.[]each device has many events and each event can have more than one category.i want to run apriori algorithm to find out which categories seem together.my idea is to create a list of lists[[]]: to save the categories which are in the same event for each device. like: [('a'),('a','b')('d'),('s','a','b')] then giving the list of lists as transactions to the algorithm. i need help to create the list of lists.if you have better idea please tell me because i am new in python and this was the only way i found out.",
    "present_kp": [
      "python",
      "pandas"
    ],
    "absent_kp": [
      "dataset",
      "association rules"
    ]
  },
  {
    "text": "env -i and bash-c. can someone please help me understand the difference betweenbash -c 'echo $shell $home $user'andenv -i bash -c 'echo $shell $home $user'i tried going over it many times but i still don't get it. i'm studying about env and bash -c appears in the example. what does bash -c do exactly?",
    "present_kp": [],
    "absent_kp": [
      "environment variables"
    ]
  },
  {
    "text": "how does solaris find man pages?. initially, my manpath environment variable is not set. despite this, i can use the man command to view most man pages as usual.man top can't find that particular man page, but which man tells me the command is in /opt/sfw/bin.there are man pages for top and other commands in /opt/sfw/man.i set export manpath=/opt/sfw/man and i can now see the man page with man top. however man can no longer find pages for bash, cp or any other standard command.how can i add this one directory to the list used to find man pages?i'm using sunos 5.10 and bash 3.0.16, if it matters.",
    "present_kp": [
      "solaris",
      "man"
    ],
    "absent_kp": []
  },
  {
    "text": "what do you mean by minimum height of a binary search tree?. i came across the term minimum height of a binary search tree (in java) in class, but i don't fully understand. could someone please elaborate on: (a) what it is ? (b) how to determine/find it ?",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "binary trees"
    ]
  },
  {
    "text": "which design pattern to use for a house bills desktop application. i want to create a desktop application using java and mysql which allows me to save the details of the bills like cost, period of the bill, date paid etc., for various bills. i have some doubts:is the mvc design pattern correct for this application?is using ejb for the business logic unnecessary and an overkill for my aplication?",
    "present_kp": [
      "java",
      "desktop application"
    ],
    "absent_kp": [
      "design patterns"
    ]
  },
  {
    "text": "vps and hosting. no this is no duplicate of the above. my question is very specific to vps and is not solely related to hosting but also to virtual desktop and such. the above barely writes 2 lines about vps and never speak of virtual desktop needs. case:i'm going to upload a (small) symfony2 website soon. i plan to create another one after and maybe a little wt app ( which forces me to have a vps ). i also would like to have a 100% uptime virtual desktop + storage available from anywhere. for symfony2, i need to be able to manage apc pecl cache extension at the very least. for wt i need root access to compile and run c/c++ code and play with apache.questions:when it comes to vps, price differences are huge for similar front characteristics. why ?given my needs ( website traffic should never exceed 100 dudes daily ). what should i look for ? ( cpu, ram[guaranteed?], bandwidth )basically i'm looking for one or two guys that have experienced professionally a few vps and php-hosting solutions, and be advised about everything i ask... and did not ask !",
    "present_kp": [
      "vps"
    ],
    "absent_kp": [
      "web hosting"
    ]
  },
  {
    "text": "are people notified when added to gmail contacts list?. if you add a new gmail address to your gmail contact list, is that person notified that they were added to your gmail contacts list? both people have gmail.",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "google contacts"
    ]
  },
  {
    "text": "cryptographic key exchange. i initially posted this on stackoverflow, and was redirected here.i have been playing around with bouncy castle (java) for the last few days, and i've reached the point where i believe i can securely exchange secret keys with a diffie-hellman exchange.having read many posts underlining the difficulty of properly implementing a cryptographic exchange, i would like your honest opinion on my work.all the underlying cipher operations are based on bouncy castle and may therefore be deemed reliable.string message = hello world;aescipher aes_client = new aescipher(256);rsacipher rsa_server = new rsacipher(2048);// (public key sent over the wire)rsacipher rsa_client = new rsacipher(rsa_server.getpublickey().getmodulus(), rsa_server.getpublickey().getexponent());// the client encodes his aes key with the rsa public key:byte[] aes_key = rsa_client.encode(aes_client.getkeybytes());byte[] aes_iv = rsa_client.encode(aes_client.getinitializationvector());// (data sent back over the wire)byte[] decoded_aes_key = rsa_server.decode(aes_key);byte[] decoded_aes_iv = rsa_server.decode(aes_iv);// the server creates an aes server which uses the client key:aescipher aes_server = new aescipher(decoded_aes_key, decoded_aes_iv);byte[] encoded_message = aes_client.encode(message.getbytes());byte[] decoded_message = aes_server.decode(encoded_message);system.out.println(new string(decoded_message));can this exchange be considered safe? should i be sticking with ssl sockets, eventhough it'd hurt to thrash my hard work?thanks in advance for your input!(by the way, my bouncy-castle-wrapping-library is totally open-source, so just let me know if you want the repository's url.)",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "security",
      "cryptography"
    ]
  },
  {
    "text": "how to manage threads in a framework. i'm developing a framework with c++, and it contains three layers:low level functions which do the hard workan upper layer which uses the low level functions to accomplish tasks (functions at this level generally uses only one lower level function and explicitly accepts the pointer of the function to know which function to call)top level classes which utilizes these middle layer functions to accomplish complete tasks.the problem is, i'm introducing concurrency into the framework and need a way to tune this concurrency per function basis. i can design an object to transfer concurrency parameters, but i don't want to pass an object to functions which are not concurrent.concurrent functions can be at any level and their concurrency needs to be controlled independently.is there a better pattern or method to allow only concurrent functions to access this information?",
    "present_kp": [
      "c++",
      "concurrency"
    ],
    "absent_kp": [
      "parallel programming"
    ]
  },
  {
    "text": "why are optimization problems always np-hard and not np-complete and what does this mean for other levels of the polynomial time hierarchy?. i have read that optimization problems cannot be $\\mathcal{np}$-complete, but are always classified as $\\mathcal{np}$-hard. when a problem is np-complete, i know it is contained in $\\mathcal{np}$p. this implies in particular that it is not hard for the second level of the polynomial time hierarchy, e.g. for $\\sigma_2^p$ or $\\pi_2^p$. but since optimization problems are only np-hard, i have no such knowledge. or are optimization problems usually also $\\sigma_2^p$-hard or $\\pi_2^p$-hard, or just some of them?are there any interesting problems from combinatorial optimization that are harder than $\\mathcal{np}$-hard, e.g. hard for the second level of the polynomial time hierarchy?i am in particular interested in problems from combinatorial optimization, e.g. bp (bin packing), tsp and cvrp (capacitated vehicle routing problem). they are all classified as $\\mathcal{np}$-hard, but cvrp is a generalization of both tsp and bp, so it should be harder? bin packing should be easier, are there any results showing this?does anyone know, if there are hardness results for any of these problems that imply more difficult than $\\mathcal{np}$-hard?i know there are many versions of cvrp and tsp and unfortunately i know not a lot about them.",
    "present_kp": [
      "optimization"
    ],
    "absent_kp": [
      "complexity theory",
      "terminology",
      "integer programming"
    ]
  },
  {
    "text": "two-way hash functions. while i'm aware most (good) hash functions are one-way (or at least mostly so), i'm wondering if there's any construct (not necessarily called a hash function) which behaves in many ways like a hash function, but can be easily reversed.for example, a function $f$ takes an arbitrary string $x$ and maps it to $y$, where $|y| = c$ for some constant $c$ (i.e. $y$ is always the same length), and collisions are infrequent, so in general, $f(x) = y$.in this case, i'm wondering if it's possible to construct a function $f$ matching the criteria above, but where $f^{-1}(y) = x$ is as easily calculable as $f(x) = y$, in a computational complexity sense.in the case of collisions, where $ orall x \\in s$, $f(x) = y$, $f^{-1}(y)$ might give you either the entire set $s$, some subset of $s$, or even a single element from $s$in the case that this is not theoretically possible, possibly due to the fact that $f$ allows strings of arbitrary lengths and $|y| = c$, so infinite collisions must occur(?), then what if we only allow $|x| < c$, such that the number of possible collisions are finite?obviously, you wouldn't use this kind of function for anything security related, but it might be useful for something like reverse image searching?",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "complexity theory",
      "hashing"
    ]
  },
  {
    "text": "sed or awk: add line after each ocurrance of pattern between a range of line numbers. i need to add a line of text after each occurence of a pattern. i need this:pattern1pattern2to look like thispattern1pattern2new line data herethe new line data will always come after pattern2. pattern2 will always be the same and i have well over 100 occurences of patter2. and i only want to do this when i seen pattern 2 between lines 226 and 2858. i would like to do an in-place modification and do all this without wiping out anything else in the file. (already did that once while testing, don't want to do it again)update - i need to be more precise as my patterns contain special characters. so i'm actually changing this:pattern1pattern2 { text; };to thispattern1pattern2 { text; };new data { text; text; text; };so matching on pattern 2 that contains special characters and adding the new data line with the special characters. should have disclosed that before. sorry for any confusion.",
    "present_kp": [
      "sed",
      "awk"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "dell m3800 with qhd - no 1920x1080. normally i am working on two fullhd 27 screens, but when i am in school i need to use my laptop display with qhd. but seriously, who can work with 3200x1080 on a 15 display? :dmy windows vm can display fullhd on the laptop, but fedora 21. my question now: is there any graphical driver for fedora 21 or do i have to create a custom solution?",
    "present_kp": [
      "fedora"
    ],
    "absent_kp": []
  },
  {
    "text": "entering mm:ss: milliseconds into google sheets for time duration (arithmetic). i would like to enter times mm, seconds, milliseconds into google sheets and subtract times to determine duration. i use format> numbers > more formats > more dates and times > and apply mm:ss: ms.i enter my numbers (e.g. 02:23 44), the cell contains text not number and the format shows automatic. it does not matter if i use colons or not (cells g6, g7).how can i enter times in the format of mm, ss, and milliseconds? i've tried duration format, the cells still ends up as text not numbers. i've tried using time (hh:mm:ss am) - the times show up as numbers and i can display these with milliseconds. i tried copying the correctly formatted cells, but then i cannot insert the new times (no place for milliseconds). any help would be appreciated - i've searched for similar problems but can't find exactly what i am looking for. if this can be done without formulas that would be great. <url> the way, i noticed this question and reply about entering time. but the timevalue formula does not appear to have milliseconds. any help on using the formula for getting ms would be great.time duration formatting in google spreadsheets",
    "present_kp": [
      "google spreadsheets",
      "formatting",
      "duration"
    ],
    "absent_kp": []
  },
  {
    "text": "debugging win32.upatre - why does ollydbg fail to analyze this?. so i've been looking at this thread - where can i, as an individual, get malware samples to analyze?and grabbed myself a binary sample of win32.upatre from halvar flake's blog.i started analyzing the file in my vm (win xp sp 3) and loaded up the malware in olly.what i noticed is that the code looks encrypted - i searched for all the calls in the code and got this: which doesn't seem quite normal.so i went ahead and started stepping from the ep hopefully landing on some decryption procedure - i'll briefly explain what i concluded from debugging this code:1 - gets the arguments passed to this executable - i'm pretty sure any code before this is irrelevant, but i might be wrong.2 - calls getstartupinfo - not quite sure why3 - call 00401c80 passing the ep as a parameterso i went ahead jumping to 00401c80 to check what this is all about and found this code which kinda looks like junk code to me - i suspect because there are some instructions that just don't seem logic to me like:mov eax, 64cmp eax,3e8but i might be wrong.the problem is that after at the end of the function a value is copied into ecx and then call ecx is called which eventually ends in memory access violation:no matter what i do or how i play with the flags inside this function i get an access violation or the code exits. sooooooooo, my first thought was that i'm dealing with some kinda anti-debugging technique, so i tried to run the malware inside the vm and intercept some data from it - and it seems like it's running alright and even created a udp socket, no access violation or something like that.i tried looking online for reports about this virus but i couldn't found any resources about how to bypass this obstacle.anyone got an idea how i should approach this? why is olly failing? how does this code knows that it's being debugged? it doesn't seem like it uses some kind of api for that (like isdebuggerpresent).thanks for everyone in advance.",
    "present_kp": [
      "ollydbg",
      "malware"
    ],
    "absent_kp": [
      "obfuscation",
      "anti debugging",
      "deobfuscation"
    ]
  },
  {
    "text": "can i make a derived work of a gpl project and a non gpl project for personal use?. in the gnu general public license, version 2, some limits on how you can modify the program are listed. point 2.b states that (emphasis mine):you must cause any work that you distribute or publish, that in whole or in part contains or is derived from the program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this license.as there seem to be no further limitations on how the changes have to be licensed and you are not required to release your modifications:can i make changes to a gnu gpl v2 program that i would not be allowed to distribute or publish provided i don't distribute and/or publish it?for instance, adding some code coming from an apache v2 project.",
    "present_kp": [
      "gpl"
    ],
    "absent_kp": [
      "licensing",
      "license compatibility",
      "gpl 2"
    ]
  },
  {
    "text": "a doubt in ladner's proof. i got stuck in ladner's proof while reading computational complexity: a modern approach by sanjeev arora and boaz barak. pardon me if i'm missing something really obvious here but the authors do the following:for every function $h\\colon\\mathbb{n} o\\mathbb{n}$ define$$sat_h=\\{\\psi01^{n^{h(n)}}: \\psi \\in sat \\ and \\ n=|\\psi|\\}$$now $h$ is defined as follows:$h(n)$ is the smallest number $i<\\log \\log n$ such that for every $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$, $m_i$ (tm encoded by binary representation of $i$) outputs $sat_h (x)$ within $i|x|^i$ steps. if there is no such number $i$ then $h(n)=\\log \\log n$.$m_i$ outputs $sat_h (x)$ is equivalent to the statement that: the machine $m_i$ on an input $x$ outputs a 1 $\\iff$ $x \\in sat_h$.my question is:by definition of $sat_h$, every string in it will have length exactly $n+1+n^{h(n)}$. for every string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$, we note that $|x|<n+1+n^{h(n)}$. so there does not exist any string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$ and $x \\in sat_h$. this would mean that the machine $m_i$ should trivially output 0 for every string $x\\in\\{0,1\\}^*$ with $|x|\\le \\log n$. but then how would such an argument be used for a proof? where exactly am i going wrong?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory"
    ]
  },
  {
    "text": "simple labyrinth. i'm making a a simple labyrinth. i want to make it so that i could hit a wall, and if i did hit the wall, i wouldn't cross it.from turtle import *from time import *speed(0)for a in range(0,401,20): sety(a); forward(400); #write(a); forward(-400);home()left(90)for a in range(0,401,20): setx(a) forward(400) backward(400)home()map=[ '####################', '# # #', '# #### ### # #### #', '# # # # # # #', '# #### #### # # # #', '# # # # #', '###### # #### ## # #', '# # # # #', '# #### ####### ### #', '# # # #', '# # ##### ### # # #', '# # # # #', '# # # # #### ## #', '# ## ##### # # ## #', '# # #', '# ########## ### # #', '# # # # #', '### #### # ####### #', '#s # # #', '####################']delay(0)home(); sety(400)for row in map: for cell in row: if cell == ' ': color('black', 'black') if cell == '~': color('black', 'red') if cell == '#': begin_fill() for x in range(4): forward(20) right(90) end_fill() if cell=='s' or cell=='f': if cell=='s': color('green') else: color('yellow') right(90) forward(20) left(90) write(cell, font=(arial, 14)) left(90) forward(20) right(90) forward(20) forward(-400) right(90); forward(20); left(90)goto(20,20)color('black', 'green')begin_fill()for i in range(4): forward(20); left(90)end_fill()write('s', font=(arial, 14))hideturtle()setx(160)color('black', 'yellow')begin_fill()for i in range(4): forward(20); left(90)end_fill()write('f', font=(arial, 14))hideturtle()hero=turtle()hero.color('pink')hero.penup()hero.speed(0)hero.goto(50,30)screen=getscreen()screen.listen()hero.row=8hero.col=2def w(): hero.clear() hero.setheading(90) hero.forward(20) hero.row-=1 react_to_cell() cell = map[hero.row][hero.col] if cell == '#': hero.forward(-20) hero.row+=1def s(): hero.clear() hero.setheading(-90) hero.forward(20) hero.row+=1 react_to_cell() cell = map[hero.row][hero.col] if cell == '#': hero.forward(-20) hero.row-=1def a(): hero.clear() hero.setheading(180) hero.forward(20) hero.col-=1 react_to_cell() cell = map[hero.row][hero.col] if cell == '#': hero.forward(-20) hero.col+=1def d(): hero.clear() hero.setheading(0) hero.forward(20) hero.row+=1 react_to_cell() cell = map[hero.row][hero.col] if cell == '#': hero.forward(-20) hero.row-=1def react_to_cell(): cell=map[hero.row][hero.col] if cell==' ': hero.write('ia negalima eiti', font=(arial, 14)) hero.goto(50,30) hero.setheading(0) hero.row=18 hero.col=1 elif cell=='f': hero.color('green') color('red') goto(-120,0) write(u'finias', font=(arial, 20, 'bold'))screen.onkey(w,'up')screen.onkey(s,'down')screen.onkey(a,'left')screen.onkey(d,'right')",
    "present_kp": [],
    "absent_kp": [
      "python",
      "beginner",
      "turtle graphics"
    ]
  },
  {
    "text": "software recommendation for plotting data from lab tests. i have several files of data created by labview of hydraulic pressure testing over the course of a few days. this data is mostly time with various pressure and temperature measurements.can you recommend software that will plot several hours worth of data and then let me zoom/pan and select certain intervals? i need to comb through the data a find examples of acceptable pressure holds. excel is inadequate for this task.",
    "present_kp": [
      "plotting"
    ],
    "absent_kp": [
      "data visualization"
    ]
  },
  {
    "text": "using sed on files with certain extension inside shell script. i am trying to use sed to find files with certain extension and then replace occurrences of a certain string with another. no directory mentioned using current directory*.hsed: can't read *.h: no such file or directory*.csed: can't read *.c: no such file or directory*.ccsed: can't read *.cc: no such file or directoryun.cppthis is the code in my script:for file in *.{h,c,cc,cpp} do echo $file; sed -i -e 's/${1}/${2}/g' $file; donei am having a similar issue when i am trying to use sed on sub folders recursively using find:find ./*.{h,c,cc,cpp} -type f -exec sed -i -e 's/${2}/${3}/g' {} \\;thank you",
    "present_kp": [
      "shell script",
      "sed"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "how to setup apple keyboard on linux?. i just bought old aluminum from apple and it is look great but i can't find the insert key. in google, i found that fn+enter shall do magic but it does not.any idea how to fix that?",
    "present_kp": [
      "linux",
      "keyboard",
      "apple"
    ],
    "absent_kp": []
  },
  {
    "text": "switch between keyboard layout based on input event. i have a french and a us keyboard on my computer. i'm using awesome wm and have set everything so that it is easy for me to switch between keyboard layout. but i still have to do it myself.theoretically, it should be possible for the computer to understand from which keyboard the input event comes and use the layout associated with the keyboard. i have looked it up but found no good answer.is it possible to do so ?i was thinking that i could write a short code analyzing keyboard event and do the switch, but :it would run in parallel with the event handler so there could be concurrency problem (something like this);it looks like a dirty way of doing it and i prefer a clean solution.thanks for your help",
    "present_kp": [
      "keyboard layout"
    ],
    "absent_kp": [
      "xorg",
      "udev",
      "xkb"
    ]
  },
  {
    "text": "is it safe to add . to my path? how come?. i've seen people mention in other answers that it's a bad idea to include the current working directory ('.') in your $path environment variable, but haven't been able to find a question specifically addressing the issue.so, why shouldn't i add . to my path? and if despite all warnings i do it anyway, what do i have to watch out for? is it safer to add it to the end than to the the start?",
    "present_kp": [
      "path"
    ],
    "absent_kp": []
  },
  {
    "text": "c++ vector the basics. following on from my two previous posts.an alternative vectoran alternative vector (copy assignment operator)i have written a detailed blog about how to write a minimal vector like class. this set of articles has been inspired by multiple posts here on <url> (see sources).indexresource management: allocationresource management: copy and swapresource management: resizeresource management: simple optimizationthe other stuffthe final result is below.but now it is my turn for some review to make sure i did not screw up too much. :-)head:#ifndef thorsanvil_container_vector#define thorsanvil_container_vector#include <type_traits>#include <memory>#include <algorithm>#include <stdexcept>#include <iterator>#include <cmath>namespace thorsanvil{ namespace container {types:template<typename t>class vector{ public: using value_type = t; using reference = t&; using const_reference = t const&; using pointer = t*; using const_pointer = t const*; using iterator = t*; using const_iterator = t const*; using difference_type = std::ptrdiff_t; using size_type = std::size_t; private: size_type capacity; size_type length; t* buffer; struct deleter { void operator()(t* buffer) const { ::operator delete(buffer); } };constructors: public: vector(int capacity = 10) : capacity(capacity) , length(0) , buffer(static_cast<t*>(::operator new(sizeof(t) * capacity))) {} template<typename i> vector(i begin, i end) : capacity(std::distance(begin, end)) , length(0) , buffer(static_cast<t*>(::operator new(sizeof(t) * capacity))) { for(auto loop = begin;loop != end; ++loop) { pushbackinternal(*loop); } } vector(std::initializer_list<t> const& list) : vector(std::begin(list), std::end(list)) {} ~vector() { // make sure the buffer is deleted even with exceptions // this will be called to release the pointer at the end // of scope. std::unique_ptr<t, deleter> deleter(buffer, deleter()); clearelements<t>(); } vector(vector const& copy) : capacity(copy.length) , length(0) , buffer(static_cast<t*>(::operator new(sizeof(t) * capacity))) { try { for(int loop = 0; loop < copy.length; ++loop) { push_back(copy.buffer[loop]); } } catch(...) { clearelements<t>(); ::operator delete(buffer); // make sure the exceptions continue propagating after // the cleanup has completed. throw; } } vector& operator=(vector const& copy) { copyassign<t>(copy); return *this; } vector(vector&& move) noexcept : capacity(0) , length(0) , buffer(nullptr) { move.swap(*this); } vector& operator=(vector&& move) noexcept { move.swap(*this); return *this; } void swap(vector& other) noexcept { using std::swap; swap(capacity, other.capacity); swap(length, other.length); swap(buffer, other.buffer); }access: reference operator[](size_type index) {return buffer[index];} const_reference operator[](size_type index) const {return buffer[index];} reference at(size_type index) {validateindex(index);return buffer[index];} const_reference at(size_type index) const {validateindex(index);return buffer[index];} reference front() {return buffer[0];} const_reference front() const {return buffer[0];} reference back() {return buffer[length - 1];} const_reference back() const {return buffer[length - 1];}comparison: bool operator!=(vector const& rhs) const {return !(*this == rhs);} bool operator==(vector const& rhs) const { return (size() == rhs.size()) ? std::equal(begin(), end(), rhs.begin()) : false; }iterators: iterator begin() {return buffer;} iterator rbegin() {return std::reverse_iterator<iterator>(end());} const_iterator begin() const {return buffer;} const_iterator rbegin() const {return std::reverse_iterator<iterator>(end());} iterator end() {return buffer + length;} iterator rend() {return std::reverse_iterator<iterator>(begin());} const_iterator end() const {return buffer + length;} const_iterator rend() const {return std::reverse_iterator<iterator>(begin());} const_iterator cbegin() const {return begin();} const_iterator crbegin() const {return rbegin();} const_iterator cend() const {return end();} const_iterator crend() const {return rend();}non-mutating functions: size_type size() const {return length;} bool empty() const {return length == 0;}mutating functions: void push_back(t const& value) { resizeifrequire(); pushbackinternal(value); } void push_back(t&& value) { resizeifrequire(); movebackinternal(std::forward<t>(value)); } template<typename... args> void emplace_back(args&&... args) { resizeifrequire(); constructbackinternal(std::forward<t>(args)...); } void pop_back() { --length; buffer[length].~t(); } void reserve(size_type capacityupperbound) { if (capacityupperbound > capacity) { reservecapacity(capacityupperbound); } }private: private: void validateindex(size_type index) { if (index >= length) { throw std::out_of_range(out of range); } } void resizeifrequire() { if (length == capacity) { size_type newcapacity = std::max(2.0, capacity * 1.62); reservecapacity(newcapacity); } } void reservecapacity(size_type newcapacity) { vector<t> tmpbuffer(newcapacity); simplecopy<t>(tmpbuffer); tmpbuffer.swap(*this); } void pushbackinternal(t const& value) { new (buffer + length) t(value); ++length; } void movebackinternal(t&& value) { new (buffer + length) t(std::forward<t>(value)); ++length; } template<typename... args> void constructbackinternal(args&&... args) { new (buffer + length) t(std::forward<args>(args)...); ++length; } template<typename x> typename std::enable_if<std::is_nothrow_move_constructible<x>::value == false>::type simplecopy(vector<t>& dst) { std::for_each(buffer, buffer + length, [&dst](t const& v){dst.pushbackinternal(v);} ); } template<typename x> typename std::enable_if<std::is_nothrow_move_constructible<x>::value == true>::type simplecopy(vector<t>& dst) { std::for_each(buffer, buffer + length, [&dst](t& v){dst.movebackinternal(std::move(v));} ); } template<typename x> typename std::enable_if<std::is_trivially_destructible<x>::value == false>::type clearelements() { // call the destructor on all the members in reverse order for(int loop = 0; loop < length; ++loop) { // note we destroy the elements in reverse order. buffer[length - 1 - loop].~t(); } } template<typename x> typename std::enable_if<std::is_trivially_destructible<x>::value == true>::type clearelements() { // trivially destructible objects can be re-used without using the destructor. } template<typename x> typename std::enable_if<(std::is_nothrow_copy_constructible<x>::value && std::is_nothrow_destructible<x>::value) == true>::type copyassign(vector<x>& copy) { if (this == &copy) { return; } if (capacity <= copy.length) { clearelements<t>(); length = 0; for(int loop = 0; loop < copy.length; ++loop) { pushbackinternal(copy[loop]); } } else { // copy and swap idiom vector<t> tmp(copy); tmp.swap(*this); } } template<typename x> typename std::enable_if<(std::is_nothrow_copy_constructible<x>::value && std::is_nothrow_destructible<x>::value) == false>::type copyassign(vector<x>& copy) { // copy and swap idiom vector<t> tmp(copy); tmp.swap(*this); }};tail: }}#endif",
    "present_kp": [
      "c++"
    ],
    "absent_kp": [
      "c++11",
      "vectors",
      "raii",
      "sfinae"
    ]
  },
  {
    "text": "what is a good smartcard for home use?. i'm always looking for ways to improve my security in the internet. as i'm also a programmer and somewhat active on infosec and crypto i decided that a smart card is the way to go.i'm thereby looking for a smart card (or an usb-token) that has the following qualifications:support for elliptic curve cryptography (256 bits+)support for rsa (2048 bits+)storage for at least 10 keys of each of themfips 140-2 level 3 certification (preferred) or high common criteria certification (eal 4+)should be acquirable for private persons (non-companies)driver (pkcs#11 / csp / cng) support for windows 7 and windows 10 (both x64), either directly or via opensc.support for secure key backup and key recovery in case of a disaster (e.g. wrapped key exports along with a way to unwrap on a different physical card)for actual cards: standard physical interfaces (i.e. no vendor-specific card readers needed)non-mandatory points include:support for custom ecc curvesnative support for curve25519 / curve448support for rsassa-pss or ecdsa (without the software doing the hashing)for actual cards: contactless operatibilitylow price (< $100 per piece)qualification for qualified electronic signatures (i.e. legally binding signatures), preferably under german law",
    "present_kp": [
      "security"
    ],
    "absent_kp": [
      "smartcards"
    ]
  },
  {
    "text": "does the following transformation preserve context-freeness?. i encountered this problem involving manipulating a context-free language. let $l$ be a context-free language. define $l^{\\#} = \\{ x : x^i \\in l$ for every $i=0,1,2,...\\}$. is $l^{\\#}$ always context-free?my guess is that it will preserve context-freeness. can anyone provide an elementary proof of this?",
    "present_kp": [],
    "absent_kp": [
      "formal languages",
      "context free"
    ]
  },
  {
    "text": "find command returns different results when -print0 is added. when doing a search like find -type d, adding the -print0 argument right after the find command such as find -print0 -type d causes the search to return more results than without it.",
    "present_kp": [
      "find"
    ],
    "absent_kp": []
  },
  {
    "text": "is the multiset - subset sum problem variant not in np?. if the input for a subset sum problem is a multiset (with repetitions) instead of a set (without repetitions), e.g.set $a = \\{1282,1588,3590,5138,5505,5777,6198,7962,8827,9838,10137,12037,15296,16089\\}$multiset $a = \\{1282,1282,3590,3590,5505,5505,6198,6198,8827,8827,10137,10137,15296,15296\\}$(above sets are samples, the real sets have lengths up to 64 and each element is up to 64bits, i'm working with density-1 instances).in both cases $n$ is the same (183 bits if we use $\\sum_{i=1}^n \\log_2 a_i$ or 224 bits if we use a more generic approach $\\mathrm{length}(a)\\cdot \\log_2 \\max\\,\\{a_1, \\dots, a_n\\}$.is there any chance the repetitions could affect the problem so bad that could move the multiset version out of np?everything i know and have read about subset sum for long time says both instances are equally hard, and subset sum and all its variant are np-complete and just dependent on the input size but i'm getting a weird different result. (i found this discrepancy when i was validating the solver works well with multisets.)",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "np complete",
      "np hard"
    ]
  },
  {
    "text": "mount.nfs: access denied by server while mounting on ubuntu machines?. i am a linux newbie and i have a very basic question. i have three machines in production - machinea 10.66.136.129machineb 10.66.138.181machinec 10.66.138.183and all those machines have ubuntu 12.04 installed in it and i have root access to all those three machines.now i am supposed to do below things in my above machines - create mount point /opt/exhibitor/confmount the directory in all servers. sudo mount <nfs-server>:/opt/exhibitor/conf /opt/exhibitor/conf/i have already created /opt/exhibitor/conf directory in all those three machines as mentioned above. now i am trying to create a mount point. so i followed the below process - install nfs support files and nfs kernel server in all the above three machines$ sudo apt-get install nfs-common nfs-kernel-servercreate the shared directory in all the above three machines$ mkdir /opt/exhibitor/conf/edited the /etc/exports and added the entry like this in all the above three machines - # /etc/exports: the access control list for filesystems which may be exported# to nfs clients. see exports(5).## example for nfsv2 and nfsv3:# /srv/homes hostname1(rw,sync,no_subtree_check) hostname2(ro,sync,no_subtree_check)## example for nfsv4:# /srv/nfs4 gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check)# /srv/nfs4/homes gss/krb5i(rw,sync,no_subtree_check)#/opt/exhibitor/conf/ 10.66.136.129(rw)/opt/exhibitor/conf/ 10.66.138.181(rw)/opt/exhibitor/conf/ 10.66.138.183(rw)i have tried mounting on machinea like below from machineb and machinec and it gives me this error- root@machineb:/# sudo mount -t nfs 10.66.136.129:/opt/exhibitor/conf /opt/exhibitor/conf/mount.nfs: access denied by server while mounting 10.66.136.129:/opt/exhibitor/confroot@machinec:/# sudo mount -t nfs 10.66.136.129:/opt/exhibitor/conf /opt/exhibitor/conf/mount.nfs: access denied by server while mounting 10.66.136.129:/opt/exhibitor/confdid my /etc/exports file looks good? i am pretty sure, i have messed up my exports file. as i have the same content in all the three machines in exports file.any idea what wrong i am doing here? and what will be the correct /exports file here?",
    "present_kp": [
      "linux",
      "ubuntu",
      "mount",
      "nfs"
    ],
    "absent_kp": []
  },
  {
    "text": "unix chroot jail shell (with or without sudo?). at the moment i am creating a chroot jail. therefore i read some articles and everything seems to be clear, exept for one thing: the chroot jail shell in one source they created the following setup (of course the setup is much bigger, but this is the part i have a question in): the jail is set up with some programs and there libs.the chroot jail folder is /jail/.now we want to create the user prison within our new jail.therefore we open the file /etc/sudoers and write the following line in it: prison all=nopasswd: /usr/bin/chroot, /bin/su - prison we then create the file /bin/chroot-shell within our jail as the shell the user must use when he connects with ssh. the content is: #!/bin/bash/usr/bin/sudo /usr/bin/chroot /jail/ /bin/su - $user @ the interesting part ist, that neither /usr/bin/sudo nor /bin/chroot are copied into the /jail/.and linke expected: when the user tries to log in with sftp (winscp for example) it workes. but when he tries to use a terminal on ssh (with putty for example) then it failes with the following line: sudo: unknown uid 1001: who are you?so my questions are: isn't this way of configuring a chroot jail a unsecure one? putting a jailed person in the sudo config file does not appear meaningful to me. so what is the idea behind it? why not just copy /bin/bashto the jail and let the user use this instead of the own bin/chroot-shell and the sudo entry?if this way somehow is more secure then using /bin/bash, then how can i make it work? i think the first step would be to copy /usr/bin/sudo and /usr/bin/chroot to the jail directory, right? but what next? sudo does not know the user ... thanks for all your help and sorry for my bad english.greetings,chriss solutionuntil now i have no idea, why the author of the article i read wanted to create an own shell and give the user in the jail sudo rights for some commands.but the article was from 2008, so a little bit outdated.i now put the /bin/bash shell as the default shell for jailed users (with the chsh command). also i had to make sure, that the libs /lib/libdl.so.2 /lib/libc.so.6 /lib/ld-linux.so.2 (in my case both 32bit and 64bit) are all three in the jail, so a jailed user had a proper username. because without these there is no proper way to get the username out of the user id within the paswd file.after that the users could open a proper ssh connection with a working shell and the command line knew who they are (the prfix name at the beginning of the line and also the whoami command).that's it, now everything is working just fine^^",
    "present_kp": [
      "linux",
      "shell",
      "chroot"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i update existing .crt file with new encrypted rsa .key file?. suppose i have 2 files: an rsa key file client.key and a certification file client.crt.i have created them without pass-phrase and now i have encrypted client.key file with pass-phrase by command:openssl rsa -des3 -in client.key -out client-enc.keynow i want to re-create/update client.crt file with client-enc.key. how can i do that?",
    "present_kp": [
      "ssl",
      "openssl"
    ],
    "absent_kp": []
  },
  {
    "text": "lower bounds on monotone space complexity. the monotone space complexity of a language $l \\subseteq \\sigma^*$ can be defined in terms of monotone switching networks (see e.g. average case lower bounds for monotone switching networks by filmus et al.). this notion is linked to the monotone $nc$ hierarchy and may have applications to the non-monotone setting for which most questions are open.here is an equivalent definition in term of circuits. let $k$ be a circuit (or dag) whose arcs are labelled by elements of $[n] imes \\sigma$, and which has a single root node $r$. we say that $k$ accepts a word $w \\in \\sigma^n$ iff there is a root-leaf path $p$ in $k$ whose sequence of labels matches $w$, i.e. for each label $(i,a)$ in $p$ we have $w[i] = a$. now, given a language $l$, for each integer $n$ we define its $n$-slice complexity $c_l(n)$ as the minimum size of a circuit accepting exactly the words in $l \\cap \\sigma^n$. we can put some restrictions on this notion, for instance by requiring that the circuits are read-once, meaning that each accepting path makes a single access to a given position. this leads to a second complexity measure $c'_l(n)$ which seems easier to analyze, as illustrated below.an example is the perfect matching problem ($pm$), which can be shown to have monotone complexity $c'_{pm}(n) = 2^{\\omega(n)}$ as follows. let $pm_n$ denote the slice of the language corresponding to bipartite graphs $g$ with $n$ vertices on each side of the bipartition (denoted by $a,b$). consider a circuit $k$ accepting it. given an integer $k$, let $\\mathcal{p}_k$ denote the set of paths of length $k$ in $k$ starting from the root, and let $\\mathcal{t}_k$ denote the pair of sets $(s,t)$ with $s \\subseteq a, t \\subseteq b$ and $|s| = |t| = k$. by monotonicity, we can make the following assumption:(*) for each node $u$ of depth $k$, there is a tuple $t = (s,t) \\in \\mathcal{t}_k$ such that each path $p \\in \\mathcal{p}_k$ leading to $u$ is labeled by a permutation $\\sigma_p : s ightarrow t$.indeed, if there were two different paths leading to $u$ corresponding to different tuples, one of them could be extended to a function that is not a permutation (and thus would recognize an $n$-edges graph that is not a matching).now observe that we must have the following coverage property: for each permutation $\\sigma : a ightarrow b$, there should exist some path $p \\in \\mathcal{p}_k$ such that $\\sigma$ extends $\\sigma_p$. observe that a given permutation $\\sigma_p$ can be extended to at most $(n-k)!$ different permutations, and that a given tuple in $\\mathcal{t}_k$ can induce at most $k!$ different permutations. this implies that the number of nodes at depth $k$ is at least $ rac{n!}{k! (n-k)!}$. in particular, the number of nodes at level $ rac{n}{2}$ is at least $ rac{n!}{( rac{n}{2})!^2} = 2^{\\omega(n)}$.there are two things i would like to understand: (i) why does this reasoning break down for read-many / nonmonotone space complexity, (ii) how does it relate to known lower bounds for the monotone space complexity of $pm$.",
    "present_kp": [],
    "absent_kp": [
      "circuit complexity"
    ]
  },
  {
    "text": "cannot mount usb stick after putting a yosemite bootable image on it. i was trying to put a bootable image on a usb stick so i could reinstall mac os yosemite on my macbook pro (i am doing this all in in linux so that's why this question is here). once i finally converted the .dmg file into an .iso file, i ran the following command:sudo dd if=yosemite.iso of=/media/usb bs=4k; sync the command said it ran smoothly, but before i even ran it, i could mount the stick very easily; hell, even debian mounted it for me automatically. but afterwards, i could no longer do it. i now receive this error message when i try to mount it again:$ sudo mount /dev/sdc1 /media/usbmount: wrong fs type, bad option, bad superblock on /dev/sdc1, missing codepage or helper program, or other error in some cases useful info is found in syslog - try dmesg | tail or so.and here's the output of dmesg | tail:[ <phone>] usbcore: registered new interface driver usb-storage[ <phone>] scsi 6:0:0:0: direct-access sandisk cruzer glide 1.27 pq: 0 ansi: 6[ <phone>] sd 6:0:0:0: attached scsi generic sg3 type 0[ <phone>] sd 6:0:0:0: [sdc] 31266816 512-byte logical blocks: (16.0 gb/14.9 gib)[ <phone>] sd 6:0:0:0: [sdc] write protect is off[ <phone>] sd 6:0:0:0: [sdc] mode sense: 43 00 00 00[ <phone>] sd 6:0:0:0: [sdc] write cache: disabled, read cache: enabled, doesn't support dpo or fua[ <phone>] sdc: sdc1[ <phone>] sd 6:0:0:0: [sdc] attached scsi removable disk[ <phone>] fat-fs (sdc1): utf8 is not a recommended io charset for fat filesystems, filesystem will be case sensitive!is there any way to fix this? will debian even attempt to mount a mac image?",
    "present_kp": [
      "linux",
      "debian",
      "mount",
      "fat"
    ],
    "absent_kp": [
      "osx"
    ]
  },
  {
    "text": "is the m subdomain automatically supported / redirected by mobile devices, if not how should i redirect?. i'm trying to set up a mobile version of a site, and i'm wondering if i can just set up a m subdomain and put the mobile site in there, or if i need to set up some kind of redirect to make phones automatically go to it.could you point me in the right direction for getting started on this? i'm having trouble finding good info.thanks",
    "present_kp": [
      "mobile"
    ],
    "absent_kp": [
      "iphone",
      "android"
    ]
  },
  {
    "text": "i installed the kernel and some drivers from jessie-backports. should i leave the backports repo in /etc/apt/sources.list?. i installed debian jessie on a laptop with relatively new hardware, e.g. a skylake i7-6600u processor, so i had to install the kernel and firmware-iwlwifi driver from jessie-backports. /etc/apt/sources.list has this linedeb <url> jessie-backports main non-free contribi then installed linux-image-4.5.0-0.bpo.2-amd64 and firmware-iwlwifi=20160110-1~bpo8+1. now that these are correctly installed, does it make sense to remove that line from /etc/apt/sources.list?i'd like these packages to receive updates from the backports repo if any are available, but i don't want any other packages to get updates from jessie-backports. i have apt::default-release jessie; in /etc/apt/apt.conf.d/70debconf, so that should be enough to guarantee this, right?",
    "present_kp": [
      "debian",
      "apt",
      "backports"
    ],
    "absent_kp": []
  },
  {
    "text": "biologically plausible cognitive model of wisconsin card sorting task. as discussed previously, there are a wide range of models that have been applied to the wisconsin card sorting task. however, which one is most biologically plausible? that is, uses a realistic model of neurons, respects the constraints of the human brain and maps readily onto experimental data.",
    "present_kp": [],
    "absent_kp": [
      "cognitive neuroscience",
      "theoretical neuroscience",
      "cognitive modeling",
      "computational modeling"
    ]
  },
  {
    "text": "is using nested try-catch blocks an anti-pattern?. is this an antipattern? it is an acceptable practice? try { //do something } catch (exception e) { try { //do something in the same line, but being less ambitious } catch (exception ex) { try { //do the minimum acceptable } catch (exception e1) { //more try catches? } } }",
    "present_kp": [],
    "absent_kp": [
      "anti patterns",
      "exception handling"
    ]
  },
  {
    "text": "how to pipe an echo command through grep when adding?. <url> all,im trying to write a script that will add any input numbers and return the sum. i have this part, here's the code: sum=0 for number in $@; do ((sum += number)) done echo $sumnow i need it to do the rest that is attached in the image, but we only learned if statements and for loops two days ago, and i'm having trouble getting through this. i've tried all combinations i could think of, and i just end up getting frustrating errors.",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "shell script"
    ]
  },
  {
    "text": "why turing wasn't wrong?. computer science is a science and as a science each thesis can be refutable. so, why there is no major counter-thesis?after all, einstein was a well known genius and has lived a long life and he has got many opponents. why isn't it the same case for turing?",
    "present_kp": [],
    "absent_kp": [
      "church turing thesis"
    ]
  },
  {
    "text": "one way boolean function. if one way functions exist, what would the truth table of a one way boolean function look like?",
    "present_kp": [
      "one way function"
    ],
    "absent_kp": [
      "cr.crypto security"
    ]
  },
  {
    "text": "algorithm to reach high packing fraction by increasing particles' size. what is the general name (if it exists) of those algorithms in which, in order to reach an high packing fraction $\\phi$, the size of the particles is increased starting from a very small size until the desired value of $\\phi$ is obtained? where can i find a good reference on the subject, explaining how to write an efficient algorithm of such kind?",
    "present_kp": [],
    "absent_kp": [
      "molecular dynamics"
    ]
  },
  {
    "text": "trampoline that automatically balances heap and stack. while working through fogus' functional javascript, i came across the trampoline function, which can be used to make safe recursive functions that don't blow up the stack. in fogus' words, of course there is no free lunch, even when using trampolines. while ive managed to avoid exploding the call stack, ive just transferred the problem to the heap.on top of moving this problem to the heap, the trampolined version of the function is slower. is it possible to make a smart trampoline function that takes two forms of a function, a trampolined version and a non-trampolined version, and chooses (or predicts) the most efficient strategy?* ref: <url> better yet combines both strategies (is this possible?) that uses fewer trampoline bounces, where each bounce is almost the maximum number of computations that can be performed recursively using the stack strategy)",
    "present_kp": [],
    "absent_kp": [
      "functional programming",
      "recursion"
    ]
  },
  {
    "text": "python feature disabled vim-nox. i have installed vim-nox version 7.4 package in my debian wheezy machine from backports. i am confused that the python feature still does not work as shown from vim --version command as -python as well as -python3. i have been surfing around and finding a possible solution by purging vim-tiny and reinstall vim-nox, but it didn't work out. here is the output of dpkg -l vim*desired=unknown/install/remove/purge/hold| status=not/inst/conf-files/unpacked/half-conf/half-inst/trig-await/trig-pend|/ err?=(none)/reinst-required (status,err: uppercase=bad)||/ name version architecture description+++-=====================================-==================================-============-================================================================================================ii vim 2:7.4.488-3~bpo70+1 amd64 vi improved - enhanced vi editorun vim-athena <none> (no description available)ii vim-common 2:7.4.488-3~bpo70+1 amd64 vi improved - common filesun vim-doc <none> (no description available)un vim-gnome <none> (no description available)un vim-gtk <none> (no description available)un vim-lua <none> (no description available)ii vim-nox 2:7.4.488-3~bpo70+1 amd64 vi improved - enhanced vi editor - with scripting languages supportun vim-perl <none> (no description available)un vim-python <none> (no description available)un vim-ruby <none> (no description available)ii vim-runtime 2:7.4.488-3~bpo70+1 all vi improved - runtime filesun vim-scripts <none> (no description available)un vim-tcl <none> (no description available)un vim-tiny <none> (no description available)",
    "present_kp": [
      "vim",
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "unresolved dependencies of bz* files for rpm make from source. i am trying to do a build of rpm from source. i got through the ./configure and ran through a good chunk of make. unfortunately i keeping getting stopped up on undefined references to bzerror, bzwrite, bzflush and others. looking around online i see these functions are part of the bzip2 package. ive installed the development libraries, but i am still getting this message. can anyone assist me in resolving these dependencies? thanks...make[2]: entering directory '/mnt/fedroot/rpm-4.6.1/lib'make all-ammake[3]: entering directory '/mnt/fedroot/rpm-4.6.1/lib'/bin/sh ../libtool --tag=cc --mode=link gcc -std=gnu99 -g -o2 -fpic -dpic -d_reentrant -wall -wpointer-arith -wmissing-prototypes -wno-char-subscripts -fno-strict-aliasing -fstack-protector -o rpmdb_archive ../db3/db_archive.o ../db3/util_sig.o librpm.la -lrt -lpthread gcc -std=gnu99 -g -o2 -fpic -dpic -d_reentrant -wall -wpointer-arith -wmissing-prototypes -wno-char-subscripts -fno-strict-aliasing -fstack-protector -o .libs/rpmdb_archive ../db3/db_archive.o ../db3/util_sig.o ./.libs/librpm.so /mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so -lmagic -lelf -llua -lm -lnss3 -lpopt -lrt -lpthread -wl,--rpath -wl,/usr/local/lib/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzerror'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzwrite'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzflush'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzdopen'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzread'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzclose'/mnt/fedroot/rpm-4.6.1/rpmio/.libs/librpmio.so: undefined reference to 'bzopen'collect2: ld returned 1 exit statusmake[3]: *** [rpmdb_archive] error 1make[3]: leaving directory '/mnt/fedroot/rpm-4.6.1/lib'make[2]: *** [all] error 2make[2]: leaving directory '/mnt/fedroot/rpm-4.6.1/lib'make[1]: *** [all-recursive] error 1make[1]: leaving directory '/mnt/fedroot/rpm-4.6.1'make: *** [all] error 2",
    "present_kp": [
      "rpm",
      "make"
    ],
    "absent_kp": [
      "compiling"
    ]
  },
  {
    "text": "how can i get googlefinance to see 1 year and 5 year return of a stock?. you can use googlefinance(name, return52) for mutual funds, but not for stocks. is there another way to get the same result?",
    "present_kp": [],
    "absent_kp": [
      "google finance"
    ]
  },
  {
    "text": "why my $path is not inherited by the invoked bash?. i work on an aix system where i have no administrator privileges. it has several shells installed, default being tcsh. i am not allowed to change the login shell. usually i start my session from exec bash. the problem is that i do not inherit the $path i had in tsch. the first strange thing is that some of the entries in my $path are duplicated, when i do exec bash. another strange thing is that when i do exec bash --norc and then source .bashrc everything is fine -- i get the path from tcsh and some additions from my .bashrc.i have tried commenting out my .bashrc enirely, but it gave no result -- i still do not get the $path from tcsh. it seems that the system wide /etc/profile is manipulating my $path. i tried running exec bash --noprofile, but i still see the changes, that are introduced by /etc/profile script (which i have no control over). so in the end perhaps someone spotted a flaw in my investigation and can tell me how to invoke bash with inhereted $path or can suggest a way to do it without reading the global config scripts?(i have posted this question on superuser as well, i am not sure if it is ok, to duplicate questions, but i got no answer there, so what a heck...)",
    "present_kp": [
      "bash",
      "aix",
      "path",
      "tcsh"
    ],
    "absent_kp": [
      "environment variables"
    ]
  },
  {
    "text": "javascript / jquery memory guessing game. i want some tips on how to make my code better, more efficient, better coding practices, etc.codepen/** * created by alonski on 6/14/2016. */ use strict; $(function () { console.log(start); // class gameitem { // constructor(x, y) // } let playeroneturn = true; let inturn = false; let firstglyph = 0; let secondglyph = 0; let lock = false; const colororig = 'blue'; const numofcols = 12; const numofrows = 4; const glyphorig = 'glyphicon-tree-deciduous'; const glyphs = [ 'glyphicon-plane', 'glyphicon-fire', 'glyphicon-thumbs-up', 'glyphicon-gbp', 'glyphicon-phone', 'glyphicon-heart-empty', 'glyphicon-paperclip', 'glyphicon-earphone', 'glyphicon-education', 'glyphicon-king', 'glyphicon-queen', 'glyphicon-pawn', 'glyphicon-asterisk', 'glyphicon-plus', 'glyphicon-minus', 'glyphicon-euro', 'glyphicon-cloud', 'glyphicon-envelope', 'glyphicon-pencil', 'glyphicon-glass', 'glyphicon-music', 'glyphicon-search', 'glyphicon-heart', 'glyphicon-star', 'glyphicon-star-empty', 'glyphicon-user', 'glyphicon-film', 'glyphicon-th-large', 'glyphicon-th', 'glyphicon-th-list', 'glyphicon-ok', 'glyphicon-remove', 'glyphicon-zoom-in', 'glyphicon-zoom-out', 'glyphicon-off', 'glyphicon-signal', 'glyphicon-cog', 'glyphicon-trash', 'glyphicon-home', 'glyphicon-file', 'glyphicon-time', 'glyphicon-road', 'glyphicon-download-alt', 'glyphicon-download', 'glyphicon-upload', 'glyphicon-inbox', 'glyphicon-play-circle', 'glyphicon-repeat', 'glyphicon-refresh', 'glyphicon-list-alt', 'glyphicon-lock', 'glyphicon-flag', 'glyphicon-headphones', 'glyphicon-volume-off', 'glyphicon-volume-down', 'glyphicon-volume-up', 'glyphicon-qrcode', 'glyphicon-barcode', 'glyphicon-tag', 'glyphicon-tags', 'glyphicon-book', 'glyphicon-bookmark', 'glyphicon-print', 'glyphicon-camera', 'glyphicon-font', 'glyphicon-bold', 'glyphicon-italic', 'glyphicon-text-height', 'glyphicon-text-width', 'glyphicon-align-left', 'glyphicon-align-center', 'glyphicon-align-right', 'glyphicon-align-justify', 'glyphicon-list', 'glyphicon-indent-left', 'glyphicon-indent-right', 'glyphicon-facetime-video', 'glyphicon-picture', 'glyphicon-map-marker', 'glyphicon-adjust', 'glyphicon-tint', 'glyphicon-edit', 'glyphicon-share', 'glyphicon-check', 'glyphicon-move', 'glyphicon-step-backward', 'glyphicon-fast-backward', 'glyphicon-backward', 'glyphicon-play', 'glyphicon-pause', 'glyphicon-stop', 'glyphicon-forward', 'glyphicon-fast-forward', 'glyphicon-step-forward', 'glyphicon-eject', 'glyphicon-chevron-left', 'glyphicon-chevron-right', 'glyphicon-plus-sign', 'glyphicon-minus-sign', 'glyphicon-remove-sign', 'glyphicon-ok-sign', 'glyphicon-question-sign', 'glyphicon-info-sign', 'glyphicon-screenshot', 'glyphicon-remove-circle', 'glyphicon-ok-circle', 'glyphicon-ban-circle', 'glyphicon-arrow-left', 'glyphicon-arrow-right', 'glyphicon-arrow-up', 'glyphicon-arrow-down', 'glyphicon-share-alt', 'glyphicon-resize-full', 'glyphicon-resize-small', 'glyphicon-exclamation-sign', 'glyphicon-gift', 'glyphicon-leaf', 'glyphicon-fire', 'glyphicon-eye-open', 'glyphicon-eye-close', 'glyphicon-warning-sign', 'glyphicon-plane', 'glyphicon-calendar', 'glyphicon-random', 'glyphicon-comment', 'glyphicon-magnet', 'glyphicon-chevron-up', 'glyphicon-chevron-down', 'glyphicon-retweet', 'glyphicon-shopping-cart', 'glyphicon-folder-close', 'glyphicon-folder-open', 'glyphicon-resize-vertical', 'glyphicon-resize-horizontal', 'glyphicon-hdd', 'glyphicon-bullhorn', 'glyphicon-bell', 'glyphicon-certificate', 'glyphicon-thumbs-up', 'glyphicon-thumbs-down', 'glyphicon-hand-right', 'glyphicon-hand-left', 'glyphicon-hand-up', 'glyphicon-hand-down', 'glyphicon-circle-arrow-right', 'glyphicon-circle-arrow-left', 'glyphicon-circle-arrow-up', 'glyphicon-circle-arrow-down', 'glyphicon-globe', 'glyphicon-wrench', 'glyphicon-tasks', 'glyphicon-filter', 'glyphicon-briefcase', 'glyphicon-fullscreen', 'glyphicon-dashboard', 'glyphicon-paperclip', 'glyphicon-heart-empty', 'glyphicon-link', 'glyphicon-phone', 'glyphicon-pushpin', 'glyphicon-usd', 'glyphicon-gbp', 'glyphicon-sort', 'glyphicon-sort-by-alphabet', 'glyphicon-sort-by-alphabet-alt', 'glyphicon-sort-by-order', 'glyphicon-sort-by-order-alt', 'glyphicon-sort-by-attributes', 'glyphicon-sort-by-attributes-alt', 'glyphicon-unchecked', 'glyphicon-expand', 'glyphicon-collapse-down', 'glyphicon-collapse-up', 'glyphicon-log-in', 'glyphicon-flash', 'glyphicon-log-out', 'glyphicon-new-window', 'glyphicon-record', 'glyphicon-save', 'glyphicon-open', 'glyphicon-saved', 'glyphicon-import', 'glyphicon-export', 'glyphicon-send', 'glyphicon-floppy-disk', 'glyphicon-floppy-saved', 'glyphicon-floppy-remove', 'glyphicon-floppy-save', 'glyphicon-floppy-open', 'glyphicon-credit-card', 'glyphicon-transfer', 'glyphicon-cutlery', 'glyphicon-header', 'glyphicon-compressed', 'glyphicon-earphone', 'glyphicon-phone-alt', 'glyphicon-tower', 'glyphicon-stats', 'glyphicon-sd-video', 'glyphicon-hd-video', 'glyphicon-subtitles', 'glyphicon-sound-stereo', 'glyphicon-sound-dolby', 'glyphicon-sound-5-1', 'glyphicon-sound-6-1', 'glyphicon-sound-7-1', 'glyphicon-copyright-mark', 'glyphicon-registration-mark', 'glyphicon-cloud-download', 'glyphicon-cloud-upload', 'glyphicon-tree-conifer', 'glyphicon-cd', 'glyphicon-save-file', 'glyphicon-open-file', 'glyphicon-level-up', 'glyphicon-copy', 'glyphicon-paste', 'glyphicon-alert', 'glyphicon-equalizer', 'glyphicon-king', 'glyphicon-queen', 'glyphicon-pawn', 'glyphicon-bishop', 'glyphicon-knight', 'glyphicon-baby-formula', 'glyphicon-tent', 'glyphicon-blackboard', 'glyphicon-bed', 'glyphicon-apple', 'glyphicon-erase', 'glyphicon-hourglass', 'glyphicon-lamp', 'glyphicon-duplicate', 'glyphicon-piggy-bank', 'glyphicon-scissors', 'glyphicon-bitcoin', 'glyphicon-yen', 'glyphicon-ruble', 'glyphicon-scale', 'glyphicon-ice-lolly', 'glyphicon-ice-lolly-tasted', 'glyphicon-education', 'glyphicon-option-horizontal', 'glyphicon-option-vertical', 'glyphicon-menu-hamburger', 'glyphicon-modal-window', 'glyphicon-oil', 'glyphicon-grain', 'glyphicon-sunglasses', 'glyphicon-text-size', 'glyphicon-text-color', 'glyphicon-text-background', 'glyphicon-object-align-top', 'glyphicon-object-align-bottom', 'glyphicon-object-align-horizontal', 'glyphicon-object-align-left', 'glyphicon-object-align-vertical', 'glyphicon-object-align-right', 'glyphicon-triangle-right', 'glyphicon-triangle-left', 'glyphicon-triangle-bottom', 'glyphicon-triangle-top', 'glyphicon-superscript', 'glyphicon-subscript', 'glyphicon-menu-left', 'glyphicon-menu-right', 'glyphicon-menu-down', 'glyphicon-menu-up', ]; const colors = [ 'red', 'green', 'teal', 'black', 'darkmagenta', ]; // let style='<div style=color:darkmagenta></div>'; array.prototype.shuffle = function () { let arr = this; for (let i = 0; i < arr.length; i++) { let randomnum = math.floor(math.random() * arr.length); let temp = arr[i]; arr[i] = arr[randomnum]; arr[randomnum] = temp; } return arr; }; function createrows(numofrows) { let oldglyphs = glyphs.shuffle().splice(0, (numofcols * numofrows) / 2); // let oldglyphs = glyphs.shuffle(); let newglyphs = []; newglyphs.push(...oldglyphs); for (let i = 0; i < ((numofcols * numofrows) / 2) - oldglyphs.length; i++) { newglyphs.push(oldglyphs[i]); } let randomglyphs = newglyphs; randomglyphs.foreach(function (element, index, array) { let randomnum = math.floor(math.random() * colors.length); array[index] = [element, colors[randomnum]]; }); randomglyphs.push(...newglyphs); // console.log('to flow:', randomglyphs, old:, glyphs); // for (let i = 0; i < numofrows - 1; i++) { // randomglyphs.push(...oldglyphs); // } // console.log('before random', randomglyphs); randomglyphs.shuffle(); // randomglyphs.push(...glyphs.shuffle()); // console.log('random', randomglyphs); // let randomglyphs = glyphs; // console.log(randomglyphs); while (randomglyphs.length) { let row = $('<div class=row></div>'); for (let i = 0; i < numofcols; i++) { // console.log('h: ${h} i: ${i}'); let cell = randomglyphs.pop(); let col = $('<div class=col-xs-1><h1><span class=glyphicon ${glyphorig} aria-hidden=true data-behind=${cell[0]} data-color=${cell[1]} style=color:blue></span></h1></div>'); col.appendto(row); } row.appendto('#gamegame div.container'); } } function changeuser() { if (playeroneturn) { $('#player1').removeclass('label-success').addclass('label-danger'); $('#player2').removeclass('label-danger').addclass('label-success'); } else { $('#player1').removeclass('label-danger').addclass('label-success'); $('#player2').removeclass('label-success').addclass('label-danger'); } playeroneturn = !playeroneturn; } function adduserscore() { if (playeroneturn) { let player = $('#player1score'); console.log('player 1 score:${player.text()}'); player.text(number(player.text()) + 10); } else { let player = $('#player2score'); console.log('player 2 score:${player.text()}'); player.text(number(player.text()) + 10); } } function resetuserscore() { $('#player1').removeclass('label-danger').addclass('label-success'); $('#player2').removeclass('label-success').addclass('label-danger'); $('#player1score,#player2score').text('0'); } function resetvariables() { playeroneturn = true; inturn = false; firstglyph = 0; secondglyph = 0; } function resetgame() { $('section#gamegame').children('div.container').children().remove(); $('#gamealert').removeclass('alert-success alert-warning alert-danger').addclass('alert-info'); $('#gamealert').text('hello! match the glyphs to win!'); resetuserscore(); resetvariables(); createrows(numofrows); // createrow(); } function checkendgame() { let player1score = number($('#player1score').text()); let player2score = number($('#player2score').text()); if (player1score/10 + player2score/10 >= (numofcols * numofrows) / 2) { if (player1score > player2score) { $('#gamealert').text('good game! player 1 wins!'); $('#gamealert').removeclass('alert-info alert-warning alert-danger').addclass('alert-success'); // alert('good game! player 1 wins!'); } else if (player1score < player2score) { $('#gamealert').text('good game! player 2 wins!'); $('#gamealert').removeclass('alert-info alert-warning alert-danger').addclass('alert-success'); // alert('good game! player 2 wins!'); } else { $('#gamealert').text('good game! its a tie!'); $('#gamealert').removeclass('alert-info alert-success alert-danger').addclass('alert-warning'); // alert('good game! its a tie!'); } // resetgame(); } console.log(player1score, player2score); // $('span.glyphicon-eye-open').each((index, element) => { // // console.log(index, $(element).data('behind')); // }); } $('#newgamebutton').on('click', function () { console.log(new game); resetgame(); }); $('div.container').on('click', '.' + glyphorig, function () { if (lock) { return; } if (!inturn) { firstglyph = $(this); firstglyph.removeclass(glyphorig); firstglyph.addclass(firstglyph.data('behind')); firstglyph.css('color', firstglyph.data('color')); inturn = true; console.log(firstglyph.data('behind'), firstglyph.data('color')); return; } secondglyph = $(this); secondglyph.removeclass(glyphorig); secondglyph.addclass($(this).data('behind')); secondglyph.css('color', secondglyph.data('color')); lock = true; window.settimeout(function () { inturn = false; lock = false; if (firstglyph.data('behind') === secondglyph.data('behind') && firstglyph.data('color') === secondglyph.data('color')) { console.log(correct!); firstglyph.removeclass(firstglyph.data('behind')); secondglyph.removeclass(secondglyph.data('behind')); // firstglyph.remove(); // secondglyph.remove(); adduserscore(); checkendgame(); } else { console.log(not correct!); changeuser(); firstglyph.removeclass(firstglyph.data('behind')); firstglyph.addclass(glyphorig); firstglyph.css('color', colororig); // firstglyph.addclass(glyphorig).slideup(300).delay(800).fadein(400); secondglyph.removeclass(secondglyph.data('behind')); secondglyph.addclass(glyphorig); secondglyph.css('color', colororig); } }, 500); // console.log(secondglyph.data('behind')); // switch (inturn) { // case tri: // // case 1: // // // case 2: // // console.log(firstglyph.data('behind')); // // console.log(secondglyph.data('behind')); // // firstglyph.removeclass(firstglyph.data('behind')); // // firstglyph.addclass(glyphorig); // // secondglyph.removeclass(secondglyph.data('behind')); // // secondglyph.addclass(glyphorig); // // inturn = 0; // // break; // } }); // function updatetotal() { // // console.log($('ul.cart li.item').data('price')); // let total = 0; // $('ul.cart li.item').each((index, element) => { // // console.log(logging, index, element); // // console.log(price: , $(element).data('price')); // total += $(element).data('price') * number($(element).children('span').text()); // }); // // console.log('total: ${total}'); // $(#total).text('${total} shmekels'); // } // // $(ul.inventory).on('click', 'li', function () { // let el = $(this); // let elcart = 0; // let contains = false; // $('ul.cart li.item').each((index, element) => { // // console.log('el id: ${el.data('type')}, element id: ${$(element).data('type')}'); // if (el.data('type') === $(element).data('type')) { // contains = true; // elcart = $(element); // return false; // // console.log(same id); // } // // console.log(logging, index, element); // // console.log(this); // // console.log(element); // // console.log('el: ${el} and element: ${element}'); // // if ($('ul.cart').find(this).length > 0) { // // contains = true; // // console.log('contains el'); // // } // }); // // let el_price = number($(this).data('price')); // // $(#total).text(number($(#total).text()) + el_price); // // el.slidetoggle(fast, function () { // if (contains) { // // let numofitem = number($('ul.cart li.item span.badge').text()); // let numofitem = number(elcart.children('span').text()); // if (numofitem >= 0) { // elcart.children('span').text((numofitem + 1)); // } // // elcart.append('<span class=badge>1</span>'); // // console.log(adding + to current element); // } // else { // let newel = el.clone(); // newel.children('span').text('1'); // // let newelbutton = '<button type=button class=btn btn-sm btn-danger>delete</button>'; // newel.append('<button type=button class=btn btn-danger data-type=delete><span class=glyphicon glyphicon-remove></span></button>'); // newel.append('<button type=button class=pull-right btn btn-warning data-type=minus><span class=glyphicon glyphicon-minus></span></button>'); // newel.prepend('<button type=button class=pull-right btn btn-success data-type=plus><span class=glyphicon glyphicon-plus></span></button>'); // $('ul.cart').prepend(newel); // // $('ul.cart').prepend(el.slidetoggle()); // // }); // } // updatetotal(); // // console.log($(this).text(), $(this).data('price')); // }); // // $('ul.cart').on('click', 'button', function () { // // console.log($(this)); // let numofitem = number($(this).parent().children('span').text()); // switch ($(this).data('type')) { // case('delete'): // $(this).parent().remove(); // break; // case('plus'): // if (numofitem >= 0) { // $(this).parent().children('span').text((numofitem + 1)); // } // break; // case('minus'): // if (numofitem > 1) { // $(this).parent().children('span').text((numofitem - 1)); // } // else { // $(this).parent().remove(); // } // break; // } // updatetotal(); // }); // // // $(ul.cart).on('click', 'li', function () { // // let el = $(this); // // // el.slidetoggle(fast, function () { // // $('ul.inventory').prepend(el); // // // }); // // // console.log($(this).text(), $(this).data('price')); // // updatetotal(); // // }); }); <!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta http-equiv=x-ua-compatible content=ie=edge> <meta name=viewport content=width=device-width, initial-scale=1> <title>memory game</title> <!--<style>--> <!--p {--> <!--color: black;--> <!--}--> <!--.error {--> <!--border: 1px solid red;--> <!--color: red;--> <!--}--> <!--</style>--> <link href=<url> rel=stylesheet> <!--<link href=css/bootstrap-theme.min.css rel=stylesheet>--> <!--<link href=<url> rel=stylesheet/>--> </head> <body> <section id=gametop> <div class=container> <div class=row align=center> <div class=col-xs-4><h3><span class=label label-success id=player1>alon <span class=badge>score:<span id=player1score>0</span></span></span></h3></div> <div class=col-xs-4><h1>memory game!</h1></div> <div class=col-xs-4><h3><span class=label label-danger id=player2>moral <span class=badge>score:<span id=player2score>0</span></span></span></h3></div> </div> <div class=alert alert-info text-center role=alert id=gamealert>hello! match the glyphs to win!</div> <div align=center><button type=button class=btn btn-default id=newgamebutton>new game</button></div> </div> </section> <section id=gamegame> <div class=container> <!--<div class=row>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-plane></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-fire></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-thumbs-up></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-gbp></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-phone></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-heart-empty></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-paperclip></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-earphone></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-education></span></h1></div>--> <!--<div class=col-xs-1><h1><span class=glyphicon glyphicon-eye-open aria-hidden=true data-behind=glyphicon-king></span></h1></div>--> <!--</div>--> <!--<div class=row>--> <!--<div class=col-md-6>--> <!--<h1><span class=glyphicon glyphicon-shopping-cart aria-hidden=true></span><span class=glyphicon glyphicon-chevron-down aria-hidden=true></span>:</h1>--> <!--<ul class=list-group inventory>--> <!--<li class=item list-group-item data-price=5 data-type=inv1>cheese 5 shmekels<span class=badge></span></li>--> <!--<li class=item list-group-item data-price=3 data-type=inv2>milk 3 shmekels<span class=badge></span></li>--> <!--<li class=item list-group-item data-price=4 data-type=inv3>taco 4 shmekels<span class=badge></span></li>--> <!--<li class=item list-group-item data-price=5 data-type=inv4>meat 5 shmekels<span class=badge></span></li>--> <!--<li class=item list-group-item data-price=6 data-type=inv5>tofu 6 shmekels<span class=badge></span></li>--> <!--</ul>--> <!--</div>--> <!--<div class=col-md-6>--> <!--<h1><span class=glyphicon glyphicon-shopping-cart aria-hidden=true></span><span class=glyphicon glyphicon-chevron-up aria-hidden=true></span>:</h1>--> <!--<ul class=list-group cart>--> <!--<li class=list-group-item>total: <span id=total>0 shmekels</span></li>--> <!--</ul>--> <!--</div>--> <!--</div>--> </div> </section> <script src=<url> <script src=<url> <script src=memorygame.js></script> </body> </html>",
    "present_kp": [
      "javascript",
      "jquery"
    ],
    "absent_kp": [
      "html5",
      "ecmascript 6"
    ]
  },
  {
    "text": "apache and systemd. i've just started using debian 8 which has introduced systemd. i'm not interested in the politics around sysv vs systemd, but i am confused, especially around apache (2.4).there are now two ways to restart apache:apache2ctl restart or apache2ctl gracefulsystemctl restart apache2 and it seems systemctl restart apache2.service does the same thing.and they appear to do different things(!). i don't understand the difference.i seem to need to do both to get a proper full restart working. e.g. after changing a config file for the php module it only noted the change after both.another time when apache2ctl configtest was failing and the failure was reported in systemctl status apache2 i fixed the config so that the first of these commands was happy, restarted with apache2ctl restart but the systemd status command still listed it as not running and with the old config problem.i promise to spend ages reading about systemd (rtfm) in depth at some point, but meanwhile on a practical level relating to apache, i'd appreciate advice.",
    "present_kp": [
      "debian",
      "systemd"
    ],
    "absent_kp": [
      "apache httpd"
    ]
  },
  {
    "text": "$k$-clique in $k$-partite graph. is the decision whether a $k$-clique exists in a $k$-partite graph np-hard? i have found only a very limited number of references on this problem, and they seem to be concerned with heuristics to enumerate the cliques (in particular k-cliques in k-partite graphs). on complexity, they only comment that the max-clique problem is generally hard, but nothing on the specific case. note: this is an edit of my earlier question: whether the max-clique problem in a $k$-partite graph is np-hard, with $k$ being part of the input? as austin pointed out in the comments, it is easy to see that the answer is trivially yes by a reduction from the general max-clique problem; any graph $g$ on $n$ vertices can be considered $n$-partite. the new question, however, is more specific and a reduction does not seem so obvious. for example, (and contrary to the original question) for $k=n$ one can easily check if an $n$-partite graph contains/is an $n$-clique. what about general $k$?",
    "present_kp": [
      "clique"
    ],
    "absent_kp": [
      "np hardness"
    ]
  },
  {
    "text": "installing a wildcard ssl cert. i am in the process of putting the final touches to a rather complex multi-server setup where the server domain names are along the lines of srva.example.com, srvb.example.com etc. at present i have four servers but that number will grow. i have done a lot to keep my admin burden to a bare minimum and want to ensure that stays the case with providing ssl access to the servers. with that in mind what i want do do is thiscomplete the server configuration for srva.example.com by installing a wildcard ssl cert. they seem to be reasonably cheap these days. my servers do not do any e-commerce so i do not need much by way of certificte - the one i am looking at is from an outfit called comodo.get an image of srva.example.comreplicate it as many times as necessary - now and in the future.question - am i liable to have any issues doing things this way? i.e. will i end up finding that i have to do individual cert installs on each server? i am something of a newbie when it comes to ssl certs so i would much appreciate any help.",
    "present_kp": [],
    "absent_kp": [
      "security certificate"
    ]
  },
  {
    "text": "algorithm to create n arrays with maximum difference. let's suppose i want to generate n equal sized boolean arrays with maximum difference. - difference in this case is defined as that the arrays share as low as possible fields with one another. (an example of share: array1 = {1,0,0,0) and array2 = {1,1,1,1} -> array1 and array2 share 1 field (array1[0] / array2[0])just for example: n would equal 2 and the size of the field would be 6-> the optimum solution would be the arrays [0,0,0,0,0,0],[1,1,1,1,1,1] because they share no fields and so are very different from one anotheranother example: n was equal to 4 and the size of the array would be 4-> a solution would be [0,0,0,0], [1,1,1,1], [1,1,0,0], [0,0,1,1] - the arrays share 1.33 fields per array by averagehas anybody an idea of an algorithm or solution strategy that could solve this problem (generate n of these arrays) perfectly (or very good - so that they are as different as possible) (in a realistic runtime)? thanks very much in advance :d",
    "present_kp": [
      "arrays"
    ],
    "absent_kp": [
      "algorithms",
      "optimization"
    ]
  },
  {
    "text": "hosting a web site for local network. i'm trying to access website located on xampp server on my other computer located on the same lan network. i am able to see welcome screen of xampp server, i.e., 192.168.0.1/xampp/ but when i am pointing to my website, i.e., 192.168.0.1/xampp/website/ it says:object not found! the requested url was not found on this server. error 404.",
    "present_kp": [
      "xampp"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i keep awk variables in scope?. i am attempting to keep track of the lowest/highest values from a list of counties and populations. i can't figure out how to stop variables from resetting themselves at 0. this is my cmd.awk file.begin { fs= hpd=0 hpdname= lpd=0 lpdname= hpw=0 hpwname= lpw=0 lpwname=}# stuff in here needs to be printed during the process.{ print $1 pd=$2/$4 print pd pw=($3/($3+$4))*100 print pw# these if statements see if there is a new highest or lowest value for the categories. if ($pd>$hpd) { hpd=$pd hpdname=$1 } if ($pd<$lpd) { lpd=$pd lpdname=$1 } if ($pw>$hpw) { hpw=$pw hpwname=$1 } if ($pw<$lpw) { lpw=$pw lpwname=$1 }}# prints off all of the ending information that we have been keeping track of.end { print the highest population density: $hpdname $hpd print the lowest population density: $lpdname $lpd print the highest percentage of water: $hpwname $hpw print the lowest percentage of water: $lpwname $lpw}the output of end always shows the last county to be analyzed instead of keeping track of the highest or lowest.",
    "present_kp": [
      "awk"
    ],
    "absent_kp": []
  },
  {
    "text": "query of attributes of mobile phone models, using several unions to find distinct values. i'd like to know if there's any room to improve the following query which is to find distinct values from multiple tables when someone searches for a model name. two of the tables are storing phones' series attributes and model attributes. the model attr table is there to deal with special cases, like a series generally use black cases, but it also has released a special edition that uses golden cases.here's the query that i have come up. basically i'm using union to unpivot table cpu and find distinct values across cpu,model_attr and series_attr is there any need for improvement?here's a fiddle example.query:select attr_name,attr_valfrom(select 'cpu_country' attr_name, c.country attr_val from cpu c inner join series s on s.cpu_id = c.cpu_id inner join model m on m.series_id = s.series_id where m.model_name rlike 'c79' union select 'cpu_hours' attr_name, c.hours attr_val from cpu c inner join series s on s.cpu_id = c.cpu_id inner join model m on m.series_id = s.series_id where m.model_name rlike 'c79'unionselect a.attr_name attr_name,a.attr_value attr_valfrom model m inner join series s on m.series_id = s.series_id left join series_attr sa on sa.series_id = s.series_id left join attr saa on saa.attr_id = sa.attr_id left join model_attr ma on ma.model_id = m.model_id left join attr a on a.attr_id = ma.attr_id where m.model_name rlike 'c79' and a.attr_value is not nullunion select saa.attr_name attr_name,saa.attr_value attr_valfrom model m inner join series s on m.series_id = s.series_id left join series_attr sa on sa.series_id = s.series_id left join attr saa on saa.attr_id = sa.attr_id left join model_attr ma on ma.model_id = m.model_id left join attr a on a.attr_id = ma.attr_id where m.model_name rlike 'c79' and saa.attr_value is not null )kgroup by attr_name,attr_valorder by attr_nametable schema (innodb):create table series ('series_id' int, 'series_name' varchar(20),'cpu_id' int ,'ram'int);insert into series ('series_id','series_name','cpu_id','ram')values (1,'nokia series',1,512), (2,'sony series',2,1024);create table model ('model_id' int, 'model_name' varchar(20),'series_id' int);insert into model ('model_id','model_name','series_id')values (1,'a6578',1), (2, 'b2345',1), (3, 'c7906',2), (4, 'd3544',2);create table attr ('attr_id' int, 'attr_name' varchar(20),'attr_value' varchar(20));insert into attr ('attr_id','attr_name','attr_value')values (1, 'material','gold'), (2, 'material','plastic'), (3, 'color','grey'), (4, 'color','black'), (5, 'color','green'), (6, 'color','white');create table series_attr ('series_id' int, 'attr_id' int );insert into series_attr ('series_id','attr_id')values (1,2), (1,5), (2,2), (2,3);create table model_attr ('model_id' int, 'attr_id' int);insert into model_attr ('model_id','attr_id')values (2,1), (2,4), (4,6);create table cpu ('cpu_id' int,'cpu_name' varchar(20), 'country' varchar(20),'hours'int,'frequency' int);insert into cpu ('cpu_id','cpu_name','country','hours','frequency')values (1,'cpu a','china',40,24000), (2,'cpu b','us',80,30000), (3,'cpu c','japan',100,35000);",
    "present_kp": [],
    "absent_kp": [
      "sql",
      "mysql"
    ]
  },
  {
    "text": "unset http_proxy enviroment variable. updated 11/03: after doing some test with your suggestions, i only can be sure about one thing: there is something related to the graphical environment, because if i login through ssh or using a virtual terminal, the variable is not defined. any new idea?i have defined in some persistent way the http_proxy variable. always i open a terminal, i have the http_proxy already defined.this is not my desired behaviour, so i'm looking where i defined http_proxy environment variable.i'm pretty sure that is something user related, because with other users in the same computer i don't have the problem.i have checked the .bashrc and other bash-related configuration files, but any of them include the http_proxy variable definition.obviously, i can unset de variable without any problem, but i want to know where the hell is the variable defined.thanks in advance",
    "present_kp": [
      "bash",
      "proxy"
    ],
    "absent_kp": [
      "environment variables"
    ]
  },
  {
    "text": "is this a good/safe way to convert enums?. due to the fact that entity does not support enums, i am converting them to strings, string lists, and back again.the reason is two fold:type-safety, and consistency in the database.now, i have a bunch of these, but i will use credit cards as an example: public enum creditcardname { visa, master_card, discover, american_express }originally, i decided on writing the same method for them, over and over again: public static list<string> getcreditcardtypes() { var list = enum.getnames(typeof(creditcardname)); return list.select(n => n.replace(_, )).tolist(); }then it occurred to me that i could make one private method to do this: public static list<string> getcreditcardtypes() { return enumtolist(typeof(creditcardname)); } private static list<string> enumtolist(type type) { var list = enum.getnames(type); return list.select(n => n.replace(_, )).tolist(); }now i'm also doing something similar in reverse, but will skip the code. the question i have is if this is a good way to go about this? i know there are other workarounds for entity's lack of enum support, but they are a bit cumbersome for my simple needs. i have never used types in this way, so i just wanted to check that this is how type/typeof are intended to be used, and that this will not cause unforeseen runtime issues.",
    "present_kp": [
      "enum"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "checking an md5 of a device. the point of this code snippet is to calculate and compare an md5 obtained from a usb device connected to the computer against a database to check its validity.var md5string = string.empty;using (var md5 = md5.create()){ var md5crc = md5.computehash(file.readallbytes(destinationfilename)); foreach (byte b in md5crc) md5string += b.tostring(x2);}// here i check the md5 against the database to check the usb device is validthe code meets its purpose, but i want to know how i can improve this code.",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "cryptography"
    ]
  },
  {
    "text": "tab completion hangs. when i first open a terminal, or open a new one after not having used one for a while, any kind of tab completion in my home directory (for example, ls and tab) takes several seconds. i have seen this behavior before when using autofs to mount network drives, but i don't have any in ~/. i do mount nfs shares with systemd's automount, but those are in ~/badabing/, so everything in ~/ itself is just a local file. in case it is an automount issue, here are the relevant /etc/fstab lines (yes, the server is called badabing, i named it during a sopranos binge a few years ago):badabing:/nfs_shares/music /mnt/badabing/music nfs4 noauto,x-systemd.automount,x-systemd.device-timeout=5sec,x-systemd.idle-timeout=1min 0 0badabing:/nfs_shares/series /mnt/badabing/series nfs4 noauto,x-systemd.automount,x-systemd.device-timeout=5sec,x-systemd.idle-timeout=1min 0 0badabing:/nfs_shares/movies /mnt/badabing/movies nfs4 noauto,x-systemd.automount,x-systemd.device-timeout=5sec,x-systemd.idle-timeout=1min 0 0then, in ~/badabing i have:$ ls -l ~/badabing/total 0lrwxrwxrwx 1 terdon terdon 32 jan 10 2016 movies -> /mnt/badabing/nfs_shares/movies/lrwxrwxrwx 1 terdon terdon 31 jan 10 2016 music -> /mnt/badabing/nfs_shares/music/lrwxrwxrwx 1 terdon terdon 31 jan 10 2016 series -> /mnt/badabing/nfs_shares/seriesi'd like to investigate this more. can i somehow strace tab completion? is the only way to add echo commands in the various bash completion scripts to see what's hanging? there are quite a few of those so i'd really rather avoid that. so, what's causing this or, at least, how can i debug it further?",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "autocomplete",
      "automounting"
    ]
  },
  {
    "text": "what are the key algorithms for learning optimal behavior of economic agents?. i'm playing around with social learning of near-optimal behavioral rules on a set of agents. the idea is roughly that given an income process (or technology process, depending on the question) an optimal nonlinear, intertemporal policy rule exists. assume this rule can be approximated closely by a linear function. agents would like to learn this policy rule, and a first pass is to have them learn the rule simply by experimentation. in autarky, i.e. without any information exchange with other agents, an agent would try a rule for some time, use some metric to determine how well it does against other rules he/she has tried, and perhaps reassess, perhaps try an entirely different rule via experimentation. this agent only observes his/her own history.a second pass is to allow the agent access to all other agents' histories. presumably this would speed up learning. a third pass might be to put these agents on an information network of some sort. i've been perusing literature on social learning, but am not entirely sure the frameworks i am looking at are exactly what i want. many of them appear to be bayesian learning about a hidden state of nature, for which everyone has a private signal. i'm actively reviewing literature right now, but as i do, does anyone have any thoughts/suggestions?",
    "present_kp": [
      "learning"
    ],
    "absent_kp": [
      "reference request",
      "social psychology",
      "game theory",
      "agent based modeling"
    ]
  },
  {
    "text": "view-model for a wpf usercontrol that validates regular expressions. i've created a small user control library in wpf that contains a few gui widgets that allow users to enter regular expressions. the widgets provide visual feedback when the user has entered an invalid regular expression, and support all the regexoptions that are provided by the .net regular expressions library. here is the view-model for all the regular-expression-input widgets:using system;using system.collections.generic;using system.componentmodel;using system.runtime.compilerservices;using system.text.regularexpressions;namespace newellclark.wpf.usercontrols.viewmodels{ internal sealed class regexviewmodel : inotifypropertychanged { public regexviewmodel() { _flagbools = new list<flagbool>(); _dirtyproperties = new hashset<string>(); _ignorecase = createflag(regexoptions.ignorecase); _multiline = createflag(regexoptions.multiline); _explicitcapture = createflag(regexoptions.explicitcapture); _compiled = createflag(regexoptions.compiled); _singleline = createflag(regexoptions.singleline); _ignorepatternwhitespace = createflag(regexoptions.ignorepatternwhitespace); _righttoleft = createflag(regexoptions.righttoleft); _ecmascript = createflag(regexoptions.ecmascript); _cultureinvariant = createflag(regexoptions.cultureinvariant); } public regex regex { get { return _regex; } set { updateregex(value); } } private regex _regex; public string pattern { get { return _pattern; } set { setfield(ref _pattern, value); } } private string _pattern; public bool isvalid { get { return _isvalid; } private set { setfield(ref _isvalid, value); } } private bool _isvalid; public regexerror error { get { return _error; } set { setfield(ref _error, value); } } private regexerror _error; public regexoptions options { get { return _options; } set { foreach (flagbool flag in _flagbools) { regexoptions next = flag.valuewhenenabled & value; regexoptions current = flag.valuewhenenabled & _options; if (next != current) setdirty(flag.name); } setfield(ref _options, value); } } private regexoptions _options; public bool ignorecase { get { return _ignorecase.enabled; } set { _ignorecase.enabled = value; } } private flagbool _ignorecase; public bool multiline { get { return _multiline.enabled; } set { _multiline.enabled = value; } } private flagbool _multiline; public bool explicitcapture { get { return _explicitcapture.enabled; } set { _explicitcapture.enabled = value; } } private flagbool _explicitcapture; public bool compiled { get { return _compiled.enabled; } set { _compiled.enabled = value; } } private flagbool _compiled; public bool singleline { get { return _singleline.enabled; } set { _singleline.enabled = value; } } private flagbool _singleline; public bool ignorepatternwhitespace { get { return _ignorepatternwhitespace.enabled; } set { _ignorepatternwhitespace.enabled = value; } } private flagbool _ignorepatternwhitespace; public bool righttoleft { get { return _righttoleft.enabled; } set { _righttoleft.enabled = value; } } private flagbool _righttoleft; public bool ecmascript { get { return _ecmascript.enabled; } set { _ecmascript.enabled = value; } } private flagbool _ecmascript; public bool cultureinvariant { get { return _cultureinvariant.enabled; } set { _cultureinvariant.enabled = value; } } private flagbool _cultureinvariant; public event propertychangedeventhandler propertychanged; // because many of the properties depend on each other, we have to update them all at once. // i don't want any event subscribers to see the object in an invalid state, so i hold off on firing any of the // propertychanged events until all properties have been updated. private void updateproperties() { _isupdating = true; setregexvalueswallowexceptions(_pattern, _options); isvalid = regex != null; raiseeventsondirtyproperties(); _isupdating = false; } /// <summary> /// same as <c>updateproperties</c>, but called when the <c>regex</c> property was set. /// </summary> /// <param name=regex></param> private void updateregex(regex regex) { _isupdating = true; if (!setfield(ref _regex, regex, nameof(regex))) { _isupdating = true; return; } if (_regex != null) { options = _regex.options; pattern = _regex.tostring(); isvalid = _regex != null; } raiseeventsondirtyproperties(); _isupdating = false; } private bool setfield<t>(ref t field, t value, [callermembername]string name = ) { //return common.setfield(propertychanged, ref field, value, name); if (equalitycomparer<t>.default.equals(field, value)) return false; field = value; setdirty(name); if (!_isupdating) updateproperties(); return true; } private void setdirty(string propertyname) { _dirtyproperties.add(propertyname); } private void raiseeventsondirtyproperties() { foreach (string dirtyname in _dirtyproperties) propertychanged?.invoke(this, new propertychangedeventargs(dirtyname)); _dirtyproperties.clear(); } private void setregexvalueswallowexceptions(string pattern, regexoptions options) { regex result; regexerror error = regexerror.none; try { result = new regex(pattern, options); } catch (argumentnullexception) { result = null; error = regexerror.nullpattern; } catch (argumentoutofrangeexception) { result = null; error = regexerror.invalidoptions; } catch (argumentexception) { result = null; error = regexerror.invalidpattern; } error = error; regex = result; } private flagbool createflag(regexoptions valuewhenenabled) { flagbool result = new flagbool(this, valuewhenenabled); _flagbools.add(result); return result; } /// <summary> /// sets the bit-flag that was assigned to it on <c>regexviewmodel.options</c> when its <c>enabled</c> property is set to true. /// also raises a propertychanged event on the containing <c>regexviewmodel</c> object when its <c>enabled</c> property changes. /// </summary> private class flagbool { public flagbool(regexviewmodel outer, regexoptions valuewhenenabled) { _outer = outer; valuewhenenabled = valuewhenenabled; name = enum.getname(typeof(regexoptions), valuewhenenabled); } public regexoptions valuewhenenabled { get; } public regexoptions currentvalue { get { return _outer.options & valuewhenenabled; } } public bool enabled { get { return (_outer.options & currentvalue) == valuewhenenabled; } set { if (value) { _outer.options |= valuewhenenabled; return; } _outer.options &= ~valuewhenenabled; } } public string name { get; } private regexviewmodel _outer; } private list<flagbool> _flagbools; private hashset<string> _dirtyproperties; private bool _isupdating = false; } internal enum regexerror { none = 0, nullpattern = 1, invalidpattern = 2, invalidoptions = 3 }}the view-model does work, and i already have a couple regex-input-widgets that use it and they work fine. however, i feel like the view-model is somewhat ugly in some areas. in particular, the code that raises propertychanged events is getting pretty tangled. the problem is that most of the properties on this object are dependent on other properties, so to raise all the correct property-changed events, any time i change one of the properties, i have to update all the properties. this happens in the updateproperties() method, unless it was the regex property that was initially mutated, in which case the updateregex() method is called instead. this was necessary because usually when all the properties are updated, a new regular expression object is created based on the values of the other properties. however, when it was the regex property that was mutated, we need to preserve its value and set the values of the other properties based on the properties of the regular expression that we were handed. i feel like the code that implements inotifypropertychanged is starting to smell, and is going to be a source of fragility if i ever need to add any properties to this class. i feel like i'm missing something when it comes to implementing inotifypropertychanged. any critiques would be appreciated.",
    "present_kp": [
      "wpf"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "what is the threat of a user trying to sudo without permission?. i was sshing into a certain computing system that i use. i was trying to follow some linux instructions that involved sudo, and tried a few times to enter the password unsuccessfully, before realizing that i was getting it incorrect because i was typing in my ssh terminal. i then received a very accusatory email about how my trying to sudo constituted a threat to the system. the tone was sustained even after i explained that it was an accident.my concrete question is: what is the threat model whereby trying a couple times to sudo without permission is considered a serious violation of system security?note: i understand in principle why the rule is there. my guess is that you don't want people writing automated scripts trying to crack the password - or i guess try to input a password one obtained via social engineering. but a couple unsuccessful guesses for some silly command...what's the threat model?",
    "present_kp": [
      "security",
      "sudo"
    ],
    "absent_kp": []
  },
  {
    "text": "why do google freshbot crawled and indexed pages disappear from serps? will they come back?. sometimes a page on our site will show up in the google serps that was previously not indexed (yet) due to a news story or blog posting on another site that points to it.from what i understand, the google freshbot has crawled it. the freshbot's job is to find information that is current or newsworthy to the time and get it indexed and into the serps quickly.however, the pages that benefit from that drop out of the serps after two or three days. as a matter of fact, if i do an advanced query and request that page specifically from our site (using site:), it appears to not even be indexed any more.what's happening to our google freshbot crawled pages?do pages that are indexed by the freshbot still need to be re-indexed by the deepbot?for what it's worth, we're ordinarily getting indexed daily at a healthy rate, but we don't yet have all of our pages indexed (large site). it has been encouraging to see the effect of the freshbot indexing, but watching it fade away is hard to understand. on our pages indexed as part of our normal crawls, our serps are strong -- without the added relevancy of news or other off-page links.",
    "present_kp": [
      "google",
      "indexing",
      "serps"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "testing whether characters of a string are unique. critiques (even pedantic ones) are welcome.bool unique_chars(std::string &s) { if (s.length()>256) return false; std::bitset<256> bs; for (auto &c:s) { if (bs.test(c)) return false; bs.set(c); } return true;}edit 1:for (auto &c:s) { //oldfor (unsigned char c:s) { //newreasoning:char can be either signed or unsignedif signed then bs[] can be out of boundscasting to unsigned eliminates issue as negative values will wrapedit 2:this string is to be made up of characters from the standard ascii character set, i.e. fitting into a 1 byte char.edit 3:renamed function / added test harness with examples. function parameter changed to const, as string not being modified.#include <iostream>#include <bitset>bool arecharsunique(const std::string &s) { if (s.length()>256) return false; std::bitset<256> bs; for (unsigned char c:s) { if (bs.test(c)) return false; bs.set(c); } return true;}int main() { std::string s1 = hi there; std::string s2 = hey man; std::cout << arecharsunique(s1) << std::endl; //0 std::cout << arecharsunique(s2) << std::endl; //1 return 0; }",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "algorithm",
      "strings",
      "c++11"
    ]
  },
  {
    "text": "permanent link to media library files?. if i upload a pdf file to the media library it gets a link like <url> is it possible to make a permanent link to it (e.g. the link will not change if i replace myfile.pdf with a new version next month or later). either <url> or just <url> would be fine.",
    "present_kp": [
      "files"
    ],
    "absent_kp": [
      "wordpress",
      "links"
    ]
  },
  {
    "text": "msata upgrade to install system envy 15-j108el. i own this laptop: hp envy 15-108elit comes with 1tb hard disk and the following msata drive:smartctl 6.4 2014-10-07 r4002 [x86_64-linux-4.2.0-23-generic] (local build)copyright (c) 2002-14, bruce allen, christian franke, <url> start of information section ===device model: adata axm21s3-24gm-bserial number: 2e1220002978lu wwn device id: 5 0<phone>firmware version: 168b-hpuser capacity: 24.015.495.168 bytes [24,0 gb]sector size: 512 bytes logical/physicalrotation rate: solid state deviceform factor: < 1.8 inchesdevice is: not in smartctl database [for details use: -p showall]ata version is: acs-2 (minor revision not indicated)sata version is: sata 3.1, 6.0 gb/s (current: 6.0 gb/s)local time is: wed jan 13 13:37:58 2016 cetsmart support is: available - device has smart capability.smart support is: enabledi would like to upgrade the msata drive, replacing it with a crucial mx200.will it fit inside the laptop? can i use it to boot windows? is there any way?i'm not scared of strange ways.",
    "present_kp": [
      "hard disk"
    ],
    "absent_kp": [
      "ssd"
    ]
  },
  {
    "text": "rsyslog stalled on tcp forward when file rotates. our rsyslog forward nginx log to our log tools.after some hours, rsyslog is stalled, this occurs when the log file is rotatedtcp 1 0 10.3.6.165:44823 someip:10514 close_wait 30469/rsyslogd if i do a strace i get: select(1, null, null, null, {63907, 299741}version used 7.4.4-1ubuntu2.6conf:$modload imfile# input for nginx$inputfilename /var/log/nginx/api.myserver.com.ssl.json.log$inputfiletag nginx$inputfilestatefile nginx-access$inputfileseverity info$inputfilefacility local1$inputrunfilemonitor[...]$workdirectory /var/spool/rsysloglocal1.* @@somewhere:10514;myformati tried to add$actionresumeretrycount -1but still have the issueany idea ?",
    "present_kp": [
      "ubuntu",
      "tcp",
      "rsyslog"
    ],
    "absent_kp": []
  },
  {
    "text": "how to set up nerdtree to cd to current folder when opening it for the first time via :nerdtreefind. given:$ cd ~/sites/projectproject $ vim:nerdtreefindi would like to see nerdtree opening with ~/sites/project as a root folder. instead i see ~/sites with project folder selected. so i have to cd to the work folder each time.i am sure there should be a setting for that but i can't find it. help.",
    "present_kp": [],
    "absent_kp": [
      "plugin nerdtree",
      "working directory"
    ]
  },
  {
    "text": "what is intelligence in artificial intelligence?. as far as artificial intelligence is concerned, what is intelligence? the definition i see on various sites like wikipedia: intelligence has been defined in many different ways including as one's capacity for logic, understanding, self-awareness, learning, emotional knowledge, planning, creativity, and problem solving merriam webster: the ability to learn or understand or to deal with new or trying situations : reason; also : the skilled use of reason. the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests).etc seem to be a bit broad and nebulous, and not necessarily what i would be thinking of if i wanted to build an ai, or evaluate the intelligence of non human life-forms. the definition i currently go with is: general problem solving ability. however, i'm not sure if this is broad enough to encompass all we think of when we say intelligence in the context of ai, or what we would be looking for in intelligent life-forms. what's a useful definition of intelligence. broad enough to encompass all the we consider when we think intelligence, yet narrow enough to exclude particular idiosyncrasies of specific intelligent agents? a universal definition of intelligence applicable to all intelligent agents.",
    "present_kp": [
      "intelligence",
      "artificial intelligence"
    ],
    "absent_kp": []
  },
  {
    "text": "how to to design a cronjob-like requirement. i have to design a system where i need to make some processing (which might take say 10 mins). after some amount of time (say 30 mins), i need to come back and check the status of this processing and possibly stop any further processing.there would be multiple such processes fired and running sequentially or in parallel. each would have a different processing time, and each would have a different 'stop' time.one way is that this would be a cronjob which comes back every 30 mins and checks the processing component.my solution is currently designed on nodejs and i intend it to be stateless. i am running a callback in a interval of 10 mins to check for the final state.what i want to know is how are such systems designed? is there a better alternative to having a cron job and / or continuously polling for the state of a processing. how would you do this? if i am being too vague in the requirement, please let me know and i can add in more details.",
    "present_kp": [
      "design",
      "polling",
      "cron"
    ],
    "absent_kp": [
      "node.js"
    ]
  },
  {
    "text": "what is the best way of storing centralised data for (and from) translation?. we are starting the process of internationalizing our software. to do this we will be writing a series of filters to convert all of our different resource files (resx, text, java resource, etc) into a common format. we will then be outputting xliff files for translation. after translation the process will run in reverse.we would like to keep the central store updated with any changes that developers make to the resource files ideally using ant during the build process, maintaining knowledge of which branch or version of the software is using which resources. we'd also like to keep track of which version of software the resources were taken from which are sent for translation, the dates when the files were sent and received back and also who translated them.the idea then being we apply the translations to the correct branch, we can take diffs of the central store in future to send partial resources for translations and we can report on quantity of translation at a point in time.we are considering storing all of this data within the svn repository as a tree of xliffs, perhaps branched in a mirror of the main code repository. is this sufficient or would we be better off just using a database to maintain this information?",
    "present_kp": [],
    "absent_kp": [
      "internationalization"
    ]
  },
  {
    "text": "is_numeric_array() is missing. i found that in php (or i probably can't find it) a proper is_numeric_array($array) function is missing. so i created one. the problem is that i don't think it's great and i don't know how to improve it.any suggestion?my first functionfunction is_numeric_array($array){ $i = 0; foreach ($array as $a => $b) { if (is_int($a)) { ++$i; } } if (count($array) === $i) { return true; } else { return false; }}is_numeric_array(array(0,0,0,0,0)); // trueis_numeric_array(array('str' => 1, 'str2' => 2, 'str3' => 3)); // falseexampleas asked, i provide an example on how this could be any useful.function is_numeric_array($array){ # code below}function somefunction($array){ if (is_numeric_array($array)) { $query = $array[0]; $param = $array[1]; $fetch = $array[2]; } else { $query = $array['query']; $param = $array['param']; $fetch = $array['fetch']; } # do your sql/pdo stuff here}# this use is the same of ...somefunction(array( 'pdo sql statement', array('param1' => 1, 'param2' => 2, 'param3' => 3), true));# ... this one.somefunction(array( 'query' => 'pdo sql statement', 'param' => array('param1' => 1, 'param2' => 2, 'param3' => 3), 'fetch' => true));# to choose one form instead of the other is coder's decision# also i know it is useless but i was just wondering why anybody actually looked forward this function",
    "present_kp": [
      "php",
      "array"
    ],
    "absent_kp": [
      "php5"
    ]
  },
  {
    "text": "mailqueue - follow up. follow up of this question.things altered: put logging (debug level) for creating and starting thread.a separate thread for starting the different threads.locking object and synchronise for starting the threadincreaser.changed the while condition of the while loop of threadincreaser so getting the size of the queue only happens when we don't have the maximum threads running.changed run to runningremoved the interface runnable.public enum mailqueue { instance; private javamailsender sender; private boolean running = false; private final thread threadincreaser = new thread(new runnable() { @override public void run() { logger.debug(threadincreaser started); int currentthreads = current_threads_send_mail.get(); while (currentthreads < max_threads_send_mail && mailstosend.size() > (max_elements_before_new_thread * currentthreads)) { new thread(createsendmailsthread(currentthreads + 1)).start(); currentthreads = current_threads_send_mail.incrementandget(); logger.debug((thread + currentthreads + created)); } threadincreaserrunning = false; } }); private boolean threadincreaserrunning = false; private static final object thread_increaser_lock_object = new object(); private final concurrentlinkedqueue<mimemessage> mailstosend = new concurrentlinkedqueue<mimemessage>(); private final concurrentlinkedqueue<mimemessage> errorrun = new concurrentlinkedqueue<mimemessage>(); private final map<mimemessage, mailexception> mailswitherrors = new concurrenthashmap<mimemessage, mailexception>(); private static final logger logger = loggerfactory.getlogger(mailqueue.class); private static final int wait_failure_time = 120000; private static final int max_threads_send_mail = 4; private static final int max_elements_before_new_thread = 25; private static final atomicinteger current_threads_send_mail = new atomicinteger(0); /** * adding a mail to the queue. when queue is not started, it will start. * * @param message to send. * @return true is mail is successfully added to the queue */ public boolean addmail(mimemessage message) { boolean result = mailstosend.add(message); checkaliveandstartthreadcounts(); return result; } /** * adding a mail to the queue. when queue is not started, it will start. * * @param messages to send. * @return true is mail is successfully added to the queue */ public boolean addmails(set<mimemessage> messages) { boolean result = mailstosend.addall(messages); checkaliveandstartthreadcounts(); return result; } /** * * @param threadnumber * @return the thread for sending mails. */ private thread createsendmailsthread(final int threadnumber) { return new thread(new runnable() { @override public void run() { logger.debug(thread + threadnumber + started); running = true; while (mailstosend.peek() != null) { mimemessage message = mailstosend.remove(); sendmessage(message); } running = false; if (current_threads_send_mail.decrementandget() < 1) { geterrorthread().start(); } } }); } /** * removes a specific mail from the error list. * * @param message to remove * @throws messagingexception when there is a fault with getting recipients * for logging. mail is not removed when this error comes up. */ public void removemailfromerror(mimemessage message) throws messagingexception { logger.info(removed mail to + message.getrecipients(message.recipienttype.to)[0].tostring() + with title : + message.getsubject() + from error queue. error was : + mailswitherrors.remove(message).getmessage()); } /** * starts a new thread, to try sending the erroneous mails again. */ public void starterrorthread() { logger.debug(creating error thread); geterrorthread().start(); } /** * try to send this specific mail from error list. * * @param message to send * @return true if mail was send. */ public boolean trysingleerrormail(mimemessage message) { if (sendmessage(message)) { logger.trace(erroneous mail succesfull send, mailswitherrors.remove(message)); return true; } return false; } /** * check if the threadincreaser is dead, if so => start it over. */ private void checkaliveandstartthreadcounts() { synchronized (thread_increaser_lock_object) { if (!threadincreaserrunning) { threadincreaserrunning = true; logger.debug(starting the threadincreaser); threadincreaser.start(); } } } /** * creates a thread for sending all the erroneous mails again. * * @return the error thread */ private thread geterrorthread() { return new thread(new runnable() { @override public void run() { logger.debug(error thread started); pauze(wait_failure_time); tryerrorsagain(); } private void pauze(int time) { try { thread.sleep(time); } catch (interruptedexception ex) { logger.error(sleep interrupted., ex); } } }); } private void tryerrorsagain() { errorrun.addall(mailswitherrors.keyset()); while (errorrun.peek() != null) { mimemessage message = errorrun.remove(); if (sendmessage(message)) { mailexception exception = mailswitherrors.remove(message); if (exception != null) { logger.trace(errorneous mail succesfull send., exception); } } } } private boolean sendmessage(mimemessage message) { mailexception exception; try { sender.send(message); return true; } catch (mailexception e) { try { logger.error(sending mail failed + string.valueof(message.getrecipients(message.recipienttype.to)[0]), e); } catch (messagingexception ex) { logger.error(this error shouldn't happen., ex); } exception = mailswitherrors.put(message, e); if (exception != null) { logger.trace(added duplicated mail in errors, e); } } return false; } public mimemessage createmimemessage() { return sender.createmimemessage(); } public void setsender(javamailsender sender) { this.sender = sender; } public map<mimemessage, mailexception> getmailswitherrors() { return mailswitherrors; } public collection<mimemessage> gettosend() { return collections.unmodifiablelist(arrays.aslist(mailstosend.toarray(new mimemessage[0]))); } public boolean isrunning() { return running; }}",
    "present_kp": [
      "java",
      "queue",
      "email"
    ],
    "absent_kp": [
      "multithreading"
    ]
  },
  {
    "text": "is it possible to indentify real file format from a 1995 file?. i have some files with the following extensions: .env .lev .vhcthose are from a pretty old game (1995) that is abandonware, i wanted to open them for a testing project in unity, but i don't know what could be the real extension. after using a hex editor, i can read some pieces of text, but i can't identify anything telling me what was the software used to create the file. i think they are models, maps, and sprites/textures.inside the file i found some .txt, .3dw and .spr.the files are available on dropbox if someone wants to have a look at them.",
    "present_kp": [
      "file format"
    ],
    "absent_kp": []
  },
  {
    "text": "how to compare two different hashset objects with more than 100,000 records. i have two classes class a{ int id; string name; public boolean equals(object o) { if(o instanceof a) { a a=(a)o; if(a.getid().equals(this.getid())) return true; } return false; } public int hashcode() { return id;} //setter& getter }class b{ int id; string address; public boolean equals(object o){ if(o instanceof b) { b b=(b)o; if(b.getid().equals(this.getid())) return true; } return false; } public int hashcode() { return id;} //setter& getter}i have 100,000 a type objects and 100,000 b type objects.so that, i have eliminated duplicates in both classes using hashset.now i am comparing hashset<a> and hashset<b> with id field and place matched objects in another list with following code in main class..hashset<a> a_set=new hashset<>();hashset<b> b_set=new hashset<>(); for (a c1 : a_set) { for (b c2 : b_set) { if (c1.getid().equals(c2.getiid())) { matcheddata.add(c1); } } }the above code taking 15 minutes to compare 100,000 records...is there any solution to increase performance of code.. (with in less time)",
    "present_kp": [],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "introduce bindings for macro user. i'm doing the racket track on exercism.io and solved the grains exercise:write a program that calculates the number of grains of wheat on a chessboard given that the number on each square doubles.(test cases etc on exercism)so i wrote a straightforward recursive solution:#lang racket(provide square total)(define (square n) (cond [(n . = . 1) 1] [(n . > . 1) (* 2 (square (- n 1)))] [else (error invalid number: n)]))(define (sum n) (cond [(n . = . 1) 1] [(n . > . 1) (+ (square n) (sum (- n 1)))] [else (error invalid number: n)]))(define (total) (sum 64))then i went to clean it up by factoring out the induction:#lang racket(provide square total)(define-syntax (induction stx) (syntax-case stx () ((induction base rule) (with-syntax ((n (datum->syntax stx 'n))) #'(lambda (n) (cond ((n . = . 1) base) ((n . > . 1) rule) (else (error invalid number: n))))))))(define square (induction 1 (* 2 (square (- n 1)))))(define sum (induction 1 (+ (square n) (sum (- n 1)))))(define (total) (sum 64))i got a couple of questions:1) is that the most straightforward way to introduce a new binding for the macro user?like, this is quite wordy. i guess i could wrap the with-syntax part into another macro, 'cause right now this feels very built out of raw plumbing to me.it's also annoying that define-syntax-rule doesn't give me stx, so i don't see a way to introduce new bindings. i'd like to write something like:(define-syntax-rule (induction base rule) (syntax-let ((n)) (lambda (n) (cond ((n . = . 1) base) ((n . > . 1) rule) (else (error invalid number:))))))is there anything built-in for that?2) for argument clarity, i'd like to write it more like this:(define (square n) (induction 1 (* 2 (square (- n 1)))))how'd i do that? like, i'd... have to capture the n argument correctly (how?), and return, uh... the body of the lambda? i'm confused.",
    "present_kp": [
      "racket",
      "exercism"
    ],
    "absent_kp": [
      "macros"
    ]
  },
  {
    "text": "merits of copy-on-write semantics. i am wondering what possible merits does copy-on-write have? naturally, i don't expect personal opinions, but real-world practical scenarios where it can be technically and practically beneficial in a tangible way. and by tangible i mean something more than saving you the typing of a & character.to clarify, this question is in the context of datatypes, where assignment or copy construction creates an implicit shallow copy, but modifications to it creates an implicit deep copy and applies the changes to it instead of the original object.the reason i am asking is i don't seem to find any merits of having cow as a default implicit behavior. i use qt, which has cow implemented for a lot of the datatypes, practically all which have some underlying dynamically allocated storage. but how does it really benefit the user?an example:qstring s(some text);qstring s1 = s; // now both s and s1 internally use the same resourceqdebug() << s1; // const operation, nothing changess1[o] = z; // s1 detaches from s, allocates new storage and modifies first character // s is still some textwhat do we win by using cow in this example?if all we intend to do is use const operations, s1 is redundant, might as well use s.if we intend to change the value, then cow only delays the resource copy until the first non-const operation, at the (albeit minimal) cost of incrementing the ref count for the implicit sharing and detaching from the shared storage. it does look like all the overhead involved in cow is pointless.it is not much different in the context of parameter passing - if you don't intend to modify the value, pass as const reference, if you do want to modify, you either make an implicit deep copy if you don't want to modify the original object, or pass by reference if you want to modify it. again cow seems like needless overhead that doesn't achieve anything, and only adds a limitation that you cannot modify the original value even if you want to, as any change will detach from the original object.so depending on whether you know about cow or are oblivious to it, it may either result in code with obscure intent and needless overhead, or completely confusing behavior which doesn't match the expectations and leaves you scratching your head.to me it seems that there are more efficient and more readable solutions whether you want to avoid an unnecessary deep copy, or you intend to make one. so where is the practical benefit from cow? i assume there must be some benefit since in it used in such a popular and powerful framework.furthermore, from what i've read, cow is now explicitly forbidden in the c++ standard library. don't know whether the con's i see in it have something to do with it, but either way, there must be a reason for this.",
    "present_kp": [
      "c++",
      "qt"
    ],
    "absent_kp": []
  },
  {
    "text": "when using github flow, what if my next feature depends on code from a pending pull request?. we are experimenting with github flow, as defined here.in short, every change starts off as a well-named branch off of master. when it's done, you open a pr for that branch, it gets reviewed, and then gets merged into master. it's a very simple workflow.however, we have run into this a couple of times: i develop feature x, and open a pr for it. while i'm waiting for the pr for x to be reviewed, i want to start work on another feature y, but i need the code from pr x. should i just start a branch from the feature x branch, or if i've already started feature y, just merge feature x into the feature y branch? it seems so, but i wanted to check with other teams that are following this model to see how they handled multiple prs and features that are dependent upon each other.",
    "present_kp": [
      "git"
    ],
    "absent_kp": [
      "branching"
    ]
  },
  {
    "text": "default configuration i need to change?. a few days ago i installed a new linux os. today i realize /root has o+r (755) so everyone is able to see my root sql password in /root/.my.cnf. i freaked out and simply changed /root to 750.my /var/www folder is 2755 but all the folders in it are 2750 (so certain users can browse to the folder without being blind). what software, file permissions and other default configuration should i change?",
    "present_kp": [],
    "absent_kp": [
      "security",
      "defaults"
    ]
  },
  {
    "text": "what happens when an unexpected packet arrives at a computer?. i have been wondering this for a few days. i basically understand how networks and packets work. but what happends when an unexpected packet arrives? like, when i didn't send a request for a website's index, but it sends the index to my machine anyways ? does my browser pop up? does it ignore it? anyway to actually catch it?",
    "present_kp": [],
    "absent_kp": [
      "networking",
      "internet"
    ]
  },
  {
    "text": "how to solve a 2d non-linear poisson equation?. i am trying to solve the following equation for $p(x,y)$:$$i = p abla \\cdot rac{1}{p^2} abla{p}$$where $p$ and $i$ are functions of x and y. $i(x,y)$ and $p(x,y)$i want to understand the algorithm for solving this equation; andan optimized python/fortran/c code that solve it.",
    "present_kp": [],
    "absent_kp": [
      "optimization",
      "finite element",
      "finite difference",
      "numpy"
    ]
  },
  {
    "text": "how to generate bootstrapping samples in r?. here is my original dataset from a voting activity. each participant voted for one option (a,b,c,d,e,f) listed below. the numerical value is the total number of participants who voted for each option.i want to bootstrap the voting for 1000 times (sample with replacement) and make a comparison between the pre-event and post-event voting for each category using independent sample t-test.however, i don't know how to start with generating the 1000 bootstrapping samples...i have the boot packages installed on r. could anyone give me a hint what kind of steps i should take in order to generate 1000 bootstrap samples based on the original data i provide above?",
    "present_kp": [
      "r",
      "data"
    ],
    "absent_kp": [
      "statistics"
    ]
  },
  {
    "text": "email notification if cell value goes below set amount. i'm having trouble finding a google sheet script that does what i need so i figured i would ask if someone could help me. basically i have a simple sheet setup to track inventory of one item. there is a formula in g1 on sheet qai stickers that calculates the remaining inventory and i would like to add a script that emails specific people when the value drops below 11. i also just want it to email when just that value changes and not just when any value in the sheet changes.here is what i've been trying to use. i have a trigger setup to run on edit, but it seems to only run if i push play on the script. the program is also telling me that lines 5 & 8 are deprecated. function mynotification() { var ss = spreadsheetapp.getactivespreadsheet(); var value = ss.getsheetbyname(qai stickers).getrange(g1).getvalue(); if( value < 11 ) { var last = scriptproperties.getproperty(last); value = value.tostring(); if( value != last ) { var email = session.getuser().getemail(); mailapp.sendemail(email, 'my notification', 'new value: '+value+' '+ss.geturl()); scriptproperties.setproperty(last, value); } } }",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "what is the state of the art in the field of nlp?. i am new to natural language processing, i think nlp is a challenging field, the syntax and semantic ambiguities could cause a lot of problems. for example i think for these problems machine translation is a hard task.therefore there are probably many approaches and methods that have been applied to this field. but what are the latest and most promising approaches and methods in the field of nlp?are these techniques highly dependent on the target language?",
    "present_kp": [
      "nlp"
    ],
    "absent_kp": []
  },
  {
    "text": "finding the convex layers of a given set of points. definition of convex layers can be found at wikipedia. i was trying to understand this algorithm , which works in o(n log n) time, which is optimal. in the paper, the author has described two types of deletions, among which one is direct deletion.in direct deletions, the author deletes the a point of the previous convex layer, from the hull graph( an endemic concept). the author has written something about direct deletions that i didn't understand: in general, a pulling operation will be accomplished by conceptually replaying the previous two pulling operations. this replay might be necessary in order to guide the current tangent on it's way down, and in particular find at little cost the vertices over which it must fold. where,hull graph: a union of the upper(resp. lower) chains of the subsets of vertices of the given set of points.pulling operation: deletion of edges that are connected to the vertex to be deleted in the hull graph(called tangents).i would like to know how can the line in bold be accomplished. moreover, there's a keen interest of mine to implement this algorithm. would that be irrational, given the hardness of this algorithm? thanks.any reasonable help about this paper is appreciated. moon",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "computational geometry",
      "convex hull"
    ]
  },
  {
    "text": "file renaming with ruby. this is a minimal little utility that i've found useful while reorganizing my music and book libraries. any issues you can see? anything i could be doing better or more elegantly? anyone wanna take a crack at the equivalent in python/perl?take 2:#!/usr/bin/rubyrequire 'optparse'require 'pp'require 'fileutils'$options = {:sub => , :downcase => nil}optionparser.new do |opts| opts.on('-r', '--regex regex', string, 'specify the regular expression to replace') {|reg| $options[:regex] = regexp.new(reg)} opts.on('-s', '--sub substitute', string, 'specify what to replace the match with. by default, the empty string (so matches are stripped).') {|$options[:sub]|} opts.on('-d', '--downcase', 'if passed, all filenames will be downcased.'){|$options[:downcase]|}end.parse!usage unless argv.length > 0def rename(str) ($options[:downcase] ? str.downcase : str).gsub($options[:regex], $options[:sub])endargv.each do |target| file.rename(target, rename(target))end",
    "present_kp": [
      "ruby"
    ],
    "absent_kp": []
  },
  {
    "text": "fun learning exercises recommendations. possible duplicate:where can i find programming puzzles and challenges? recently in our workplace we have been playing design pattern poker. this is fun and really helps the participants to understand design patterns and to think of useful way to apply them.can anyone recommend any other similar, fun games that will help us improve our development skills?",
    "present_kp": [],
    "absent_kp": [
      "self improvement"
    ]
  },
  {
    "text": "why was the first compiler written before the first interpreter?. the first compiler was written by grace hopper in 1952 while the lisp interpreter was written in 1958 by john mccarthy's student steve russell. writing a compiler seems like a much harder problem than an interpreter. if that is so, why was the first compiler written six-years before the first interpreter?",
    "present_kp": [
      "compiler"
    ],
    "absent_kp": [
      "history",
      "interpreters"
    ]
  },
  {
    "text": "optimal greedy algorithms for np-hard problems. greed, for lack of a better word, is good. one of the first algorithmic paradigms taught in introductory algorithms course is the greedy approach. greedy approach results in simple and intuitive algorithms for many problems in p. more interestingly, for some np-hard problems the obvious and natural greedy/local algorithm results in (provably) optimal approximation factor (under suitable complexity theoretic assumptions). a classic example is the set cover problem. a natural greedy algorithm gives an o(ln n) approximation factor, which is optimal unless p = np.name some natural greedy/local algorithms for np-hard problems that are provably optimal under suitable complexity theoretic assumptions.",
    "present_kp": [
      "greedy algorithms"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "lower bounds",
      "approximation algorithms",
      "approximation hardness"
    ]
  },
  {
    "text": "naming rules: standards, reserved, and what do they depend on?. i want to know the rules of naming (alwayscapitalize, _underscore, firstsmallletter, etc...) for each of namespaces, classes, interfaces, exceptions, data members, methods, variables, etc....also i would like to know:are they standards?do they differ according to the access modifiers? (public, private.....)what about compiler and library reserved formats?also are they language, ide, or framework relative?i only know that these rules exist, but don't actually know any.any help would be appreciated.edit: ok, if the question is really wide, then i have to narrow my question:what are the naming rules of classes, interfaces, data members, and methods in c# (and java if possible).also, inspired by renesis's comment, i've created a wiki to write coding conventions, here's the link:<url>",
    "present_kp": [
      "naming",
      "standards"
    ],
    "absent_kp": [
      "coding style",
      "coding standards",
      "syntax"
    ]
  },
  {
    "text": "cognito-- merge document upload. i am attempting to upload a custom document (to take advantage of the new merge document capabilities). the instructions say upload your template-- however, i cannot locate any button or portal in the manage templates section that would allow me to do so. can you point me to the correct place?",
    "present_kp": [
      "upload"
    ],
    "absent_kp": [
      "cognito forms"
    ]
  },
  {
    "text": "does license have to be in text format?. does a software license have to be in text format? i am thinking of adopting the mit license to my software. i have a documentation in html format, which is distributed together with the software, and am thinking of including the license in it at the beginning. will it be effective if the license is in html? i can also include a separate text file with the same content, but thought it would be better to put it in the documentation to get easier attention.also, would it make sense, or does it have any problem if i include license as part of the documentation?",
    "present_kp": [
      "documentation",
      "mit license"
    ],
    "absent_kp": [
      "licensing"
    ]
  },
  {
    "text": "in the mvp architecture, how should the model layer get its data?. i am new to high-level (android / java) application development and i learned of the mvp (model, view, presenter) architecture. but it's not clear what the role and design of the model layer is supposed to be.most tutorials and blogs about mvp directly discuss and show examples of the view and presenter layers, but either skip or only lightly touch on the model.should an api that passes data via events have the callback handled in the model or the presenter, and in this case is it the presenter's job to notify the model of new data from the api or the model's job to notify the presenter that it's state changed? who's responsibility is it to handle updates to the model not originating from the view?i understand the model should store the data to be displayed by the view, and it's responsible for how the data is handled. but, how should it get its data that doesn't specifically come from the view?",
    "present_kp": [
      "android",
      "mvp"
    ],
    "absent_kp": [
      "data structures"
    ]
  },
  {
    "text": "how does google detect duplicate content?. have a quick question about duplicate content. how does google work this all out? in that on my pages i have a form on each page with the same bit of text explaining it, is this going to count against me? the content on each page is original. surly most sites might have small bits of repeating text on it, would this count against you?",
    "present_kp": [
      "duplicate content"
    ],
    "absent_kp": [
      "seo",
      "google search"
    ]
  },
  {
    "text": "would it be better to have extra checks, or would it be a waste of time?. in your opinion, do you think it is a waste of time to make checks that you know there is no possible way of it being there/not being there, or would you just put it there just in case there is a bug or something? for example, below checks to see if a button is visible, then music is playing, but there is no way for that button to be shown without the music playing:if (buttonvisible) if ([music playing] == true) //is always true if the button is visible [music stopplaying];",
    "present_kp": [],
    "absent_kp": [
      "programming languages",
      "object oriented",
      "programming practices",
      "performance"
    ]
  },
  {
    "text": "extension method to do linq lookups. does this extension method contain unnecessary work? - thanks for reviewingscenario - a series of tables are key-value pairs (int id / nvarchar title). this extension method dots-off any integer (id) and provide the corresponding string value (title) given a target typeused in aspx-code-behind. an extension method was chosen for readable one-liners. there are many panels with similar controls to be set conditionally.// aspx.cstxtparentgender.text=parent.genderid.rhget(typeof(gender)); //male, femaletxtparentethnicity.text=parent.ethnicityid.rhget(typeof(ethnicity)); //caucasian, etc. txtparentmaritalstatus.text=parent.maritalstatusid.rhget(typeof(maritalstatus)); // married, divorced etc.txtchildgender.text=child.genderid.rhget(typeof(gender));txtchildethnicity.text=child.ethnicityid.rhget(typeof(ethnicity));txtchildrelation.text=child.relationid.rhget(typeof(relation)); //son, daughter etc.// class.csusing system.linq.dynamic; // nuget packagepublic static string rhget(this int id, type type ){ string returnvalue = string.empty; // set up data context using (mydatacontext dc = new mydatacontext()) { // get table corresponding to this type var table = dc.gettable(type); // match and select record using id var matchingrecord = ((iqueryable)table).where(string.format(id.equals({0}), id)) .select(new(title)).cast<object>().firstordefault(); // do a lot of contorting to finally get the string value returnvalue = matchingrecord.gettype().getproperty(title).getvalue(matchingrecord,null).tostring(); } return returnvalue;}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "extension methods",
      "linq to sql"
    ]
  },
  {
    "text": "a simple caesar cipher in python. i wrote an encryption/decryption algorithm for the caesar cipher. it works fine, but i'm curious if there are any constructive critiques, tips, tricks, comments, or advice anyone may have on how the code operates, performs, looks, etc.# caesar cipherdef choosemode(): while true: mode = raw_input( choose a mode (encryption or decryption): 1) encrypt 2) decrypt 3) brute force ) if mode in ['1', '2', '3']: return modedef collectmessage(): message = raw_input(enter the message you would like to translate: ) return messagedef collectkey(): while true: key = raw_input(what is the key for your message? (enter a number from 0 to 26): ) try: if int(key) in range(27): return int(key) else: print(please enter an integer between 0 and 26. ) continue except valueerror: print(please enter an integer between 0 and 26. ) continuedef translatemessage(text, cipher_mode, caeser_key): translation = '' # if decrypting, convert key to negative. if cipher_mode == '2': caeser_key = -caeser_key for symbol in text: # convert only alphabetical symbols if symbol.isalpha(): num = ord(symbol) # shift num down to 1 through 26 for more easier to visualize modulous. # then apply the key; then modulate; then move back up; then build into chr and translation if symbol.isupper(): num -= ord('a') num += caeser_key num %= 26 num += ord('a') translation += chr(num) else: num -= ord('a') num -= caeser_key num %= 26 num += ord('a') translation += chr(num) else: translation += symbol return translationdef bruteforce(text, cipher_mode): if cipher_mode == '3': for index in range(26): print a caeser key of , str(index), reveals: , translatemessage(text, cipher_mode, 26 - index) exit() else: return nonechoice_of_mode = choosemode()entered_message = collectmessage()bruteforce(entered_message, choice_of_mode)entered_key = collectkey()final_form = translatemessage(entered_message, choice_of_mode, entered_key)print final_form",
    "present_kp": [
      "python",
      "caesar cipher"
    ],
    "absent_kp": [
      "python 2.7",
      "cryptography"
    ]
  },
  {
    "text": "looking for dedicated volunteer matching website software. i am building a medical volunteering website for a nfp using wordpress and the nine to five theme. it is working (in a test environment) okay, but wondering if anyone has come across dedicated volunteer matching website software.",
    "present_kp": [],
    "absent_kp": [
      "looking for a script"
    ]
  },
  {
    "text": "worker mpm or prefork?. i understand that there is a comparison topic between the two modules but this is different.i was contacting cpanel support in order to help me freeing up some memory usage on the vps. they found apache 2.4 'httpd' child processes are using approximately 80mb rss, while on their test server, a similar apache 2.4 build only uses approximately 3mb rss per apache child process.after discussing the issue for a while, they suggested switching to the worker mpm in apache 2.4 rather than using prefork.i searched for what they said, and found that worker mpm use a less memory but it is not thread safe. some other topics on websites tell that worker will not work with php applications or mod_php. i'm not sure if this is correct or not.i'm too confused what should i do? i have php scripts running on my accounts and don't want to interrupt any of them or get data corrupted.what are your suggestions guys? does switching to worker mpm will solve the problem of running out of memory without interrupting php applications? is there any solution regarding the apache usage? as 80mb rss is too high comparing to the 3mb rss.",
    "present_kp": [
      "memory"
    ],
    "absent_kp": [
      "centos",
      "apache httpd",
      "resources"
    ]
  },
  {
    "text": "calling lua by c/c++ in compiled applications. so, currently i've been reverse engineering an application, that allows lua coding. because for some special purposes, i need to call lua directly by c/c++ coding. however, as this application is compiled obviously, i can't simply write a function that calls it. i would need the signature of the original functions (incl. the mask) and then write the function prototype, with calling convention, return type, etc. and later compile it as dll, then inject it.all this was done already. i've got the signature by idapro using the sigmaker plugin, made the base functions for scanning for the pattern and the masks. so, that's how for example the lua print functions looks like:dec_func(__cdecl, dword, print, int a1); looking into the lua source, a1 is lua_state *l. how would i now call this function and for example print hello world in lua? excuse me for my incompetence in such things like that, but i've been stuck to this for a couple of days now.for comparison you may look here to the code part from lbaselib.c (in the lua source):static int luab_print (lua_state *l) {int n = lua_gettop(l); // number of argumentsint i;lua_getglobal(l, tostring);for (i=1; i<=n; i++) {const char *s;lua_pushvalue(l, -1); // function to be calledlua_pushvalue(l, i); // value to printlua_call(l, 1, 1);s = lua_tostring(l, -1); // get resultif (s == null) return lual_error(l, lua_ql(tostring) must return a string to lua_ql(print));if (i>1) fputs( , stdout);fputs(s, stdout);lua_pop(l, 1); // pop result}fputs( , stdout);return 0;} thanks in advance. if some more information is needed, i may provide it of course.",
    "present_kp": [
      "dll",
      "c++"
    ],
    "absent_kp": []
  },
  {
    "text": "install already built linux environment. i have configured amint-based environment : openvpn, hostapd, and a bunch of other configured package. this is done on a rasp-like computer (oem).i planned to clone my disk on other machines.i dont even know if it s working but...... now i plan to clone and lusk-encrypt my clones.im said lusk is very simplier to make at install.but i dont plan to install, i plan to clone.please help.is there any hope to make such clone automatically (factory thinking) ?",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "debian",
      "encryption",
      "cloning"
    ]
  },
  {
    "text": "spiritual interpretation of dreams vs. scientific interpretation of dreams. what is the spiritual interpretation of dreams and the scientific interpretation of dreams? how are they different? please give evidence.",
    "present_kp": [
      "dreams"
    ],
    "absent_kp": [
      "scientific psychology"
    ]
  },
  {
    "text": "building websites, which is the better approach mvp or mvc?. i'm looking for feedback on mvp and mvc patterns used as a framework to build a website. i've used both with a certain degrees of success and failure. furthermore i've worked in places which have miserable implement mvp across the web, desktop and services layers. i've also seen a few terrible mvc implementations. one thing i've noticed is the mvp stuff-up appear terrible for maintenance or adding any new features compared to the mvc debacles.mvp - model view presenterhttp://en.wikipedia.org/wiki/model-view-presenterthe view holds a reference to the presenter. the presenter is also reacting to events being triggered from the view, so its aware of the view its associated with.the presenter updates the view based on the requested actions it performs on the model, but the view is not model aware.mvvm pattern was designed to support wpf and silverlight. it's similar to mvp, in the concept the view doesn't know about the model however its not mvp.",
    "present_kp": [
      "mvc",
      "mvp"
    ],
    "absent_kp": []
  },
  {
    "text": "inference rule with two conclusions or rather inverse function application. i want to express a simple correctness theorem for a term-desugaring function $\\delta$. the goal is to express that if the evaluation of a desugared term yields a value, this value is the desugared result of evaluating the original term. since the implication operator $\\rightarrow$ is already used in my dynamic semantics, i'd rather use an inference rule to express the implication. however, in the premise i have to introduce a variable $v$ that is the result of applying $\\delta$ to a variable bound in the conclusion. since there is no inverse of $\\delta$ i am somewhat stuck between two odd variants to express the relation.the first variant uses two conclusions (like multiple premises the idea is that both always hold):$$ rac{\\delta(t) \\downarrow v}{t \\downarrow v^\\prime \\quad \\delta(v^\\prime) = v}$$this looks odd to me. the alternative would be to see the rule as a scheme subject to some substitution over the meta-variables $t$ and $v$. in that case i could also write:$$ rac{\\delta(t) \\downarrow \\delta(v)}{t \\downarrow v}$$this is obviously cleaner, but i am not quite happy with the implications (pun not intended) to the theorem: in the first case, if $v eq \\delta(v^\\prime)$ the premise still holds, but the conclusion does not, so $\\delta$ is not correct. in the second case the premise would not apply - so correctness simply does not cover the case at all. is there a common pattern to deal with such problems? did i overlook something?",
    "present_kp": [],
    "absent_kp": [
      "formal languages",
      "programming languages",
      "correctness proof"
    ]
  },
  {
    "text": "automatic registration on release, for new gtld's. what ways are there of automatically purchasing gtlds?specifically - some domains under the new gtlds set to be released will be extremely popular, and ideally i would like to order some as close to the very second they are released.what options are there to do this? is it possible to do so programmatically? are there any php scripts which could do it, for example?from what i can tell, for example, as described here, companies offering pre-registration cannot guarantee you will get the domain you pre-register for. why is this the case? is it possible, in theory, or not?",
    "present_kp": [],
    "absent_kp": [
      "domain registration",
      "top level domains",
      "automation"
    ]
  },
  {
    "text": "bipolar and paintings. a year ago or so i discovered a study where the power spectrum of paintings were compared among various painters from the past and present day. among the present day painters there were bipolar, etc. people. these present day painter's paintings were then compared with painters such as van gogh.these finding were used to suggest a method to prove that painters, like van gogh, were bipolar or had some other mental illness.i thought this was interesting but have long since been unable to find this again for further review. does anyone know of this particular study,? if so could you please reference it.",
    "present_kp": [],
    "absent_kp": [
      "psychology",
      "bipolar disorder"
    ]
  },
  {
    "text": "how to preserve seo when transferring registrar?. sorry for the newbie question i may be totally off with my understanding, but i am unable to find anywhere where my question is explicitly listed.from my understanding seo can be preserved if a totally new domain name and hosting is registered with a new registrar, and a 301 redirect was employed from the old registrar (with the old domain and hosting still intact). but is there a way to migrate the previous domain name to the new registrar and preserve seo rankings (on both the root directory and sub-directories)?",
    "present_kp": [
      "seo",
      "301 redirect"
    ],
    "absent_kp": [
      "domains",
      "redirects",
      "domain registrar"
    ]
  },
  {
    "text": "optimisation of bash globs. looking for a guide to optimising regexp matches in bash.i have a script that loops over a very long list of urls looking for patterns. currently it looks a little like the fragment below. is there a guide to optimising these kinds of matches?if [[ ${url} == */oai/request ]]then echo first optionelif [[ ${url} =~ .*/index.php/[^/]+/journal=.* ]]then echo second optionelif [[ ${url} =~ .*/[ee][tt][dd]-[dd][bb]/.* ]]then echo third optionelif [[ ${url} =~ .*/handle/[0-9]+/[0-9].* || ${url} =~ .*/browse.* ]]then echo fourth optionelse echo no-match optionfi",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell",
      "wildcards",
      "optimization"
    ]
  },
  {
    "text": "z buffer working in opengl. after z-buffer testing does the fragment shader run on the discarded fragments?does the z-test happen after the fragment shader runs?please, tell me the step by step events that occur in the z-test.also what is early z-test and how to achieve it?",
    "present_kp": [
      "opengl",
      "fragment shader"
    ],
    "absent_kp": [
      "rasterizer",
      "buffers"
    ]
  },
  {
    "text": "how to configure screen-restore in a terminal?. depending on the terminal/environment following sequence has different effects:$ ls12$ man lsenter qeither i see last displayed man-page screen above the current prompt or the ls output and previous shell output is restored. same effect is observed e.g. when using vim and then suspending it to do something on the shell.on fedora 19 - the default of screen seems to be no-restore, a gnome-terminal/xterm uses do-restore by default.on solaris it depends on the used terminal/terminfo db it seems.i want to configure the restore behavior consistently between different systems/terminals.",
    "present_kp": [
      "terminal",
      "xterm"
    ],
    "absent_kp": []
  },
  {
    "text": "scaling yourself up against a better programmer/role model?. after having watched this video i have to ask how a programmer can go about measuring themselves against other, better programmers much as a chess player would.how would you decide who is a role model to start with? i mean james gosling is known by every java programmer but he invented the language and there is almost certainly an expert out there who could show him a few tricks.now say you have you found that role model. this could be, say, stackoverflow's own superstar jon skeet. it's possible to read his answers on stackexchange, visit his blog and read his books but what about actual programming skill? how could you go about fixing challenges and determining where you are in the programming skill spectrum?",
    "present_kp": [],
    "absent_kp": [
      "self improvement"
    ]
  },
  {
    "text": "index pages for previous months?. is there a way on how to find number of index pages for last 2-3 months. if yes, then how??please help.thanks.",
    "present_kp": [],
    "absent_kp": [
      "google index"
    ]
  },
  {
    "text": "tic-tac-toe solver. as a programming exercise, i've attempted a tic-tac-toe solver which takes a finished board and determines a winner. on top of checks for malformed input/ambiguous games (e.g. both players with winning positions), what else can i do to improve this? in particular, is the coding style acceptable and are there better ways to check for win conditions? def tictac(b): parses a tic-tac-toe board and returns a winner. input: a list of lists containing values 0 or 1. 0 corresponds to 'noughts' and 1 to 'crosses' e.g. >>> gameboard = [[0,0,1],[0,1,0],[1,1,0]] >>> tictac(gameboard) x wins # if the sum of a column/row/diagonal is 0, o wins. # if the sum is number of rows/columns, x wins. winner = board_range = range(len(b)) # check rows and columns. for i in board_range: row_sum = sum(b[i]) col_sum = sum([x[i] for x in b]) if row_sum == 0 or col_sum == 0: winner = o wins elif row_sum == len(b) or col_sum == len(b): winner = x wins # check the diagonals. fwd_diag_sum = sum([b[i][i] for i in board_range]) bck_diag_sum = sum([b[i][len(b)-i-1] for i in board_range]) if fwd_diag_sum == 0 or bck_diag_sum == 0: winner = o wins if fwd_diag_sum == len(b) or bck_diag_sum == len(b): winner = x wins if winner: print winner else: print game is a tie!for convenience, here's a little test function too:def test_tic_tac(): def pretty_print(b): for row in b: print row gameboard = [[0,0,1],[0,1,0],[1,1,0]] pretty_print(gameboard) tictac(gameboard) gameboard = [[0,1,1],[0,0,0],[1,1,0]] pretty_print(gameboard) tictac(gameboard) gameboard = [[1,0,1],[0,0,1],[0,1,0]] pretty_print(gameboard) tictac(gameboard) gameboard = [[0,0,1,0],[1,1,0,1],[0,1,1,1],[0,1,0,1]] pretty_print(gameboard) tictac(gameboard)",
    "present_kp": [],
    "absent_kp": [
      "python",
      "python 2.7",
      "tic tac toe"
    ]
  },
  {
    "text": "detect if screensaver is active. i want to detect whether the screensaver is active. on ubuntu 14.04 and fedora 21, i tried the following command:$ dbus-send --print-reply=literal --dest=org.freedesktop.screensaver /org/freedesktop/screensaver org.freedesktop.screensaver.lockerror org.freedesktop.dbus.error.notsupported: this method is not implementedi'm probably misunderstanding dbus-send as d-feet shows me that the method getactive is available.how can i detect screensaver activity, preferably in a desktop independent manner? there is a related question, which however wasn't solved.",
    "present_kp": [
      "screensaver"
    ],
    "absent_kp": [
      "d bus"
    ]
  },
  {
    "text": "did where the really hard problems are hold up? what are current ideas on the subject?. i found this paper to be very interesting. to summarize: it discusses why in practice you rarely find a worst-case instance of a np-complete problem. the idea in the article is that instances usually are either very under- or very overconstrained, both of which are relatively easy to solve. it then proposes for a few problems a measure of 'constrainedness'. those problems appear to have a 'phase transition' from 0 likelihood of a solution to 100% likelihood. it then hypothesizes:that all np-complete (or even all np-problems) problems have a measure of 'constrainedness'.that for each np-complete problem, you can create a graph of the probability of a solution existing as a function of the 'constrainedness'. moreover, that graph will contain a phase-transition where that probability quickly and dramatically increases. the worst case examples of the np-complete problems lie in that phase-transition.the fact whether a problem lies on that phase-transition remains invariant under transformation of one np-complete problem to another.this paper was published in 1991. my question is was there any follow-up research on these ideas the last 25 years? and if so, what is the current mainstream thinking on them? were they found correct, incorrect, irrelevant?",
    "present_kp": [
      "worst case"
    ],
    "absent_kp": [
      "np hardness"
    ]
  },
  {
    "text": "what is the history of 0x2e (ascii) as a prefix for filenames?. why was 0x2e (us-ascii), of many other available choices, used as a prefix for node names so as to make a distinction which could be used to hide them from usual directory lists?i ask because of the small conflicts with the '.' and '..' nodes which occur when globbing. there are various protections in place which prevent renaming or damaging those two while using most system calls, but it nevertheless begs the question: why 0x2e?i would like to review some of the engineer's notes because i am selecting from other possibilities for mostly frivolous purposes.",
    "present_kp": [
      "ls",
      "filenames",
      "history"
    ],
    "absent_kp": []
  },
  {
    "text": "java/android crud sql design. all the sql in my app... should i be confining it to its own special class? for example a mydatabase class that extends sqliteopenhelper and implements all the create-tables, defines all the table names, column names, queries, holds all the crud methods for all my objects, etc. or should i be putting all this stuff in the actual objects themselves and have all my objects implement some common interface like databasemodel where all databasemodels implement things like create, save, delete, oncreate, onupgrade, etc? what do people choose and why?i want to know how most people handle create/update. in my case i have my objects contain many of the same members that they do in the sql database. for example a player object might have an id, name, about-me text, etc. that id would correspond to the auto-incremented id in the database. but in the app, when you're first filling in the data for that object, it doesn't exist in the database yet, so i default it to an id of -1. then if someone wants to save the object, i have it check if the id is negative, and if so, i create it in the database and assign the object that id immediately in the sql method. otherwise it is an update and it'll have the correct id anyway. is this what most people do? is this a sound decision?if anyone does answer, please provide some kind of example of what you mean.",
    "present_kp": [
      "java",
      "design",
      "sql",
      "android",
      "crud"
    ],
    "absent_kp": []
  },
  {
    "text": "recommendation of books to setup and admin a web server in linux. hi i am quite a newbie on linux, i knew basic concept and some commands of it. and now i am going to setup and admin a web server in ubuntu linux distribution. i installed it by default setting, and seems all works fine, and now i need to setup it to be a virtual web host server, mainly i will create more accounts and for each account, i will setup its home/folder, and ftp, so the user with the account can upload their php scripts to it, also i would like to make home/bin, home/lib for the account, so they can use ssh too, to install local binary or libs, even more..i am thinking to read some books, but i don't know which one is good for me basically it could have something about how to setup virtual web host server, admin it, and how to make it secure.any advice is appreciated.",
    "present_kp": [
      "linux",
      "ubuntu",
      "books"
    ],
    "absent_kp": []
  },
  {
    "text": "isostoragemanager. a manager for a speedy async saving objects to isolated storage, using serialization from newtonsoft.json. a project to play with is here.public static async task<t> readjsonex<t>(string filepath) { if (string.isnullorempty(filepath)) return default(t); return await await task.factory.startnew(async () => { using (var store = isolatedstoragefile.getuserstoreforapplication()) using (var stream = new isolatedstoragefilestream(filepath, filemode.open, store)) using (var sr = new streamreader(stream)) using (var jr = new jsontextreader(sr)) return await jr.readjsonasynctask<t>(); }); } public static async task<bool> writejsonex<t>(string filepath, t content) { if (string.isnullorempty(filepath)) return false; return await await task.factory.startnew(async () => { using (var store = isolatedstoragefile.getuserstoreforapplication()) using (var stream = new isolatedstoragefilestream(filepath, filemode.create, store)) using (var sw = new streamwriter(stream)) using (var jw = new jsontextwriter(sw)) await jw.writejsonasynctask(content); return true; }); }where extensions areprivate static readonly jsonserializer jsonserializer = new jsonserializer { nullvaluehandling = nullvaluehandling.ignore, missingmemberhandling = missingmemberhandling.ignore }; public static async task<bool> writejsonasynctask<t>(this jsontextwriter writer, t content) { writer.formatting = formatting.indented; return await taskex.run(() => { try { jsonserializer.serialize(writer, content); } catch (exception) { return false; } return true; }); } public static async task<t> readjsonasynctask<t>(this jsontextreader reader) { return await taskex.run(() => jsonserializer.deserialize<t>(reader)); }i'm just wondering if this code is secure and if it can be used in the real app.is the current approach safe enough?",
    "present_kp": [
      "json"
    ],
    "absent_kp": [
      "c#",
      "async await",
      "windows phone",
      "windows phone 7"
    ]
  },
  {
    "text": "set apt-get options to tolerate harmless 'dpkg --force-conflicts' kludge?. a trivially conflicting package foo can be made to work with bar, by running dpkg --force-conflicts -i foo. but eventually it's time to upgrade, and 'apt-get' objects:% apt-get upgradereading package lists... donebuilding dependency tree reading state information... doneyou might want to run 'apt-get -f install' to correct these.the following packages have unmet dependencies: foo : conflicts: bar but 0.2-1 is installede: unmet dependencies. try using -f.can apt-get be tweaked/forced to tolerate the (pretty much fixed) conflict, then upgrade? (quickie existence proof: uninstall foo, then upgrade, then reinstall foo as before. therefore it is possible, the question is finding the least cumbersome mechanism.)an example, but this question is not about any two particular packages.for several years gnu parallel has had a trivial conflict with moretutils; each provides /usr/bin/parallel. dpkg can force co-existence:# assume 'moreutils' is already installed, and 'parallel' is in# apt's cache directory.dpkg --force-conflicts -i /var/cache/apt/archives/parallel_20141022+ds1-1_all.debthis creates a diversion, renames the moreutils version to /usr/bin/parallel.moreutils. both programs work, until the user upgrades. i tried an -o option, but that didn't bring on peace:apt-get -o dpkg::options::=--force-conflicts install parallel moreutilspossible -o options number in the hundreds, however...",
    "present_kp": [
      "apt",
      "dpkg"
    ],
    "absent_kp": [
      "linux",
      "debian",
      "package management"
    ]
  },
  {
    "text": "review request: my app engine library (python). update: i didn't write the library pasted below i just make use of it. i'm unable to paste the part i wrote here because the message exceeds 30k characters when i try to do so. i have been working on my webapp and this a simple came into life as i needed to scratch my own itch. it basically enables you to store models and query results into datastore, memcache or local instance storage using a basic api. i haven't published any open source work before, but as this thing helped me keep the lines of code and cpu usage low, i thought it would help others too. how can i make it any better? i'm planning to write unit tests, but i'm not experienced with it, so any suggestions on which libraries to use etc. is welcome.author: juan pablo guerecamodule which implements a per gae instance data cache, similar to what you can achieve with apc in php instances.each gae instance caches the global scope, keeping the state of every variable on the global scope. you can go farther and cache other things, creating a caching layer for each gae instance, and it's really fast becausethere is no network transfer like in memcache. moreover gae doesn't charge for using it and it can save you many memcacheand db requests. not everything are upsides. you can not use it on every case because: - there's no way to know if you have set or deleted a key in all the gae instances that your app is using. everything you do with cachepy happens in the instance of the current request and you have n instances, be aware of that.- the only way to be sure you have flushed all the gae instances caches is doing a code upload, no code change required. - the memory available depends on each gae instance and your app. i've been able to set a 60 millions characters string which is like 57 mb at least. you can cache somethings but not everything. import timeimport loggingimport oscache = {}stats_hits = 0stats_misses = 0stats_keys_count = 0 flag to deactivate it on local environment. active = true#false if os.environ.get('server_software').startswith('devel') else true none means forever.value in seconds.default_caching_time = noneurl_key = 'url_%s'curious thing: a dictionary in the global scope can be referenced and changed inside a function without using the global statement,but it can not be redefined.def get( key ): gets the data associated to the key or a none if active is false: return none global cache, stats_misses, stats_hits return a key stored in the python instance cache or a none if it has expired or it doesn't exist if key not in cache: stats_misses += 1 return none value, expiry = cache[key] current_timestamp = time.time() if expiry == none or current_timestamp < expiry: stats_hits += 1 return value else: stats_misses += 1 delete( key ) return nonedef set( key, value, expiry = default_caching_time ): sets a key in the current instance key, value, expiry seconds till it expires if active is false: return none global cache, stats_keys_count if key not in cache: stats_keys_count += 1 if expiry != none: expiry = time.time() + int( expiry ) try: cache[key] = ( value, expiry ) except memoryerror: it doesn't seems to catch the exception, something in the gae's python runtime probably logging.info( %s memory error setting key '%s' % ( __name__, key ) )def delete( key ): deletes the key stored in the cache of the current instance, not all the instances. there's no reason to use it except for debugging when developing, use expiry when setting a value instead. global cache, stats_keys_count if key in cache: stats_keys_count -= 1 del cache[key]def dump(): returns the cache dictionary with all the data of the current instance, not all the instances. there's no reason to use it except for debugging when developing. global cache return cachedef flush(): resets the cache of the current instance, not all the instances. there's no reason to use it except for debugging when developing. global cache, stats_keys_count cache = {} stats_keys_count = 0def stats(): return the hits and misses stats, the number of keys and the cache memory address of the current instance, not all the instances. global cache, stats_misses, stats_hits, stats_keys_count memory_address = 0x + str(%x % id( cache )).zfill(16) return {'cache_memory_address': memory_address, 'hits': stats_hits, 'misses': stats_misses , 'keys_count': stats_keys_count, }def cacheit( keyformat, expiry=default_caching_time ): decorator to memoize functions in the current instance cache, not all the instances. def decorator( fxn ): def wrapper( *args, **kwargs ): key = keyformat % args[:keyformat.count('%')] data = get( key ) if data is none: data = fxn( *args, **kwargs ) set( key, data, expiry ) return data return wrapper return decorator",
    "present_kp": [
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "is it better to blur the input or output of an edge detection shader for noise reduction?. to reduce noise of edge detection the norm seems like it is to apply a blur. however, is it generally better to apply the blur to the input of the edge detection. the input in my case being the depth and normal gbuffers in which i compare neighbouring pixels.or is it better to blur the output of the edge detection, e.g. a greyscale image of edge strength, before i use that to apply some edge to a colour buffer?",
    "present_kp": [
      "blur",
      "edge detection"
    ],
    "absent_kp": [
      "image processing"
    ]
  },
  {
    "text": "how can i extend a memory of an analysed executable in ida pro?. i'm analysing some malware executable with immdbg and ida pro.the executable calls the kernel32.virtualalloc() at runtime with an argument lpaddress=null what means that an operating system decides itself where the memory has to be allocated. the virtualalloc() returns an address 0x003f0000. after that the executable writes some function to this memory, which is quite big, and i would like to analyse this function in ida pro.the problem is, that my executable is loaded to the 0x004010000 in ida proand i don't know how could i extend the memory of the executable in ida pro in order to create this function manually(with help of patchbytes).also maybe it's possible somehow to build a function from a sequence of opcodes in ida pro?thank you in advance!",
    "present_kp": [
      "ida",
      "malware"
    ],
    "absent_kp": [
      "disassembly",
      "anti debugging",
      "immunity debugger"
    ]
  },
  {
    "text": "monomial decomposition as product of smaller monomials. is there an algorithm to get all possible decompositions of a monomial as the product of smaller monomials ?for example $x^2y^3$ is $xxy^3$, $x^2y^3$, $xyxy^2$, and so on.for a monomial in one inderminate, i know i can use an integer partitions of the monomial degree. but this does not apply when there are at least two indeterminates.(sorry for misuse of vocabulary and may be uncomplete tags : i am french).note : this is a step in construction of an invariant polynomial as described in doi : 10.1016/j.ijsolstr.2005.05.021.",
    "present_kp": [],
    "absent_kp": [
      "co.combinatorics"
    ]
  },
  {
    "text": "neural network simulator with openmp. i wrote a simple neural network simulator (the biophysical kind) from scratch, and was hoping to get some feedback on how i can speed things up, or any c++ / compilation best practices that i can improve on.the code is at this repository.main problem:openmp doesn't seem to be conferring speedup.the performance-critical section of the code is in src/networks/spikingnet.cpp, but for additional context, see the rest of the code in the repository.#pragma omp parallel forfor (size_t li=0; li < nl; ++li) { spikinglayer *layer = net->layers[li]; stim *stim = rs->stimuli[li]; boolvec dospike = stim->yield(); conn_vec pre_arr = net->pre[li]; updatelayer(layer, pre_arr, dospike, t); recordspikes(results.mutable_spikes(li), layer, i);}// update transmission & stdp#pragma omp parallel forfor (size_t li=0; li < nl; ++li) { spikinglayer *layer = net->layers[li]; // transmission for (spikingconnection *conn : net->post[li]) { for (spikingsynapse* syn : conn->synapses) { updatetransmission(syn, layer->units[syn->s]); } } // stdp for (spikingconnection *conn : net->pre[li]) { spikinglayer *source = net->layers[conn->s]; spikinglayer *target = net->layers[conn->t]; if (conn->stdp_enabled) { #pragma omp parallel for for (spikingsynapse* syn : conn->synapses) { updatestdp(syn, source->units[syn->s], target->units[syn->t]); } } } // end stdp} // end forgprof tracearchitectural details:the network consists of l=9 layers, each with 100-900 units. there are on the order of l^2 connections (bundles of synapses between layers), and 2000 synapses per connection (synapses are sparse).during each update cycle, all the layers (neurons) are updated (conditioned on connections), and then all the connections (synapses) are updated (conditioned on layers). that is to say, layer updating is independent conditioned on connections, and connection updating is independent conditioned on layers.given that there are so many neurons and synapses, the program naturally spends most of its time updating layers and synapses (line 133). i thought that using openmp over the per-layer loop, or even per-neuron/synapse, would really speed things up, but that does not seem to be the case at all.if it's of any interest to the reader, my machine has a 4.0ghz cpu with 8 cores. 12k steps run in approximately 30 seconds on either single-threaded or openmp-enabled builds.i'm aware that i should be using smart pointers, but memory management is fairly straightforward in this simple simulator, so i chose to live dangerously.general c++ programming style tips / pointing out my bad practices are also welcome!",
    "present_kp": [
      "c++",
      "ai",
      "openmp",
      "neural network"
    ],
    "absent_kp": [
      "multithreading"
    ]
  },
  {
    "text": "process termimates after attaching. i am using ollydbg and whenever i attach ollydbg to running process (in this case it's game and it has xtrap) this game terminates all threads and nothing is shown in olly . and when i use ollyadvanced and when i attach olly into this proces then olly is stopping execution at ntdll.dll.dbguiremotebreakin. is there any plugin/way to fix that ?",
    "present_kp": [],
    "absent_kp": [
      "memory"
    ]
  },
  {
    "text": "installing ssh via cygwin. i have a laptop with windows 8. i'm trying to setup ssh from this laptop to a windows 2012 server via cygwin64. i followed the steps as described here.however, when i am at the step: ssh-user-config, i get the error: error: there is no home directory set for you in /etc/passwd.<br>error: setting $home is not sufficient!in my cygwin64 installation folder, i see a directory home with a user that is copied from the windows user i'm logged in with (say this user is nifty). i also see a file cygwin64/etc/passwd - but in the file my windows user (nifty) is not present. the only line i see there is:[computername]+sshd:*:197610:197121:[computername]\\sshd,s-1-5-21-<phone>-<phone>-<phone>:/var/empty:/bin/falsei have tried to manually add the passwd file, inserting: nifty:*:1:1:/home/nifty:/bin/bash/i also tried to add: [computername]++sshd:*:1:1::/home/swuyts:/bin/bashwhen googling, the only thing i come up with is try to run this command: mkpasswd -l -u >> /etc/passwdi noticed this adds some accounts present in windows (such as the administrators group, system account and the created cyg_server from the step above), but it doesn't help me in letting me execute ssh-user-config. can somebody explain me how to proceed?",
    "present_kp": [
      "ssh",
      "cygwin"
    ],
    "absent_kp": []
  },
  {
    "text": "key phrases showing benefits performing certified software testing for your company?. i am wondering what phrases that would have the most impact when approaching a business, to inform them why they should test their software.obviously you have easy ones; reduce costs/risk, improves stability/reliability/usability. but these are just words, how would you wrap them into something concrete that even people living in their own world, could see the potential benefit of software testing. i'm looking for shared experience. and how would you as a developer like to be approached by a software tester?ps: help! i'm not sure how to ask this question properly!",
    "present_kp": [
      "testing"
    ],
    "absent_kp": []
  },
  {
    "text": "clone git repo via ssh'ing from another pc. how can i clone git repos in a non-interactive way as follows:for h in server1 server2; do ssh $h git clone <email>/reponame.gitdonewhen i interactively clone the repository, it works. (ssh keys are ok.) however, when i run the above-mentioned script on another pc, i get the following error:cloning into 'reponame'...host key verification failed.fatal: could not read from remote repository.",
    "present_kp": [
      "ssh",
      "git"
    ],
    "absent_kp": []
  },
  {
    "text": "creating table with python script. the output looks like this: name: s210_21tb_800gb-ssd_128gb nodes: 1, 2, 3requested protection: +2d:1n hdd used: 13.2094t hdd total: 55.9520t hdd % used: 23.61%from this output, the following information is extracted.parity y is the value at the end of the requested protection line. we want the penultimate character, before the n (1 in this case)the number of nodes cis the last value from the nodes: linethe individual capacity in tb m is the value from the hdd total linethe used capacity p is similarly the value from the hdd used line based on these values, we perform the following calculations.total = m /c * (c-y) tbeffective total volume = m / c * (c-y)*0.8 tbused = p / c tbeffective used = p / c* (c-y)*0.8 tbavailable volume = (m - p)/c * (c-y)*0.8 tbis it possible to get the below output in table with python scripting?here is our current script:#!/bin/bashy=$(grep -n protection storage_info | cut -d ':' -f4 | cut -c1)echo y=$yc=$(grep -n node storage_info | awk '{print substr($0,length,1)}')echo c=$cm=$(grep hdd total storage_info | cut -d ':' -f2|rev|cut -c 2- | rev)echo m=$mp=$(grep hdd used storage_info_info | cut -d ':' -f2|rev|cut -c 2- | rev)echo p=$pecho parity=$yecho nodenumber=$cdiv=$(echo $m/$c| bc)div1=$(echo $p/$c| bc)minus=$(echo $c-$y|bc)minus1=$(echo $m-$p|bc)total=$(echo $div \\* $minus |bc)echo total = $total tbeffectivetotalvolume=$(echo $div \\* $minus \\* 0.8 |bc)echo effective total volume = $effectivetotalvolume tbecho used =$div1 tbeffectiveused=$(echo $div1 \\* $minus \\* 0.8 |bc)echo effective used=$effectiveused tbavailablevolume=$(echo $minus1/$c \\* $minus \\* 0.8|bc)echo available volume=$availablevolume tbhere is the desired output:total = 36 tbeffective total volume = 28.8 tbused =4 tbeffective used=6.4 tbavailable volume=22.4 tb(the values do not correspond to the example output, they are different runs, sorry.)",
    "present_kp": [
      "python"
    ],
    "absent_kp": []
  },
  {
    "text": "automate backup from remote mysql. i make daily backups of the mysql database storing the contents of my onlinewebsite, and i would like to automate those half-dozen commands intoa single command.i tried a nave solution, by simply putting the list of commands intoa bash script. this fails, as the script stops once it's entered theremote host.any help appreciated.my failed (bash script) attempt :#! /bin/bash echo connecting to the remote host ...; ssh -p myport <email> ; echo making the backup on the remote host ...; mysqldump --databases --user=mysqluser --password=mypassword mydatabase > backup_copy.sql ; echo compressing the sql backup ...; gzip backup_copy.sql; echo leaving the remote host ...; exit; echo copying the backup from the remote host ...; scp -p myport <email>_copy.sql.gz /my/location/to/store/backups ; echo task finished;",
    "present_kp": [
      "bash",
      "remote"
    ],
    "absent_kp": []
  },
  {
    "text": "what are good mathematical formulas to know for programming?. what are some somewhat common math formulas you learned that helped you write better algorithms and become a better programmer?example: i learned about the ecludian distance formula: sqrt((x1-x2)^2+(y1-y2)^2) which helped me understand how to find like objects by comparing 2 factors.",
    "present_kp": [
      "math",
      "algorithms"
    ],
    "absent_kp": [
      "learning"
    ]
  },
  {
    "text": "find the longest subsequence of two strings. i want to know which is the best way to find the longest common subsequence of two strings",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "algorithm analysis",
      "dynamic programming",
      "subsequences"
    ]
  },
  {
    "text": "sudo -u username -s cmd arg returns command not found. i used to execute the command:sudo -u elasticsearch -s ulimit -hnand it was returning the value of ulimit -hn as seen by user elasticsearch until i tried it on ubuntu 11.10. there it returns:/bin/bash: ulimit -hn: command not foundi tried a few different commands, and when i use an argument i always get command not found:$ sudo -u elasticsearch -s ls all.sh/bin/bash: ls all.sh: command not foundany ideas on how can i execute a command that requires arguments through sudo?",
    "present_kp": [
      "sudo"
    ],
    "absent_kp": [
      "quoting"
    ]
  },
  {
    "text": "design implementation for a project. i have a question in regards to the implementation of a program that i am trying to do. i have a mysql database with numerous users, and each have a task executed at a certain time.for each user they have a time for the task to be executed, and a time zone for the task to be executed (each seperate colums in the mysql db). so far when i've been testing things i excecute the program every 5 minutes via cron, it loops through all the users and checks to see if (timetobesent)-(currenttime) < 5, if it is the task is executed. i know this isn't 100% accurate but it was the closest and easiest way to start some testing.now that i have finished the general idea of my program, what are some options for this to work? i could keep looping through all the users every 5 minutes but thatis going to be resource intensive, and not accurate to the minute.another idea where i convert all the times the task is executed to a common time zone, then sort the database based on the time.once i've done this just run it every minute and select the rows thatpertain directly to that current minuteedit: another idea from the comments would be to sort the db in order based on all the times converted to utc. start with the first user at the earliest time and execute the task. then i would find the time difference between that user and the next and have the thread sleep until the next user's time comes up. i'm rather new to software engineering, and i haven't taken school classes on design implementation at my school so if there is a way to do this i would love if links to articles/sources could be posted so that i can learn.thank you very much!edit: language is java",
    "present_kp": [
      "design",
      "mysql"
    ],
    "absent_kp": [
      "implementations"
    ]
  },
  {
    "text": "do you sign each of your source files with your name?. possible duplicate:how do you keep track of the authors of code? one of my colleagues is in the habit of putting his name and email address in the head of each source file he works on, as author metadata. i am not; i prefer to rely on source control to tell me who i should be speaking to about a given set of functionality.should i also be signing files i work on for any other reasons? do you? if so, why?to be clear, this is in addition to whatever metadata for copyright and licensing information is included, and applies to both open sourced and proprietary code.",
    "present_kp": [],
    "absent_kp": [
      "source code"
    ]
  },
  {
    "text": "complexity of convolution in the max/plus ring. we can do convolution in $o(nlgn)$ for plus/multiply polynomials with fft. however the approach doesn't seem very generalisable to rings in general. has there been any progress over the naive $o(n^2)$ convolution for the max/plus ring?",
    "present_kp": [
      "polynomials",
      "fft",
      "convolution"
    ],
    "absent_kp": [
      "algebra"
    ]
  },
  {
    "text": "how do i convert a byte array to bitmap for a dot matrix lcd?. the device i'm using uses a dot matrix lcd and i would like to find the bmp it's using to draw things on the screen. i've checked for a standard bmp header but didn't see it.is there any tool out there that will do this conversion for me so i can see what's stored.i don't know if the data is compressed or not nor do i know how to figure that out. first time dealing with one of these.",
    "present_kp": [],
    "absent_kp": [
      "disassembly"
    ]
  },
  {
    "text": "what's the maximum length of the meta keywords tag?. could you please tell me that what is the maximum length for meta keywords?",
    "present_kp": [
      "meta keywords"
    ],
    "absent_kp": [
      "seo"
    ]
  },
  {
    "text": "is there a constructive parallel repetition theorem for nice mip protocols?. theorem 1.1 of ran raz's paper is a non-constructive upper bound on the soundness error of parallel repetitions of a 2-prover minimally minimally interactive proof system with perfect completeness.as far as i can see, despite the second sentence of that paper's abstract suggesting otherwise, that paper does not give a constructive upper bound on the relevant quantities.is there a known constructive upper bound on the soundness error of parallel repetitions of a 2-prover minimally minimally interactive proof system with perfect completeness?",
    "present_kp": [],
    "absent_kp": [
      "interactive proofs"
    ]
  },
  {
    "text": "security implications of using unsanitized data in shell arithmetic evaluation. in a comment to a recent question, stphane chazelasmentions that there are security implications to double parentheses arithmetic such as:x=$((1-$x))on most shells.my google skills seem to be rusty and i can't find anything. what are the security implications of double parentheses arithmetic?",
    "present_kp": [
      "shell",
      "security",
      "arithmetic"
    ],
    "absent_kp": []
  },
  {
    "text": "a question on cholmod. when i change cholmod_* to cholmod_l_ (because the size of my matrix is large, use cholmod_ will outputs errorproblem too large), it shows sparse:error: integer and real must match the routines, i feel strange, i didn't change anything execpt those mentioned above, what does this message mean? this message shows after cholmod_l_start(&c), cholmod_l_print_sparse(a,a,&c), and then the following steps l = cholmod_l_analyze(a,&c), cholmod_l_factorzie(a,l,&c), x=cholmod_l_solve(l,&c) can't execute. does anyone know anything about this? thanks!",
    "present_kp": [],
    "absent_kp": [
      "linear solver",
      "solver"
    ]
  },
  {
    "text": "linuz-linux can't be found in efi-bootmanager on imac. ive just installed a fresh new instance of arch-linux on my old imac.unfortunately, the apple default efi bootloader isn't be able to load the efi-entry.my partitions are:#1 efi#2 mac os x#3 rescure mac#4 boot (my /boot-partition for linux)#5 encryptedpartition 5 is my enrypted partition, which contains the lvm volume-group which contains 3 partitions (root, home and swap).i've mounted efi (#1) on /boot/efi. in boot, there is my kernel-image vmlinuz-linux. in /boot/efi/loader/entries/arch-encrypted.conf, i've edited the file so the option linux has /vmlinuz-linux. now it looks like that:title arch linuxlinux /vmlinuz-linuxinitrd /initramfs-linux.imgoptions encrypteddevice=uuid=<uuid of partition #5>:lvm root=/dev/mapper/vg--base-lv--root quiet rwbut now when im rebooting my system, arch isn't booting but an error message will get printed containing mlinuz-linux can't be found.i guess this is so because the linux-image is located on an different partition but this efi-entry points to the efi-partition where the entry is located itselv.can anybody help me with this please?",
    "present_kp": [
      "arch linux"
    ],
    "absent_kp": [
      "boot loader",
      "uefi"
    ]
  },
  {
    "text": "pagination with static data. i am using following code to implement pagination functionality. all items are rendering on page load and li elements greater than page set are hidden with css.i want to make this code reusable so that any static pagination in my project can use this snippet with dynamic parameters.var countshown = $('ul li').not('.hidden').length;$('.load-more').on('click', function(){ var counthidden = $('ul li.hidden'); for(var i=0; i < countshown; i++) { counthidden.eq(i).removeclass('hidden'); } });js fiddleplease help me with suggestions to improve above written code.",
    "present_kp": [
      "pagination"
    ],
    "absent_kp": [
      "javascript",
      "performance",
      "jquery",
      "plugin"
    ]
  },
  {
    "text": "how do you organize your usability testings?. what is your process?how do you get feedback?what software do you use? (like morae from techsmith)who does them?have you measured how it positively affected the quality of your software?i'm looking for your experience on the subject. this is something i want to improve.",
    "present_kp": [
      "testing",
      "usability"
    ],
    "absent_kp": []
  },
  {
    "text": "finding kernel in dag. let $g=(v,e)$ be a dag. a subset $a \\subseteq v$ is called a kernel if for all $u,v \\in a$ $uv otin e$ and for all $v \\in v-a$ there exists an $a \\in a$ such that $av \\in e$ (note again, this is a directed graph).i need to find an algorithm that runs in $o(v+e)$ that upon giving a dag $g$, would find a kernel in the graph.i started like this:sort the graph toplogically. such a sorting exists since it is a dag. let us mark the output as $v_1, v_2,...,v_n$. then we run right to left:if $v_n$ has no ingoing edges, we add it to our kernel set $k$. else, here i got stuck.maybe dynamic programming can help us here?",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "graphs"
    ]
  },
  {
    "text": "how to merge multiple strings in errorformat. suppose a source code interpreter outputs the error messages in the following format:m123 warning path/to/file 123 description messagethat is:error_code error_type file line_number messagehow can i set errorformat such that i get both the error_code and message in the quickfix window?please note that error_type can be any string, with and without numbers.",
    "present_kp": [
      "errorformat"
    ],
    "absent_kp": []
  },
  {
    "text": "using newton-raphson method to solve the hydrostatic equation. i'm trying to use newton-raphson method for nonlinear systems of equations as described in 'numerical recipies' book in chapter 9.6 to solve the hydrostatic equation for a polytropic star.for each iteration, i change the radius vector as described in the book like $x o x+\\delta$ ($\\delta$ can be calculated for each iteration) but i can't ignore the fact that it can do shell crossing - meaning the i shell moves to a higher shell then $i+1 $, this cause a negative volume. i know there is a method to avoid shell crossing by multiplying delta with a factor but i don't know how to calculate it. there is no description in the book about shell crossing.let me be more specific:i want to solve $f_i(x_1,....x_n)=0$ set of equations,( when i goes from 1 to n).the method is to expand $f$ to a taylor series:$ec{f}(ec{x}+ec{\\delta x})=ec{f}+jec{\\delta x} +o(x^2)$, where $j$ is the partial deriviatives of $f$. by setting $ec{f}(ec{x}+ec{\\delta x})=0 $ we can get n sets of equations : $j \\cdot ec{\\delta x}=-f$ that can be solved by lu decomposition.the method starts from initial point $x_{old}$. for each step we calculate $\\delta x$ and add it to $x_{old}$ , meaning : $x_{new}=x_{old}+\\delta x$if the newton step $\\delta x$ minimizes $f=0.5\\cdot f\\cdot f$ we can say this step is acceptible. by using line searches and backtracking we can guaranty to minimize $f$. be aware that every solution to $f_i(x_1,....x_n)=0$ is a minimum of $f$ but not the oposite, so we must check if $f$ goes to zero.my set of equations are:$f_i= rac{dp_i/dm_i}{gm_i/4\\pi r_i^4}+1=0$ where $\\delta p_i=p_{i-1}-p_i$ , $\\delta m_i =0.5\\cdot (m_{i+1}-m_{i-1})$ , and from the polytropic equetion: $p_i=k( rac{m_i-m_{i-1}}{4\\pi / 3 (r_i^3-r_{i-1}^3)})^\\gamma$where do i stuck? in the first iteration. and it's suppose to be bad. the problem is shell crossing. $\\delta x$ changes $r$ so much that it changes the order of the cells. meaning, $r_i$ the radius of the star (from zero) is suddenly bigger then $r_{i+1}$. i know there is a method to correct this by multiplying $\\delta$ by some factor. how to calculate it? is there any other methods to correct it?do anyone know how to help?",
    "present_kp": [],
    "absent_kp": [
      "computational physics"
    ]
  },
  {
    "text": "what are the reasons for rebuild and redeployment libraries?. it's difficult to understand the meaning of the question from the topic's name.here is what i mean.i'm watching uncle bob's clean code episodes. in many episodes where he is talking about solid principles he mentions the problem of rebuild and redeployment caused by code changing. he says that bad architecture causes frequent rebuilds and redeployments.but i have a couple of questions:why frequent rebuilds and redeployments is bad?can you enumerate causes of rebuilds and redeployments of dll's?is there any difference between different languages according to thesecond question?what causes rebuild and redeployment of dll's in c#?the second question (and the most common) is based on dll's coupling. what should i change in one of two coupled dll's so then i have to rebuild and redeploy the other?",
    "present_kp": [
      "c#",
      "architecture",
      "solid"
    ],
    "absent_kp": [
      "design",
      ".net"
    ]
  },
  {
    "text": "why doesn't my ~/.bash_profile work?. i'm using linux mint. my login shell (cat /etc/passwd | grep myusername) is bash.after i start my graphical desktop environment and run terminal emulator from it, i could see that .bash_profile is not sourced (environment vars that export in it is unset). but if i login from text console (ctrl+alt+f1) or manually run bash -l from terminal emulator, .bash_profile works fine.am i wrong when i think that .bash_profile should source when x starts and all export'ed vars should be available in terminal, running from x?p.s. placing all in .bashrc and sourcing it from .bash_profile is not good idea (<url>): environment stuff should be sourced only once.",
    "present_kp": [
      "bash",
      "shell",
      "login",
      "profile"
    ],
    "absent_kp": []
  },
  {
    "text": "will google analytics automatically convert breadcrumbs when running an experiment?. i want to run an experiment to try out alternative pages using google analytics experiments. what i want to know though is will my breadcrumbs be handled by google or will i have to update them automatically?e.g. on my home page it displays the breadcrumb you are here: homeon my experiment page will it think it is the home page, or will i have to manually configure this. for info this is an asp.net webforms site with the breadcrumb control bound to the web.sitemap file",
    "present_kp": [
      "google",
      "google analytics",
      "breadcrumbs"
    ],
    "absent_kp": [
      "seo",
      "structured data"
    ]
  },
  {
    "text": "how does a 2d fourier transform of an image work?. i understand how a 1d fourier transform separates a signal into its component frequencies, but i'm having difficulty understanding how a 2d fourier transform affects a 2d image.from another question, john calsbeek linked to an interesting paper about measuring the quality of noise functions. this showed various noise functions and the fourier transform of each.is this a discrete transform of the pixel data, or a continuous transform of the continuous interpolating function which is used to generate the noise at arbitrary points?is the annular shape analagous to taking 1d fourier transforms of the line through the centre of the image at every possible angle? or is the transform for each possible angle also measured across the whole 2d space rather than only along a line through the centre? i'm trying to get an intuitive feel for what changes in the input image correspond to what changes in the fourier transform.",
    "present_kp": [
      "noise",
      "fourier transform"
    ],
    "absent_kp": []
  },
  {
    "text": "tips for developing with a remote team?. my company has corporate offices around the country and i have been hired under contract to work in one office while the rest of my team works in another. we are in the same time zone, but definitely remote. i have not met the team yet, but will be flying up there soon.what is your best advice for integrating and developing with this team? what are the most important priorities? standard versioning control, e-mail, phone, conference call and im are all available resources, however google apps, skype and the like are not for security reasons.",
    "present_kp": [],
    "absent_kp": [
      "communication",
      "teamwork",
      "telecommuting"
    ]
  },
  {
    "text": "fix a leaky abstraction (type checking). i have a method that accepts an interface and does type checking on the parameter, and depending upon the type a decision is made to either send an email or an alert public void bar(isomeinterface someclass) { if (someclass is someclasstoo) { emailer.send(someclass.something()); } else { alerter.alert(someclass.something()); } }i know this is bad for obvious reasons, but i would like to know what other options i have to resolve this, as one of the solutions i have is to put an abstraction on each of the classes that implements isomeinterface for the emailer/alerter using an icommunicator (see below) but i am not sure that is right as it feels like somewhere in my code there will have to be something that checks the type or knows about each type even if it is just in an ioc container configuration.public class someclass : isomeinterface{ private icommunicator _communicator; public someclass(icommunicator communicator) { _communicator = communicator; } public void something() { if (_communicator != null) { _communicator.send(yee ha); } }",
    "present_kp": [
      "abstraction"
    ],
    "absent_kp": [
      "c#",
      "design",
      "object oriented"
    ]
  },
  {
    "text": "i wish to extract several nodes in an xml document based on their content using ksh script. pre requisite:should be done using ksh script commandsi have the following document, and need to extract all the <sw:rmarecrd>s whose <doc:crspdt> children contain bsdtus30 or mitmus30.<?xml version=1.0 encoding=utf-8 ?><sw:rmafile xmlns:sw=urn:swift:snl:ns.sw xmlns:doc=urn:swift:snl:ns.doc xmlns:swsec=urn:swift:snl:ns.swsec><sw:rmafilehdr><sw:bic8lst><doc:bic8>bsdtgb20</doc:bic8><doc:bic8>bsdtus30</doc:bic8>doc:bic8>bwtrus30</doc:bic8><doc:bic8>melnjpj0</doc:bic8><doc:bic8>neimgb20</doc:bic8><doc:bic8>zyhjgb20</doc:bic8><doc:bic8>zyiyus30</doc:bic8><doc:bic8>zyjdgb20</doc:bic8></sw:bic8lst><sw:svclst><doc:svcnm>swift.fin!p</doc:svcnm></sw:svclst><sw:filemaintncsts>partial</sw:filemaintncsts><sw:filedesc/><sw:crdttm>2016-08-01t10:17:02z</sw:crdttm><sw:tltrecrd>254</sw:tltrecrd><sw:lau><sw:lauval>rrgl2lsocxdswchxgnf4ww==</sw:lauval></sw:lau></sw:rmafilehdr><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>rejected</sw:rmasts><doc:issr>zylcus30</doc:issr><doc:crspdt>bsdtgb20</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-09-12t13:16:19z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>agigus30</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2013-06-26t13:20:20z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>aqrmus30</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-11-05t02:17:34z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>blbggb20</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2015-11-20t10:30:18z</doc:issddttm><swsec:signature><swsec:signedinfo><sw:reference><sw:digestvalue>s6ytg+2ev+e4pg0uzuwd+lw0haudr3n/veswleg3bzu=</sw:digestvalue></sw:reference></swsec:signedinfo><swsec:signaturevalue>pemf@proc-type: 4,mic-onlycontent-domain: rfc822entrustfile-version: 2.0originator-dn: cn=blbggb2l-2,ou=prod,o=blbggb2l,o=swiftorig-sn: 1416707530mic-info: sha256, rsa, twfvov22y+iqinwiz5p40kgk7a9gm8bhcdph1bzf19063q8bsgle59df8fsscnk8 m1sudzwavzfi4na1iqf/cabuugvbxkthbuatnrqypvehrsl4boxku3lk0xgvtrdj ovhsbs0k8zhk/6cobuiwr2o+wqa9opvgmeydanqvw2oc+ucbsdv8gdyzfvi/cnvr men4ooekfnrqmvpr+ackpwfdb5fe70n/l2izjrygpcvbkr/ubg6zcoojueoqbsdo eezt5dvd8d3ahb2neqxoynnrmkxk9qqiijcw5vhtpcbanmkujvlcimw0vv+rrbsu miip/mkoppw17r0ts9acoq==</swsec:signaturevalue><swsec:keyinfo><swsec:signdn>cn=blbggb2l-2,ou=prod,o=blbggb2l,o=swift</swsec:signdn><swsec:certpolicyid>1.3.21.6.2</swsec:certpolicyid></swsec:keyinfo><swsec:manifest><sw:reference><sw:digestref>authorisation</sw:digestref><sw:digestvalue>alxflajsqfylohlau2gzpfudno9sdeqgpb3g8gbkwea=</sw:digestvalue></sw:reference><sw:reference><sw:digestref>sw.e2s</sw:digestref><sw:digestvalue>7xfotuftg0l2fmnoc+mzpamtkgeipvlctk0q3klw8fw=</sw:digestvalue></sw:reference><sw:reference><sw:digestref>sw.nrs</sw:digestref><sw:digestvalue>qruwmillsut2lamwkg8zo7qrrxqolrcwnlps//osvce=</sw:digestvalue></sw:reference></swsec:manifest></swsec:signature></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>blbggb50</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-11-17t17:30:27z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>bripus40</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-07-22t06:28:12z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>cfsmau20</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2015-02-26t23:24:52z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>citibgs0</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-04-08t07:34:10z</doc:issddttm></sw:rmarecrd><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>enabled</sw:rmasts><doc:issr>citiczp0</doc:issr><doc:crspdt>bsdtus30</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-01-20t07:52:11z</doc:issddttm></sw:rmarecrd></sw:rmafile>given the above file, the output i am hoping to achieve is the following:<?xml version=1.0 encoding=utf-8 ?><sw:rmafile xmlns:sw=urn:swift:snl:ns.sw xmlns:doc=urn:swift:snl:ns.doc xmlns:swsec=urn:swift:snl:ns.swsec><sw:rmafilehdr><sw:bic8lst><doc:bic8>bsdtgb20</doc:bic8></sw:bic8lst><sw:svclst><doc:svcnm>swift.fin!p</doc:svcnm></sw:svclst><sw:filemaintncsts>partial</sw:filemaintncsts><sw:filedesc/><sw:crdttm>2016-08-01t10:17:02z</sw:crdttm><sw:tltrecrd>254</sw:tltrecrd><sw:lau><sw:lauval>rrgl2lsocxdswchxgnf4ww==</sw:lauval></sw:lau></sw:rmafilehdr><sw:rmarecrd><sw:tp>received</sw:tp><sw:rmasts>rejected</sw:rmasts><doc:issr>zylcus30</doc:issr><doc:crspdt>bsdtgb20</doc:crspdt><doc:svcnm>swift.fin!p</doc:svcnm><doc:issddttm>2014-09-12t13:16:19z</doc:issddttm></sw:rmarecrd></sw:rmafile>",
    "present_kp": [
      "ksh",
      "xml"
    ],
    "absent_kp": []
  },
  {
    "text": "differentiating user triggered system reboot from daemon triggered system reboot. when the linux system is rebooting, how could i get to know on who triggered the reboot. it is sufficient for me to know whether it is triggered by user using the shutdown or reboot command or it is triggered by some daemon.",
    "present_kp": [
      "linux",
      "shutdown",
      "reboot"
    ],
    "absent_kp": []
  },
  {
    "text": "run an executable with a shell script. i have mplayer installed and i want to create a simple shell script that runs in bash and executes mplayer * in the current directory. so, how to call upon mplayer in the shell script? i am a newbie to linux and would like detailed instructions.",
    "present_kp": [
      "bash",
      "shell script",
      "mplayer"
    ],
    "absent_kp": []
  },
  {
    "text": "queue implementation using arrays. please review the code: package com.gmail.practice;import java.util.arrays;public class queues { int head; int tail; int size; int[] queue; public queues(int arraysize) { if(arraysize<0) { throw new illegalargumentexception(size cannote be less than equals zero); } head = -1; tail = -1; size = arraysize; queue = new int[size]; } public boolean isempty() { return(tail == -1 && head == -1); } public void enqueue(int value) { if((tail+1)%size == head) { system.out.println(the queue is full); }else if(isempty()) { head++; tail++; queue[tail] = value; }else{ tail = (tail+1)%size; queue[tail] = value; } } public int dequeue() { int value = 0; if(isempty()) { system.out.println(the queue is empty cant dequeue); }else if(tail == head){ value = queue[head]; head = -1; tail = -1; }else{ value = queue[head]; head = (head+1)%size; } return value; } public void display() { system.out.println(arrays.tostring(queue) + + tail is + + tail + the head is + + head); } public static void main(string[] args) { queues q = new queues(5); q.enqueue(3); q.enqueue(4); q.enqueue(2); q.enqueue(1); q.enqueue(5); q.display(); q.dequeue(); q.dequeue(); q.display(); q.enqueue(1); q.enqueue(5); q.dequeue(); q.dequeue(); }}",
    "present_kp": [
      "java",
      "array",
      "queue"
    ],
    "absent_kp": []
  },
  {
    "text": "what are the refresh characteristics of the google spreadsheet import functions?. the imported data is not always up to date with the source pages when i load the spreadsheet. when this happens, f5 refresh does not help. nor does ctl-f5. apparently there is some kind of caching going on.i'm thinking that they may be limiting the url fetches when i try to refresh too often - like when i'm actively modifying my spreadsheet.doc reference: <url>",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "systemd fedora 25 startup script permission denied. i have been following numerous tutorials on how to write a startup script for systemd (fedora 25 on vbox). however, i'm not able to make it work.here is the bash script /home/dario/desktop/unix/systemd/print_date.sh that i want to run:#!/bin/bashdate > startup_datei changed permissions on the file, chmod 755 print_date.shi created the service file /etc/systemd/system/print_date.service (this is just the last versions, i tried out many other iterations):[unit]description=example startup scriptafter=multi-user.target[service]type=forkingexecstart=/home/dario/desktop/unix/systemd/print_date.shuser=rootgroup=root[install]wantedby=multi-user.targeti run systemctl daemon-reloadsystemctl enable print_dateand to test it out witout rebootingsystemctl start print_datewhich gives me the error[root@dario systemd]# systemctl start print_datejob for print_date.service failed because the control process exited with error code.see systemctl status print_date.service and journalctl -xe for details.if i try to debug it with journal -xn the result is:[root@dario systemd]# journalctl -xn-- logs begin at wed 2016-12-28 13:03:41 pst, end at sat 2017-03-18 12:25:39 pdt. --mar 18 12:25:35 dario systemd[4143]: print_date.service: failed at step exec spawning /home/dario/desktop/unix/systemd/print_date.sh: permissi-- subject: process /home/dario/desktop/unix/systemd/print_date.sh could not be executed-- defined-by: systemd-- support: <url> -- the process /home/dario/desktop/unix/systemd/print_date.sh could not be executed and failed.-- -- the error number returned by this process is 13.mar 18 12:25:35 dario systemd[1]: print_date.service: control process exited, code=exited status=203mar 18 12:25:35 dario systemd[1]: failed to start example startup script.-- subject: unit print_date.service has failed-- defined-by: systemd-- support: <url> -- unit print_date.service has failed.-- -- the result is failed.mar 18 12:25:35 dario systemd[1]: print_date.service: unit entered failed state.mar 18 12:25:35 dario audit[1]: service_start pid=1 uid=0 auid=<phone> ses=<phone> subj=system_u:system_r:init_t:s0 msg='unit=print_datemar 18 12:25:35 dario systemd[1]: print_date.service: failed with result 'exit-code'.mar 18 12:25:38 dario dbus-daemon[682]: [system] activating service name='org.fedoraproject.setroubleshootd' requested by ':1.36' (uid=0 pid=6mar 18 12:25:38 dario dbus-daemon[682]: [system] successfully activated service 'org.fedoraproject.setroubleshootd'",
    "present_kp": [
      "systemd",
      "startup"
    ],
    "absent_kp": []
  },
  {
    "text": "helper class to interact with unity's playerprefs system. unity3d has a class for platform-independent data storage called playerprefs. supported data types: int, float and string can be retrieved and set using static methods, but no bool support exists, and you have to manually call save() to make sure value changes persist.i wrote a little helper class to cut down on the the boilerplate, and also add support for bool and enum datatypes. i'm looking for a general critique on style and efficiency, there's a fair amount of duplication, but i'm not sure how i can reduce that./// <summary>/// helper class that simplifies common playerprefs getting and setting./// </summary>public static class playerprefshelper{ /// <summary> /// gets an int value from playerprefs /// </summary> /// <remarks> /// this method has a side effect of creating a playerprefs entry for the given key if one does not exist. /// </remarks> /// <param name=key>the key.</param> /// <param name=defaultvalue>the default value.</param> /// <returns>the int value stored in playerprefs for the given key, or defaultvalue if no such key exists</returns> public static int getint(string key, int defaultvalue) { if (!playerprefs.haskey(key)) { setint(key, defaultvalue); } return playerprefs.getint(key); } /// <summary> /// sets an int value on playerprefs /// </summary> /// <param name=key>the key.</param> /// <param name=value>the value.</param> public static void setint(string key, int value) { playerprefs.setint(key, value); playerprefs.save(); } /// <summary> /// gets a bool value from playerprefs. /// </summary> /// <remarks> /// this method has a side effect of creating a playerprefs entry for the given key if one does not exist. /// the value will be converted from an integer value, because playerprefs does not support boolean values. 0 will be converted to false, all other values will be converted to true. /// </remarks> /// <param name=key>the key.</param> /// <param name=defaultvalue>the default value.</param> /// <returns>the bool value stored in playerprefs for the given key, or defaultvalue if no such key exists</returns> public static bool getbool(string key, bool defaultvalue) { return getint(key, defaultvalue ? 1 : 0) != 0; } /// <summary> /// sets a bool value on playerprefs. /// </summary> /// <remarks> /// the value will be stored as an integer, because playerprefs does not support boolean values. true will be stored as 1, false as 0. /// </remarks> /// <param name=key>the key.</param> /// <param name=value>the value.</param> public static void setbool(string key, bool value) { setint(key, value ? 1 : 0); } /// <summary> /// gets a float value from playerprefs /// </summary> /// <remarks> /// this method has a side effect of creating a playerprefs entry for the given key if one does not exist. /// </remarks> /// <param name=key>the key.</param> /// <param name=defaultvalue>the default value.</param> /// <returns>the float value stored in playerprefs for the given key, or defaultvalue if no such key exists</returns> public static float getfloat(string key, float defaultvalue) { if (!playerprefs.haskey(key)) { setfloat(key, defaultvalue); } return playerprefs.getfloat(key); } /// <summary> /// sets a float value on playerprefs /// </summary> /// <param name=key>the key.</param> /// <param name=value>the value.</param> public static void setfloat(string key, float value) { playerprefs.setfloat(key, value); playerprefs.save(); } /// <summary> /// gets a string value from playerprefs /// </summary> /// <remarks> /// this method has a side effect of creating a playerprefs entry for the given key if one does not exist. /// </remarks> /// <param name=key>the key.</param> /// <param name=defaultvalue>the default value.</param> /// <returns>the string value stored in playerprefs for the given key, or defaultvalue if no such key exists</returns> public static string getstring(string key, string defaultvalue) { if (!playerprefs.haskey(key)) { setstring(key, defaultvalue); } return playerprefs.getstring(key); } /// <summary> /// sets a string value on playerprefs /// </summary> /// <param name=key>the key.</param> /// <param name=value>the value.</param> public static void setstring(string key, string value) { playerprefs.setstring(key, value); playerprefs.save(); } /// <summary> /// gets a value from playerprefs as enumerated type t. /// </summary> /// <remarks> /// this method has a side effect of creating a playerprefs entry for the given key if one does not exist. /// </remarks> /// <typeparam name=t>the type of enum expected.</typeparam> /// <param name=key>the key.</param> /// <param name=defaultvalue>the default value if no playerprefs setting exists for the key.</param> /// <returns>the value stored in playerprefs for the given key, converted to type t, or defaultvalue if no such key exists</returns> /// <exception cref=argumentexception>t must be an enumerated type</exception> /// <exception cref=invalidoperationexception>cannot get an enum that doesn't have underlying type int32.</exception> public static t getenum<t>(string key, t defaultvalue) where t : struct, iconvertible { var enumtype = typeof(t); if (!enumtype.isenum) { throw new argumentexception(t must be an enumerated type); } if (enum.getunderlyingtype(enumtype) == typeof(int)) { var value = getint(key, defaultvalue.toint32(cultureinfo.invariantculture)); return (t)enum.toobject(enumtype, value); } throw new invalidoperationexception(cannot get an enum that doesn't have underlying type int32.); } /// <summary> /// sets an int value on playerprefs based on an enumerated value. /// </summary> /// <typeparam name=t>the type of enum.</typeparam> /// <param name=key>the key.</param> /// <param name=value>the value.</param> /// <exception cref=argumentexception>t must be an enumerated type</exception> /// <exception cref=invalidoperationexception>cannot store an enum that doesn't have underlying type int32.</exception> public static void setenum<t>(string key, t value) where t : struct, iconvertible { var enumtype = typeof(t); if (!enumtype.isenum) { throw new argumentexception(t must be an enumerated type); } if (enum.getunderlyingtype(enumtype) == typeof(int)) { setint(key, value.toint32(cultureinfo.invariantculture)); } throw new invalidoperationexception(cannot store an enum that doesn't have underlying type int32.); }}",
    "present_kp": [
      "unity3d"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "dynamic linq from string with ef. i wrote an ef browser to dynamically navigate through entities. beside basic properties of system types, each entity can have several singular or plural navigation properties. in order to support all of these using a single batch of code, i come up with the following solution considering the following requirement:each entity has an integer id primary key.sample query strings (person is an entity (id = 10) with job and cars navigation property):person/10/jobperson/10/carssolution:public list<dynamic> loadentitiesbyquery(string query) { string[] parts = query.split(/.tochararray(), stringsplitoptions.removeemptyentries); string entityname = parts[0]; int id = int.parse(parts[1]); string subentityname = parts[2]; type entitytype = gettypefromentityname(entityname); var tempobj = db.set(entitytype) .asqueryable() .where(string.format(id == {0}, id)) .firstordefault(); var propertyinfo = tempobj.gettype().getproperty(subentityname); list<dynamic> objects; if (propertyinfo.propertytype.isgenerictype) objects = ((ienumerable<dynamic>)propertyinfo.getvalue(tempobj, null)).tolist(); else { var tr = propertyinfo.getvalue(tempobj, null); objects = new list<dynamic>(); objects.add(tr); } return objects;}internal static type gettypefromentityname(string entityname){ type entitytype = null; switch (entityname) { case person: entitytype = typeof(person); break; case job: entitytype = typeof(job); break; /// .... } return entitytype;}i'm looking for faster ways of doing dynamic query instead of reflection.",
    "present_kp": [
      "strings",
      "linq"
    ],
    "absent_kp": [
      "c#",
      "entity framework"
    ]
  },
  {
    "text": "operator-precedence grammar's symmetrical rule. i have a basic question, but i cannot find an answer anywhere on the web. i have the following grammar rules:s -> if c ;c -> o < oo -> o + io -> ithe part than i'm interested in is at rules 1,2 and 4.i have calculated first(o) = {i, +} and last(o) = {i}.so, first(c) = {i,+,<} and last(c) = {<, i}.also, if <* first(c) and last(c) >* ; i have build the precedence table and now i want to parse the input: if < ;so when i parse it, i first have if on top of my stack. then i look at <, if <* <, so i push < on top of the stack. so now i compare < to ;, ; has higher precedence according to the rules, so i must pop. the last part is trivial, and leads me to s, thus accepting the sentence.but, as we can clearly see from the rules, this sentence should not be accepted (we only have 1 <, not enough to form c in order to reduce it).i have noticed that this happens because there is a symmetrical rule (rule 2 in our case), which means that if <* {i, <} >* ;, so we cannot verify that there was indeed an < or only an i.what is the solution to this problem? how do we handle these special cases where symmetrical rules's precedence relations overlap? i'm sure there must be one, because this grammar is conceptually close to a programming language parsing problem itself.thank you for your time!",
    "present_kp": [],
    "absent_kp": [
      "formal grammars"
    ]
  },
  {
    "text": "caching query results vs querying each time (finding a middle ground). this is kind of an expansion on a previously asked questionsome background info:querying over 5,000 items from sql database that eventually get sorted into a list depending on who the user is. one problem is that users are allowed to have customized lists which means that filtering these 5,000+ items in a uniform way is probably impossible.also, important that the amount of users (and users wanting to have custom item lists) is constantly growing, so there will be an unprecedented amount of ways to sort. basically, we won't be paying attention to filtering this growing list.two methods we've come up with so far: -option 1: cache item list per user (and filter the items needed after) or -option 2: cache the list once for the whole site (every user accesses this one cached list)the issue with option 1 is that there will be duplicated lists in cache. although we do not have an amount of users that will strain our server's memory, we obviously want our system to have scalability.the issue with option 2 is that there will be duplicated items in the single, cached list. with the amount of users we have, this can quickly turn into a disorganized list full of duplicated items (i.e. 5,000 items can quickly turn into 10,000 based on a few user's custom item preferences)is there a middle ground for dealing with this situation? one that combines some benefits of querying and caching.even if a response is a link to a potentially helpful source, i would appreciate it as i am kind of at a fork in the road.looking to open up new possible paths in my brainstorming.",
    "present_kp": [
      "caching"
    ],
    "absent_kp": [
      "performance",
      "sql server"
    ]
  },
  {
    "text": "how to ignore certain coding standard errors in php codesniffer. we have a php 5 web application and we're currently evaluating php codesniffer in order to decide whether forcing code standards improves code quality without causing too much of a headache. if it seems good we will add a svn pre-commit hook to ensure all new files committed on the dev branch are free from coding standard smells.is there a way to configure php codesniffer to ignore a particular type of error? or get it to treat a certain error as a warning instead?here an example to demonstrate the issue:<!doctype html public -//w3c//dtd xhtml 1.0 transitional//en <url> <meta http-equiv=content-type content=text/html; charset=utf-8 /></head><body><div> <?php echo gettabcontent('programming', 1, $numx, $numy); if (isset($msg)) { echo $msg; } ?></div></body></html>and this is the output of php_codesniffer:> phpcs test.php --------------------------------------------------------------------------------found 2 error(s) and 1 warning(s) affecting 3 line(s)-------------------------------------------------------------------------------- 1 | warning | line exceeds 85 characters; contains 121 characters 9 | error | missing file doc comment 11 | error | line indented incorrectly; expected 0 spaces, found 4--------------------------------------------------------------------------------i have a issue with the line indented incorrectly error. i guess it happens because i am mixing the php indentation with the html indentation. but this makes it more readable doesn't it? (taking into account that i don't have the resouces to move to a mvc framework right now). so i'd like to ignore it please.",
    "present_kp": [
      "standards",
      "code",
      "php",
      "code quality"
    ],
    "absent_kp": []
  },
  {
    "text": "best communication strategy for monitoring dashboard. i have a requirement where i need to display certain stats on admin dashboard in my web application (angular+java). these stats (transnational data) are being generated on different servers (connected via lan to my web app host server) by c++ programs.since we don't have a centralized database we can't just store statistics into db and retrieve it in java services and display on ui. as a workaround i have created a shell script which ssh on different servers, collect stats and prints them on console one by one. this script can also be fired on regular intervals from my java web service.i can parse output of script and send it to ui but this is not an efficient solution. the constant shh after every few seconds generates lots of interrupts.few thoughts which initially crossed my mind are belowcreate a java tcp client which sends requests to different serversand get the data periodically. create a java tcp server whichaccepts json data from different servers.i have never worked on something like this. can somebody suggest a better strategy or preferably point me to online resources in order to learn and understand these sort of architectures.",
    "present_kp": [
      "java",
      "c++",
      "tcp"
    ],
    "absent_kp": [
      "http"
    ]
  },
  {
    "text": "fpras on #p complete problems and self reducibility. i am quoting a phrase of martin dyer in his paper approximate counting by dynamic programming:since 0-1 knapsack is self-reducible, existence of an fpras for the problem now follows indirectly from a general result of sinclair and jerrum[19] in that paper of sinclair and jerrum it is stated that: it follows that, for self-reducible structures, polynomial timerandomised algorithms for counting to within factors of the form (1 +$n^{-eta}$) areavailable either for all $eta \\in r$ or for no $eta \\in r$.question 1: does statement 2 mean that counting self reducible structures might have an fpras?question 2: what is the indirect method dyer is talking about? is it some folklore method considered well known?",
    "present_kp": [],
    "absent_kp": [
      "ds.algorithms",
      "counting complexity",
      "randomized algorithms"
    ]
  },
  {
    "text": "iptables... blocking a range without flooding ipset set with ips. i have this range of ips 197.192.x.x that is brute force attacking my pop/imap/smtp servers day after day.i have this ipset in place that is blocking every ip that tries to hack on my server.i would like to block access for pop/smtp/imap for all ips starting with 197.192to do this, i have typed this command:ipset -a myipset 197.192.0.0/24but this added 65536 ips to my ipset, making it huge and now i cannot add more ips to it.is there another way to do this in a more elegant way?",
    "present_kp": [
      "ipset"
    ],
    "absent_kp": []
  },
  {
    "text": "how to understand output from ssh -o check in bash scripts?. i want to check the master process listening on ssh.sock is still alive.currently i'm checking whether the exit code returned by ssh -s ssh.sock -o check <my-server> is zero, but i'm not sure if that's the correct way to handle this problem and i can't find any documentation. the master process is supposed to have serveraliveinterval=20, so that it will die if the connection fails. is there any case in which the return code would be non-zero, but the process itself would be alive?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": []
  },
  {
    "text": "record all audio inputs at the same time with arecord. is it possible to automatically record, with arecord and possibly a small script or external helper program, every audio input both on my external usb soundcard and on my integrated soundcard? synchronization doesn't matter, as long as i know when the recording is started on every channel.",
    "present_kp": [
      "audio"
    ],
    "absent_kp": []
  },
  {
    "text": "tdd negative experience. what is a negative side of your tdd experience? do you find baby steps (the simplest fix to make test green) annoying and useless? do you find no-value tests (when test has sense initially but in final implementation checks the same logic as other test) maintanence critical? etc.the questions above are about things which i am uncomfortable with during my tdd experience. so i am interested whether other developers have similar feelings and what do they think about them.would be thankful for the links to articles describing negative sides of tdd (google is fullfilled by positive and often fanatic articles).",
    "present_kp": [
      "tdd"
    ],
    "absent_kp": []
  },
  {
    "text": "what are some general guidelines for setting up an ios project i will want to personally publish but sell in the future?. i have an idea for a personal ios project that i would like to write and release to the ios store. i'm the type of developer who enjoys developing and publishing. i want to write quality software and take care of my customers. assuming that i wrote an application that had reasonable success, there is a fair chance that i would want to sell the ownership rights of the app to another party and i'd use the proceeds to develop my next personal project which, in turn, i'd probably want to sell in the future.with that said, what are some general guidelines for creating, making and publishing an ios project that i will eventually want to transfer to another company/developer?i know this is a bit of a broad question, but i request that the given advice be a general list of tips, suggestions and pitfalls to avoid. if any particular bullet point on your list needs more explanation, i'll either search for the answer or post a new question specific to that requirement.thank you!note regarding this questioni am posting this question on programmers.so because i think that this is an issue of software architecting, seeking advice for setting a new application project and publishing a project to the apple ios store-- all within the requirements for questions on this site. update - 2012-09-14i would further like to request that if anyone is aware of a good article on a case study of such a transition, i would consider that a good answer as well. such an article may not have all the answers, but it could outline quite a few of the pitfalls which should be avoided.apps are sold to other holding companies on a semi-frequent basis. often, it happens when a small app becomes a runaway success and a bigger company wants to purchase the ownership and rights.i've had difficulty finding any information on this topic (probably my poor googling skills.) most keywords that i tend to search also relate to promoting an app so that people will download it. thanks for your insight.",
    "present_kp": [
      "ios",
      "requirements"
    ],
    "absent_kp": [
      "design",
      "project management",
      "licensing"
    ]
  },
  {
    "text": "how does the rendering equation incorporate shadowing. this is how the rendering equation is written in the textbook$$l(p,\\omega) = l_e(p,\\omega) + \\int f(p,\\omega_i,\\omega) \\, l(p*,-\\omega_i)\\cos heta \\, d\\omega_i$$which component of this equation handles the shadowing?",
    "present_kp": [
      "rendering",
      "shadow"
    ],
    "absent_kp": []
  },
  {
    "text": "how to download the latest file from sftp server?. i need to first get the data a file was uploaded to the sftp server on, then check whether it was today's date and if so download it else echo file not found. i would like to do all this using a bash script. this is what i have so far: sftp> cd testsftp> get myfile* sftp> exit today='date +%y%m%d'ls -lt | less |head 1 | awk '{print $7,$8,$9}' > $filedateif ($filedate == $today) echo today's fileelse echo today's file not foundfiusing the script above, i am always getting today's file not found even if the file has today's date.",
    "present_kp": [
      "sftp"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "how do you go about checking your open source libraries for keystroke loggers?. a random person on the internet told me that a technology was secure(1), safe to use and didn't contain keyloggers because it is open source. while i can trivially detect the key stroke logger in this open source application, what can developers(2) do to protect themselves against rouge committers to open source projects?doing a back of the envelope threat analysis, if i were a rogue developer, i'd fork a branch on git and promote it's download since it would have twitter support (and a secret key stroke logger). if it was an svn repo, i'd create just create a new project. even better would be to put the malicious code in the automatic update routines.(1) i won't mention which because i can only deal with one kind of zealot at a time.(2) ordinary users are at the mercy of their virus and malware detection software-- it's absurd to expect grandma to read the source of code of their open source word processor's source code to find the keystroke logger.",
    "present_kp": [
      "open source"
    ],
    "absent_kp": [
      "security"
    ]
  },
  {
    "text": "can i block all facebook messenger conversations?. i'm only a moderate user of facebook, and i don't use facebook messenger at all. however, if a friend messages me on fb messenger, i get an alert on my phone that i can't clear without going to the desktop site or installing messenger. i've found that if a friend messages me, i can block them individually when this happens, but i don't want to have to do this each time. is there a way to disable or otherwise block all messenger conversations to my account?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "treewidth and the nl vs l problem. st-connectivity is the problem of determining whether there exists a directed path between two distinguished vertices $s$ and $t$ in a directed graph $g(v,e)$. whether this problem can be solved in logspace, is a long-standing open problem. this is called the $nl$ vs $l$ problem.what is the complexity of st-connectivity, when the underlying undirected graph of $g$ has bounded treewidth.is it known to be nl-hard ? is there a $o({\\log}^2n)$ upper bound known ?",
    "present_kp": [
      "treewidth",
      "logspace"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "graph theory",
      "space bounded"
    ]
  },
  {
    "text": "removing friends information from klout when account is unlinked. at some point, my facebook account was enabled (was testing something) and well after that i decided to remove it. i would assume when one unlinks an account, all information that came with gets removed too.this seems to not be the case.so i went into my facebook application settings and noticed that the kloutapplication is still there. i removed the application and was presented withif you remove klout, it will no longer have access to your data and be removed from your profile, bookmarks, and apps page.good, go back to klout.com, friends are still there.okay, maybe the pictures are just cached go incognito (/logout out of facebook, stayed logged intotwitter for oauth), the facebook friends are still there.okay... let's block the klout app.blocking klout will prevent others from sending you invitations and requests for this app and will prevent this app from getting any info about you. this will also prevent you from seeing klout if other people have it installed.good, requests don't work but you still have the data.so, how does one remove information from klout after unlinking a specific account? or is this how data is supposed to be handled?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i add a help system to my winforms project?. i have pretty much completed work on a winforms application, and would like to add a help feature for users. i cannot send users to a website, and am thinking along the lines of the kind of help you get when you click on help in ie (or hit f1). i believe this is compiled html or something, but am not sure what tools are available to assist in building this kind of thing, or how many options are out there.anyway, how about some suggestions?",
    "present_kp": [
      "winforms"
    ],
    "absent_kp": [
      "help documentation"
    ]
  },
  {
    "text": "extract lines from a file based on sequential pair of patterns, and output to separate files. a) i have one huge file, from which i need to extract all the lines that match specific patterns, letus say paterna and patternb. so i need to extract all lines that start with patterna something like ^patterna, and all lines, that start with patternb something like ^patternb.then write the output to a file named patternapatternb.txtb) how could i make this work with a loop. for example, do the same for patterna2 and patternb2, then do the same with patterna3 and patternb3, so the file will be parsed many times, with new pairs of patterns to match lines each time, and finally the output then would be three files:patternapatternb.txtpatterna2patternb2.txtpatterna3patternb3.txt sample input001 8767<phone> 87387600: sometext601: someothertext 001 7123<phone>: sometext702: differenttext <phone> 7456<phone> 600: sometext601: someothertext 001 987345 87238 600: sometext702: differenttext patterna: ^001patternb: 600: sometextthe output would be a file named 600: sometext.txt001 876786600: sometext001 712345600: sometext001 <phone>: sometext001 987600: sometext actually, the first element in the pair of patterns, will be the ^001, and the second, each occurrence of a line that starts with three digits, followed by a :, then a space",
    "present_kp": [
      "sed"
    ],
    "absent_kp": [
      "text processing",
      "awk"
    ]
  },
  {
    "text": "when ssh'ing into a guest vm from within a host, why does vmplayer allow ssh via nat by default whereas virtualbox requires configuration. having been used to vmplayer for decades, i experimented with virtualbox yesterday and spent quite a few hours trying to ssh into an instance, when in vmp it was a breeze. i understand from these answers that vbox needs port forwarding or alternatively use bridged (which worked for sometime then broke connectivity on the guest after some time) - then i just gave up on vbox.why this difference in implementation between the two ? why does vmp require no port forwarding while vbox does ? is it for better security ?even cloning a vm was not as easy as it is with vmp (just copy the entire dir!)to elaborate:my guest ip: 192.168.124.153; host: (i am assuming 192.168.124.1 (vmnet1) is the one - so it seems like it is being bridged (i had earlier not looked at vmnets, just my wlan ip 192.168.0.x- my bad) - but it still begs the question - why does it work with the vmplayer guest in nat mode while the actual underlying connection looks bridged ? is vmp doing something under the covers ?) - so when i changed to bridged, the guest ip address is now 192.160.0.22 (correctly) - and yes, i did restart after each n/w changei guess i will accept the answer the nat/bridge setting is largely irrelevant if you're only communicating from the vm host to one of its guests",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "moved cgi-bin folder by mistake, now site won't work. i moved the cgi-bin folder into a different folder by mistake using ftp, and when i moved it back my website stopped working.using centos6.what should i do?",
    "present_kp": [],
    "absent_kp": [
      "webserver"
    ]
  },
  {
    "text": "how does one minimize or prevent user lawsuits?. i work in a bunch of tools that do things to customer's computers. some of these tools allow scripting, which allows someone to run a script to nuke files, registry keys, or the like. of course, if the script is bad, or if there's a serious bug in the tool, it could cause damage to the person's system. i'm concerned that a user might become... angry... with me if something goes wrong.how do i minimize the likelihood of being sued as a result of publishing such a tool?",
    "present_kp": [],
    "absent_kp": [
      "legal"
    ]
  },
  {
    "text": "best way to structure class + instantiation. is this a good way to design a class so i can prevent values being changed/ the state must remain as it was when it was intantiated...this code would be normally instantiated after a call from the database.public class instructionworkflow : istageworkflow{ private readonly int _companyid; public instructionworkflow(int instructionid, int progressid, int companyid, instructionkeyinfodto keyinfo, instructionstageprogress currentstage) { _companyid = companyid; currentstage = currentstage; keyinfo = keyinfo; progressid = progressid; instructionid = instructionid; } public int instructionid { get; private set; } public int progressid { get; private set; } public instructionkeyinfodto keyinfo { get; private set; } private instructionstageprogress currentstage { get; set; } public bool ismycompanyownerofstage { get { return currentstage.stageownerid == _companyid; } } /// <summary> /// #1 stage cannot be ticked as completed /// #2 stage must be initiated by the user, this will mean stage is open /// this is the best way so we can code against opening and closing a stage elsewhere, /// that will have a lot of rules on its own /// #3 stage must be owned by loggedon users company /// </summary> public bool isstageopenforupdates { get { return ismycompanyownerofstage && !currentstage.iscompleted && currentstage.dateinitiated != null; } } public int? stageownerid { get { return currentstage.stageownerid; } }}public interface istageworkflow{ bool ismycompanyownerofstage { get; } bool isstageopenforupdates { get; } int? stageownerid { get; } int progressid { get; } int instructionid { get; } instructionkeyinfodto keyinfo { get; }}update: as per suggestionspublic class instructionworkflow : istageworkflow{ private readonly iusersession _usersession; private readonly ireadonlysession _readonlysession; public instructionworkflow(int instructionid, int progressid, iusersession usersession, ireadonlysession readonlysession) { _usersession = usersession; _readonlysession = readonlysession; progressid = progressid; instructionid = instructionid; currentstage = resolveworkflow(); } public int instructionid { get; private set; } public int progressid { get; private set; } public instructionkeyinfodto keyinfo { get; private set; } private instructionstageprogress currentstage { get; set; } public bool mycompanyisownerofstage { get { return currentstage.stageownerid == _usersession.myprofile.companyid; } } /* notes: * #1 stage cannot be ticked as completed * #2 stage must be initiated by the user, this will mean stage is open * this is the best way so we can code against opening and closing a stage elsewhere, * that will have a lot of rules on its own * #3 stage must be owned by loggedon users company */ public bool stageisopenforupdates { get { return mycompanyisownerofstage && !currentstage.iscompleted && currentstage.dateinitiated != null; } } public int? stageownerid { get { return currentstage.stageownerid; } } private instructionstageprogress resolveworkflow() { var currentstage = _readonlysession.single<instructionstageprogress>( x => x.progressid == progressid && x.instructionid == instructionid); if (currentstage == null) throw new noaccessexception(string.format(workflow stage progress not found for instruction #{0} and progressid#{1}, instructionid, progressid)); keyinfo = null; //set here similar to currentstage above... return currentstage; }}additional info: origincal iusersessionpublic interface iusersession{ void setclientstore(string loginid, string identifier); void logout(); string loginid { get; set; } string companyidentifier { get; set; } userprofile myprofile { get; }}//new user sessionpublic interface iusersession{ void setclientstore(string loginid, string identifier); void logout(); string loginid { get; set; } int userid { get; set; } rolename role { get; set; } string companyidentifier { get; set; } int companyid { get; set; } companytype companytype { get; set; } string companyfriendlyname { get; set; } priceplantype priceplan { get; set; }}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "object oriented",
      "classes"
    ]
  },
  {
    "text": "making gmail to use reply all automatically in mailing list replies. i am using gmail and have subscribed to several mailing lists (mailman based).gmail defaults to reply to person instead of reply to list when i try to reply the mailing list messages.is there any way to change this behavior?",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": []
  },
  {
    "text": "two duplicated tags and one hidden. is that bad for seo?<h1 class=responsive-hidden>this is my title</h1><h1 class=hidden responsive-show>this is my title</h1>",
    "present_kp": [
      "seo"
    ],
    "absent_kp": [
      "html",
      "css",
      "hidden text"
    ]
  },
  {
    "text": "how to make mappings that yank text without overwriting the global registers. many useful mappings need to temporarily save text.some practical examples are: move line up/downnnoremap <c-j> ddpnnoremap <c-k> ddkp substitute word under cursor (use 'cc' instead of default 's')nnoremap ss yiw:s/<c-r>/nnoremap s% yiw:%s/<c-r>/ substitute selectionvnoremap ss y:s/<c-r>/vnoremap s% y:%s/<c-r>/these mappings has to yank a piece of text for later use. i have always used the default register for this but there is a problem with this approach.by using the default register in the mapping i am overwriting it's previous content.if the user has yanked some text and then executes one of the mappings the yanked text will be overwritten. this is something very minor but it has started to annoy me lately.there has to be a better way to do this.is there a way to make mappings like these but do not affect the global vim environment? if not then what is your solution to this problem?",
    "present_kp": [
      "register"
    ],
    "absent_kp": [
      "key bindings",
      "vimscript"
    ]
  },
  {
    "text": "google algorithm penalty & reconsideration request. there is no any manuel penalty message on my webmaster tools > manual actions tab.but, my visitors count decrease 10.000 to 1.000 in last 3 years.all seo-check services says my site is ok: w3c standarts, mobile site, unique content, site speed, etc.but especially in last 6 month, i fell from 1st page to 6th page on search results.this week i also will use disavow file for harmful backlinks.do you also suggest me to use a google reconsideration request or is it just for manuel penalties, which are seen in webmaster tools / manuel actions tab?",
    "present_kp": [
      "seo",
      "penalty"
    ],
    "absent_kp": [
      "google search console",
      "negative seo"
    ]
  },
  {
    "text": "design by contract and defensive programming confusion. i have been interested in better coding practices/methods which makes the reliability and maintenance less painful effort. i read the chapter about design by contract on object oriented software construction by bertrand meyer. despite the fact that, there are many definition and discussion about defensive programming, i have problems in understanding the key differences and benefits.as far as i understood, dbc supports preconditions and says it is redundant to check any input parameter because (or if) they are preconditions. it is the responsibility of caller (client) to check the validity of these inputs. however, many widely used programming languages like c++, java and etc. do not have a built-in contract system (like eiffel) and third party support depends on assertions or exceptions. is it okay to check these conditions on the supplier side and test it like that due to the lack of this built-in support? i think input validation is a part of defensive programming approach (at least people think in that way?) which is also a kind of precondition check with the third party contract support i mentioned in the above paragraph. i think, in case of an invalid input - according to preconditions - throwing exception(s) for invalid inputs (which are also against preconditions) is a common case. if supplier mentioned valid inputs as a precondition (via javadoc and etc.), isn't it a redundant check? if we follow dbc, should we remove such kind of checks, because this is the responsibility of the client? i assume supplier code has required methods for preconditions to be checked by client.at last, i believe in different problems may require different solutions and there is no ultimate answer. however, in that caseit is hard for me to separate these concepts.",
    "present_kp": [
      "design by contract",
      "defensive programming"
    ],
    "absent_kp": [
      "object oriented design"
    ]
  },
  {
    "text": "php tcp socket server. i created a php script which will be running 24/7 as a tcp socket server and will send data from the db back to clients. the code is working, and so far, i see no problems.however, i can only test it with one client. the info i need is, what will happen when there will be 100+ clients? can any of you see any weaknesses in the code? can i test it somehow?include('db_con.php');include('db_functions.php');error_reporting(e_all);// allow the script to hang around waiting for connectionsset_time_limit(0);// turn on implicit output flushing so we see what we're getting as it comes inob_implicit_flush();$address = '10.4.1.6';$port = 4950;$failed = 0;try { // create a socket (af_inet = ipv4, sock_stream=tcp stream) $failed = 1; $sock = socket_create(af_inet, sock_stream, sol_tcp); // bind connection to ip/port $failed = 2; socket_bind($sock, $address, $port); $failed = 3; socket_listen($sock, somaxconn); while (true) { // accept connection $failed = 4; $client = socket_accept($sock); $failed = 6; $rec = socket_read($client, 1024); $id_d = substr($rec, 0, 1); $id = intval(substr($rec, 1, 1)); // connect to database and get results $failed = 7; $failed = 8; $data = ok ; if (strcmp($id_d, 'o') == 0) { $in_o = returnresultsfortcp_o($db, $id); foreach ($in_o as $r) { $data .= 'o' . $r['ring_time'] . ' ' . ((int) $r['duration'] < 100 ? '0' : '') . $r['duration'] . ' ' . $r['bell_mode'] . ' '; } } else { $in_d = returnresultsfortcp_d($db, $id); $in_w = returnresultsfortcp_w($db, $id); foreach ($in_d as $r) { $data .= 'd' . $r['ring_time'] . ' ' . ((int) $r['duration'] < 100 ? '0' : '') . $r['duration'] . ' ' . $r['bell_mode'] . ' '; } foreach ($in_w as $r) { $data .= 'w' . $r['ring_time'] . ' ' . ((int) $r['duration'] < 100 ? '0' : '') . $r['duration'] . ' ' . $r['day'] . ' ' . $r['bell_mode'] . ' '; } } $failed = 5; socket_write($client, $data); socket_close($client); }} catch (exception $e) { if ($failed < 6) { $causes = array('create', 'bind', 'listen', 'accept', 'write'); echo 'socket_' . $causes[$failed - 1] . '() failed. reason: ' . socket_strerror(socket_last_error($sock)) . ' '; } else { echo 'failed at ' . $failed . ' ' . $e . ' '; } socket_close($sock);}the $failed part is just for testing; i'll remake it later (change it so the logs will be written to file - logging).",
    "present_kp": [
      "php",
      "tcp"
    ],
    "absent_kp": []
  },
  {
    "text": "does google discount links via redirects...conditionally?. i have a situation that i have never seen before and i didn't find any relevant questions/answers on here...i'm not new to this, i'm just hesitant to post about it so forgive my being somewhat vague:i registered an expired domain (with nice backlinks) and redirected it to my website.the previous registrants had created a plugin for a well-known open source cms (with a high authority domain) and the plugin page featured a link to their site/domain (and had gotten nice coverage by blogs at the time).i set up a 301 redirect from that domain to my domain.my site is in the same industry/niche as theirs so the relevance is fine.my site/domain is verified in google search console/webmaster tools.about a week after i set up the redirect, i checked the 'links to my site' report and saw a couple hundred links from domain.org.this was actually a pleasant surprise because the links were from all the different sub-domains the domain.org uses to host content that has been translated into different languages for different countries.a couple/few weeks later, those links weren't included in the google search console 'links to my site' report anymore.i know gsc reports are kinda buggy and can have long delays so i didn't really worry about it...but now it's been months.google found the links and reported them within a week of setting up the redirect but maybe a month later they weren't in the report anymore. that was probably 6 months ago.the redirected domain has other nice links from blog coverage of the plugin and those show up in the 'links to my sites' report, the link from the plugin page still exists (i even visited it and clicked it to register the traffic in ga).have you ever had google ignore links from high authority/quality sites?i'm not interested in white/black/grey hat discussions and i'm fully aware of rankbrain and google's increasing use of ai.what i have never seen before is google indexing, and then disregarding, reasonably relevant links coming from domains of the highest authority.anybody experienced this or have theories about it?",
    "present_kp": [
      "google search console",
      "redirects",
      "links",
      "backlinks"
    ],
    "absent_kp": []
  },
  {
    "text": "minimum number of shopping trips for a group of people to buy presents for each other. we have a group of $n$ people. we are given a list of who must buy presents for whom within the group. each person might need to buy/receive any number of presents, or possibly none at all. in a shopping trip, a subset of the people travel together to the same store, and buy presents for anyone who is not present at the store. they may not buy presents for someone else on the same shopping trip because then it wouldn't be a surprise. a person may go on multiple shopping trips. we want to minimize the total number of shopping trips required for everyone to buy all the presents they need.as an example, consider the case where there are 5 people, and each must buy presents for every other person in the group. let the people be numbered 1 to 5. this can be done in 4 shopping trips, as shown:trip 1: 1, 2, 3 go shoppingtrip 2: 1, 4, 5 go shoppingtrip 3: 2, 4 go shoppingtrip 4: 3, 5 go shoppinghow would i go about solving this problem? it is obvious that the input can be represented by a directed graph, but i don't know where to go from there. someone brought up the biclique cover problem, but while similar, it does not answer this question.we can think of the input as a directed graph $g$ on $n$ vertices, where the edge $(u,v)$ means that person $u$ must buy a present for person $v$. the goal is to find a set of bicliques $(s_1,t_1),\\dots,(s_k,t_k)$ such that $k$ is minimal and the edge set $e$ of the graph is a subset of $\\cup_i (s_i imes t_i)$. also, in extending the definition of bicliques to a directed graph, a biclique $(s_i,t_i)$ only contains edges which map $s_i$ to $t_i$. this differs from the biclique cover problem in that we don't require each biclique to be a subgraph of $g$ (we don't require $s_i imes t_i \\subseteq e$ for each $i$).specifically, i will accept an answer that either:demonstrates that this problem is np-hard orpresents a polynomial time algorithm that answers this question exactly (no approximants or upper bounds)for the record, i did not see this problem anywhere, i am just wondering about it for my own curiousity.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "graph theory",
      "set cover"
    ]
  },
  {
    "text": "how to execute scripts in a parent-child behavior in bash?. suppose i have two scripts named parent.sh and child.sh. the parent.sh script contains bash child.sh line and the child.sh script contains echo this is the child script. now, if the user executes the parent.sh, it should simply call the child.sh script and exit. but if the user executes the child.sh script, it should produce some error saying only parent.sh can execute the child.sh script.is there a way that i can achieve this type of behaviour of executing the scripts? this was just a small example, i have a huge set of scripts which a user can execute but these scripts should only be executed by the parent script.this is just to make sure that the user doesn't executes the wrong script by mistake. i don't want to strip away the users read/write permissions.my requirements in a nut shell:bash parent.sh -> execute bash child.sh -> execute something by child.sh",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "process"
    ]
  },
  {
    "text": "solid application structure and design. a one possible structure for an application is to have it broken down into modules such as data access, core, services, ui. now depending on what type of orm you are using data access layer will have a set of entities that represent the tables in the database. the core layer will have a set of entities that represent the business logic. the service layer will have a set of dto entities that it will communicate with to the ui. and finally the ui will have a set of view models that it will use inside the views.now when we access or store information in the database we have to transform objects from one type to another. when the service calls the core it needs to transform objects from one type to another and finally the ui needs to transform the dto's to view models. in a lot of the cases the transformation is a simple act of copying the properties from one object to another. it is a very repetitive and time consuming task that generates large amounts of code.my question is am i doing something wrong here. should i only have one entity type? if so don't you think that it would have too much information in one object for data access, business logic etc... is there a quick way to copy the properties between objects? reflection is an option but gets complicated fast when dealing with object graphs? i know there is no silver bullet to fix this problem but there must be a number of good approaches over copying the properties by hand between the entities?",
    "present_kp": [
      "solid"
    ],
    "absent_kp": [
      "c#",
      "design patterns"
    ]
  },
  {
    "text": "how to convert html entities to readable text?. i want html number entities like &#x119; and want to convert it to real character. i have emails mostly from linkedin that look like this:chcia&#x142;abym zapyta&#x107;, czy rozwa&#x17c;a pan takze udzia&#x142; w nowych projektach w warszawie ? obecnie poszukujemy specjalisty javascript/architekta z bardzo dobr&#x105; znajomo&#x15b;ci&#x105; angular.js do projektu, kt&#xf3;ry dotyczy systemu, s&#x142;u&#x17c;&#x105;cego do monitorowania i zarz&#x105;dzania flot&#x105; pojazd&#xf3;w. zesp&#xf3;&#x142;, do kt&#xf3;rego poszukujemyi'm using clawsmail, switching to html don't convert it to text, i've try to copy and usexclip -o -sel clip | html2text | lessbut it didn't convert the entities. is there a way to have that text using command line tools?the only way i can think of is to use data:text/html,<paste the email> and open it in a browser, but would prefer the command line.",
    "present_kp": [
      "html"
    ],
    "absent_kp": [
      "text processing",
      "character encoding"
    ]
  },
  {
    "text": "trying to improve code-text ratio without a catch-22. my website has several subdomains with it that represent each major section of the website and i have that to allow search engines to understand what each section is about.my problem lies with the calendar and photo gallery section of my site, each having its own subdomain.now when i recently checked my code/text ratio, most pages report lower than the required 15% which is probably why my adsense rpm is almost zero. on each calendar page i have roughly 300 words, but whats killing me that i can't remove are the css sprites. the website is mostly image focused. on the calendar page, i have events which refer to url's on the photo gallery subdomain, so i have links similar to <url> i feel now my only options are the following:either restructure the url's to make them shorter and a lot less friendly and/or meaningful (so i could have something like: <url>)ormake ridiculously short accessible url's in the current domain so that anchor tags like this will work:day oneif i choose #2, then the code/text radio will be fabulous but the server will have to work harder to process redirect pages.if i choose #1, then i risk losing ranking in search engines for favoring a less-friendly url.i have already removed comments and unnecessary code.i'm not exactly asking for code for an answer. i'm just asking based on what i mentioned here, how i can improve the code-to-text ratio on my website so that search engines don't believe i'm writing code only for robots.any ideas?if not, then i think i'll have to revamp a whole set of links which is what i didn't plan on doing.",
    "present_kp": [
      "url",
      "links",
      "code"
    ],
    "absent_kp": [
      "seo",
      "user friendly"
    ]
  },
  {
    "text": "is it possible to use ansi color escape codes in bash here-documents?. i'm printing a message in a bash script, and i want to colourise a portion of it; for example,#!/bin/bashnormal='\\e[0m'yellow='\\e[33m'cat <<- eof ${yellow}warning:${normal} this script repo is currently located in: [ more messages... ]eofbut when i run in the terminal (tmux inside gnome-terminal) the ansi escape characters are just printed in \\ form; for example,\\e[33mwarning\\e[0m this scr....if i move the portion i want to colourise into a printf command outside the here-doc, it works. for example, this works:printf ${yellow}warning:${normal}cat <<- eof this script repo is currently located in: [ more messages... ]eoffrom man bash here documents:no parameter and variable expansion, command substitution, arithmetic expansion, or pathname expansion is performed on word. if any characters in word are quoted, the delimiter is the result of quote removal on word, and the lines in the here-document are not expanded. if word is unquoted, all lines of the here-document are subjected to parameter expansion, command substitution, and arithmetic expansion. in the latter case, the character sequence \\<newline> is ignored, and \\ must be used to quote the characters \\, $, and '.i can't work out how this would affect ansi escape codes. is it possible to use ansi escape codes in a bash here document that is catted out?",
    "present_kp": [
      "bash",
      "escape characters"
    ],
    "absent_kp": [
      "colors"
    ]
  },
  {
    "text": "are the major and minor numbers of a device the same as the device type and subdevice number describe in the version 7 unix manual?. according to a paper in the manual, written by ken thompson and dennis ritchie:when an i/o request is made to a file whose i-node indicates that it is special, the last 12 device address words are immaterial, and the first specifies an internal device name, which is interpreted as a pair of numbers representing, respectively, a device type and subdevice number. the device type indicates which system routine will deal with i/o on that device; the subdevice number selects, for example, a disk drive attached to a particular controller or one of several similar terminal interfaces.the linux documentation on mass storage describes major and minor device numbers:when accessing a device file, the major number selects which device driver is being called to perform the input/output operation. this call is being done with the minor number as a parameter and it is entirely up to the driver how the minor number is being interpreted. the driver documentation usually describes how the driver uses minor numbers.i'm wondering if these two literatures describe the same concept. it's somewhat confusing.",
    "present_kp": [],
    "absent_kp": [
      "devices"
    ]
  },
  {
    "text": "how to filter pair of braces. i have a .toc (table of contents file) from my .tex document.it contains a lot of lines and some of them have the form\\contentsline {part}{some title here\\hfil }{5}\\contentsline {chapter}{ umberline {}person name here}{5}i know how to grep for part and for chapter. but i'd like to filter for those lines and have the output in a csv file like this:{some title here},{person name here},{5}or with no bracessome title here,person name here,51. for sure the number (page number) in the last pair {} is the same for both two lines, so we can filter only the second one.2. note that some empty pair {} could happens or also could contain another pair {}. for example, it could be\\contentsline {part}{title with math $ rac{a}{b}$\\hfil }{15}which should be filtered astitle with math $ rac{a}{b}$edit 1: i was able to obtain the numbers without braces at end of line usinggrep '{part}' file.toc | awk -f '[{}]' '{print $(nf-1)}'edit 2: i was able to filter the chapter lines and remove the garbage withgrep '{chapter}' file.toc | sed 's/\\numberline//' | sed 's/\\contentsline//' | sed 's/{chapter}//' | sed 's/{}//' | sed 's/^ {/{/'and the output without blank spaces was {person name here}{5}edit 3: i was able to filter for part and clean the output with \\contentsline {chapter}{ umberline {}person name here}{5}which returns{title with math $ rac{a}{b}$}{15}",
    "present_kp": [
      "awk",
      "grep"
    ],
    "absent_kp": []
  },
  {
    "text": "are there real lexers that use nfas directly instead of first transforming them to dfas?. i am taking the coursera class on compilers and in the lesson about lexers it is hinted that there is a time-space tradeoff between using non-deterministic finite automaton (nfa) and deterministic finite automaton (dfa) to parse regular expressions. if i understand correctly, the tradeoff is that a nfa is smaller, but is more time consuming to traverse because all possible states have to be regarded at the same time and therefore it is most of the time transformed into a dfa. are there any lexers that use nfas instead of dfas in real-life i.e. some compiler that is used in production and not a just a proof of concept?",
    "present_kp": [
      "compilers"
    ],
    "absent_kp": [
      "finite automata",
      "efficiency",
      "nondeterminism",
      "lexical analysis"
    ]
  },
  {
    "text": "real time vim keylogger. is there anyway to log vim keypresses (or keypresses in general activated by vim) and record it somewhere (stdout, file, etc) in real time? i want somthing similar to vim -w file.log file and this question, but in real-time (within 5 seconds updates) and without saving the file.",
    "present_kp": [],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "which de to use for setting up defaults. i'll use awesomewm as my main de but without installing any actual de(like kde, gnome, xfce etc) i have to setup too many basic stuff like mouse cursor themes, gtk/qt theme engines and themes, clipboard manager, sound manager, screen manager(like lxrandr, arandr etc.), auto-mounter ...now i was thinking if it's possible to just install a de and get it's settings for those, and then move to awesomewm with all those settings are set up.is it possible, and if so, which de do you recommend for that purpose ?",
    "present_kp": [
      "gnome",
      "kde",
      "xfce"
    ],
    "absent_kp": [
      "desktop",
      "desktop environment"
    ]
  },
  {
    "text": "using cd command with a variable. edit : actually as @thrig says both ways do work.mods feel free to delete this question (i can't because it has answers)i have a folder that i want to cd into.for example, suppose i am in /home/yannick and i want to cd into my_folder.now my problem is when the name of the folder is in a variable.this doesn't work :#doesn't workmy_var=myfoldercd $my_varbut this does :#okmy_var=myfoldercd $my_varwhy is that ?is there a better way to do it ?",
    "present_kp": [
      "cd command"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "is a cloud server enough for a video converting service?. i was wondering if my cloud server can do it , or i must have a dedicated server .. it's a service for for video converting , the specifcations of the server now is medium , but as the member number grows , i can upgrade ram /cpu cores and bandwidth ...i'm using a job queue server , that runs 5 converting at a time .. so , the server won't be overloaded ....please advise me !",
    "present_kp": [
      "server",
      "cloud"
    ],
    "absent_kp": [
      "web hosting",
      "webserver",
      "dedicated hosting"
    ]
  },
  {
    "text": "wget images with certain path. im looking to only grab images from a document with a certain path for exampledomain.com/uploads/287167/file_name.jpgonly grab those with the uploads/number/filenameim currently doing it this waywget <url> -q -o - | sed -n -es%^.*\\(<url>][^ \\']*\\.jpg\\).*$%%p | xargs wget -qany other ways of doing this?thanks in advance",
    "present_kp": [
      "sed",
      "wget"
    ],
    "absent_kp": [
      "grep",
      "console"
    ]
  },
  {
    "text": "seo techniques for a complete flex website. i am planning to build a website completely in flex. all the contents will be static. no db will be used. unfortunately i am not building the website for puma or nike and so seo is important. there is an overwhelming and confusing information out there about flex and seo.the following is a piece of information i found on the web flex( flash ) uses xml as a primary source of content, and xhtml is just a custom xml. the idea is to to use the html pages as xml content for the flex( flash ) application. the xml can be read and indexed by the search engines, and its also the ideal content source for your flex( flash ) application.' it goes on to explain how this can be done. is this really that simple. could someone give some credible links. seo is important for me since i am planning to build the site for a resort.",
    "present_kp": [
      "seo",
      "flex"
    ],
    "absent_kp": []
  },
  {
    "text": "local apt repository returns 404 on 'release' files. i've setup a local apt repository using reprepro signed with gpg, but apache returns the following error on a update query:get /repos/apt/debian/dists/stretch/inrelease http/1.1 404 474 - debian apt-http/1.3 (1.4~rc2)get /repos/apt/debian/dists/stretch/release http/1.1 404 472 - debian apt-http/1.3 (1.4~rc2)i don't understand why, these two files exist and are both widely readable:$ ll /var/www/repos/apt/debian/dists/stretch/-rw-r--r-- 1 www-data www-data 2,1k mar 1 15:12 inrelease-rw-r--r-- 1 www-data www-data 1,6k mar 1 15:11 release-rw-r--r-- 1 www-data www-data 488 mar 1 15:12 release.gpgmaybe the error is elsewhere, i include the apache configuration:<directory /var/www/repos/ > options indexes followsymlinks multiviews order allow,deny allow from all</directory><directory /var/www/repos/apt/*/db/> order deny,allow deny from all</directory><directory /var/www/repos/apt/*/conf/> order deny,allow deny from all</directory><directory /var/www/repos/apt/*/incoming/> order allow,deny deny from all</directory>thanks in advance.editsource.list:deb <url> stretch main",
    "present_kp": [
      "debian",
      "repository"
    ],
    "absent_kp": [
      "apache httpd",
      "apache virtualhost"
    ]
  },
  {
    "text": "how can i work on multiple programming languages at same time. it always happen to me that if i leave the stuff for 1-2 months i forget the stuff.5 months back i had symfony project and i did that. at that time i was very much confident that i can do any project in symfony2.then we got one python project in django and i worked full time on that for few months.but now when i had to fix the error in symfony2, i completely forgot the structure and i keep mixing python stuff with php symfony.i want to know that how people work with different languages at same time.should i need to keep studying all languages at same time so that i don't forget?i am confused what should i do. or whenever i do some project then i keep notes of each and every step so that i can follow that later on how i did it?",
    "present_kp": [
      "programming languages",
      "php",
      "python"
    ],
    "absent_kp": [
      "programming practices"
    ]
  },
  {
    "text": "how to avoid duplicate if-else statements within a typescript switch?. export function operator(a: number, b: number, operator: string, type: string): string | number { switch (operator) { case 'add': if (type == answer) { return a + b; } else if (type == assignment) { return a.tostring() + + + b.tostring(); } case 'sub': if (type == answer) { return a - b; } else if (type == assignment) { return a.tostring() + - + b.tostring(); } }}how to avoid code duplication in a typescript switch?attemptif (operator == 'add' && type == answer) { return a + b;} else if (operator == 'add' && type == assignment) { return a.tostring() + + + b.tostring();} else if (operator == 'sub' && type == answer) { return a - b;} else if (operator == 'sub' && type == assignment) { return a.tostring() + - + b.tostring();}",
    "present_kp": [
      "typescript"
    ],
    "absent_kp": []
  },
  {
    "text": "permissions to see content. if the owner/group of a folder and/or is set to 0 0 (zero zero), can i see its content? i'm trying to access a directory with such permissions.",
    "present_kp": [
      "permissions",
      "directory"
    ],
    "absent_kp": []
  },
  {
    "text": "installing usb network interface drivers kali linux. i bought a network interface to finally make my (persistent) live usb kali work on my macbook pro.network interface :dlink wireless n nano usb adapter dwa-131 e1 which uses the realtek rtl8192eu chipsetthe problem is i can't install the drivers.according to this site i can use the following drivers:possibly r8192u_usb, r8712u, or rtl8192cu (in backports) or maybe something else depending on chipseti tried downloading the chipset drivers (rtl8192cu) from realtek (here)after unzipping, going into the /driver/ directory and make and make install i get the following error:make[1]: *** /lib/modules/4.0.0-kali1-amd64/build: no such file or directory. stop.how do i make this work? any help is really appreciated.thanks a lot for your help!cheers.",
    "present_kp": [
      "kali linux",
      "realtek"
    ],
    "absent_kp": [
      "macintosh"
    ]
  },
  {
    "text": "transform $a\\land b \\leftrightarrow b\\lor a$ into conjunctive normal form. how do i transform the following formula into conjunctive normal form?$$a \\land b \\leftrightarrow b \\lor a$$",
    "present_kp": [],
    "absent_kp": [
      "propositional logic"
    ]
  },
  {
    "text": "compiler tokenizer implementation in c#. i'm writing a compiler for a couple of months now, this is the tokenization part of the lexer.i would like a code review to improve my coding style and learn new techniques to pretty up my code and make it easier to maintain.also because i did not actually study compiler design, i do not know if the structure makes sense at all, so feel free to give any kind of criticism.this class is a compiler instance, today i will only discuss the tokenization part of it.using system;using system.collections.generic;using system.diagnostics;using system.io;namespace shirlanguagecompiler{ public class shirenvironment { public shirenvironment(string inputpath) { this.code = file.readalltext(inputpath); console.writeline(starting tokenizer); this.tokenizer = new tokenizer(this); console.writeline(starting parser); this.parser = new parser(this); console.writeline(starting compiling environment); this.factory = new ilfactory(this); console.writeline(starting virtual machine); this.virtualmachine = new vm(this); } public void compile() { tokenizer.tokenize(); console.writeline(string.join(environment.newline, tokens)); parser.parse(); debug.assert(tokenizer.ascode() == code); factory.generate(); virtualmachine.execute(); } public tokenizer tokenizer; public parser parser; public ilfactory factory; public vm virtualmachine; public ilenv intermidiate = new ilenv(); public list<token> tokens = new list<token>(); public list<syntaxnode> nodes = new list<syntaxnode>(); public programnode program = new programnode(); public string code; }}the tokenizer:using system.collections.generic;using system.linq;using system.text.regularexpressions;namespace shirlanguagecompiler{ public class tokenizer { public tokenizer(shirenvironment _env) { this.env = _env; } shirenvironment env; int cursor; int line = 0, col = 0; private readonly dictionary<string, regex> patterns = new dictionary<string, regex>() { {charpattern, new regex([\\$a-za-z])}, {stringpattern, new regex([^\\]) }, {numcharpattern, new regex([[0-9a-za-z])}, {numberpattern, new regex([0-9\\.]) } }; private static readonly dictionary<string, syntaxkind> keywords = new dictionary<string, syntaxkind>() { {true, syntaxkind.literaltruekeyword }, {false, syntaxkind.literalfalsekeyword }, {ref, syntaxkind.refkeyword }, {val, syntaxkind.valkeyword }, {return, syntaxkind.returnkeyword }, {bind, syntaxkind.bindkeyword }, {boolean, syntaxkind.booleankeyword }, {number, syntaxkind.numberkeyword }, {letter, syntaxkind.letterkeyword }, {string, syntaxkind.stringkeyword } }; private static readonly dictionary<syntaxkind, regex> definitions = new dictionary<syntaxkind, regex>() { { syntaxkind.colontoken, new regex(:) }, { syntaxkind.semicolontoken, new regex(;) }, { syntaxkind.assignmenttoken, new regex(=>) }, { syntaxkind.accessortoken, new regex(->) }, { syntaxkind.literalchartoken, new regex(') }, { syntaxkind.literalstringtoken, new regex(\\) }, { syntaxkind.literalnumbertoken, new regex([0-9]) }, { syntaxkind.opencurlybrackettoken, new regex(\\{) }, { syntaxkind.closecurlybrackettoken, new regex(\\}) }, { syntaxkind.openparenthesistoken, new regex(\\() }, { syntaxkind.closeparenthesistoken, new regex(\\)) }, { syntaxkind.opensquarebrackettoken, new regex(\\[) }, { syntaxkind.closesquarebrackettoken, new regex(\\]) }, { syntaxkind.commatoken, new regex(,) }, { syntaxkind.eoltoken, new regex([\\r\\n]) }, { syntaxkind.whitespacetoken, new regex(\\s) }, { syntaxkind.questionmarktoken, new regex(\\?) }, { syntaxkind.plusoperationtoken, new regex(\\+) }, { syntaxkind.minusoperationtoken, new regex(\\-) }, { syntaxkind.multiplyoperationtoken, new regex(\\*) }, { syntaxkind.poweroperationtoken, new regex(\\*\\*) }, { syntaxkind.rootoperationtoken, new regex(\\/\\/) }, { syntaxkind.divideoperationtoken, new regex(\\/) }, { syntaxkind.equaltoken, new regex(==) }, { syntaxkind.inequaltoken, new regex(!=) } }; static readonly syntaxkind[] literaltokens = { syntaxkind.eoltoken , syntaxkind.whitespacetoken , syntaxkind.questionmarktoken , syntaxkind.colontoken , syntaxkind.semicolontoken , syntaxkind.commatoken , syntaxkind.openparenthesistoken , syntaxkind.closeparenthesistoken , syntaxkind.opensquarebrackettoken , syntaxkind.closesquarebrackettoken , syntaxkind.opencurlybrackettoken , syntaxkind.closecurlybrackettoken , syntaxkind.plusoperationtoken , syntaxkind.minusoperationtoken , syntaxkind.multiplyoperationtoken , syntaxkind.divideoperationtoken }; /* * implementing a generic tokenizer here * this might seem not standart, but im not following any standarts here. that would be boring wouldn't it */ private bool matchespattern(regex expression, int size = 1) => env.code.length >= cursor + size && expression.ismatch(env.code.substring(cursor, size)); private bool matchesdefition(syntaxkind kind, int size = 1) => matchespattern(definitions[kind], size); public void tokenize() { for (cursor = 0; cursor < env.code.length;) { int savecursor = cursor; if (matchesdefition(syntaxkind.poweroperationtoken, 2)) { maketoken(syntaxkind.poweroperationtoken, cursor, 2); cursor += 2; continue; } if (matchesdefition(syntaxkind.rootoperationtoken, 2)) { maketoken(syntaxkind.rootoperationtoken, cursor, 2); cursor += 2; continue; } if (matchesdefition(syntaxkind.equaltoken, 2)) { maketoken(syntaxkind.equaltoken, cursor, 2); cursor += 2; continue; } if (matchesdefition(syntaxkind.inequaltoken, 2)) { maketoken(syntaxkind.inequaltoken, cursor, 2); cursor += 2; continue; } if (matchesdefition(syntaxkind.accessortoken, 2)) { maketoken(syntaxkind.accessortoken, cursor, 2); cursor += 2; continue; } if (literaltokens.any(n=>matchesdefition(n))) { maketoken(literaltokens.first(n=>matchesdefition(n))); cursor++; continue; } if (matchesdefition(syntaxkind.assignmenttoken,2)) { maketoken(syntaxkind.assignmenttoken,cursor,2); cursor+=2; continue; } if (matchesdefition(syntaxkind.literalchartoken)) { int oldcursor = cursor; do { cursor++; } while (matchespattern(patterns[numberpattern])); if (matchesdefition(syntaxkind.literalchartoken)) maketoken(syntaxkind.literalchartoken,oldcursor,cursor - oldcursor + 1); else throw new shirexception.tokenizerexception.countnottokenizecharexception($char: {env.code.substring(oldcursor, cursor - oldcursor + 1)} could not be tokenized); cursor++; continue; } if (matchesdefition(syntaxkind.literalstringtoken)) { int oldcursor = cursor; do { cursor++; } while (matchespattern(patterns[stringpattern])); if (matchesdefition(syntaxkind.literalstringtoken)) maketoken(syntaxkind.literalstringtoken, oldcursor, cursor - oldcursor + 1); else throw new shirexception.tokenizerexception.countnottokenizecharexception($char: {env.code.substring(oldcursor, cursor - oldcursor + 1)} could not be tokenized); cursor++; continue; } if (matchesdefition(syntaxkind.literalnumbertoken)) { int oldcursor = cursor; do { cursor++; } while (matchespattern(patterns[numberpattern])); maketoken(syntaxkind.literalnumbertoken, oldcursor, cursor - oldcursor); continue; } if (matchespattern(patterns[charpattern])) { int oldcursor = cursor; do { cursor++; } while (matchespattern(patterns[numcharpattern])); int len = cursor - oldcursor; string tokenstring = env.code.substring(oldcursor, len); if(keywords.containskey(tokenstring)) maketoken(keywords[tokenstring], oldcursor, len); else { char nextchar = env.code[cursor]; if (nextchar == '(') maketoken(syntaxkind.functionnametoken, oldcursor, len); else maketoken(syntaxkind.variablenametoken, oldcursor, len); } continue; } if (savecursor == cursor) throw new shirexception.tokenizerexception.countnottokenizecharexception($char: {env.code[cursor]} could not be tokenized); cursor++; } } public string ascode() { return string.join(,env.tokens.select(n=>n.getvalue())); } private void maketoken(syntaxkind type, int oldcursor, int length) { col += length; if (type == syntaxkind.eoltoken) { line++; col = 0; } env.tokens.add(new token(oldcursor, length, type, env,line,col)); } private void maketoken(syntaxkind type, int length = 1) { col += length; if (type == syntaxkind.eoltoken) { line++; col = 0; } env.tokens.add(new token(cursor,length,type, env,line,col)); } }}a token:using system.text.regularexpressions;namespace shirlanguagecompiler{ public enum syntaxkind { // math operators plusoperationtoken, minusoperationtoken, divideoperationtoken, multiplyoperationtoken, poweroperationtoken, rootoperationtoken, //boolean tokens equaltoken, inequaltoken, variablenametoken, functionnametoken, // variable type rokens numberkeyword, booleankeyword, letterkeyword, stringkeyword, // function related rokens bindkeyword, returnkeyword, refkeyword, valkeyword, // literal values literaltruekeyword, literalfalsekeyword, literalnumbertoken, literalchartoken, literalstringtoken, eoltoken, quotetoken, colontoken, semicolontoken, commatoken, questionmarktoken, whitespacetoken, assignmenttoken, accessortoken, openparenthesistoken, closeparenthesistoken, opencurlybrackettoken, closecurlybrackettoken, opensquarebrackettoken, closesquarebrackettoken, } public class token { shirenvironment env; public int start { get; private set; } public int length { get; private set; } public int line, col; public syntaxkind type { get; private set; } public token(int _start, int _length, syntaxkind _type,shirenvironment _env,int line,int col) { this.start = _start; this.length = _length; this.type = _type; this.env = _env; this.line = line; this.col = col; } public string getlocation() => $<line:{line},col:{col}>; public override string tostring() => $<{type}> start: {start} length: {length} value: {evaluate()}; public string evaluate() => $'{regex.escape(env.code.substring(start, length))}'; public string getvalue() => env.code.substring(start, length); //type == syntaxkind.eoltoken ? environment.newline : }}",
    "present_kp": [
      "c#",
      "compiler"
    ],
    "absent_kp": [
      "lexical analysis"
    ]
  },
  {
    "text": "can adhd and ocd coexist? is it in the same way mania and depression can coexist (in bipolar disorder)?. is it really possible for someone to have both adhd and ocd?i was thinking that adhd is the opposite of ocd: 1 2from 1:alexthepotato:with adhd you may be forgetful, distracted, make careless mistakes, daydream, etc. with ocd, my impression is that you'd be very focused on details, a bit perfectionist, and generally meticulous. so how do they coexist, and what kind of behaviors do you attribute to each?kukienboks:seems to me that ocd is about putting a lot of focus and energy into unimportant things, something which adhd-ers also can tend to do. the main difference is probably that ocd-ers are driven by anxiety rather than suffering from inability to prioritize tasks.from 2:there are also those who believe that ocd and adhd often occur together. this site on adhd states, it is not uncommon for someone to have both adhd and ocd. i find this statement baffling, as the basic symptoms of adhd (listed below), in my opinion, seem to be in direct contrast to those of ocd:inattention: having a short attention span and easily distracted. (most people with ocd would love to be able to not pay attention to their thoughts.)impulsivity: causes a person to do dangerous or unwise things without thinking about the consequences. (those with ocd do the exact opposite. they play it safe and obsess about the consequences.)hyperactivity: inappropriate or excessive activity. (those with ocd often go out of their way to do what they feel is appropriate. also, in dans case, he often had very low energy as he was wiped out from struggling with his ocd.)however i read here that:some research has suggested that ocd and obsessive compulsive spectrum disorders fall upon a compulsive-impulsive continuum. in other words there exists a gradient of disorders ranging from behavioral impulsivity to compulsivity. ocd appears to lie at one end of this spectrum, while adhd exists at the other.that reminds of this picture (taken from here):does this then mean that adhd and ocd together is like mania and depression together? is there a term for the former just like the latter has bipolar disorder?there's someone in 1 who saysadhd makes my mind wander but then my ocd latches onto things i get so focused that nothing else exists.and someone else who saysthe ocd part of is killing me on the inside on how messy my room is. i hate messy rooms.,but there seem to be contesting comments such asactual clinical ocd is so very far from the perfectionism you're describing.andyou are confusing obsessive compulsive disorder with obsessive compulsive personality disorder...i don't know if ocpd and be comorbid with adhd, but i agree that intuitively they don't seem compatible. ocd on the other hand is sometimes misdiagnosed as adhd (and vice versa) as they both involve problems with impulse control.there's another comment which might explain how adhd and ocd are not opposites, but i'm not quite sure i understand (assuming it is right):they aren't opposites. ocd is when you have strong anxious compulsions that you can't resist. adhd is when you are unable to resist even weak impulses. they harm the patient in a devilishly sinergistic manner - let's take someone who already has difficulty resisting impulses, and give her compulsions to do useless things!is it right? what exactly does that mean?",
    "present_kp": [
      "depression",
      "adhd",
      "bipolar disorder"
    ],
    "absent_kp": [
      "abnormal psychology",
      "mood"
    ]
  },
  {
    "text": "updating data validation for a group of cells. i have a spreadsheet where a particular group of cells has defined drop down values to choose from, using data validation rules to get the list from a seperate sheet.how do i update all of the cells using this validation to use a new formula? (when changing the sheet/cells where possible values are stored)to explain further; i have a document where some cells are validating w.r.t. a group of values in another sheet. when copying this 1st sheet to another file, i lose the validation that pulls info from sheet #2. now, in this particular case the cells were all in one column - so i could select multiple and change data validation to refer to a different set of addresses.however, what if the validating cells were scattered throughout a sheet, and i wasn't aware of their locations? hence, what i am asking is given a particular validation, how could i update it in all cells that refer to it (of if this is not possible)",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "opengl programming vs blender software, which is better for custom video creation?. i am learning opengl api bit by bit and also develop my own c++ framework library for effectively using them. recently came across blender software which is used for graphics creation and is in turn written in opengl itself.for my part time hobby of graphics learning, i want to just create small-small movie or video segments; e.g. related to construction engineering, epic stories and so on.there may be very minimal to nil mouse-keyboard interaction for those videos, unlike video games which are highly interactive.i was wondering if learning opengl from scratch is worth for it or should i invest my time in learning blender software? there are quite a few good movie examples are created using blender and are shown in its website.other such opensource cross platform alternatives are also welcome, which can serve my aforementioned purpose.",
    "present_kp": [
      "learning",
      "graphics",
      "opengl"
    ],
    "absent_kp": [
      "decisions"
    ]
  },
  {
    "text": "transform a fan page into a group. i have a fan page and would like to change it into a group without losing my fans and retaining my videos and pictures.is it possible to transform a facebook fan page into a group?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": [
      "facebook pages",
      "facebook groups"
    ]
  },
  {
    "text": "how can i see the exact command line being executed inside some bash instance?. i have a long running bash instance (inside a screen session) that is executing a complex set of commands inside a loop (with each loop doing pipes, redirects, etc). the long command line was written inside the terminal - it's not inside any script. now, i know the bash process id, and i have root access - how can i see the exact command line being executed inside that bash?examplebash$ echo $$1234bash$ while true ; do \\ something | somethingelse 2>/foo/bar | \\ yetanother ; sleep 600 ; doneand in another shell instance, i want to see the command line executed inside pid 1234:bash$ echo $$5678bash$ su -sh# cd /proc/1234sh# # do something here that will display the string \\ 'while true ; do something | somethingelse 2>/foo/bar | \\ yetanother ; sleep 600 ; done'is this possible?edit #1adding counter-examples for some answers i've got. about using the cmdline under /proc/pid: that doesn't work, at least not in my scenario. here's a simple example:$ echo $$8909$ while true ; do echo 1 ; echo 2>/dev/null ; sleep 30 ; donein another shell:$ cat /proc/8909/cmdlinebashusing ps -p pid --noheaders -o cmd is just as useless:$ ps -p 8909 --no-headers -o cmdbashps -eaf is also not helpful:$ ps -eaf | grep 8909ttsiod 8909 8905 0 10:09 pts/0 00:00:00 bashttsiod 30697 8909 0 10:22 pts/0 00:00:00 sleep 30ttsiod 31292 13928 0 10:23 pts/12 00:00:00 grep --color=auto 8909that is, there's no output of the original command line, which is what i'm looking for - i.e the while true ; do echo 1 ; echo 2>/dev/null ; sleep 30 ; done.",
    "present_kp": [
      "bash",
      "process"
    ],
    "absent_kp": [
      "debugging"
    ]
  },
  {
    "text": "print bounding box in the terminal. right now i am finding ways to write better code in javascript and i see many coding styles used by different authors but right now i am thinking to write code which adheres to the object oriented paradigm better suited for this type of language.code// terminal'use strict';class terminal { constructor() { this.cols = process.stdout.columns || 80 this.rows = process.stdout.rows || 60 } width() { return this.cols } height() { return this.rows }}module.exports = terminal// box'use strict';const terminal = require('./terminal')class box { constructor(opts) { let terminal = new terminal() const defaults = { w: terminal.width(), h: terminal.height(), t: '', tr: '', r: '', br: '', b: '', bl: '', l: '', tl: '', fill: '' } this.settings = object.assign(defaults, opts) } tostring() { const res = []; const { t, tr, r, br, b, bl, l, tl } = this.settings const { w , h } = this.settings // filling row wise for (let i = 0; i < h; i++) { for (let j = 0; j < w; j++) { if (i === 0 && j === 0) { res.push(tl) } else if (i === 0 && j === w - 1) { res.push(tr) } else if ((i === h - 1) && (j === w - 1)) { res.push(br) } else if ((i === h - 1) && j === 0) { res.push(bl) } else if (this.isfirstrow(i) || this.islastrow(i)) { res.push(t) } else if (this.isfirstcol(j) || this.islastcol(j)) { res.push(l) } else { const { fill } = this.settings res.push(fill) } } res.push(' ') } return res.join('') } isfirstrow(row) { return row === 0 } islastrow(row) { const { h } = this.settings return row === h - 1 } isfirstcol(col) { return col === 0 } islastcol(col) { const { w } = this.settings return col === w - 1 }}class topright { constructor() { this.symbol = '' } tostring() { return this.symbol }}class bottomright { constructor() { this.symbol = '' } tostring() { return this.symbol }}class bottomleft { constructor() { this.symbol = '' } tostring() { return this.symbol }}class topleft { constructor() { this.symbol = '' } tostring() { return this.symbol }}module.exports = box// o/p/*> const b = require('./box')> console.log(new b({w: 8, h: 8, fillsymbol: '||'}).tostring())*/i would like to know how to improve the above code to make better use of prototypal inheritance and delegation which is widely advocated in javascript world.notei thought to use classes for printing symbols but i see that they make code more bloated. i left them there hear opinion of others.",
    "present_kp": [
      "javascript",
      "object oriented"
    ],
    "absent_kp": [
      "programming challenge",
      "node.js"
    ]
  },
  {
    "text": "iptables: block communication with others in same subnet. i have a couple of devices in my subnet (e.g. 192.168.0.0/24) and would like to make sure that one of these devices (identified by mac or ip) can only talk via the router (where i'd like to set up this rule) to the internet but not to others in this subnet. how can i do this using iptables?",
    "present_kp": [
      "iptables"
    ],
    "absent_kp": [
      "firewall"
    ]
  },
  {
    "text": "what makes disengaged participants tired / exhausted after corporate meetings?. why do disengaged people feel tired, fatigued or unfocused after long, boring corporate style meetings? (there is an agenda, but not everyone participates?) over the years i've observed dozens of meetings where a 6-8 of optional people get invited, but only 1-2 people really talk, while the rest are disengaged and are checking email, etc.is it related to long period of inactivity, lack of engagement or mirror neurons reading each other's emotions?another way to put it : why do periods of cognitive inactivity or lack of engagement result in people feeling tired?",
    "present_kp": [],
    "absent_kp": [
      "cognitive neuroscience",
      "collaboration"
    ]
  },
  {
    "text": "how to use monit environment variables?. according to monit link :no environment variables are used by monit. however, when monit executes a start/stop/restart program or an exec action, it will set several environment variables which can be utilised by the executable to get information about the event, which triggered the action.is it possible to use those variables on custom actions?for example, for notification i don't use mail service, then rather custom script which should receive that env monit variable and provide output.this is a basic example to test env variables.check process dhcp with pidfile /var/run/dhcpd.pid start = /etc/init.d/isc-dhcp-server start stop = /etc/init.d/isc-dhcp-server stop if does not exist program then exec /bin/echo $monit_event > /tmp/monittest depends on lanand when i intentionally make the program fail, like check process dhcp with pidfile /var/run/unexisting.pidi get no output in /tmp/monittest. am i doing something wrong?",
    "present_kp": [
      "environment variables",
      "monit"
    ],
    "absent_kp": [
      "monitoring"
    ]
  },
  {
    "text": "are all problems approached and solved in fundamentally the same way?. this question might be a bit to vague, not make sense, or not developed enough yet to ask, but i thought i might give it a shot. this questions stems from a conversation a friend and i were having about the google interview process. it boiled down to my argument that they are searching for individuals who are fundamentally better problem solvers than others (his argument is that prior job experience proves this, mine is that it doesn't).this got me thinking. say we want to solve a simple problem 2 + 2, we could go about this the simply way and just count 1 2, 3 4 to get to the answer or we could chose a much more complex way to arrive there. i argue that both ways fundamentally solve the problem the same way; that the more complex solution is reducible to the simplest. this linked up in my brain to big o. it has been shown that all problems in np are equivalent and can be translated (reduced?) to each other (i might be completely wrong on this); essentially if you solve one (in p time) you solve them all. it kind of shows to me that all problems within their given class are fundamentally the same. this leads me to question, is the way that problems are solved fundamentally the same? moreover, is there a way to solve all problems (nothing about running time)?again disclaimer, not a full complete thought. i just wanted to get it out there before i forget it and never think of it again. i found it interesting enough to share and just wanted input. please correct if (where.) i am wrong.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "algorithm analysis",
      "asymptotics"
    ]
  },
  {
    "text": "interact with a 868,95 mhz device. i've got a device that measures the heat in my apartment and sends the data to a master every day. it works on 868,95 mhz frequency. i want to be able to read this data. i've got some basic in arduino, can it be a way?",
    "present_kp": [],
    "absent_kp": [
      "radio interception"
    ]
  },
  {
    "text": "multiple-choice vocabulary tester. import java.awt.color;import java.awt.eventqueue;import java.awt.font;import java.awt.systemcolor;import java.awt.event.actionevent;import java.awt.event.actionlistener;import java.io.file;import java.io.inputstream;import java.util.random;import javax.sound.sampled.audioinputstream;import javax.sound.sampled.audiosystem;import javax.sound.sampled.clip;import javax.swing.jbutton;import javax.swing.jcombobox;import javax.swing.jframe;import javax.swing.jlabel;import javax.swing.jmenu;import javax.swing.jmenubar;import javax.swing.jmenuitem;import javax.swing.jpanel;import javax.swing.jtextarea;import javax.swing.jtextfield;import javax.swing.swingconstants;import javax.swing.timer;import javax.swing.border.emptyborder;public class main extends jframe { private jpanel contentpane; private jtextfield txtfielda; private jtextfield txtfieldb; private jtextfield txtfieldc; private jtextfield txtfieldd; private jtextfield txtfieldtimer; private jtextarea textarea; private jbutton btnstart; private jbutton btnfinish; private jbutton btna; private jbutton btnb; private jbutton btnc; private jbutton btnd; private int timerval = 0; private jcombobox<string> combobox; private boolean clicka = false; private boolean clickb = false; private boolean clickc = false; private boolean clickd = false; private file correct = new file(c:\\users\\brian\\workspace\\vocabtester\\src\\correct.wav); private file fail = new file(c:\\users\\brian\\workspace\\vocabtester\\src\\fail.wav); private timer t; private timer timer; private integer maxtime; /** * launch the application. */ public static void main(string[] args) { eventqueue.invokelater(new runnable() { public void run() { try { main frame = new main(); frame.setvisible(true); } catch (exception e) { e.printstacktrace(); } } }); } /** * create the frame. */ public main() { setdefaultcloseoperation(jframe.exit_on_close); setbounds(100, 100, 491, 465); jmenubar menubar_1 = new jmenubar(); setjmenubar(menubar_1); jmenu mnfile = new jmenu(file); menubar_1.add(mnfile); jmenuitem mntmexit = new jmenuitem(exit); mntmexit.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { system.exit(0); } }); mnfile.add(mntmexit); jmenu mnhelp = new jmenu(help); menubar_1.add(mnhelp); jmenu mnsettings = new jmenu(settings); menubar_1.add(mnsettings); contentpane = new jpanel(); contentpane.setborder(new emptyborder(5, 5, 5, 5)); setcontentpane(contentpane); contentpane.setlayout(null); txtfielda = new jtextfield(); txtfielda.seteditable(false); txtfielda.setbounds(96, 202, 232, 39); contentpane.add(txtfielda); txtfielda.setcolumns(10); txtfieldb = new jtextfield(); txtfieldb.seteditable(false); txtfieldb.setbounds(96, 252, 232, 40); contentpane.add(txtfieldb); txtfieldb.setcolumns(10); txtfieldc = new jtextfield(); txtfieldc.seteditable(false); txtfieldc.setbounds(96, 303, 232, 40); contentpane.add(txtfieldc); txtfieldc.setcolumns(10); txtfieldd = new jtextfield(); txtfieldd.seteditable(false); txtfieldd.setbounds(96, 354, 232, 40); contentpane.add(txtfieldd); txtfieldd.setcolumns(10); btna = new jbutton(a); btna.setenabled(false); btna.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { setbtnsdisabled(); if (clicka) { playsound(correct); txtfielda.setbackground(color.green); } else { playsound(fail); txtfielda.setbackground(color.red); showcorrectanswer(); } delaybeforenextround(); } }); btna.setbackground(systemcolor.control); btna.setbounds(10, 201, 76, 40); contentpane.add(btna); btnb = new jbutton(b); btnb.setenabled(false); btnb.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { setbtnsdisabled(); if (clickb) { playsound(correct); txtfieldb.setbackground(color.green); } else { playsound(fail); txtfieldb.setbackground(color.red); showcorrectanswer(); } delaybeforenextround(); } }); btnb.setbackground(systemcolor.control); btnb.setbounds(10, 252, 76, 40); contentpane.add(btnb); btnc = new jbutton(c); btnc.setenabled(false); btnc.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { setbtnsdisabled(); if (clickc) { playsound(correct); txtfieldc.setbackground(color.green); } else { playsound(fail); txtfieldc.setbackground(color.red); showcorrectanswer(); } delaybeforenextround(); } }); btnc.setbackground(systemcolor.control); btnc.setbounds(10, 303, 76, 40); contentpane.add(btnc); btnd = new jbutton(d); btnd.setenabled(false); btnd.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { setbtnsdisabled(); if (clickd) { playsound(correct); txtfieldd.setbackground(color.green); } else { playsound(fail); txtfieldd.setbackground(color.red); showcorrectanswer(); } delaybeforenextround(); } }); btnd.setbackground(systemcolor.control); btnd.setbounds(10, 354, 76, 40); contentpane.add(btnd); txtfieldtimer = new jtextfield(); txtfieldtimer.setbackground(systemcolor.activecaption); txtfieldtimer.sethorizontalalignment(swingconstants.center); txtfieldtimer.settext(string.valueof(timerval)); txtfieldtimer.setfont(new font(tahoma, font.bold, 35)); txtfieldtimer.setbounds(372, 312, 86, 82); contentpane.add(txtfieldtimer); txtfieldtimer.setcolumns(10); textarea = new jtextarea(); textarea.seteditable(false); textarea.setlinewrap(true); textarea.setbounds(10, 48, 448, 116); contentpane.add(textarea); btnstart = new jbutton(start); btnstart.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { setbtnsdisabled(); t = new timer(500 * 1, new actionlistener() { public void actionperformed(actionevent e) { startround(); } }); t.start(); } }); btnstart.setbackground(new color(0, 204, 0)); btnstart.setbounds(372, 202, 86, 39); contentpane.add(btnstart); btnfinish = new jbutton(finish); btnfinish.addactionlistener(new actionlistener() { public void actionperformed(actionevent e) { t.stop(); timer.stop(); btnstart.setenabled(true); combobox.setenabled(true); setbtnsdisabled(); txtfieldtimer.settext(0); textarea.settext(); txtfielda.settext(); txtfieldb.settext(); txtfieldc.settext(); txtfieldd.settext(); txtfielda.setbackground(color.getcolor(240, 240, 240)); txtfieldb.setbackground(color.getcolor(240, 240, 240)); txtfieldc.setbackground(color.getcolor(240, 240, 240)); txtfieldd.setbackground(color.getcolor(240, 240, 240)); } }); btnfinish.setbackground(new color(204, 0, 0)); btnfinish.setbounds(372, 252, 89, 40); contentpane.add(btnfinish); combobox = new jcombobox(); combobox.setbounds(10, 171, 76, 20); contentpane.add(combobox); combobox.additem(java); combobox.additem(puppet); jlabel lblvocabtester = new jlabel(vocab tester!); lblvocabtester.setfont(new font(tahoma, font.bold | font.italic, 28)); lblvocabtester.setbounds(10, 11, 216, 26); contentpane.add(lblvocabtester); } public void startround() { btnstart.setenabled(false); combobox.setenabled(false); if (t.isrunning()) { t.stop(); } txtfielda.setbackground(color.white); txtfieldb.setbackground(color.white); txtfieldc.setbackground(color.white); txtfieldd.setbackground(color.white); setbtnsenabled(); clicka = false; clickb = false; clickc = false; clickd = false; // turn timer for app on maxtime = 20; timer = new timer(1000, new actionlistener() { public void actionperformed(actionevent e) { txtfieldtimer.settext(maxtime.tostring()); if (maxtime > 0) { maxtime -= 1; } else { if (clicka) { txtfielda.setbackground(color.green); } else { txtfielda.setbackground(color.red); } if (clickb) { txtfieldb.setbackground(color.green); } else { txtfieldb.setbackground(color.red); } if (clickc) { txtfieldc.setbackground(color.green); } else { txtfieldc.setbackground(color.red); } if (clickd) { txtfieldd.setbackground(color.green); } else { txtfieldd.setbackground(color.red); } setbtnsdisabled(); playsound(fail); delaybeforenextround(); } } }); timer.start(); // select random ids for the 4 textfields random rand = new random(); int id1 = rand.nextint(10) + 1; int id2 = rand.nextint(10) + 1; int id3 = rand.nextint(10) + 1; int id4 = rand.nextint(10) + 1; // make sure that no ids match each other (otherwise their will be two // of the same words in two differeen fields) while (id4 == id3 || id4 == id2 || id4 == id1) { id4 = rand.nextint(10) + 1; } while (id3 == id4 || id3 == id2 || id3 == id1) { id3 = rand.nextint(10) + 1; } while (id2 == id4 || id2 == id3 || id2 == id1) { id2 = rand.nextint(10) + 1; } while (id1 == id4 || id1 == id3 || id1 == id2) { id1 = rand.nextint(10) + 1; } wordsdao dao = new wordsdao(); string word1 = null; string word2 = null; string word3 = null; string word4 = null; string vocabwords = ; if (combobox.getselecteditem().equals(java)) { vocabwords = javawords; } else if (combobox.getselecteditem().equals(puppet)) { vocabwords = puppetwords; } else { system.out.println(some other words!); } // nneed to -1 after ids, because the ids are one ahead due to the 0 // value word1 = dao.getallwords(vocabwords).get(id1 - 1).getword(); word2 = dao.getallwords(vocabwords).get(id2 - 1).getword(); word3 = dao.getallwords(vocabwords).get(id3 - 1).getword(); word4 = dao.getallwords(vocabwords).get(id4 - 1).getword(); // make an array of the 4 words, and choose one as the correct one int[] arr = { id1, id2, id3, id4 }; random random = new random(); int correctid = random.nextint(arr.length); // get desc of correct word word desc = dao.getwordbyid(arr[correctid], vocabwords); textarea.settext(desc.getdescription()); txtfielda.settext(word1); txtfieldb.settext(word2); txtfieldc.settext(word3); txtfieldd.settext(word4); /// if an id of a word is the correct one // then make appropriate btn (one next to it) correct if clicked if (arr[correctid] == id1) { clicka = true; } if (arr[correctid] == id2) { clickb = true; } if (arr[correctid] == id3) { clickc = true; } if (arr[correctid] == id4) { clickd = true; } } void delaybeforenextround() { t = new timer(1000 * 2, new actionlistener() { public void actionperformed(actionevent e) { startround(); } }); t.start(); } void setbtnsenabled() { btna.setenabled(true); btnb.setenabled(true); btnc.setenabled(true); btnd.setenabled(true); } void setbtnsdisabled() { btna.setenabled(false); btnb.setenabled(false); btnc.setenabled(false); btnd.setenabled(false); } void playsound(file sound) { try { clip clip = audiosystem.getclip(); clip.open(audiosystem.getaudioinputstream(sound)); clip.start(); } catch (exception e) { e.printstacktrace(); } timer.stop(); } void showcorrectanswer() { if(clicka){ txtfielda.setbackground(color.green); } if(clickb){ txtfieldb.setbackground(color.green); } if(clickc){ txtfieldc.setbackground(color.green); } if(clickd){ txtfieldd.setbackground(color.green); } }}",
    "present_kp": [
      "java",
      "swing"
    ],
    "absent_kp": [
      "object oriented",
      "quiz"
    ]
  },
  {
    "text": "kvm can't access iso o raw images outside /var/lib/libvirt/images. i'm using linux mint debian edition (up. 8)when tryng to start a virtual machine from libvirt (either from commandline or using virt-manager to local qemu-kvm)i get this error when i use an image that is not loaded in the default datastore:if i copy the same image (in this example an .iso file) to the /var/lib/libvirt/images folder it works.i've tried to chown and chmod it to every possible owner and mode but it just won't work.selinux is not in place in this distro so i don't know where's the point, in logs i can see just permission denied and i'm quite stuck.impossibile completare l'installazione: 'internal error: process exited while connecting to monitor: qemu-system-x86_64: -drive file=/home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso,if=none,id=drive-ide0-1-0,readonly=on,format=raw: could not open disk image /home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso: could not open '/home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso': permission denied'traceback (most recent call last): file /usr/share/virt-manager/virtmanager/asyncjob.py, line 96, in cb_wrapper callback(asyncjob, *args, **kwargs) file /usr/share/virt-manager/virtmanager/create.py, line 1949, in do_install guest.start_install(false, meter=meter) file /usr/lib/pymodules/python2.7/virtinst/guest.py, line 1249, in start_install noboot) file /usr/lib/pymodules/python2.7/virtinst/guest.py, line 1317, in _create_guest dom = self.conn.createlinux(start_xml or final_xml, 0) file /usr/lib/python2.7/dist-packages/libvirt.py, line 2897, in createlinux if ret is none:raise libvirterror('virdomaincreatelinux() failed', conn=self)libvirterror: internal error: process exited while connecting to monitor: qemu-system-x86_64: -drive file=/home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso,if=none,id=drive-ide0-1-0,readonly=on,format=raw: could not open disk image /home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso: could not open '/home/penzo/scaricati/elementaryos-stable-amd64.20130810.iso': permission deniedany clues?",
    "present_kp": [
      "kvm"
    ],
    "absent_kp": [
      "virt manager",
      "lmde"
    ]
  },
  {
    "text": "using gnu make for a build system without hand-written rules. for my own projects, i regularly use gnu make and often had the same requirements likeit should work in windows cmd as well as in a *nix shellit should work for parallel builds and without recursionit should support cross compilingit should generally be configurable at the command lineit should be reliable wrt which object files need rebuildingthis ultimately led to a lot of copy-pasting from project to project with the newest project having the newest makefile features, so i decided to finally create a project only for the build system.it consists of several included modules, i'll present the most important ones here. the first one is a relatively simple module determining the host environment and setting some variables based on it:ifeq ($(os),windows_nt)undefine posixshellifneq ($(strip $(filter %sh,$(basename $(realpath $(shell))))),)posixshell := 1endifosver := $(subst ],,$(lastword $(shell cmd /c ver)))_zimk__osver := $(subst ., ,$(osver))osver_maj := $(firstword $(_zimk__osver))osver_min := $(word 2, $(_zimk__osver))osver_rev := $(word 3, $(_zimk__osver))elseposixshell := 1endififdef posixshellcmdsep := ;psep := /cpf := cp -frmf := rm -frmfr := rm -frmdp := mkdir -pmv := mvstamp := touchxif := if [ -xxthen := ]; thenxfi := ; ficatin := catcatadd :=catout := >eqt := # make vim syntax highlight happycmdquiet := >/dev/null 2>&1codnoerr := 2>/dev/nullcmdnoin := </dev/nullinstall ?= installinstdir := $(install) -dinstfile = $(instdir) $(2) $(cmdsep) $(install) -m$(3) $(1) $(2)geq = $(shell if test $(1) -ge $(2); then echo 1; fi)touch = touch $(1)sysname := $(shell uname 2>/dev/null)elsecmdsep := &psep := \\cpf := copy /yrmf := del /f /qrmfr := -rd /s /qmdp := -mdmv := movestamp := copy /y nulxif := if existxthen := (xfi := )catin := copy /bcatadd := +catout :=eqt :=cmdquiet := >nul 2>nul & verify >nulcmdnoerr := 2>nul & verify >nulcmdnoin := <nulinstdir := $(mdp)instfile = $(mdp) $(dir $(2)) $(cmdquiet) $(cmdsep) copy $(1) $(2) $(cmdquiet)geq = $(shell if $(1) geq $(2) echo 1)touch = copy /b $(1) +,,sysname := $(shell uname 2>nul & verify >nul)endifafter that, i know whether i'm in cmd or a *nix shell and i have some variables and functions defined to do the right thing in $(shell ) or in recipes.a little more complicated is the module that handles configurations. it can save a given set of configuration variables to config files and use them automatically. there is support for using default_[name] variants if the user didn't specify a value for a variable. this module is also responsible for determining the target platform and set the default output directories based on build configuration and platform:define zimk__uniq$(strip $(eval undefine __zimk__uniq__seen)$(foreach \\ _v,$1,$(if $(filter $(_v),$(__zimk__uniq__seen)),,$(eval \\ __zimk__uniq__seen += $(_v))))$(__zimk__uniq__seen))endefsingleconfvars += prefix exec_prefix bindir sbindir libexecdir datarootdir \\ sysconfdir sharedstatedir localstatedir runstatedir \\ includedir docrootdir libdir localedirsingleconfvars := $(call zimk__uniq,cc cxx cpp ar strip moc $(singleconfvars))listconfvars := $(call zimk__uniq,cflags cxxflags defines includes ldflags \\ $(listconfvars))confvars := $(singleconfvars) $(listconfvars)buildcfgs := $(call zimk__uniq,release debug $(buildcfgs))nobuildtargets := $(sort clean distclean config changeconfig showconfig \\ _build_config _build_changeconfig $(nobuildtargets))makecmdgoals ?= all-include global.cfgundefine zimk__emptyzimk__empty :=zimk__tab := $(zimk__empty) $(zimk__empty)#default configdefault_buildcfg ?= releasebuildcfg ?= $(default_buildcfg)buildcfg := $(strip $(buildcfg))zimk__buildcfg := $(filter $(buildcfg),$(buildcfgs))ifndef zimk__buildcfg$(error unknown buildcfg $(buildcfg))endifzimk__doubleconfvars := $(filter $(singleconfvars),$(listconfvars))ifdef zimk__doubleconfvars$(error variables can't be in both singleconfvars and listconfvars: $(zimk__doubleconfvars))#' make vim syntax highlight happyendifuserconfig:=$(buildcfg).cfgzimk__cfgcache:=.cache_$(buildcfg).cfgdefine zimk__writecacheline$(zimk__tab)$$(vr)echo $$(eqt)c_$(_cv) := $$(strip $($(_cv)))$$(eqt) >>$$(zimk__cfgcache)endefdefine zimk__writecache$$(zimk__cfgcache): $$(vr)echo $$(eqt)# generated file, do not edit!$$(eqt) >$$(zimk__cfgcache)$(foreach _cv,$(confvars),$(if $(strip $($(_cv))),$(zimk__writecacheline),))endefdefine zimk__writecfgline$(zimk__tab)$$(vr)echo $$(eqt)$(_cv) ?= $$(strip $($(_cv)))$$(eqt) >>$$(userconfig)endefdefine zimk__writecfg$(zimk__cfgtarget): $$(userconfig) $$(vcfg) $$(vr)echo $$(eqt)# generated file, do not edit!$$(eqt) >$$(userconfig)$(foreach _cv,$(confvars),$(if $(strip $($(_cv))),$(zimk__writecfgline),))endefdefine zimk__writecfgtagundefine zimk__cfgtag$$(foreach _cv,$$(confvars), \\ $$(if $$($$(_cv)),$$(eval zimk__cfgtag += $$(_cv)=$$$$(strip $$$$($$(_cv)))),))ifdef zimk__cfgtagzimk__cfgtag := $$(zimk__prbold)[$$(zimk__prred)$$(buildcfg)$$(zimk__prnorm)$$(zimk__prbold): $$(zimk__pryellow)$$(zimk__cfgtag)$$(zimk__prnorm)$$(zimk__prbold)]$$(zimk__prnorm)elsezimk__cfgtag := $$(zimk__prbold)[$$(zimk__prred)$$(buildcfg)$$(zimk__prnorm)$$(zimk__prbold)]$$(zimk__prnorm)endifzimk__cfgmsg :=zimk__cfgmsg +=zimk__cfgmsg +=zimk__cfgmsg += $$(zimk__prbold)$$(zimk__pryellow)[cfg]$$(zimk__prnorm) $$(zimk__cfgtag)$$(info $$(zimk__cfgmsg))endefifndef make_restartsifneq ($(filter config,$(makecmdgoals)),)$(eval $(zimk__writecfgtag))endifendif# save userconfigzimk__cfgtarget := _build_config$(eval $(zimk__writecfg))-include $(userconfig)zimk__cfgtarget := _build_changeconfig$(eval $(zimk__writecfg))# save / compare config cacheifneq ($(filter-out $(nobuildtargets),$(makecmdgoals)),)$(eval $(zimk__writecache))-include $(zimk__cfgcache)ifneq ($(foreach _cv,$(confvars),$(_cv):$(strip $(c_$(_cv)))),$(foreach _cv,$(confvars),$(_cv):$(strip $($(_cv))))).phony: $(zimk__cfgcache)endifendifconfig: global.cfg _build_config $(vcfg) $(vr)echo $(eqt)# generated file, do not edit!$(eqt) >$< $(vr)echo $(eqt)buildcfg ?= $(buildcfg)$(eqt) >>$<changeconfig: global.cfg _build_changeconfig $(vcfg) $(vr)echo $(eqt)# generated file, do not edit!$(eqt) >$< $(vr)echo $(eqt)buildcfg ?= $(buildcfg)$(eqt) >>$<global.cfg: ;$(userconfig): ;ifndef make_restartsifneq ($(filter-out $(filter-out changeconfig,$(nobuildtargets)),$(makecmdgoals)),)$(eval $(zimk__writecfgtag))endifendifdefault_cc ?= ccdefault_cxx ?= c++default_cpp ?= cppdefault_ar ?= ardefault_strip ?= stripdefault_moc ?= mocdefault_cflags ?= -std=c11 -wall -wextra -wshadow -pedanticdefault_cxxflags ?= -std=c++11 -wall -wextra -pedanticdefault_ldflags ?= -l$(libdir)platform_win32_cflags ?= -wno-pedantic-ms-formatplatform_win32_cxxflags ?= -wno-pedantic-ms-formatplatform_win32_ldflags ?= -static-libgcc -static-libstdc++build_debug_cflags ?= -g3 -o0build_debug_cxxflags ?= -g3 -o0build_debug_defines ?= -ddebugbuild_release_cflags ?= -g0 -o2 -ffunction-sections -fdata-sectionsbuild_release_cxxflags ?= -g0 -o2 -ffunction-sections -fdata-sectionsbuild_release_ldflags ?= -o2 -wl,--gc-sectionsifdef posixshellprefix ?= /usr/localexec_prefix ?= $(prefix)bindir ?= $(exec_prefix)/binsbindir ?= $(exec_prefix)/sbinlibexecdir ?= $(exec_prefix)/libexecdatarootdir ?= $(prefix)/sharesysconfdir ?= $(prefix)/etcsharedstatedir ?= $(prefix)/comlocalstatedir ?= $(prefix)/varrunstatedir ?= $(localstatedir)/runincludedir ?= $(prefix)/includedocrootdir ?= $(datarootdir)/doclibdir ?= $(exec_prefix)/liblocaledir ?= $(datarootdir)/localeelsedestdir ?= distprefix ?= $(psep).exec_prefix ?= $(prefix)bindir ?= $(exec_prefix)sbindir ?= $(exec_prefix)libexecdir ?= $(exec_prefix)datarootdir ?= $(prefix)sysconfdir ?= $(prefix)sharedstatedir ?= $(prefix)localstatedir ?= $(prefix)runstatedir ?= $(localstatedir)includedir ?= $(prefix)docrootdir ?= $(datarootdir)libdir ?= $(exec_prefix)localedir ?= $(datarootdir)endifdefine zimk__updatesinglecfgvarsifeq ($$(strip $$(origin $(_cv))$$($(_cv))),command line)override undefine $(_cv)endif$(_cv) := $$(if $$($(_cv)),$$($(_cv)),$$(default_$(_cv)))$(_cv) := $$(if $$($(_cv)),$$($(_cv)),$$(platform_$(platform)_$(_cv)))$(_cv) := $$(if $$($(_cv)),$$($(_cv)),$$(build_$(buildcfg)_$(_cv)))endef$(foreach _cv,cc,$(eval $(zimk__updatesinglecfgvars)))zimk__defdefines:= $(shell $(cross_compile)$(cc) -dm -e - $(cmdnoin))ifeq ($(filter _win32,$(zimk__defdefines)),)platform:= posixexe:=elseplatform:= win32exe:=.exeendiftargetarch:= $(strip $(shell $(cross_compile)$(cc) -dumpmachine))ifeq ($(targetarch),)targetarch:= unknownendifobjbasedir ?= objbinbasedir ?= binlibbasedir ?= libtestbasedir ?= testobjdir ?= $(objbasedir)$(psep)$(targetarch)$(psep)$(buildcfg)bindir ?= $(binbasedir)$(psep)$(targetarch)$(psep)$(buildcfg)libdir ?= $(libbasedir)$(psep)$(targetarch)$(psep)$(buildcfg)testdir ?= $(testbasedir)$(psep)$(targetarch)$(psep)$(buildcfg)$(foreach _cv,$(singleconfvars),$(eval $(zimk__updatesinglecfgvars)))define zimk__updatelistcfgvarsifeq ($$(strip $$(origin $(_cv))$$($(_cv))),command line)override undefine $(_cv)endif$(_cv) := $$(if $$($(_cv)),$$($(_cv)),$$(default_$(_cv)))$(_cv) := $$(strip $$(build_$(buildcfg)_$(_cv)) $$($(_cv)))$(_cv) := $$(strip $$(platform_$(platform)_$(_cv)) $$($(_cv)))endef$(foreach _cv,$(listconfvars),$(eval $(zimk__updatelistcfgvars)))ifneq ($(filter showconfig,$(makecmdgoals)),)$(foreach _cv,buildcfg platform targetarch $(confvars),$(info $(_cv) = $($(_cv))))endifclean += $(zimk__cfgcache)showconfig: @:.phony: config changeconfig _build_config _build_changeconfig _cfg_message showconfiganother module provides some helper functions. the most interesting of them is zinc. this is my replacement for include, it operates on relative paths and automatically sets a variable to the path where the included file is found, so i can use relative paths there as well:zimk__dir :=zimk__pdirs :=zimk__mk :=zimk__pmks :=define __f_zinczimk__pdirs := $$(zimk__dir) $$(zimk__pdirs)zimk__pmks := $$(zimk__mk) $$(zimk__pmks)zimk__dir := $$(zimk__dir)$$(strip $$(subst /,$$(psep),$$(dir $(1))))zimk__mk := $$(zimk__dir)$$(notdir $(1))include $$(zimk__mk)zimk__mk := $$(firstword $$(zimk__pmks))zimk__dir := $$(firstword $$(zimk__pdirs))zimk__pmks := $$(wordlist 2, $$(words $$(zimk__pmks)), $$(zimk__pmks))zimk__pdirs := $$(wordlist 2, $$(words $$(zimk__pdirs)), $$(zimk__pdirs))endefdefine zinc$(eval $(__f_zinc))endefdefine __f_binrules_t := $$(strip $(1))$$(eval $$(binrules))endefdefine binrules$(eval $(__f_binrules))endefdefine __f_librules_t := $$(strip $(1))$$(eval $$(librules))endefdefine librules$(eval $(__f_librules))endeftoupper = $(subst a,a,$(subst b,b,$(subst c,c,$(subst d,d,$(subst e,e,$(subst \\ f,f,$(subst g,g,$(subst h,h,$(subst i,i,$(subst j,j,$(subst \\ k,k,$(subst l,l,$(subst m,m,$(subst n,n,$(subst o,o,$(subst \\ p,p,$(subst q,q,$(subst r,r,$(subst s,s,$(subst t,t,$(subst \\ u,u,$(subst v,v,$(subst w,w,$(subst x,x,$(subst y,y,$(subst \\ z,z,$1))))))))))))))))))))))))))tolower = $(subst a,a,$(subst b,b,$(subst c,c,$(subst d,d,$(subst e,e,$(subst \\ f,f,$(subst g,g,$(subst h,h,$(subst i,i,$(subst j,j,$(subst \\ k,k,$(subst l,l,$(subst m,m,$(subst n,n,$(subst o,o,$(subst \\ p,p,$(subst q,q,$(subst r,r,$(subst s,s,$(subst t,t,$(subst \\ u,u,$(subst v,v,$(subst w,w,$(subst x,x,$(subst y,y,$(subst \\ z,z,$1))))))))))))))))))))))))))then the heart of the whole thing are the modules that generate the required rules based on variables set per build target, here's the part that's common between executable and library targets:preproc_moc_suffix := mocpreproc_moc_intype := hpreproc_moc_outtype := cpppreproc_moc_preproc := $(moc)define objrules$(_t)_makefiles ?= $$(zimk__mk)$(_t)_srcdir ?= $$(patsubst %$$(psep),%,$$(zimk__dir))$(_t)_srcdir := $$(strip $$($(_t)_srcdir))$(_t)_objdir ?= $$(objdir)$$(psep)$$($(_t)_srcdir)$(_t)_objdir := $$(patsubst %$$(psep),%,$$($(_t)_objdir))ifeq ($$($(_t)_srcdir),)$(_t)_srcdir := .$$(psep)endif$(_t)_sources := $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix .c,$$($(_t)_modules)))$(_t)_objs := $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix .o,$$($(_t)_modules)))$(_t)_sobjs := $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _s.o,$$($(_t)_modules)))ifneq ($$(strip $$($(_t)_cxxmodules)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix .cpp,$$($(_t)_cxxmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix .o,$$($(_t)_cxxmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _s.o,$$($(_t)_cxxmodules)))endififneq ($$(strip $$($(_t)_asmmodules)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix .s,$$($(_t)_asmmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix .o,$$($(_t)_asmmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _s.o,$$($(_t)_asmmodules)))endififneq ($$(strip $$($(_t)_platformmodules)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix _$$(platform).c,$$($(_t)_platformmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform).o,$$($(_t)_platformmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_s.o,$$($(_t)_platformmodules)))endififneq ($$(strip $$($(_t)_platformcxxmodules)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix _$$(platform).cpp,$$($(_t)_platformcxxmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform).o,$$($(_t)_platformcxxmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_s.o,$$($(_t)_platformcxxmodules)))endififneq ($$(strip $$($(_t)_platformasmmodules)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix _$$(platform).s,$$($(_t)_platformasmmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform).o,$$($(_t)_platformasmmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_s.o,$$($(_t)_platformasmmodules)))endififeq ($$(platform),win32)ifneq ($$(strip $$($(_t)_win32_res)),)$(_t)_sources += $$(addprefix $$($(_t)_srcdir)$$(psep), \\ $$(addsuffix .rc,$$($(_t)_win32_res)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix .o,$$($(_t)_win32_res)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix .o,$$($(_t)_win32_res)))endifendififneq ($$(strip $$($(_t)_preproc)),)$(_t)_ppsrcdir ?= $$($(_t)_srcdir)$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(preproc_$$($(_t)_preproc)_suffix).o, \\ $$($(_t)_preprocmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(preproc_$$($(_t)_preproc)_suffix)_s.o, \\ $$($(_t)_preprocmodules)))$(_t)_objs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_$$(preproc_$$($(_t)_preproc)_suffix).o, \\ $$($(_t)_platformpreprocmodules)))$(_t)_sobjs += $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_$$(preproc_$$($(_t)_preproc)_suffix)_s.o, \\ $$($(_t)_platformpreprocmodules)))$(_t)_ppsources := $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(preproc_$$($(_t)_preproc)_suffix).c, \\ $$($(_t)_preprocmodules))) \\ $$(addprefix $$($(_t)_objdir)$$(psep), \\ $$(addsuffix _$$(platform)_$$(preproc_$$($(_t)_preproc)_suffix).c, \\ $$($(_t)_platformpreprocmodules)))clean += $$($(_t)_ppsources)$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).$$(preproc_$$($(_t)_preproc)_outtype): \\ $$($(_t)_ppsrcdir)$$(psep)%.$$(preproc_$$($(_t)_preproc)_intype) \\ $$($(_t)_makefiles) $$(zimk__cfgcache) \\ | $$(_$(_t)_dirs) $$($(_t)_deps) $$(vgen) $$(vr)$$(preproc_$$($(_t)_preproc)_preproc) \\ $$($(_t)_preprocflags) $$< >$$@endifclean += $$($(_t)_objs:.o=.d) $$($(_t)_objs)outfiles := $$($(_t)_objs)$(dirrules)%.o: %.c$$($(_t)_objdir)$$(psep)%.d: $$($(_t)_srcdir)$$(psep)%.c \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vdep) $$(vr)$$(cross_compile)$$(cc) -mm -mt$$@ $$(@:.d=.o) -mf$$@ \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%.d: $$($(_t)_srcdir)$$(psep)%.cpp \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vdep) $$(vr)$$(cross_compile)$$(cxx) -mm -mt$$@ $$(@:.d=.o) -mf$$@ \\ $$($(_t)_$$(platform)_cxxflags) $$($(_t)_cxxflags) $$(cxxflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%.d: $$($(_t)_srcdir)$$(psep)%.s \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vdep) $$(vr)$$(cross_compile)$$(cc) -mm -mt$$@ $$(@:.d=.o) -mf$$@ \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%.d: $$($(_t)_srcdir)$$(psep)%.rc \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vdep) $$(vr)$$(cross_compile)$$(cpp) -mm -mt$$@ $$(@:.d=.o) -mf$$@ \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<ifneq ($(filter-out $(nobuildtargets),$(makecmdgoals)),)-include $$($(_t)_objs:.o=.d)endififeq ($$(platform),win32)$$($(_t)_objdir)$$(psep)%.o: $$($(_t)_srcdir)$$(psep)%.rc \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vres) $$(vr)$$(cross_compile)windres $$< $$@endif$$($(_t)_objdir)$$(psep)%.o: $$($(_t)_srcdir)$$(psep)%.c \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_static) $$($(_t)_cflags_static) \\ $$(cflags_static) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_s.o: $$($(_t)_srcdir)$$(psep)%.c \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_shared) $$($(_t)_cflags_shared) \\ $$(cflags_shared) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%.o: $$($(_t)_srcdir)$$(psep)%.cpp \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcxx) $$(vr)$$(cross_compile)$$(cxx) -c -o$$@ \\ $$($(_t)_$$(platform)_cxxflags_static) $$($(_t)_cxxflags_static) \\ $$(cxxflags_static) \\ $$($(_t)_$$(platform)_cxxflags) $$($(_t)_cxxflags) $$(cxxflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_s.o: $$($(_t)_srcdir)$$(psep)%.cpp \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcxx) $$(vr)$$(cross_compile)$$(cxx) -c -o$$@ \\ $$($(_t)_$$(platform)_cxxflags_shared) $$($(_t)_cxxflags_shared) \\ $$(cxxflags_shared) \\ $$($(_t)_$$(platform)_cxxflags) $$($(_t)_cxxflags) $$(cxxflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%.o: $$($(_t)_srcdir)$$(psep)%.s \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcas) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_static) $$($(_t)_cflags_static) \\ $$(cflags_static) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_s.o: $$($(_t)_srcdir)$$(psep)%.s \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcas) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_shared) $$($(_t)_cflags_shared) \\ $$(cflags_shared) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<ifneq ($$(strip $$($(_t)_preproc)),)$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).c \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_static) $$($(_t)_cflags_static) \\ $$(cflags_static) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix)_s.o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).c \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_shared) $$($(_t)_cflags_shared) \\ $$(cflags_shared) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).cpp \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcxx) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cxxflags_static) $$($(_t)_cxxflags_static) \\ $$(cxxflags_static) \\ $$($(_t)_$$(platform)_cxxflags) $$($(_t)_cxxflags) $$(cxxflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix)_s.o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).cpp \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcxx) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cxxflags_shared) $$($(_t)_cxxflags_shared) \\ $$(cxxflags_shared) \\ $$($(_t)_$$(platform)_cxxflags) $$($(_t)_cxxflags) $$(cxxflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).s \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_static) $$($(_t)_cflags_static) \\ $$(cflags_static) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<$$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix)_s.o: \\ $$($(_t)_objdir)$$(psep)%_$$(preproc_$$($(_t)_preproc)_suffix).s \\ $$($(_t)_makefiles) $$(zimk__cfgcache) | $$(_$(_t)_dirs) $$(vcc) $$(vr)$$(cross_compile)$$(cc) -c -o$$@ \\ $$($(_t)_$$(platform)_cflags_shared) $$($(_t)_cflags_shared) \\ $$(cflags_shared) \\ $$($(_t)_$$(platform)_cflags) $$($(_t)_cflags) $$(cflags) \\ $$($(_t)_$$(platform)_defines) $$($(_t)_defines) $$(defines) \\ $$($(_t)_$$(platform)_includes) $$($(_t)_includes) \\ $$(includes) $$<endifendef.secondary:i know this is a lot of code, but it makes the project-specific makefiles (in my opinion) very concise and easy to understand. a single-file snake game for example uses this makefile:include zimk/zimk.mkminsnake_modules:= minsnakeminsnake_win32_staticlibs:= pdcursesminsnake_posix_libs:= ncurses$(call binrules,minsnake)for a more complex setup, i have for example this:[...]include zimk/zimk.mkincludes += -i.$(psep)include$(call zinc, src/lib/core/core.mk)[...]and in core.mk:pocascore_modules:= cmdline string stringbuilder list hashtable plugin mtwaitqueue event eventloop textcolorpocascore_platformmodules := textcolor dso plugin eventloop file processhostpocascore_defines:= -dbuilding_pocas_corepocascore_posix_ldflags:= -pthreadpocascore_win32_staticlibs:= pthreadpocascore_posix_libs:= dlpocascore_v_maj:= 0pocascore_v_min:= 0pocascore_v_rev:= 1$(call librules, pocascore)this creates a libpocascore.so.0 or a pocascore-0.dll, depending on the target system, and optionally also static libs.now, do you think this is a decent approach? am i maybe missing something important that's not doable with this design?here's a link to the whole project for reference.update: i just found one shortcoming (or: bug, depending on your point of view) myself by accident. right now, the $(eval )-generated rules only work correctly if every target has its own source directory exclusively. although this is a good rule for project layout in general, it might be broken for really small targets, like test cases. i'm not sure yet whether i'll try to update the code to support this. it would be a major change because it would mean not to use pattern rules at all.",
    "present_kp": [
      "make"
    ],
    "absent_kp": []
  },
  {
    "text": "allow input only on one specific port?. i want to be able to be able to connect to 1.1.1.1 through port 110 to send email. i currently have the following setiptables -a output -d 1.1.1.1 -j acceptbut it replies with the error 01:37:39 [mta-test] a test email has not been successfully sent to the email address <email> unable to connect to mail server: connection timed out(110)what do i need to add so 1.1.1.1 can only connect back through port 110? i have tried the following without any luck.iptables -a input tcp --sport 110 -s 1.1.1.1 -j acceptiptables -a input -p tcp -m tcp --dport 110 -s 1.1.1.1 -j accept",
    "present_kp": [
      "iptables"
    ],
    "absent_kp": []
  },
  {
    "text": "what is known about the effectiveness of reliable computing?. how well has the following problem been investigated in tcs? (i apologize if the problem statement sounds vague!) given a model of computation mc (turing machine, cellular automata, kolmogorov-uspenskii machine ... etc.) and a model of noise that could affect the computation of mc, is there a way of recovering from the errors caused by this noise in an effective way? for instance, say some type of noise affects a turing machine m, could one devise a turing machine m' that simulates m without a major cost and is reliable (which means that m' is tolerant to this noise)?it seems that some models of computations are better than others in doing this: cellular automata for instance.any results if the noise is replaced by an adversary model?sorry for the tag! i don't have enough reputation to put a suitable tag (reliable-computing, fault-tolerant-computing ... etc.)",
    "present_kp": [],
    "absent_kp": [
      "machine models"
    ]
  },
  {
    "text": "gnu screen prevent width x chars too small message on exit (c-a c-\\). when the width of the currently focused pane (in the tmux sense) is too narrow to display the confirmation message really quit and kill all your windows [y/n], screen displays width x chars too small and doesn't accept y or n. is there a way to get it to either display a truncated y/n message or disable the confirmation altogether?",
    "present_kp": [
      "gnu screen"
    ],
    "absent_kp": []
  },
  {
    "text": "twitter background image. i want to upload a custom background for my twitter profile, but when ever i select a new image from my computer and click save it just says waiting for twitter shows a blank pagehttps://twitter.com/settings/design/updateplease let me know if there is any way i can change the background image of my twitter",
    "present_kp": [
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "change what pulseaudio calls a device?. i use a headset for both my headphones and my microphone. as a result pavucontrol is labeling both my output and my input the same thing, built-in audio analogue stereo. it makes configuring my loopback-modules somewhat frustrating for obvious reasons. how would i go about just renaming them to headphones and mic?",
    "present_kp": [
      "audio",
      "pulseaudio"
    ],
    "absent_kp": [
      "alsa"
    ]
  },
  {
    "text": "content grouping not showing in google analytics. i am working on a google analytics project and am trying to implement content grouping. i enter the 'admin' panel, and look under 'view' between 'goals' and 'filters' but 'content grouping' is not there. i should have access to this with even the lowest permissions granted from my client, correct? is there somewhere else i can find the content grouping settings?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the maximum memory a 64bit process can consume?. i know that there is a hardware capacity of 2^48 bits, and i know that there isn't a lot of native limiting of app memory constraints in general by the kernel, but is there an upper bound of the memory that an app can consume in general besides 2^48 because that's the number of channels available on the dimm sockets?for reference, redmond limits their products to ~2tb on most server products.",
    "present_kp": [
      "64bit"
    ],
    "absent_kp": []
  },
  {
    "text": "does there exist a problem that is hard to do in parallel?. i am looking for a workload which is hard to paralellise/distribute between multiple machines. for example, integer factorization does not go 10 times faster if you have 10 machines to split the load, but is there a better example?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "linear programming",
      "factoring",
      "primes"
    ]
  },
  {
    "text": "(why) is it important that a unit test not test dependencies?. i understand the value of automated testing and use it wherever the problem is well-specified enough that i can come up with good test cases. i've noticed, though, that some people here and on stackoverflow emphasize testing only a unit, not its dependencies. here i fail to see the benefit. mocking/stubbing to avoid testing dependencies adds complexity to the tests. it adds artificial flexibility/decoupling requirements to your production code to support mocking. (i disagree with anyone who says this promotes good design. writing extra code, introducing things like dependency injection frameworks, or otherwise adding complexity to your codebase to make things more flexible/pluggable/extensible/decoupled without a real use case is overengineering, not good design.)secondly, testing dependencies means that critical low-level code that's used everywhere gets tested with inputs other than those that whoever wrote its tests explicitly thought of. i've found plenty of bugs in low-level functionality by running unit tests on high level functionality without mocking out the low-level functionality it depended on. ideally these would have been found by the unit tests for the low-level functionality, but missed cases always happen.what's the other side to this? is it really important that a unit test doesn't also test its dependencies? if so, why?edit: i can understand the value of mocking external dependencies like databases, networks, web services, etc. (thanks to anna lear for motivating me to clarify this.) i was referring to internal dependencies, i.e. other classes, static functions, etc. that don't have any direct external dependencies.",
    "present_kp": [
      "testing",
      "dependency injection",
      "mocking"
    ],
    "absent_kp": [
      "unit testing"
    ]
  },
  {
    "text": "cannot start kde in fedora 22. i cannot load kde, xfce or any desktop environment other than gnome in my fedora 22 system. every time i try startkde i get $display is not set or cannot connect to x server. tried all the solutions here, here and here and it still doesn't work. how to fix this?",
    "present_kp": [
      "fedora",
      "kde"
    ],
    "absent_kp": [
      "linux",
      "lxde"
    ]
  },
  {
    "text": "who converts binary/machine code to electrical signals and how?. i went through lots of blogs and posts but could not exactly figure out how the machine code is converted to electrical signals?any software program is compiled to machine code which is nothing but lots of 1s and 0s. 1 means high voltage e.g 5v and 0 means comparatively low voltage e.g. 0v or ground, what's the component which understands that okay i got 1(one) so i need to step up up the voltage to 5v and for 0(zero) i need to step down to lower voltage level and how it does that?",
    "present_kp": [],
    "absent_kp": [
      "computer architecture",
      "memory hardware"
    ]
  },
  {
    "text": "simple weighted directed graph in python. i have this simplistic python class for representing directed weighted graphs (digraphs for short):digraph.py#! /usr/bin/env python__author__ = 'rodion rodde efremov'class digraph: this class implements a directed, weighted graph with nodes represented by integers. def __init__(self): initializes this digraph. self.nodes = set() self.children = dict() self.parents = dict() self.edges = 0 def add_node(self, node): if 'node' is not already present in this digraph, adds it and prepares its adjacency lists for children and parents. if node in self.nodes: return self.nodes.add(node) self.children[node] = dict() self.parents[node] = dict() def add_arc(self, tail, head, weight): creates a directed arc pointing from 'tail' to 'head' and assigns 'weight' as its weight. if tail not in self.nodes: self.add_node(tail) if head not in self.nodes: self.add_node(head) self.children[tail][head] = weight self.parents[head][tail] = weight self.edges += 1 def has_arc(self, tail, head): if tail not in self.nodes: return false if head not in self.nodes: return false return head in self.children[tail].keys() def get_arc_weight(self, tail, head): if tail not in self.nodes: raise exception(the tail node is not present in this digraph.) if head not in self.nodes: raise exception(the head node is not present in this digraph.) if head not in self.children[tail].keys(): raise exception(the edge (, tail, , , head, ) is not in this digraph.) return self.children[tail][head] def remove_arc(self, tail, head): removes the directed arc from 'tail' to 'head'. if tail not in self.nodes: return if head not in self.nodes: return del self.children[tail][head] del self.parents[head][tail] self.edges -= 1 def remove_node(self, node): removes the node from this digraph. also, removes all arcs incident on the input node. if node not in self.nodes: return self.edges -= len(self.children[node]) + len(self.parents[node]) # unlink children: for child in self.children[node]: del self.parents[child][node] # unlink parents: for parent in self.parents[node]: del self.children[parent][node] del self.children[node] del self.parents [node] self.nodes.remove(node) def __len__(self): return len(self.nodes) def number_of_arcs(self): return self.edges def get_parents_of(self, node): returns all parents of 'node'. if node not in self.nodes: return [] return self.parents[node].keys() def get_children_of(self, node): returns all children of 'node'. if node not in self.nodes: return [] return self.children[node].keys() def clear(self): del self.nodes[:] self.children.clear() self.parents.clear() self.edges = 0def test(): digraph = digraph() assert len(digraph) == 0 for i in range(10): assert len(digraph) == i digraph.add_node(i) assert len(digraph) == i + 1 digraph.remove_node(8) assert len(digraph) == 9 digraph.remove_node(9) assert len(digraph) == 8 assert digraph.number_of_arcs() == 0 digraph.add_arc(8, 7, 20.0) assert digraph.has_arc(8, 7) assert 20.0 == digraph.get_arc_weight(8, 7) assert digraph.number_of_arcs() == 1 digraph.add_arc(9, 8, 10.0) assert digraph.number_of_arcs() == 2 assert digraph.get_arc_weight(9, 8) == 10.0 assert digraph.has_arc(9, 8) assert not digraph.has_arc(8, 9) digraph.remove_node(8) assert not digraph.has_arc(9, 8) assert digraph.number_of_arcs() == 0 digraph.remove_node(5) assert len(digraph) == 8 digraph.add_arc(0, 3, 1.0) digraph.add_arc(1, 3, 2.0) digraph.add_arc(3, 6, 3.0) digraph.add_arc(3, 7, 4.0) assert digraph.number_of_arcs() == 4 assert 0 in digraph.get_parents_of(3) assert 1 in digraph.get_parents_of(3) assert 6 in digraph.get_children_of(3) assert 7 in digraph.get_children_of(3) try: digraph.get_arc_weight(3, 100) assert false except exception: pass try: digraph.get_arc_weight(100, 3) assert false except exception: pass try: digraph.get_arc_weight(2, 3) assert false except exception: passif __name__ == __main__: test()please, tell me anything that comes to mind.",
    "present_kp": [
      "python",
      "graph"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "are there third party facebook clients?. i want to access facebook without logging into facebook.com. are there third-party facebook clients (web-based) in which we can view posts, comments, etc and like and comment in them?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": []
  },
  {
    "text": "how does google analytics know the sex, age, interests of visitors?. the demographics pane displays stats based on sex, age and interests. how did it learn this private information?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "udev rule for bluetooth device(logitec). i want to write udev rule for a logitec bluetooth. my keyboard and mouse connect to pc as one bluetooth device.when i monitor udev, i see there are separate events for keyboard and mouse. i want to allow mouse usage but not keyboard. if i ignore the device, i can't use the mouse. how can i achieve this? can i ignore the keyboard event? mouse eventudev [325.554801] add /devices/pci0000:00/0000:00:1d.0/usb4/4-1/4-1.2/4-1.2:1.0/input/input15 (input)action=adddevpath=/devices/pci0000:00/0000:00:1d.0/usb4/4-1/4-1.2/4-1.2:1.0/input/input15ev=17id_bus=usbid_input=1id_input_mouse=1id_model=usb_receiverid_model_enc=usb receiverid_model_id=c52fid_path=pci-0000:00:1d.0-usb-0:1.2:1.0id_path_tag=pci-0000_00_1d_0-usb-0_1_2_1_0id_revision=3000id_serial=logitech_usb_receiverid_type=hidid_usb_driver=usbhidid_usb_interfaces=:030102:030000:id_usb_interface_num=00id_vendor=logitechid_vendor_enc=logitechid_vendor_id=046dkey=ffff0000 0 0 0 0modalias=input:b0003v046dpc52fe0111-e0,1,2,4,k110,111,112,113,114,115,116,117,118,119,11a,11b,11c,11d,11e,11f,r0,1,6,8,am4,lsfwmsc=10name=logitech usb receiverphys=usb-0000:00:1d.0-1.2/input0product=3/46d/c52f/111prop=0rel=143seqnum=1513subsystem=inputudev_log=3uniq=usec_initialized=325550123keyboard eventudev [325.555963] add /devices/pci0000:00/0000:00:1d.0/usb4/4-1/4-1.2/4-1.2:1.1/input/input16 (input)abs=100000000action=adddevpath=/devices/pci0000:00/0000:00:1d.0/usb4/4-1/4-1.2/4-1.2:1.1/input/input16ev=1fid_bus=usbid_input=1id_input_key=1id_model=usb_receiverid_model_enc=usb receiverid_model_id=c52fid_path=pci-0000:00:1d.0-usb-0:1.2:1.1id_path_tag=pci-0000_00_1d_0-usb-0_1_2_1_1id_revision=3000id_serial=logitech_usb_receiverid_type=hidid_usb_driver=usbhidid_usb_interfaces=:030102:030000:id_usb_interface_num=01id_vendor=logitechid_vendor_enc=logitechid_vendor_id=046dkey=4837fff072ff32d bf54444600000000 1 20f908b17c000 677bfad9415fed 9ed680000<phone>modalias=input:b0003v046dpc52fe0111-e0,1,2,3,4,k71,72,73,74,77,80,82,83,85,86,87,88,89,8a,8b,8c,8e,90,96,98,9b,9c,9e,9f,a1,a3,a4,a5,a6,a7,a8,a9,ab,ac,ad,ae,b0,b1,b2,b5,b6,ce,cf,d0,d1,d2,d4,d8,d9,db,df,e4,e7,e8,e9,ea,eb,f1,100,161,162,166,16a,16e,172,174,176,178,179,17a,17b,17c,17d,17f,180,182,183,185,188,189,18c,18d,18e,18f,190,191,192,193,195,198,199,19a,1a0,1a1,1a2,1a3,1a4,1a5,1a6,1a7,1a8,1a9,1aa,1ab,1ac,1ad,1ae,1b0,1b1,1b7,1ba,r6,a20,m4,lsfwmsc=10name=logitech usb receiverphys=usb-0000:00:1d.0-1.2/input1product=3/46d/c52f/111prop=0rel=40seqnum=1519subsystem=inputudev_log=3uniq=usec_initialized=325514060",
    "present_kp": [
      "keyboard",
      "bluetooth",
      "ude"
    ],
    "absent_kp": [
      "linux",
      "monitoring"
    ]
  },
  {
    "text": "can a natural graph problem be universally hard?. is there a natural $\\mathsf{np}$-complete graph problem, which remains $\\mathsf{np}$-complete even when it is restricted to any polynomial-time recognizable graph class? to avoid degenerated cases, let us consider only dense graph classes, in which the number of non-isomorphic $\\leq n$-vertex graphs grows exponentially with $n$. notes: (1) both a yes or a no answer would be quite interesting. if the answer is yes, then we would have a natural $\\mathsf{np}$-complete graph property that could be called universally hard, because it preserves hardness even when restricted to any reasonable graph class. if the answer is no, it would mean that every natural $\\mathsf{np}$-complete graph property can be made easy on some nontrivial graph class. (2) it is important to consider only polynomial-time recognizable graph classes, to exclude that the hardness of the property is simply shifted to the class.for example, 3-colorability becomes trivial when restricted to 3-colorable graphs.",
    "present_kp": [
      "graph classes"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "graph theory",
      "graph algorithms",
      "np complete"
    ]
  },
  {
    "text": "c++ programming on a real-time linux os. is there any gotcha's programming realtime c++ applications (user space and linux drivers) on rt linux kernel compare to a std linux kernel?the linux rt patch applies changes to kernel scheduler, semaphores, muteces, etc, and i'm wondering if these changes are transparent to the developer? or would one need to take special care in writing such application?",
    "present_kp": [
      "linux",
      "linux kernel",
      "c++"
    ],
    "absent_kp": [
      "real time"
    ]
  },
  {
    "text": "full-featured wlan usb adaptor. i am searching for a wlan usb adaptor that can be used as an access point as well as a mere client and in an adhoc setup. it should support ieee 802.11n and transmit rather fast (300mbps).as i compile custom kernels for my machines, the driver should come as part of the current kernel (3.7.1 at the time of writing) and does not need to be built externally. if possible, i would even like to avoid installing external firmware. driver and hardware should support power saving mode.currently, i am using the avm fritz wlan stick n which has nearly all the features but under load crashes every few minutes and has to be restarted. so stability is also a requirement.does such a wondrous device exist?",
    "present_kp": [
      "usb",
      "firmware"
    ],
    "absent_kp": [
      "networking",
      "drivers",
      "wifi"
    ]
  },
  {
    "text": "lights off puzzle. lights off is a puzzle game consisting of an \\$n imes n\\$ grid of lights. at the beginning of the game, some of the lights are switched on. when a light is activated, it and its four neighbors in the cardinal directions are toggled. the objective is to turn off all the lights.input:000110010output should be 000000000by selecting cells \\$(0,0)\\$, \\$(1,0)\\$, \\$(1,1)\\$, \\$(2,1)\\$, and \\$(2,2)\\$i'd like to know if my code can be made any more efficient.import javax.swing.*;import java.awt.*;import javax.swing.jframe;import java.util.scanner;import java.awt.event.actionevent;import java.awt.event.actionlistener;public class lightoff extends jframe implements actionlistener{ public static final int w = 400; public static final int h = 200; jbutton[][] lights = new jbutton[3][3]; int cols = 3, rows = 3; public lightoff() { super(light off); setsize(w,h); setlayout(new gridlayout(3,3)); setdefaultcloseoperation(jframe.exit_on_close); scanner kb = new scanner(system.in); string[][] input = {{0,0,0},{1,1,0},{0,1,0}}; for(int i=0;i<3;i++) { for(int j=0;j<3;j++) { lights[i][j] = new jbutton(); // initializing all jbutton lights[i][j].addactionlistener(this); // registering listener lights[i][j].settext(input[i][j]); // setting text of each // button as per input string add(lights[i][j]); // adding jbutton to the jframe } } } public static void main(string[] args) { lightoff obj1 = new lightoff(); obj1.setvisible(true); } public void actionperformed(actionevent e) { jbutton action = (jbutton)e.getsource(); if(action==lights[0][0]) { if(0.equals(lights[0][0].gettext())) lights[0][0].settext(1); else lights[0][0].settext(0); // edgetoggle(0,0,action); forward(0,0); down(0,0); } else if(action==lights[0][1]) { if(lights[0][2].gettext()==0) lights[0][2].settext(1); else lights[0][2].settext(0); backward(0,1); forward(0,1); down(0,1); } else if(action==lights[0][2]) { if(lights[0][2].gettext()==0) lights[0][2].settext(1); else lights[0][2].settext(0); // edgetoggle(0,2,action); backward(0,2); down(0,2); } else if(action==lights[1][0]) { if(lights[1][0].gettext()==0) lights[1][0].settext(1); else lights[1][0].settext(0); up(1,0); down(1,0); forward(1,0); } else if(action==lights[1][1]) { if(lights[1][1].gettext()==0) lights[1][1].settext(1); else lights[1][1].settext(0); up(1,1); down(1,1); backward(1,1); forward(1,1); } else if(action==lights[1][2]) { if(lights[1][2].gettext()==0) lights[1][2].settext(1); else lights[1][2].settext(0); up(1,2); down(1,2); backward(1,2); } else if(action==lights[2][0]) { if(lights[2][0].gettext()==0) lights[2][0].settext(1); else lights[2][0].settext(0); // edgetoggle(2,0,action); up(2,0); forward(2,0); } else if(action==lights[2][1]) { if(lights[2][1].gettext()==0) lights[2][1].settext(1); else lights[2][1].settext(0); up(2,1); backward(2,1); forward(2,1); } else if(action==lights[2][2]) { if(lights[2][2].gettext()==0) lights[2][2].settext(1); else lights[2][2].settext(0); // edgetoggle(2,2,action); up(2,2); backward(2,2); } } public void forward(int a, int b) // calling to check status // of next jbutton in same row { if(0.equals(lights[a][b+1].gettext())) lights[a][b+1].settext(1); else lights[a][b+1].settext(0); } public void backward(int a, int b) // calling to check status of previous // jbutton in same row. { if(0.equals(lights[a][b-1].gettext())) lights[a][b-1].settext(1); else lights[a][b-1].settext(0); } public void up(int a, int b) // calling to check status of jbutton // above the current one. { if(0.equals(lights[a-1][b].gettext())) lights[a-1][b].settext(1); else lights[a-1][b].settext(0); } public void down(int a, int b) // calling to check status of jbutton // below the currrent jbutton. { if(0.equals(lights[a+1][b].gettext())) lights[a+1][b].settext(1); else lights[a+1][b].settext(0); } }",
    "present_kp": [
      "java",
      "swing"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "how do aliases or redirects work?. is it possible that i set-up a redirect of my store which is located at <url> to store.xyz.com .do i have to buy a new domain name or is there any other way.",
    "present_kp": [
      "redirects"
    ],
    "absent_kp": [
      "domains",
      "subdomain",
      "cpanel"
    ]
  },
  {
    "text": "print pdf scaled-down and aligned. i want to print a pdf file with all pages scaled down equally (to, say, 70 %). the scaled-down pages should then be left-aligned on the printing paper.this doesn't seem to be possible with lpr alone. with pdfjam i can scale the pages (--scale 0.7) but i don't know/see any option to align the scaled pages. a negative offset (like --offset '-3cm 0cm') doesn't work.",
    "present_kp": [
      "printing",
      "pdf"
    ],
    "absent_kp": [
      "cups"
    ]
  },
  {
    "text": "why do microsoft websites default to polish on my work network?. i originally asked this on super user, but it was ruled off-topic there and referred to here.i'm in belgium. when i open msn, no matter what browser or what machine i use, it's opened using pl-pl localization. it doesn't matter whether i open it on my older laptop that's always been at the office, on my desktop that's been imported from the previous dev who worked in kiev or on my personal android phone, whether i use chrome, firefox or internet explorer. even my coworkers have this problem.however, as far as i can tell, it's only microsoft-related websites that do this. netflix says i'm in belgium. google says i'm in belgium. whoismyisp says i'm in london. whatismyip says i'm in brussels. whatismyipaddress says i'm in london. being in london is understandable since that's where our isp is located (colt), but i don't understand why every microsoft website gives me the polish site by default, as well as all my coworkers. we think it might have something to do with a network setting, but we're not sure.what might cause this?",
    "present_kp": [
      "localization",
      "microsoft"
    ],
    "absent_kp": [
      "msdn"
    ]
  },
  {
    "text": "why is (ogg) vorbis not automatically supported by windows?. vorbis was never threatened by mpeg la, so it is undoubtedly completely patent free.(mpeg la never misses a chance to spread patent fud)windows supports mp3, so it isnt because they want to push their crappy wma.the gpl allows distribution alongside commercial products, andeven if they fear to ship gpl software, they can still load it automatically, like they do with xvidso why cant a windows customer not simply drop a ogg vorbis file into his/her music library and listen to it via wmp?ps: to counter misconceptions: they already download the gpld xvid codec on demand, so they already have 99% of what it takes to do the same with vorbis. it would take me about 5 minutes to do this, if i were familiar with the wmp code base and directshow filter system.pss: i was told to ask this here rather than on stackoverflow, so i do.",
    "present_kp": [
      "windows"
    ],
    "absent_kp": [
      "legal",
      "patents"
    ]
  },
  {
    "text": "automomatic typographical error correction. does anyone know where i might be able to find a list of the most common typing errors and their corrections? this is separate from more complicated considerations concerning general spelling checking (which can have very many candidates in relation to the correct spelling of the word in question); rather i am looking for a similar list as used by microsoft word (for instance correcting tehwith theorbecaisewith becausenot only can the manner in which these sort of errors are fixed be hard-coded, their frequent occurrence in text provides significant dividends in textual mining (provided that such a list of errors and corrections can be obtained, of course).",
    "present_kp": [],
    "absent_kp": [
      "text mining",
      "data cleaning"
    ]
  },
  {
    "text": "angular architecture. i have been developing a few prototype apps in angular, with various backends, including firebase and php/mysql. i'm pretty sure i'm not using a good organization pattern for development because of a couple of kluges i have to use in the code to avoid the max digest iterations reached exception.i have a template with an ng-repeat, like this:<ion-item data-ng-repeat=outcome in outcomes.getall()>...</ion-item>it is supported by a service like this:'use strict';angular.module('app.outcomes', ['app.utility']).service('outcomes', function ($http, utility) { var svc = this; svc.outcomes = false;/** * initializes the outcomes array if it has not yet been initialized. * * @returns {array} */svc.initialize = function () { if (svc.outcomes === false) { // if this is not set to something immediately, repeated calls to // digest occur during http call and digest overloads. svc.outcomes = true; $http.get('/api/outcome/all'). success(function (data, status, headers, config) { svc.outcomes = data.result; // set data to real array value }). error(function (data, status, headers, config) { }); }};/** * called in ng-repeat so that it makes sure the data is initialized. * an ng-init call does not work. * @returns {array} */svc.getall = function () { svc.initialize(); // called constantly from ng-repeat, while array actually set return svc.outcomes;};});the controller is a one-liner that sets the $scope.outcomes variable to the service.this strategy works, because the digest loop tests the condition. what seems klugy to me is that i need to set the outcomes array to some unused value while i wait for the ajax call to return. otherwise the digest loop is called and it tries to keep doing it for however long the call takes to return from the server.another related problem i have is that if i set the svc.outcomes array later, i will sometimes get the same error about too many digest iterations. the questions i have are: 1) is there a better way to organize the code? i need to be able to access that server data across multiple scopes.2) is there a way to ensure that the data array gets initialized without having to call the getall() method in the ng-repeat loop? an ng-init call doesn't populate the data, so i can't just reference outcomes.outcomes in the template.what is strange to me is that i think the max iterations thing just started happening with using a minor update (1.3.3 to 1.3.6) to angular. that could be my imagination though. any architectural suggestions would be appreciated.",
    "present_kp": [],
    "absent_kp": [
      "design patterns",
      "angularjs"
    ]
  },
  {
    "text": "nginx - allow only specific ips or specific url path to skip authentication. i have nginx configuration that looks like this:location / { satisfy any; allow some_ip_address; allow some_ip_address; allow some_ip_address; deny all; auth_basic restricted; auth_basic_user_file some_path/.htpasswd; include /etc/nginx/mime.types; try_files $uri $uri/ @handler;}location ~ .php$ { satisfy any; allow some_ip_address; allow some_ip_address; allow some_ip_address; deny all; auth_basic restricted; auth_basic_user_file some_path/.htpasswd; add_header x-ua-compatible 'ie=edge,chrome=1'; try_files $uri $uri/ =404; fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_param script_filename $realpath_root$fastcgi_script_name; fastcgi_param document_root $realpath_root; include fastcgi_params;}the current result is that only the listed ips can access the website without authentication.i want to keep it that way, but also allow everyone skip the authorization if the requested uri contains a specific string.for example: anyone who enters domain.com/...some-string... can skip the authorization.-- any idea?",
    "present_kp": [
      "nginx"
    ],
    "absent_kp": [
      "centos"
    ]
  },
  {
    "text": "how do you add a opera thumbnail for your site?. i noticed that in the speed dial feature of opera, some sites will display their logo as preview image, while other sites just a screenshot of how the site looks when you add it to speed dial. i don't know for sure but i think chrome has the same behavior.stackoverflow for example has the logo :dso how do i make my site display the logo when users add it inside speed dial?",
    "present_kp": [
      "thumbnail"
    ],
    "absent_kp": [
      "browsers"
    ]
  },
  {
    "text": "random freezes when setting modes with dual 4k monitors (chromebook pixel). i have a google pixel (2015) with fedora 24 installed. this has an intel hd 5500 graphics card.when i plug in two 4k monitors (one in each usb-c port) the displays work properly. however, if sometimes when i wake from suspend or sometimes when i boot with both monitors plugged in, the computer freezes.whether it freezes or not, the last entries in the graphics logs are always setting the mode:# journalctl --boot=-1 _comm=gdm-x-session | tail -3/usr/libexec/gdm-x-session[2678]: (ii) intel(0): resizing framebuffer to 7680x2160/usr/libexec/gdm-x-session[2672]: (ii) intel(0): switch to mode 3840x2160@60.0 on dp2 using pipe 1, position (3840, 0), rotation normal, reflection none/usr/libexec/gdm-x-session[2672]: (ii) intel(0): switch to mode 3840x2160@60.0 on dp1 using pipe 0, position (0, 0), rotation normal, reflection nonewhile the computer doesn't appear to respond to input, it does acknowledge a power-button press that turns off the computer:# journalctl --boot=-1 | tail -1systemd-logind[855]: power key pressed.none of the other default syslog output shows anything abnormal.since none of these logs show anything wrong, what can i do to further debug this? are there other logs that i can check (e.g., other _comm flag) or is there a way to enable deeper logging?",
    "present_kp": [
      "freeze"
    ],
    "absent_kp": [
      "dual monitor",
      "intel graphics",
      "chrome book"
    ]
  },
  {
    "text": "shell: combine semicolon and ampersand in bash/sh. [root@localhost tmppcm]# ls ; echo exit code was: $? & echo pid is: $!test.txt.................lastfile.txt[1] 1265pid is: 1265exit code was: 0in above it is as it runs ls to begin with, and then ends by running the echo's in 'parallel'.not quite what i want. i'd like that the sequence ls and echo exit code was: $? to be performed in the background, and echo process id in 'parallel'.a solution could be to use || instead of ; between ls and echo exit code was:[root@localhost tmppcm]# ls || echo exit code was: $? & echo pid is: $![1] 1271pid is: 1271test.txt.................lastfile.txtexit code was: 0is there a more clever way to do this with the a ; b & c combination that i'm missing?",
    "present_kp": [
      "bash",
      "shell"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the *generally accepted* definition for the percolation threshold on finite-sized graphs?. for regular graphs (lattices, if you will), it's easy to define the percolation threshold $p_c$ as the critical probability beyond which the infinite graph will contain an infinitely large cluster with probability 1. (and below that, with probability 0).in practice, you can measure that by doing a finite-size analysis and extrapolating. but what if i'm interested in just the percolation properties of a single instance of a given finite graph? in that case, i can personally think of a few ways to define a percolation threshold, but it wouldn't be unique. for example, you could say: for a graph $g$ let $p_c$ be the probability such that the largest cluster will have size $n|g|$ with probability $p > 0.99$ or something like that. but i wonder if there's one common definition that everyone in the research community uses?i find it hard to nail down my literature search, probably because i'm using the wrong terms. all papers i could dig up so far talk about finite-size-scaling analysis but with the goal at arriving at $p_c$ for the infinite graph. pointers in the right direction would be appreciated.",
    "present_kp": [
      "percolation"
    ],
    "absent_kp": [
      "graph theory"
    ]
  },
  {
    "text": "minimize longest continuous streak of $1$s after flipping $m$ $-1$s to $1$s. given an array a of length n of $-1$s and $1$s, and another input $m$, i was supposed to minimize the longest continuous streak of $1$s or $-1$s after flipping $m$ $-1$s to $1$s or vice versa.i know how to maximize it but can't figure out how to minimize it. i maximize the number of $1's$ by sliding window method. take a window ($wleft$ , $wright$).it covers given array from index $wleft$ to $wright$.i represent $-1$ with $0$ for ease.suppose number of zeros in window in $wzeros$.algorithm :while wright < length of array { wzeros <= m: increment wright wzeros>m: increment wleft // update the max window size during this whole process. int temp = wright-wleft; if(temp > mx_length){ mx_length = temp; solution_window = wleft; } }this code maximizes the number of consecutive $1$s whereas i want to minimize the number of consecutive $1$s and $-1($or $0)$s. how do i modify the algorithm/code to achieve so ?",
    "present_kp": [],
    "absent_kp": [
      "number theory",
      "searching"
    ]
  },
  {
    "text": "what to do when your work colleague doesn't understand the design trying to be maintained. a software project that i am working on involves me and another programmer. the project involved an engine backend with an mvc front end. initially i did alot of the work on the project and so setup some simple design methodologies mainly surrounding abstraction and template strategy.for quite a while i have been off the engine backend and working on the website. however i have still maintained an interest in the engine as i was informed that i might be back on it at some point.the project is under a very tight deadline so we are all rushing like made to get it finished on both the front end and back end.i don't consider myself to be a great programmer and so i never try and enforce any particular design or set of methodologies on people as i'm not always sure i'm right and like to have other people offer their opinions to try and come up with better solutions. however i have noticed changes being made to this engine code that is really starting to irk me. when i confronted the developer to suggest he do the work another way he said he didn't see the point as there seemed little benefit considering the tight deadlines.i had to try and explain that the haack he had put in could mean further development after release and i didn't think it was fair to make others pick up the slack when we could fix it now. i spent about 30mins going through what i had done and at the end of it he asked me to pretty much write the code so he could just copy it.the basis of what was i had initialy setup was:an abstract class xan abstract factory class to create concrete instances of xwhat had happened was he had put a couple of if statements that could easily have been put as virtual/abstrace methods on the abstract class and then implemented accordingly as the new change followed the same principle of other methods on the abstract class already.this seems trivial to me, however he couldn't even grasp this even when i showed him the classes involved.now my question is:is this unfair to assume he should have grasped this concept. i realise that we are on tight deadlines but i thought it was trivial. the programmer is supposed to be at least an intermediate level.this has happened in a number of places and i have constantly tried to get him to change but he doesn't seem to. should i just ignore it?should i raise this issue elsewhere, or just suck it and when i'm put back on the project just go around changing all these things.his part of the project is not going to be finished which is why i will have to go back on and help him out. i really don't want too, as he has taken a project with not great, but ok architecture and really put in alot of messy code that more than often didn't follow what was trying to be achieved.if the question is too vague or ranty, please let me know and i'll try and edit accordingly.edited: the project is expected to continue after the initial deadline as there is already follow up work planned and work that we did not fit in and has been agreed to be implemented later.",
    "present_kp": [],
    "absent_kp": [
      "code smell"
    ]
  },
  {
    "text": "how to make grub mount encrypted lvm partition. i have such boot sequence: system boots from external disk, right after start it asks about password for lvm encrypted partition (which holds /root and /home), i enter it, the partitions are mounted, boot continues, everybody happy.this was opensuse 11.4. i upgraded to 13.2 and now the boot loader (grub) does not ask about any password, it believes that lvm mount point is regular, accessible partition, and after some delay it simply states this partition is not present (/dev/my_lvm/root).i kept backup of old /boot and i compared device map of grub, and menu list, both version (previous, from os 11.4) and current looks the same (actually analogous, because now grub has current and previous menu entries).so how to make grub to ask me about the password, as before?update using the info provided in the thread about boot loaders -- <url> -- i have grub version 0.97 in my boot partition used.",
    "present_kp": [
      "opensuse",
      "lvm",
      "grub"
    ],
    "absent_kp": [
      "encryption"
    ]
  },
  {
    "text": "sorting a 2d array on 1 dimension. inspired by a previous question, i was looking into converting a table to a sorted list (ascending) -resulting in this -i used a very simple bubble-sort, but i don't know how efficient that would be with larger data sets, either in records or if i wanted to sort on more than one condition. basically, this was an exercise in using arrays when built-in excel tools would be better.option explicitpublic sub getbids() dim i as long dim j as long dim customer as string dim counter as long dim size as long dim sortedbids as variant counter = 1 dim lastrow as long lastrow = cells(rows.count, 1).end(xlup).row dim lastcolumn as long lastcolumn = cells(1, columns.count).end(xltoleft).column size = worksheetfunction.count(range(cells(2, 2), cells(lastrow, lastcolumn))) dim arrayofbids as variant redim arrayofbids(1 to size, 1 to 2) for i = 2 to lastrow customer = cells(i, 1) for j = 2 to lastcolumn if not isempty(cells(i, j)) then arrayofbids(counter, 1) = cells(i, j) arrayofbids(counter, 2) = customer counter = counter + 1 end if next next sortedbids = bubblesort(arrayofbids) range(cells(1, 6), cells(size, 7)) = sortedbidsend subprivate function bubblesort(byval arrayofbids as variant) as variant dim temporaryarray as variant dim i as integer dim exchangemade as boolean redim temporaryarray(1 to 1, 1 to 2) do exchangemade = true for i = 1 to ubound(arrayofbids) - 1 if arrayofbids(i, 1) > arrayofbids(i + 1, 1) then exchangemade = false temporaryarray(1, 1) = arrayofbids(i, 1) temporaryarray(1, 2) = arrayofbids(i, 2) arrayofbids(i, 1) = arrayofbids(i + 1, 1) arrayofbids(i, 2) = arrayofbids(i + 1, 2) arrayofbids(i + 1, 1) = temporaryarray(1, 1) arrayofbids(i + 1, 2) = temporaryarray(1, 2) end if next i loop while not (exchangemade) bubblesort = arrayofbidsend function",
    "present_kp": [
      "sorting",
      "excel"
    ],
    "absent_kp": [
      "vba"
    ]
  },
  {
    "text": "if sat is in pcp, for some constant q, then p = np. i have seen this statement before, but i haven't really seen a proof of it:if $sat\\in pcp_{1,2^{q}}[\\log(n),q]$, for some constant $q$, then $p = np$.now, if $sat\\in pcp_{1,2^{q}}[\\log(n),q]$, then sat reduces to $gap-q-csp[1,2^{-q}]$. so to show $p = np$, how do we show then that $gap-q-csp[1,2^{-q}]$ is in $p$?",
    "present_kp": [
      "sat",
      "pcp"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "p vs np"
    ]
  },
  {
    "text": "optimising insert operation for btree. i'm working on implementation insert operation for a btree, and would like to know if there is any way to optimise the inserting operation to make it go faster. the code seems really long so i'm wondering if there is anything that can be shortened and also to make the operation run quicker./** * operation which inserts the specified element * into the btree if a matching element isn't already * present. in the event where the element truly needs * to be inserted, the size of the btree is effectively * increases by one, and the pair that gets returned contains * an iterator to the inserted element and true in its first and * second fields. * * if a matching element already exists in the btree, nothing * is added at all, and the size of the btree stays the same. the * returned pair still returns an iterator to the matching element, but * the second field of the returned pair will store false. this * second value can be checked to after an insertion to decide whether * or not the btree got bigger. * * the insert method makes use of t's zero-arg constructor and * operator= method, and if these things aren't available, * then the call to btree<t>::insert will not compile. the implementation * also makes use of the class's operator== and operator< as well. * * @param elem the element to be inserted. * @return a pair whose first field is an iterator positioned at * the matching element in the btree, and whose second field * stores true if and only if the element needed to be added * because no matching element was there prior to the insert call. */template<typename t>std::pair<typename btree<t>::iterator, bool> btree<t>::insert(const t& elem) { node *cur = root_; size_t i; if (root_ != nullptr) { while (true) { // scan horizontally until we overshoot for (i = 0; i < cur->numvals_ && cur->vals_[i] <= elem; ++i) { if (cur->vals_[i] == elem) { return make_pair(iterator(cur, i, this), false); } } // descend into left child and repeat if (cur->numvals_ == cur->nodesize_) { if (cur->children_[i] == nullptr) { cur->children_[i] = new node(nodesize_, cur, i); cur = cur->children_[i]; i = 0; break; } else { cur = cur->children_[i]; } } else { break; } } } else { root_ = new node(nodesize_, nullptr, 0); cur = root_; i = 0; } ++cur->numvals_; // insert at i, shuffle the rest backwards first copy_backward(cur->vals_ + i, cur->vals_ + cur->numvals_ - 1, cur->vals_ + cur->numvals_); cur->vals_[i] = elem; if (cur->numvals_ == nodesize_) { // create the children cur->children_ = new node*[nodesize_ + 1]; for (size_t n = 0; n < nodesize_ + 1; ++n) { cur->children_[n] = nullptr; } } // update first_ and last_ if (first_ == nullptr || elem < first_->vals_[0]) { first_ = cur; } if (last_ == nullptr || elem > last_->vals_[last_->numvals_ - 1]) { last_ = cur; } return make_pair(iterator(cur, i, this), true);}example code using the function:btree<char> astring;cout << inserting these random chars into the tree... ;for(int i = 0; i < 10; i++) {pair<btree<char>::iterator, bool> result = astring.insert(static_cast<char>(getrandom('a', 'z')));cout << *result.first;}cout << endl << endl;for(btree<char>::iterator iter = astring.begin(); iter != astring.end(); ++iter)cout << *iter;cout << endl;details of the node struct:private: // the details of your implementation go here struct node { friend ostream& operator<<(ostream& os, const node& node) { for (size_t i = 0; i < node.numvals_; ++i) { os << node.vals_[i] << ; } return os; } node(size_t maxnodeelems, node *parent, size_t parentindex) : nodesize_(maxnodeelems), numvals_(0), parent_(parent), parentindex_(parentindex), children_(nullptr) { vals_ = new t[nodesize_]; } // todo check const node(node *other, node *parent, size_t parentindex) : nodesize_(other->nodesize_), numvals_(other->numvals_), parent_(parent), parentindex_(parentindex), children_(nullptr); ~node(); size_t nodesize_; size_t numvals_; node *parent_; size_t parentindex_; t *vals_; node **children_; }; size_t nodesize_; node *root_; node *first_; node *last_;};",
    "present_kp": [
      "tree"
    ],
    "absent_kp": [
      "c++",
      "c++11"
    ]
  },
  {
    "text": "comparing different string-matching functions. here is a problem came from codingbat:given 2 strings, a and b, return the number of the positions where they contain the same length 2 substring. so xxcaazz and xxbaaz yields 3, since the xx, aa, and az substrings appear in the same place in both strings.there are several answers but it may hard to choose which one is the most preferred, such as:# solution 1# using for loopdef strmatch_forloop(a, b): shorter = min(len(a), len(b)) count = 0 for i in range(shorter-1): a_sub = a[i:i+2] b_sub = b[i:i+2] if a_sub == b_sub: count = count + 1 return count# solution 2# using list comprehensiondef strmatch_listcomp(a, b): shorter = min(len(a), len(b)) return [a[i:i+2] == b[i:i+2] for i in range(shorter-1)].count(true)# solution 3# using generatordef strmatch_gen(a, b): shorter = min(len(a), len(b)) return sum(a[i:i+2] == b[i:i+2] for i in range(shorter-1))note that the preferable might be subjective; it may refer to the speed, the memory use or the coding style. for instance, their speeds are reported as:%timeit strmatch_forloop10000000 loops, best of 3: 21.7 ns per loop%timeit strmatch_listcomp10000000 loops, best of 3: 22.9 ns per loop%timeit strmatch_gen10000000 loops, best of 3: 21.8 ns per loopaccording to the results, there may no difference between these approaches. for memory use, similar results can be shown by %memit. however, coding style is too subjective to measure. how could i choose among them?",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "python",
      "performance",
      "memory management",
      "comparative review"
    ]
  },
  {
    "text": "hourglass path in svg for android. i've created my first android drawable, a hourglass shaped image, and i'm curious what can be improved with it. it seems weird having to use 4 paths, but i couldn't get it to work any other way.<?xml version=1.0 encoding=utf-8?><vector xmlns:android=<url> android:width=24dp android:height=34dp android:viewportheight=34 android:viewportwidth=24> <group> <path android:pathdata=m0,10l0,0m0,0l24,0m24,0l24,10 android:strokecolor=@color/colorprimary android:strokewidth=3/> <path android:pathdata=m0,10l24,24 android:strokecolor=@color/colorprimary android:strokewidth=1.7/> <path android:pathdata=m24,10l0,24 android:strokecolor=@color/colorprimary android:strokewidth=1.7/> <path android:pathdata=m0,24l0,34m0,34l34,34m24,34l24,24 android:strokecolor=@color/colorprimary android:strokewidth=3/> </group></vector>reason i tagged it svg, is the docs page mentions android:pathdatadefines path data using exactly same format as d attribute in the svg's path data. this is defined in the viewport space.",
    "present_kp": [
      "android",
      "xml",
      "svg"
    ],
    "absent_kp": []
  },
  {
    "text": "brace pairing ({}[]()<>) cleanup/speedup. this is working as expected, except in the speed area + i need to make it more readable and shorter if possible, i probably have lot's of things i don't need :).edit it is working now charset = dict(opening='{[(<',\\ closing='}])>',\\ string = ('', '),\\ comment=(('<!--', '-->'), ('', ''), ('#', ' ')))allowed = ''.join([x[0][0] + x[1][0] for x in charset['comment']])allowed += ''.join(charset['string'])allowed += charset['opening']allowed += charset['closing']def brace_check(text): o = [] c = [] notr = [] found = [] busy = false last_pos = none for i in xrange(len(text)): ch = text[i] if not busy: cont = true for comment in charset['comment']: if ch == comment[0][0]: como = text[i:len(comment[0])] if como == comment[0]: busy = comment[1] if ch in charset['opening']: last_pos = i cont = false break if cont: if ch in charset['string']: busy = ch elif ch in charset['opening']: o.append((ch, i)) elif ch in charset['closing']: c.append((ch, i)) else: if ch == busy[0]: if len(busy) == 1: comc = ch else: comc = text[i:i + len(busy)] if comc == busy: if last_pos is not none: if busy[-1] in charset['closing']: found.append((last_pos, i)) last_pos = none text = text[:i] + ' ' * len(comc) +\\ text[i + len(comc):] busy = not busy elif busy in charset['string']: if ch == ' ': busy = not busy for t, e in reversed(o): try: n = next((b, v) for b, v in c\\ if b == charset['closing'][\\ charset['opening'].find(t)] and v > e) c.remove(n) n = n[1] if found != []: if e < found[-1][0] and n > found[-1][0] and n < found[-1][1]\\ or e < found[-1][1] and n > found[-1][1] and e > found[-1][0]: found.append((n, false)) n = false except stopiteration: n = false found.append((e, n)) for t, e in c: found.append((e, false)) return found",
    "present_kp": [],
    "absent_kp": [
      "python",
      "regex"
    ]
  },
  {
    "text": "remove duplication in select statement. say i have the following sql:select amount, amount*.1, (amount*1)+3, ((amount*1)+3)/2, (((amount*1)+3)/2)+37from tableinstead of repeating that identical code every time, i really want to be able to do something like this:select amount, amount*.1 as a, a+3 as b, b/2 as c, c+37 as d,from tablebut this code doesn't work.so, is there another way to avoid duplication in the working query that i have?",
    "present_kp": [
      "sql"
    ],
    "absent_kp": [
      "sql server"
    ]
  },
  {
    "text": "putting numbers into words. i have some embarrassingly long code which puts into words any number up into the trillions. as a newbie, and understanding that shorter, non-repetitive code is best, i am looking for suggestions on how to reduce this code to a respectable quantity. i realize that there is a lot of repetition in it. however, depending on the number being evaluated, the math looks a little different with each rep, so i am not sure if i can reduce that. i have tried rewriting it solely as an if/else (without the recursion) but it quickly becomes just as bad if not worse.class :: fixnum def in_words(number) if number < 0 # no negative numbers. return 'please enter a number that isn't negative.' end if number == 0 return 'zero' end numstring = '' # this is the string we will return. onesplace = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'] tensplace = ['ten', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety'] teenagers = ['eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen'] #-----------------------------------------trillions left = number write = left/1000000000000 left = left - (write*1000000000000) if number > 999999999999 if write < 10 #1,00 - 9,000 millions = onesplace[write - 1] numstring = numstring + millions + ' trillion' end if (write > 9) && (write < 20) #10,000 - 19,000 if write == 10 millions = tensplace[write - 10] numstring = numstring + millions + ' trillion' else millions = teenagers[write - 11] #11 because the length of teenagers is only 9 so 15-11 = 4 and 'thirteen' is in numstring = numstring + millions + ' trillion' end end if (write > 19) && (write < 1000) #here i have to use recursion to get the first two/three digets --> 19,000,000 - 999,000,000 millions = in_words(write) numstring = numstring + millions + ' trillion' end if left > 0 numstring = numstring + ' ' end #-----------------------------------------billions #left = number write = left/<phone> left = left - (write*<phone>) if number > 999999999 if write < 10 #1,00 - 9,000 millions = onesplace[write - 1] numstring = numstring + millions + ' billion' end if (write > 9) && (write < 20) #10,000 - 19,000 if write == 10 millions = tensplace[write - 10] numstring = numstring + millions + ' billion' else millions = teenagers[write - 11] #11 because the length of teenagers is only 9 so 15-11 = 4 and 'thirteen' is in numstring = numstring + millions + ' billion' end end if (write > 19) && (write < 1000) #here i have to use recursion to get the first two/three digets --> 19,000,000 - 999,000,000 millions = in_words(write) numstring = numstring + millions + ' billion' end if left > 0 numstring = numstring + ' ' end # ----------------------------------------millions write = left/<phone> left = left - (write*<phone>) if number > 999999 if write < 10 #1,00 - 9,000 millions = onesplace[write - 1] numstring = numstring + millions + ' million' end if (write > 9) && (write < 20) #10,000 - 19,000 if write == 10 millions = tensplace[write - 10] numstring = numstring + millions + ' million' else millions = teenagers[write - 11] #11 because the length of teenagers is only 9 so 15-11 = 4 and 'thirteen' is in numstring = numstring + millions + ' million' end end if (write > 19) && (write < 1000) #here i have to use recursion to get the first two/three digets --> 19,000,000 - 999,000,000 millions = in_words(write) numstring = numstring + millions + ' million' end if left > 0 numstring = numstring + ' ' end #-----------------------------------------thousands write = left/1000 left = left - (write*1000) if number > 999 if write < 10 #1,00 - 9,000 thousands = onesplace[write - 1] numstring = numstring + thousands + ' thousand' end if (write > 9) && (write < 20) #10,000 - 19,000 if write == 10 thousands = tensplace[write - 10] numstring = numstring + thousands + ' thousand' else thousands = teenagers[write - 11] #11 because the length of teenagers is only 9 so 15-11 = 4 and 'thirteen' is in numstring = numstring + thousands + ' thousand' end end if (write > 19) && (write < 1000) #here i have to use recursion to get the first two/three digits --> 19,000 - 999,000 thousands = in_words(write) numstring = numstring + thousands + ' thousand' end if left > 0 numstring = numstring + ' ' end end endend end# ------------- hundreds write = left/100 left = left - (write*100) if write > 0 hundreds = in_words(write) numstring = numstring + hundreds + ' hundred' if left > 0 numstring = numstring + ' ' end end# ---------------- tens write = left/10 #stop here and return #numstring = numstring + left = left - write*10 if write > 0 if ((write == 1) and (left > 0)) numstring = numstring + teenagers[left-1] left = 0 else numstring = numstring + tensplace[write-1] end if left > 0 numstring = numstring + '-' end end write = left left = 0 if write > 0 numstring = numstring + onesplace[write-1] end numstringendend#classputs 95202824653012.in_words(95202824653012)another problem i have with it is that it is a method added to the fixnum class and i would like to be able to call it directly on self without an argument, for example <phone>.in_words instead of <phone>.in_words(<phone>). the problem seems to be that the recursion needs an argument when it is called, and therefore the method needs one. or is there a way around that?",
    "present_kp": [],
    "absent_kp": [
      "ruby",
      "numbers to words"
    ]
  },
  {
    "text": "how to iterate through all permutations of valid links between nodes. imagine a 2d area, with a number (array) of nodes (or points) defined within it, in arbitrary (but known) positions (integer x,y coordinates), like this:from there i want to be able to, programmatically, add as many links as possible.a link is a straight line between any two nodes, but a link cannot cross another link.i already have a method created that can verify if two links cross. egwith any given set of nodes, there is a finite number of ways that links can be laid out and i want to be able to generate all of those possible (valid) combinations.however, i have absolutely no idea where to start on this. i could randomly fill the nodes with valid links, but i don't know how to iteratively generate each possible permutation.i'm guessing that some kind of algorithm exists for problems like this, probably based around recursion, but my searches so far have been fruitless.i'm not looking for a coded solution, i can do that part. what i need is the high level design process, or algorithm, that can be followed to solve this problem.",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "algorithms"
    ]
  },
  {
    "text": "symbol lookup errors in (qt?) dynamically linked libraries. i'm using ubuntu 15.10problem:for some days now i have been getting errors like this when opening some applications: /usr/lib/x86_64-linux-gnu/libpoppler-qt5.so.1: undefined symbol: _zn6qdebugd1evsome applications affected aretexstudio shows/usr/lib/x86_64-linux-gnu/libpoppler-qt5.so.1: undefined symbol: _zn6qdebugd1evipython's qtconsole shows/usr/lib/python3.5/site-packages/pyqt5/qtcore.so: undefined symbol: _znk12qstorageinfo11displaynameevkonsole (kde's terminal emulator - i'm using unity though) shows /usr/lib/x86_64-linux-gnu/libkf5itemviews.so.5: undefined symbol: ...granatier (a kde game), ksysguard and kaddressbook also show errors in kf5 librariesalso failvlc seems to be affected too since it says there is something wrong with qt 4 (see below)qtall of this errors seem to come from qt linked libraries (qt appears in most filenames and most symbol names). afaik kde ist baed on qt, which would explain why all kde applications fail.it seems to affect both qt 4 and 5possible originthe day this problems appeared i had enabled wily-proposed packages in the ubuntu software & updates system application. i interrupted the upgrade and tried this to roll it back. after this i had a similar problem with ssl but it went away eventually.",
    "present_kp": [
      "ubuntu",
      "kde",
      "qt"
    ],
    "absent_kp": [
      "package management",
      "dynamic linking"
    ]
  },
  {
    "text": "why do computers use hex number system at assembly language?. why do computer use hex number system at assembly language? why don't they use any other number system like binary, octal, decimal? what thing forced computer designer to use hex system at assembly? why it looked so beneficial to them?",
    "present_kp": [],
    "absent_kp": [
      "time complexity",
      "computer architecture",
      "mathematical analysis",
      "memory hardware",
      "computer algebra"
    ]
  },
  {
    "text": "error trapping for dialog box reply. how can i improve upon this code to apply logic based on the user's response to a saveas dialog box 'do you want to overwrite existing file' question:sub savefile(fname as string)cancelsave = falseretry:saveasfilename = application.getsaveasfilename(initialfilename:=fname, filefilter:=excel files (*.xlsx), *.xlsx)if saveasfilename <> false then if not dir(saveasfilename) <> vbnullstring then activeworkbook.saveas filename:=saveasfilename else on error resume next activeworkbook.saveas filename:=saveasfilename, fileformat:=xlworkbook, conflictresolution:=xllocalsessionchanges if err.number = 1004 then on error goto 0 goto retry else on error goto 0 end if end ifelse cancelsave = trueend ifend sub",
    "present_kp": [
      "excel"
    ],
    "absent_kp": [
      "vba"
    ]
  },
  {
    "text": "what's the difference between readelf and eu-readelf?. you get eu-readelf from: $ sudo apt-get install elfutils i was just wondering why you would use one over the other ?",
    "present_kp": [
      "elf"
    ],
    "absent_kp": []
  },
  {
    "text": "licensing doubts. i am quite new to programming and i am now creating my own program as part of my master thesis. my program is done in java and uses several third-party libraries. these libraries come with different licenses, mainly:lgpl 2.1gpl 2 + gpl linking exceptionapache version 2bsdi have actually not touched the source code of these libraries, but use them in my program and in some cases create classes that extend classes in those libraries. if i decide to make my program publicly available (probably for free) what kind of licence could i use? i have read much about license compatibility (apache vs gpl vs whatever), derivative works discussions and i am very confused. comments and explanations would be very helpful.",
    "present_kp": [
      "java",
      "licensing"
    ],
    "absent_kp": []
  },
  {
    "text": "performing actions based on command line arguments. i'm currently reviewing a bit of an older console application which performs certain tasks depending on the command line argument that is given. these tasks are called through windows task scheduler.however reflecting on this i find the code to be ugly and i'm wondering if there is a better way to do something like this.public shared sub parsetasks(byval cmdargs() as string) convertandwriteargs(cmdargs) try select case cmdargs(0) case scripts 'scripts has 1 input parameter: scheduletype if cmdargs.length < 2 then exceptionlogger.logexceptionevent(invalid arguments, severity.error) else scripts(sheduletype:=cmdargs(1).tostring) end if case checktransferreplication checktransferreplication() case createsybasebackup11 createsybasebackup11() case sqlcommand sqlcommand() case replication_in 'replication in has 1 input parameter: range if cmdargs.length < 2 then exceptionlogger.logexceptionevent(invalid arguments, severity.error) else replicationimport(range:=cmdargs(1).tostring()) end if case replication_out 'replication out has 1 input parameter: range if cmdargs.length < 2 then exceptionlogger.logexceptionevent(invalid arguments, severity.error) else replicationexport(range:=cmdargs(1).tostring) end if case reexportfile 're export file out has 1 input parameter: filename if cmdargs.length < 2 then exceptionlogger.logexceptionevent(invalid arguments, severity.error) else reexportfile(filename:=cmdargs(1).tostring) end if case upgrade 'upgrade has 1 input parameter: scriptfolder if cmdargs.length < 2 then exceptionlogger.logexceptionevent(invalid arguments, severity.error) else upgrade(scriptfolder:=cmdargs(1).tostring) end if case duplicates duplicates() case else exceptionlogger.logexceptionevent(invalid arguments, severity.error) end select catch ex as exception exceptionlogger.logexceptionevent(ex, severity.error) end try end sub#region task functions private shared sub autoscripts(byval sheduletype as string) trace.traceinformation(creating autoscripts task.) dim task = new autoscripts with task .scheduletype = convertscheduletype(sheduletype) end with trace.traceinformation(schedule type: & task.scheduletype.tostring) task.start() end sub private shared sub checktransferreplication() trace.traceinformation(creating checktransferreplication task.) dim task = new checktransferreplication task.start() end sub private shared sub createsybasebackup11() trace.traceinformation(creating createsybasebackup11 task.) dim task = new createsybasebackup task.start() end sub private shared sub sqlcommand() trace.traceinformation(creating sqlcommand task.) dim task = new business.task.executesqlcommand task.start() end sub private shared sub reexportfile(byval filename as string) trace.traceinformation(creating reexportfile task.) dim task = new reexportfile with task .filename = filename end with task.start() end sub private shared sub upgrade(byval scriptfolder as string) trace.traceinformation(creating upgradesybasedatabases task.) dim task = new upgradesybasedatabases with task .scriptfolder = scriptfolder end with task.start() end sub#region replication private shared sub replicationimport(byval range as string) trace.traceinformation(creating replicationimport task.) dim task = new executereplication task.replicationtype = business.replicationtype.import if range.equals(001, stringcomparison.ordinalignorecase) then task.replicationgroup = business.replicationgroup.headoffice task.start() try edimarobjectdao.processreferrors() catch ex as exception exceptionlogger.logexceptionevent(ex, problemseverity.error) end try dim sqlcommandtask = new executesqlcommand sqlcommandtask.start() else task.replicationgroup = business.replicationgroup.sattelite task.replicationsatteliterange = range task.start() end if end sub private shared sub replicationexport(byval range as string) trace.traceinformation(creating replicationexport task.) dim task = new executereplication task.replicationtype = business.replicationtype.export if range.equals(001, stringcomparison.ordinalignorecase) then task.replicationgroup = business.replicationgroup.headoffice task.start() else task.replicationgroup = business.replicationgroup.sattelite task.replicationsatteliterange = range task.start() end if end sub private shared sub processlogfiles() trace.traceinformation(processing replication logfiles.) dim task = new processlogfiles task.start() end sub#end region#end region#region helper functions private shared sub convertandwriteargs(byval cmdargs() as string) dim strargs = string.empty for each arg in cmdargs if strargs = string.empty then strargs = arg else strargs += & arg end if next trace.traceinformation(arguments: & strargs) end sub private shared function convertscheduletype(byval scheduletype as string) as business.scheduletype dim schedule as business.scheduletype select case scheduletype case m schedule = business.scheduletype.monthly case w schedule = business.scheduletype.weekly case w2 schedule = business.scheduletype.weekly2 case d schedule = business.scheduletype.daily case d2 schedule = business.scheduletype.daily2 case else exceptionlogger.logexceptionevent(invalid arguments, problemseverity.error) end select return schedule end function#end region",
    "present_kp": [],
    "absent_kp": [
      "design patterns",
      "vb.net",
      "scheduled tasks"
    ]
  },
  {
    "text": "how can i clear/empty a file being piped to?. say i have some process which pipes to a file:yes > fooi know want to clear/empty the file foo, but still want the process to write to the file, i.e. start filling the file again after clearing.is this possible?",
    "present_kp": [
      "pipe"
    ],
    "absent_kp": [
      "bash",
      "io redirection"
    ]
  },
  {
    "text": "what was the first server-side language. i was thinking about different server-side languages and this question immediately cropped up in my mind. what was the first server-side programming language using which websites were being created? was it java or some other language?note: i think some languages became prime server-side because they provided or rather aimed to provide better tools and libraries for easy development. i agree java was not primarly server-side but it provided better tools and hence was and is used a lot.",
    "present_kp": [],
    "absent_kp": [
      "programming languages",
      "web development",
      "history",
      "server side"
    ]
  },
  {
    "text": "is there a problem if i add a non-existing path to 'path' environment variable?. i have a following lines in my .bash_profile.if [ -d $home/bin ] ; then path=$home/bin:$pathfii think i found it somewhere in the internet.is it also ok, if i write only path=$home/bin:$path without checking directory existence?does it cause a problem if i add a non-existing path to $path?",
    "present_kp": [
      "directory",
      "path"
    ],
    "absent_kp": [
      "test"
    ]
  },
  {
    "text": "possible options for site meta discussion. just wondering if anyone had any suggestions for software that i could use to provide meta discussion of a website that i am working on? my initial thought would be to use one of the many discussion boards available, but i hate them!, and would rather not go down the route of subjecting my users to using another forum! :)i don't need anything too complex, just a place where users can raise feature/bug requests or ask for general help from other users.",
    "present_kp": [],
    "absent_kp": [
      "tools"
    ]
  },
  {
    "text": "how can i execute multiple optional substitute commands in one line?. i am comparing a couple of files with vimdiff. there are some differences which i expect and which i'd like to get rid of. i know i can use::%s#from1#to1#g | %s#from2#to2#g | ...to replace multiple expected differences at the same time. however, the 2nd substitution is only executed if the first succeeds; i.e. from1 must be present in the file in order to replace from2, too (i get e486: pattern not found: from1 and from2 still exits). can i specify multiple optional substitutions that all should be executed? i imagine some option for | to behave like an or instead of an and.i would like to do this interactively because the expected differences differ among various files and i don't exactly know them in advance.",
    "present_kp": [
      "substitute"
    ],
    "absent_kp": []
  },
  {
    "text": "language equivalence proof. can anyone explain to me how the following is true for any language?$$l^+ = ll^* = l^*l$$i'm confused because $l^*$ is the set of all words including the empty string, while $l^+$ is the set of all words excluding the empty string. i don't understand how concatenating $l^*$ with $l$ makes it equal to $l^+$. what happens to the empty string? thank you.",
    "present_kp": [],
    "absent_kp": [
      "formal languages"
    ]
  },
  {
    "text": "why do browser javascript libraries pass the window object as an argument?. while looking at various javascript libraries, i have noticed a relatively common practice of passing either the window or the document object as part of the arguments given to the library initialization function.examples:dom4contentloadedeasyxdmfingerprintjswhile i understand very well why that would be done for libraries that are designed to run on non-browser environments, i do not know why that is done for libraries that seem designed only for client browser environments. (such as all the examples given above).",
    "present_kp": [
      "javascript"
    ],
    "absent_kp": []
  },
  {
    "text": "take over a stack on delicious. i've found an abandoned stack on delicious and want to be the owner of it. the owner has been inactive for a long time and i would like to continue their work. is this possible?",
    "present_kp": [
      "delicious"
    ],
    "absent_kp": []
  },
  {
    "text": "preferring python over c for algorithmic programming. i've been studying a bit of algorithms and have been looking at sites like spoj.pl topcoder etc. i've seen that programmers prefer c or c++ usually for most algorithmic programming contests. now i've been having some trouble lately. i know both a bit of c and python and when trying to write a code i seem to prefer python over c for most algorithms. everytime i sit down to write a code in c i give up after about 15 minutes because i find it too cumbersome and tend to move over to python. passing matrices pointers and so on seem to be useless time wasted that i could actually be utilizing to think about the algorithm itself.now i know and have heard from a lot of people that c is a very important language and is the bread and butter of a lot of programmers out there.what i wanted to know was whether this approach of mine has any drawbacks/consequences/disadvantages etc.this is not a python vs c debate; this a question about how this specific practice of preferring python over c because of the ease of use will affect me or any other programmer/computer scientist in the long run.i'd love to hear from people who've used these languages in the industry/and or to develop large software/libraries etc.",
    "present_kp": [
      "algorithms",
      "python",
      "c"
    ],
    "absent_kp": [
      "programming practices",
      "self improvement"
    ]
  },
  {
    "text": "how to search forward for pattern in the current line? like '/' and '?' but stop at end of line. is is possible to search for a regexp in only the current line.here is an example line:this is some text that i have written. can you find this word? ^this line contains many t's. i would like to search forward for this so the cursor ends up at the caret (the ^ character).the problem with using / is that if the pattern does not match in the line the cursor will jump to another part of the buffer. i do not want that behavior. i want the search to stop if there is no match in the line.i can of course search forward using ft and press ; repeatedly but if i were to record macro that would make the macro inconsistent when executed at different locations.the most obvious solution would be :./this but that did not work for me (it finds matches at other lines in the buffer). so it appears to me that vim is lacking this feature.do you know of a way to do what i am describing?",
    "present_kp": [
      "search"
    ],
    "absent_kp": [
      "regular expression"
    ]
  },
  {
    "text": "chromium (chrome) not loading home page automatically. when i start chromium browser, it loads <url> as my home page. this is configured in:settings on startup [*] open a specific page or set of pageshowever, when i open another chromium window or a new tab, instead of <url>, i get just a blank page (chrome://newtab) with a dial of some of my past visited pages. i don't want this. i have to press the home button to load <url> can i have defined home page loaded automatically whenever i do:start chromiumopen new windowopen new tab.?i am using chromium on debian wheezy",
    "present_kp": [
      "chrome",
      "browser"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the best way to store configurations of shell/script code to execute later?. i am working on a tool (python, may or may not be important) that will allow a user to maintain a configuration file containing arbitrary shell and/or language code to be executed on particular events and intervals. the code will potentially involve multiple statements.i understand there are potential behavioral and security risks associated with executing arbitrary code from a file, but i don't think this is a concern because the configuration file is managed only by the end user. however, let me know if i'm overlooking something major.my main question: what is the best way to store this code in a configurable way?some concepts i'm considering to store the code...in a shared config file (which many python libraries already look for):# setup.cfg[my_program]command_1 = cd /tmp && touch foobarin a yaml file:# my_program.yamlcommand_1: cd /tmp && touch foobarin a source file as arguments to subprocess.call():# settings.pycommand_1 = [['cd', '/tmp'], ['touch', 'foobar']] # requires special handling of 'cd'in a source file as a function:# settings.pyimport osimport subprocessdef command_1(): os.chdir('/tmp') subprocess.call(['touch', 'foobar'])",
    "present_kp": [
      "python",
      "security",
      "configuration",
      "shell"
    ],
    "absent_kp": [
      "permissions"
    ]
  },
  {
    "text": "meta description of my blog post changes. i have some problems in meta description tags in my blogger blog. when i update my pages in search engine with the help of the fetch as google feature in gwt, all my blog's results comes with a correct meta description liketoday i am back with a reason that why is original memory in hard-disk is less than printed on a box. if we buy any hard-disk or a pen drive...but after approx 5-6 days, it changes to my blog's default meta description. this is also happening after changing the default meta description of my blog.i want only one answer that why its happening?after deleting my blog and creating a new blog with the same name this problem was solved.why this problem was solved? - i am asking this question because to solve problems in the future.",
    "present_kp": [
      "meta description"
    ],
    "absent_kp": [
      "indexing",
      "google index",
      "meta tags"
    ]
  },
  {
    "text": "dice game rules implementation. my in-laws taught me a dice game a couple years ago, and we play every once in a while. a recent excellent answer from @radarbob inspired me to proceed with translating the rules of that dice game into code.here's what came out of it:so it works perfectly, and somehow i'm just as unlucky with this virtual version as in the real-life one (had to click dozens of time to get a freakin' opening roll; by that time my mother-in-law already has thousands of points, every time). at least in this version i can inject some crookeddie implementation if i want!i'd like the calculaterollscore method reviewed, to see what could be improved.it turns out i thought the code was working as it should. so i wrote a couple unit tests and... well this is where not writing unit tests has bitten me.well i had to change the rules anyway, since the rule for 4x 1's was just my wife being mixed-up. my mother-in-law and i agree that 3x 1's is 1000, 4x 1's is 2000 and 5x 1's is 3000.so before i show any code, i'll show this:now here's the working code (view original code here), with only minor changes that don't mootinize any already posted answer:namespace dicegame{ public interface irollscorerules { int calculaterollscore(ienumerable<irollresult<int>> results); } public class gamerollscorerules : irollscorerules { public virtual bool isopeningroll(ienumerable<irollresult<int>> results) { return calculaterollscore(results) >= 500; } public virtual int calculaterollscore(ienumerable<irollresult<int>> results) { var score = 0; // if less than 3 1's were rolled, each rolled 1 is 100pts: score += results.groupby(e => e.value) .where(g => g.key == 1) .where(g => g.count() < 3) .sum(g => g.count() * 100); // if less than 3 5's were rolled, each rolled 5 is 50pts: score += results.groupby(e => e.value) .where(g => g.key == 5) .where(g => g.count() < 3) .sum(g => g.count() * 50); // if more than 3 of anything other than 1 were rolled, determine number of extra dice: var extras = results.groupby(e => e.value) .where(g => g.key != 1 && g.count() > 3) .todictionary(kvp => kvp.key, kvp => kvp.count() - 3); var extraones = results.groupby(e => e.value) .where(g => g.key == 1 && g.count() > 3) .todictionary(kvp => kvp.key, kvp => kvp.count() - 3); // any triplet is 100x nominal value; each extra die is another 100x nominal value: score += results.groupby(e => e.value) .where(g => (g.key != 1 && g.count() >= 3)) .sum(g => (g.key * 100) + (extras.containskey(g.key) ? extras[g.key] : 0) * (g.key * 100)); //score += results.groupby(e => e.value) // .where(g => (g.key == 1 && g.count() >= 3)) // .sum(g => (g.key * 100) + (extraones.containskey(g.key) ? extraones[g.key] : 0) * (g.key * 100)); // 3x 1's is 1000x nominal value; each extra die is another 1000x nominal value: score += results.groupby(e => e.value) .where(g => g.key == 1 && g.count() >= 3) .sum(g => (g.key * 1000) + (extraones.containskey(g.key) ? extraones[g.key] : 0) * (g.key * 1000)); return score; } }}",
    "present_kp": [
      "dice"
    ],
    "absent_kp": [
      "c#",
      "algorithm"
    ]
  },
  {
    "text": "map estimation (for stationary iid gaussian environment). this is my first post, and have been self studying haykin's neural networks and learning machines book. i'm not sure if this is a typo or if i'm doing something wrong, but i've been stuck on a statement on page 75. the context was the process of finding a maximum likelihood estimate for a parameter vector assuming a stationary, iid, and gaussian environment.given:d is a scalar, i indexes time from 1 to n, and $\\mathbf{w},\\mathbf{x}_i $ are m-dimensional vectors.$\\hat{w}_{map} = max_{\\mathbf{w}}[- rac{1}{2}\\sigma_{i=1}^{n}(d_i - \\mathbf{w}^t\\mathbf{x}_i)^2 - rac{\\lambda}{2}||\\mathbf{w}||^2]$we should get the same result if instead we find the minimum of the quadratic function$e(\\mathbf{x}) = rac{1}{2}\\sigma_{i=1}^{n}(d_i - \\mathbf{w}^t\\mathbf{x}_i)^2 + rac{\\lambda}{2}||\\mathbf{w}||^2$haykin says you should arrive at the result (by differentiation wrt $\\mathbf{w}$ and setting the result to 0)$\\hat{w}_{map} = (r_{xx} + \\lambda i)^{-1} r_{dx}$where $r_{xx} = -\\sigma_{i=1}^n \\sigma_{j=1}^n \\mathbf{x}_i \\mathbf{x}_j^t $ is the m*m correlation matrix of x and $r_{dx} = -\\sigma_{j=1}^n \\mathbf{x}_i d_i$my question is why isn't $r_{xx} = -\\sigma_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^t?$haykin goes through about a paragraph saying how the correlation matrix is time averaged and i think this is an important point.thanks for any help!",
    "present_kp": [],
    "absent_kp": [
      "machine learning",
      "mathematical foundations"
    ]
  },
  {
    "text": "how to avoid fraud when purchasing a domain. i have approached a domain owner about purchasing their domain. we have agreed on a price, what is the safest/best way to send them payment and ensure i receive the domain?",
    "present_kp": [],
    "absent_kp": [
      "domains",
      "domain registration",
      "purchase"
    ]
  },
  {
    "text": "when do i need a website certificate?. can someone explain me when i need a web site certificate?i will have a web app that will be used for representing live data. do i need a certificate for that type of web application? a user will be allowed to enter some new records in the database and make queries.if the answer is yes, then can you provide me with some cheap options as this is a new expense for me which i haven't thought of.",
    "present_kp": [],
    "absent_kp": [
      "security certificate",
      "web applications"
    ]
  },
  {
    "text": "book or online article on analysis and tuning linux system performance. i am looking for a good book or online article on analysis and tuning linux system performance.so far i've found opensuse 12.2 system analysis and tuning guide which looks promising. any other recommendations?",
    "present_kp": [
      "linux",
      "performance"
    ],
    "absent_kp": [
      "books"
    ]
  },
  {
    "text": "how to connect to a xserver from my system-wide terminal?. i am currently trying to make an autonomous drone using the robot operating system (ros). to do this, i have installed raspbian lite (jessie) on a rasperry pi 3 and am currently using ros kinetic on it. because it is raspbian lite, there were no window managers or desktop environments that came along with the installation. i decided to go with openbox window manager and installed a terminal onto it for convenience. i can just call sudo startx, and the window manager opens up, which can be accesed by ctrl + alt + f2. since it is a system-wide terminal, i have also installed tmux for convenience. i am running the xserver on a particular pane and conduct my ros work on other panes. now when i try to run commands that call on a gui application from my system-wide terminal, i get the error:qxcbconnection: could not connect to displayabortednow there are two ways to approach this problem: since there is a terminal installed in my window manager, i should get ros working on this? however, i do not know how to change the environment of the terminal emulator inside the window manager so that it is the same as the one on the system-wide terminal. is it as easy as changing shells? actually find a way to send my gui applications to the tmux pane that is currently running the command sudo startx. how do i switch the parent of a process with another parent? note: i definitely would prefer the second solution, as it is more elegant and efficient for my workflow.",
    "present_kp": [
      "tmux",
      "raspbian",
      "gui",
      "openbox"
    ],
    "absent_kp": [
      "x server"
    ]
  },
  {
    "text": "matrix storage, many rows or many columns?. tl;dr should i store a matrix of nx3 elements row-wise or column-wise, if i'm going to access 3 elements at a time? does it matter?i'm setting up a numerical simulation with matrices of x,y,z positions in 3 dimensions, and i wonder whether it's better to store them row-wise or column-wise in r, matlab, and armadillo (c++). maybe it doesn't matter at all.the simulation considers n particles, say n=5000, and each is described by 3 coordinates, 3 angles, and 3 sizes. so i've 3 matrices of nx3 elements. in the code (setting up a linear system of 3n equations), i will need to access positions, sizes, and angles one particle at a time. therefore, i'm tempted to store those as columns, i.e. those matrices would have 3 rows, and n columns. this is because r, matlab and armadillo all have a column-major ordering, so my thinking is that accessing a column will be (ever so slightly) faster. on the other hand, maybe there is a penalty of having many columns (memory addresses)? i do not know.by-the-way, i'm mentioning three programming languages because i'll be writing the code in all three (it's not much effort, since the syntax is pretty much the same).",
    "present_kp": [
      "matlab",
      "r"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i count frequency of strings?. i have 3 billion strings. i want to make a frequency map so i can discard strings that occur fewer than 100 times or more than 100,000 times. what kind of data structure(s) should i use? i'm thinking some kind of bloom filter.",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "data structures"
    ]
  },
  {
    "text": "what is the role of qa in a bdd-driven project?. if running a project using bdd with 100% coverage of user stories with automated acceptance tests, what would be the role of a tester / quality assurance person?i guess i am imagining that developers would write the acceptance tests in conjunction with the product owner, let me know if that seems like a foolish assumption.",
    "present_kp": [
      "qa",
      "bdd"
    ],
    "absent_kp": [
      "testing",
      "team",
      "acceptance testing"
    ]
  },
  {
    "text": "is it best practice to update mysql , php and apache on linux regularly to current version?. i have a vps unmanaged and have installed centos 6.3, mysql 5.1.69, php 5.3.3 and apache 2.2.15no formal or otherwise education in computer programming so trying to follow as many documented guidelines as i can to close any obvious security holes.is it is best practice to use only current versions of each ? are the ones i am using now too out dated?",
    "present_kp": [],
    "absent_kp": [
      "software installation",
      "upgrade",
      "distros"
    ]
  },
  {
    "text": "why is google saying that the user-agent line is invalid?. i have the following robots.txt file:user-agent: *sitemap: <url> when i use the webmaster tools to validate it i get it showing that the user agent line is incorrect. however when i validate it, it comes back as allowed.in both cases it is the same file. so my questions are:what is wrong with the user-agent line?i am being asked to remove the user-agent line. while i understand that * means all agents i don't understand why it has to be removed.any ideas why google is giving inconsistent results?",
    "present_kp": [
      "robots.txt"
    ],
    "absent_kp": [
      "google search console"
    ]
  },
  {
    "text": "how to enable synproxy module in raspbian. i've being playing with raspbian for some time, and when i tried to enable synproxy target, the target wasn't found.root@piwall:~# iptables -a input -p tcp -m tcp -m conntrack --ctstate invalid,untracked -j synproxy --sack-perm --timestamp --wscale 7 --mss 1460iptables: no chain/target/match by that name.so i've checked the lsmodroot@piwall:~# lsmod | grep -i synroot@piwall:~# and the output was just like i thought - no synproxy module.can anyone help me enabling it? if you need more informations, please let me know.",
    "present_kp": [
      "iptables",
      "raspbian"
    ],
    "absent_kp": [
      "kernel",
      "raspberry pi",
      "netfilter"
    ]
  },
  {
    "text": "how do you automatically elevate an automatic task to root privileges or is there an alternative approach?. i'm trying to write, in essence, an automatic deployment script for use by our development team and i know i can set up ssh to use keys so that i can automatically authenticate via key instead of password for the purposes of executing remote commands; however, what i'm stuck on is that the task that needs to execute for deployment requires us to restart an upstart job which requires root privileges. i've looked around on the internet (and here) and have been mostly unsuccessful and finding solutions.the question: is there a way to remotely (and automatically, the script is not monitored so password authentication as sudo requires will not work) elevate to root privileges to restart a job or give a user group the ability to do that?overall i would still consider myself a newbie linux user, i haven't done a lot of work with permissions but i've learned my way around operations pretty well.",
    "present_kp": [
      "sudo",
      "authentication"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "security in transversal layer in domain driven design. i'm building a solution based on domain driven design, i'm trying to implement the security system (authentication, authorization, roles, system configuration, connection strings, etc..) in a transversal layer (cross cutting concerns like caching, security, logging, etc).the tiers of my application are two projects (contractstransversal and transversal), where the contractstransversal project only exposes the services of transversal layer using interfaces (icaching, ilogging, isecurity,etc..) but the implementation of those interfaces are in the transversal project.the design is based on the book guia de arquitectura de ncapas orienta al dominio by microsoft, that suggests the implementation of transversal layer across ioc (dependency injection) and its relation with all parts of the system are decoupled. i'm doing this, i created my container to implement ioc. i have other projects which have only my business entities like usersentity, productentity, etc.is it correct to have a references of my business entities project to my transaversal and contractstransversal project?i ask because in security project i need to know information about the user, roles, permissions, etc.. or what's the best practice to implement security in a domain driven design model?",
    "present_kp": [
      "security",
      "domain driven design"
    ],
    "absent_kp": []
  },
  {
    "text": "is not supported in html5 but its still working. how?. <center> tag to make texts centered is not supported in html5 but its still working in the latest version of chrome.is chrome making up for the mistake or is it still supporting the deprecated tags along with the new html5 tags?",
    "present_kp": [
      "html5"
    ],
    "absent_kp": [
      "google chrome"
    ]
  },
  {
    "text": "should i use the date type in jax-rs @pathparam?. this is what i'm thinking about doing on a jee glassfish server using jersey.@get@path(/{name}/{date})public string getmessages(@pathparam(name) string name, @pathparam(date) date date)i like the idea of being able to tell people consuming this restful webservice that the date here is anything that works with the date class in java. that's pretty simple from the standpoint that they can just look at the date spec, and they'll already have a working model that they can test with.the problem that i'm worried about is that when i do this, jax-rs is not very nice when date() doesn't like what it gets in the constructor. since date() throws an error if it can't parse what it's given (like if you pass it the string today instead of a real date), the jee server returns a 404 error.is this a good practice? is there a better way to do this that i'm not thinking of?",
    "present_kp": [
      "rest"
    ],
    "absent_kp": [
      "date format"
    ]
  },
  {
    "text": "scan line algorithm is too slow?. this is my code of the algorithm for making triangles :-private void sort(){ int temp = math.round(m_vertex1.getposition().getx()); int temp2 = math.round(m_vertex2.getposition().getx()); int temp3 = math.round(m_vertex3.getposition().getx()); m_minx = math.min(temp3, math.min(temp, temp2)); //sorting the x values m_maxx = math.max(temp3, math.max(temp, temp2)); temp = math.round(m_vertex1.getposition().gety()); temp2 = math.round(m_vertex2.getposition().gety()); temp3 = math.round(m_vertex3.getposition().gety()); m_miny = math.min(temp3, math.min(temp, temp2)); // sorting the y values m_maxy = math.max(temp3, math.max(temp, temp2));}public void drawtriangle(){ new line(m_vertex1, m_vertex2, m_display).drawline(optional.of(edgeonepoints)); //getting all the points on the boundary of the triangle new line(m_vertex2, m_vertex3, m_display).drawline(optional.of(edgetwopoints)); new line(m_vertex1, m_vertex3, m_display).drawline(optional.of(edgethreepoints)); vector2d start = vector2d.zero(); vector2d end = vector2d.zero(); for(float i = m_miny; i <= m_maxy ;i++){ //iterating from top to bottom of the triangle for(float j = m_minx; j <= m_maxx; j++){ //iterating left to right of the triangle vector2d temp = new vector2d(j,i); if(edgeonepoints.contains(temp) || edgetwopoints.contains(temp) || edgethreepoints.contains(temp)){ if(start.equals(vector2d.zero())){ // getting the first point of intersection between the triangle and the scanline start = temp; }else{ if(edgeonepoints.contains(start) && !edgeonepoints.contains(temp)){ // checking if start point and end point are on the same edge or not, if not then it is a valid point else not. end = temp; break; }else if(edgetwopoints.contains(start) && !edgetwopoints.contains(temp)){ end = temp; break; }else if(edgethreepoints.contains(start) && !edgethreepoints.contains(temp)){ end = temp; break; } } } } if(!start.equals(vector2d.zero()) && !end.equals(vector2d.zero())){ //if both start and end points are available then draw then fill all the points in between them. for(float j = start.getx(); j <= end.getx(); j++){ new point(new vector2d(j, i), pixeldata.white(), m_display).drawpoint(); } } start = vector2d.zero(); end = vector2d.zero(); }} now i have couple of problems with it :- it is a tortoise, i have tested it on a old machine and just with 2 rotating triangles, the frame rate is below 30.i get this weird line in between the triangle at some specific position when rotating the triangle. i don't care much about the second problem but can anyone help me making this algorithm fast. should i use something like flood fill or boundary fill algorithm ?",
    "present_kp": [
      "algorithm"
    ],
    "absent_kp": [
      "optimisation"
    ]
  },
  {
    "text": "dead keys not working in java swing applications. i'm currently using ubuntu 10.10 and netbeans 7.0 and i can't type accented letters with dead keys any more. it's not a version specific problem seems it's related with swing since i've got the same problem with older version of netbeans and os. when i type '+a on any app on linux i get a vowel. all linux apps are working fine, but netbeans doesn't. when i type '+a on netbeans i get a a vowel (no accent). i can't type quotes and double quotes either.but i got accents on netbeans using the right alt key. (that's not what i want)at terminal i got the following locale:lang=en_us.utf8lc_ctype=en_us.utf8lc_numeric=en_us.utf8lc_time=en_us.utf8lc_collate=en_us.utf8lc_monetary=en_us.utf8lc_messages=en_us.utf8lc_paper=en_us.utf8lc_name=en_us.utf8lc_address=en_us.utf8lc_telephone=en_us.utf8lc_measurement=en_us.utf8lc_identification=en_us.utf8lc_all=",
    "present_kp": [
      "java",
      "locale"
    ],
    "absent_kp": [
      "keyboard"
    ]
  },
  {
    "text": "on what name should i claim copyright in open source software?. when i want to use the apache 2.0 licence in my project, i should include this in the comments of my source code:copyright [yyyy] [name of copyright owner]licensed under the apache license, version 2.0 (the license);you may not use this file except in compliance with the license.you may obtain a copy of the license at <url> required by applicable law or agreed to in writing, softwaredistributed under the license is distributed on an as is basis,without warranties or conditions of any kind, either express or implied.see the license for the specific language governing permissions andlimitations under the license.what name should i fill in for [name of copyright owner]? i am currently working alone on this project, but i'm going to release the source code so there might be other contributors in the near future.",
    "present_kp": [
      "open source",
      "apache license"
    ],
    "absent_kp": [
      "licensing"
    ]
  },
  {
    "text": "priority value meaning. the library that i'm working on has a parameter which defines priority of a certain process. i want the interface to be as clear as possible, but it seems that different people have opposite interpretations of priority values.1. lowest number has highest priority (1 - highest priority, 10 - lowest priority)2. highest number has highest priority (1 - lowest priority, 10 - highest priority)which way do you think is more natural/logical?",
    "present_kp": [],
    "absent_kp": [
      "api",
      "libraries"
    ]
  },
  {
    "text": "intel turbo boost apparently activated for no reason?. the other day, i reinstalled my operating system (crunchbang, fork of debian). for some reason my fan has been running at full speed (and blowing colder-than-room-temperature air) even though i'm using less than 2% of my cpu.i've been told to try fancontrol, but after running sensors-detect, the only kernel module i need is coretemp, and it's already loaded by default. running pwmconfig says there are no available interfaces.i was also told to try cpu governors, but the only ones available (/sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors) are performance and powersave, and powersave is already the default.but today, i ran screenfetch (a program that displays system info), and under cpu, it said intel core i5-3230m cpu @ 3.2ghz. the i5-3230 is normally a 2.6ghz processor, but it supports turbo boost up to 3.2ghz when the processor is being used heavily. i went back and looked at some screenshots of screenfetch from my previous installs of this os on the same machine, when the fan was acting normal, and lo and behold, they said 2.6ghz just like they should. does that mean that the processor is overclocking itself for no reason, and quite possibly causing the fan to stay on full speed all the time? how could i fix this?",
    "present_kp": [
      "cpu",
      "fan"
    ],
    "absent_kp": [
      "linux",
      "acpi",
      "cpu frequency"
    ]
  },
  {
    "text": "c#/vb struct how to avoid case with zero default values, which is considered invalid for given structure?. how to implement some constrained .net struct/structure (let's say limitedstring), where its state with default values (set by clr to technical defaults, i.e. nulls, zeros, etc.) should be prohibited due to some design constraint?for example in case of trivial struct limitedstring, properties are string value and int maxlength = 10, where value of the maxlength property must be at least 1. value 0 is not allowed by design. but when i initalize the structure, i have 0 there. how to force value 10 into defaults?i see two options:throw exception in static (vb.net shared) parameterless constructor force using only costructor(s) with parameters. impractical, parameterless use is expected sometimes.add helper private field isinitialized and while it is false, assume default values, i.e. maxlength = 10. slightly higher complexity inside the struct.is option #2 a legitimate way or does this violate some design principles?is there some better way than option #2?edit: option #1 won't work anyway, mentioned constructor is called every time, even if other constructors are called.",
    "present_kp": [
      "c#",
      ".net",
      "vb.net"
    ],
    "absent_kp": [
      "data structures",
      "rules and constraints"
    ]
  },
  {
    "text": "bash if statement not working properly. i have a bash statement to test a command line argument. if the argument passed to the script is clean, then the script removes all .o files. otherwise, it builds a program. however, not matter what is passed (if anything), the script still thinks that the argument clean is being passed.#!/bin/bashif test 'whoami' != root ; then echo you must be logged in as root to build (for loopback mounting) echo enter 'su' or 'sudo bash' to switch to root exitfiarg=$1if [ $arg==clean ] ; then echo >>> cleaning up object files... rm -r src/*.o echo >>> done. echo >>> press enter to continue... readelse #builds programfi",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell",
      "shell script",
      "arguments"
    ]
  },
  {
    "text": "fixing a near singular covariance matrix. given a near singular covariance matrix, the standard method of 'fixing' it seems to be to add a small damping coefficient $c>0$ to the diagonal, which serves to bump all the eigenvalues up by this amount. is there a way to determine the optimal value of this damping coefficient without resorting to some iterative procedure where i jump back and forth between inverting the matrix to look for infinities and nans and making $c$ increasingly small?i could look at the minimum eigenvalue fairly cheaply, but it seems like the correct choice for $c$ would still also depend on both the entries of the matrix as well as its size.finally, it's more important that my algorithm always works than it is that the perturbation is as small as possible, so i'm willing to accept more error for the sake of a procedure with some sort of guarantee that it will always work.",
    "present_kp": [],
    "absent_kp": [
      "linear algebra",
      "numerical analysis",
      "matrices"
    ]
  },
  {
    "text": "smallest number divisible by all numbers from 1 to 20? project euler question 5. i'm currently working my way through the questions on project euler and i am on question 5. is this the best possible solution? any suggestions welcomed! list<int> divisors = new list<int>{ 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 }; int n = 1; while (true) { n++; foreach (int d in divisors) { if (n % d != 0) { break; } if (d==20) { console.write(n); console.readline(); } } }",
    "present_kp": [
      "project euler"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "do children inherit intelligence from their mothers and not their fathers?. this article, <url> suggests that children inherit intelligence from mothers, and that fathers have basically no role in that (except emotional and intuitional intelligence as they call it).since often journalists can misinterpret scientific studies, i am interested, if there are researchers in this field on this site, who can say to what extent is the statement in this article:children inherit intelligence only from their mothers and not their fathers - true?",
    "present_kp": [
      "intelligence"
    ],
    "absent_kp": [
      "cognitive psychology",
      "experimental psychology",
      "genetics"
    ]
  },
  {
    "text": "implementing the stochastic gradient descent algorithm of the softmax regression with only numpy. i am implementing the stochastic gradient descent algorithm. i think there is plenty of room for improvement.def array2onehot(x_shape, array, start=1): transfer a column to a matrix with each row being a onehot note that the array index defaults to start with 1 rather than 0 array += 1 - start if start != 1 else 0 onehot = np.zeros(x_shape) onehot[np.arange(x_shape[0]), array-1] = 1 return onehotdef stochastic_gradient_descent(self, batch, y): the batch contains both the x's and targets y is the output produced by the forward process using the x's in the batch ones = np.ones(batch.shape[0]) # add the bias to the x's x = np.column_stack(ones, batch[:, :-1]) t = array2onehot(x.shape, batch[:, -1]) m = self._batch_size # batch size is the size of the mini batch count = np.zeros(self._class_size) # class size is the amount of classes to predict delta = np.zeros(self._coefficients.shape) for i in range(m): k = batch[i, -1] - 1 count[k] += 1 delta[:, k] += x[i] * sum(np.multiply(t[i], y[i])) tmp = self._coefficients for i in count: if i == 0: tmp[:, i] = 0 delta = np.nan_to_num(delta / count) - 2 * self._penalty_rate * tmp self._coefficients -= delta",
    "present_kp": [
      "algorithm",
      "numpy"
    ],
    "absent_kp": [
      "python",
      "python 2.7",
      "machine learning"
    ]
  },
  {
    "text": "swap even/odd characters. i wrote some code to solve this problem <url> which basically states: take an even length string and swap all the even indexed characters. for example the string abcd should become badc. i'm looking for a general code review as i'm very new to f# and specifically i'd really like to get rid of the ignoredtuplevalue variable, it seems like a kludge to me. i'd also like to collapse the whole thing into one function but i was running into scoping issues with the stringbuilder.open systemopen system.text[<entrypoint>]let main argv = let numcases = console.readline() |> int for i = numcases downto 1 do let strin = console.readline() let pairs = seq.pairwise strin let ignoredtuplevalue = ('1', '1') let swappedtuples = pairs |> seq.mapi (fun idx pair -> if idx % 2 = 0 then let (a, b) = pair (b, a) else ignoredtuplevalue) let answer = seq.fold (fun (sb : stringbuilder) pair -> if pair <> ignoredtuplevalue then let (a, b) = pair sb.append(a) |> ignore sb.append(b) |> ignore sb) (new stringbuilder()) swappedtuples printfn %s (answer.tostring()) 0",
    "present_kp": [
      "f#"
    ],
    "absent_kp": [
      "strings",
      "programming challenge",
      "functional programming"
    ]
  },
  {
    "text": "where can i get a cheap database, no web hosting needed. possible duplicate:how to find web hosting that meets my requirements? i'm building an application which requires a fairly small online mysql database. i don't need any web hosting. what are some cheap options for an online database?****edit(a bit more about what i'll be using it for)***the database itself is very small it contains market statistics for 5 weeks of time. once a week the data will be updated, so that it always contains the most recent 5 weeks.*then i will use the data in that to create an xml file which is generated with php. the xml file will need to be accessed hundreds-thousands of times per month.**",
    "present_kp": [
      "web hosting",
      "database"
    ],
    "absent_kp": []
  },
  {
    "text": "using a trademark as a subdomain?. let's imagine a website that deals with cars: <url> order to categorize his website, the webmaster decides to create subdomains for the most famous brands:ford.cars.comchrysler.cars.comferrari.cars.comwould it be legit?",
    "present_kp": [
      "subdomain"
    ],
    "absent_kp": [
      "legal",
      "branding",
      "infringement"
    ]
  },
  {
    "text": "users that disliked my facebook page. is it possible to access stats about who and when disliked my page on facebook? i looked through menu at facebook, but i cannot find anything about this.",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": [
      "facebook pages"
    ]
  },
  {
    "text": "can i keep track of page version/variation for comments on disqus?. i have a site where i'd like to integrate user commenting.each page on the site has a version/variation of some sort -- think of an app version, an operating system the user has the app for, or the branding name and year model of a motor vehicle (or maybe even the country or language the user is from).i am thinking that in the start, i'd like to keep all the comments together (perhaps apart from the language ones), regardless of which version of the page the user is looking at, to make sure the place doesn't just look completely deserted.at the same time, i also worry that with the growth, all the mixed-version comments may become burdensome, as they'd be containing incorrectly classified or outdated information; and that'll be the perfect time to split them up to appear only on the pages of their respective versions, where such outdated information would still be very relevant to the outdated product being described (e.g., for archival purposes).is there a way for disqus to keep this extra information about which version/variation of the page the comment is being written or voted on, whilst still having the option to present all such comments at each variation of the page all together?just to make it clear -- there will be about 10k pages (each must always have their own thread), each page will have about 3 to 4 major variations (like a brand-name vendor of an oem product), and each major variation will independently have 10 to 30 minor ones (like monthly or early updates/releases).so, from the example above, what i'd like to do is keep track of comments for every version, but originally show them all together in just 10k threads (but also have the ability to filter things down as needed). can disqus do it? or what else could i use?",
    "present_kp": [
      "comments",
      "disqus"
    ],
    "absent_kp": [
      "versioning"
    ]
  },
  {
    "text": "how is it possible to have limitless availability of threads while only having a finite number of physical processing units?. so i'm having trouble understanding the relationship between threads (software) and processor cores (hardware).basically my understanding of a processor core is a unit that deals with commands and is essentially what executes them. a processor with 2 cores operating at 1 khz can execute 2000 commands per second, right? this must mean that the 2 cores are simultaneously executing a thousand commands per second.then there are software threads, which allow a programmer to execute code simultaneously, however they are not limited (theoretically).i can't understand how is it possible to have limitless availability of threads that execute commands simultaneously while only having a finite number of physical units that do so?",
    "present_kp": [
      "hardware",
      "process"
    ],
    "absent_kp": [
      "multithreading"
    ]
  },
  {
    "text": "does a hadamard gate have uses outside of pure and evenly mixed states?. the standard usage cases for the hadamard gate seem to be passing a pure $|0 angle$ or $|1 angle$ state in to get an even amplitude (probability) mixed state which has either matching or mismatching phase.the other use of course, is to take such an even amplitude mixed state, pass it through the hadamard gate, and get back a pure $|0 angle$ or $|1 angle$ state.this of course scales up to multiple qubits.are there any other usage cases for the hadamard gate? i'm wondering if say you had an uneven amplitude qubit, would passing it through a hadamard gate do anything useful? or the same question with multiple qubits, that had varying amplitudes of states.thanks!",
    "present_kp": [],
    "absent_kp": [
      "quantum computing"
    ]
  },
  {
    "text": "web page with draggable boxes in a grid. i have the following code in jsfiddle. i have been told this this code is messy and not optimised. my question is, what about this is messy and unoptimised and how can it be tidied up and optimised to reduce file size and so it becomes more responsive?$(document).ready(function() { $( .column ).sortable({ connectwith: .column, handle: .widget_header_icon, .widget_header_title, start: function( event, ui ) { $('.menu_button.active, .configure_button.active').click(); $('.menu_button, .configure_button').removeclass(active); } }); $(document).click(function(event) { $('.menu_button.active, .configure_button.active').click(); $('.menu_button, .configure_button').removeclass(active); }); $('.dropdown_left, dropdown_right').each(function() { $(this).css('left', $(this).prev().position().left); }); $('.menu_button, .configure_button').click(function(event) { $(this).siblings('.menu_button.active, .configure_button.active').click(); $(this).toggleclass('active').next().toggle(); event.stoppropagation(); }); $('.widget_configure_button').click(function(event) { var $nav3 = $(this), $dd = $nav3.next('.dropdown'); $nav3.toggleclass('active'); $dd.css({ top: $nav3.outerheight()+10, right: 10 }); $nav3.hasclass('active') ? $dd.show() : $dd.hide(); });});/* <url> v2.0 | 20110126 license: none (public domain)*/html, body, div, span, applet, object, iframe,h1, h2, h3, h4, h5, h6, p, blockquote, pre,a, abbr, acronym, address, big, cite, code,del, dfn, em, img, ins, kbd, q, s, samp,small, strike, strong, sub, sup, tt, var,b, u, i, center,dl, dt, dd, ol, ul, li,fieldset, form, label, legend,table, caption, tbody, tfoot, thead, tr, th, td,article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary,time, mark, audio, video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; font-family:arial; font-size:12px;}/* html5 display-role reset for older browsers */article, aside, details, figcaption, figure, footer, header, hgroup, menu, nav, section { display: block;}body { line-height: 1;}ol, ul { list-style: none;}blockquote, q { quotes: none;}blockquote:before, blockquote:after,q:before, q:after { content: ''; content: none;}table { border-collapse: collapse; border-spacing: 0;}/**/body{ background:#f5f5f5;}.notification{ background:#ffffff;}.inner_notification{ width:983px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; padding:10px; background:#eeeeee;}.header{ background:#eeeeee;}.inner_header{ width:983px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; padding:10px; background:#dddddd;}.top_menu{ background:#dddddd;}.inner_top_menu{ width:1003px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; position: relative; background:#cccccc;}.menu_button { float:left; padding:10px; cursor:pointer;}.configure_button { float:right; padding:10px; cursor:pointer;}.widget_configure_button { float:right; padding:10px; cursor:pointer;}.menu_button::selection, .configure_button::selection, .widget_configure_button::selection { background:transparent; }.menu_button::-moz-selection, .configure_button::-moz-selection, .widget_configure_button::-moz-selection { background:transparent; }.menu_button:hover, .configure_button:hover, .widget_configure_button:hover { background-color:#ffffff;}.menu_button.active, .configure_button.active, .widget_configure_button.active { padding:10px; background-color:#ffffff; z-index:1;}.dropdown { display:none; background-color:#ffffff; position:absolute; top:40px; padding:10px; cursor:pointer;}.dropdown_left { display:none; background-color:#ffffff; position:absolute; top:32px; padding:10px; cursor:pointer; z-index:20;}.dropdown_right { left: auto ! important; right: 0;}.clearfix{ clear:both;}.title{ background:#cccccc;}.inner_title{ width:983px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; padding:10px; background:#bbbbbb;}.content{ background:#bbbbbb;}.inner_content{ width:993px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; padding:10px 0px 0px 10px; background:#aaaaaa;}.column{ width:331px; float:left;}.widget{ background:#eeeeee; padding:10px; margin-bottom:10px; margin-right:10px; position:relative; z-index:10;}.widget_header{ background:#dddddd; margin-bottom:10px; overflow: hidden;}.widget_header_icon{ padding:10px; float:left; cursor:move;}.widget_header_title{ padding:10px; float:left; cursor:move; background:#cccccc; width:210px;}.widget_sub_header{ background:#dddddd; margin-bottom:10px; padding:10px; overflow: hidden;}.widget_content{ background:#cccccc; padding:10px; margin-bottom:10px; height:200px;}.widget_footer{ background:#bbbbbb; padding:10px;}.footer{ background:#aaaaaa;}.inner_footer{ width:983px; /*1003 max width without horizontal scroll for 1024x768 screens*/ margin:auto; padding:10px; background:#999999;}/*-------------*/.ui-sortable-placeholder { background:#bbbbbb; visibility: visible !important; }.ui-sortable-placeholder * { visibility: hidden; }/*------------*/<!doctype html public -//w3c//dtd html 4.01//en <url> <head> <meta http-equiv=content-type content=text/html; charset=utf-8> <title></title> <script type=text/javascript src=jquery.min.js></script> <script type=text/javascript src=jquery-ui.min.js></script> <script type=text/javascript src=script.js></script> <link type=text/css href=style.css rel=stylesheet /> </head> <body> <div class=notification> <div class=inner_notification> notification </div> </div> <div class=header> <div class=inner_header> header </div> </div> <div class=top_menu> <div class=inner_top_menu> <div class=menu_button>menu</div> <div class=dropdown_left> <div>icon default 2</div> <div>icon reports 2</div> <div>icon other 2</div> </div> <div class=configure_button>(c)</div> <div class=dropdown_left dropdown_right> <div>icon default 2</div> <div>icon reports 2</div> <div>icon other 2</div> </div> <div class=clearfix></div> </div> </div> <div class=title> <div class=inner_title> title </div> </div> <div class=content> <div class=inner_content> <div class=column> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> </div> <div class=column> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> </div> <div class=column> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> <div class=widget> <div class=widget_header> <div class=widget_header_icon>( i )</div> <div class=widget_header_title>header title</div> <div class=widget_configure_button>(c)</div> <div class=dropdown> <div>icon default 3</div> </div> </div> <div class=widget_sub_header> sub header </div> <div class=widget_content> content </div> <div class=widget_footer> footer </div> </div> </div> <div class=clearfix></div> </div> </div> <div class=footer> <div class=inner_footer> footer </div> </div> </body> </html>",
    "present_kp": [
      "javascript",
      "jquery",
      "html",
      "css"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "is there a wiki bot for deleting articles based on a regex?. my problem is that i have added many (about 200) images with a wiki bot to our company's wiki, a mediawiki. now i want to delete all the images i have uploaded. i gave them all a name with a specified prefix. i planned to use the prefix to delete them. the problem now is that mediawiki doesn't provide a function for deleting multiple articles.my idea was to use a wiki bot to do this task. but before i'm starting to write an, own i want to ask: is there such a bot already? i'm looking for a wiki bot that could delete articles in mediawiki based on a regex. does anybody know such a tool?",
    "present_kp": [
      "delete",
      "wiki",
      "mediawiki"
    ],
    "absent_kp": []
  },
  {
    "text": "what licence should i use for internal projects?. i need to package an internal project as a debian package. that project will never ever be downloaded by anyone outside of our company, but the debian packaging system insists on there being a copyright file.what should i choose for this file? there's a remote possibility that a sysadmin could stumble upon that package and would like to read its licence. what should it then read?",
    "present_kp": [],
    "absent_kp": [
      "licensing"
    ]
  },
  {
    "text": "how does mkswap work? what is in the swap header it creates?. i am looking at mkswap and trying to understand how exactly it works. from what i understand, it sets up swap space on a partition by creating a swap header. how large is this swap header? is it one block? or is it always a consistent size?i did try looking through the mkswap.c source code, but my c-knowledge is not enough to understand it. specifically, i think the following line writes out the swap header:strncpy((char*)signature_page+page_size-10,swap-space,10);",
    "present_kp": [
      "swap"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "debian - screen orientation on tilt. i have an hp pavilion g6 laptop which i've been running debian on for roughly 2-3 years now, with the cinnamon de.i've updated it to debian testing as i was having a couple of issue with the graphics driver for my amd a8 apu. i've only just discovered (after 4 months) that the screen will change it's orientation based on the laptops orientation.i've already gone to this question, which has described what is happening, and why it happens. all of that is great, except for the fact that the orientation is all wrong. i'ts out by 90 degrees. when i lilt the laptop from bottom to the sky, it orientates the screen 90 degrees anti-clockwise, when i would expect a full 180 degrees.i like this feature, and i want to get it working properly, but i just don't have a good enough knowledge on iio and udev/dbus to do that.this is the output of udevadm containing this particular device: p: /devices/platform/lis3lv02d/input/input8 e: abs=7 e: devpath=/devices/platform/lis3lv02d/input/input8 e: ev=9 e: id_for_seat=input-platform-lis3lv02d e: id_input=1 e: id_input_accelerometer=1 e: id_path=platform-lis3lv02d e: id_path_tag=platform-lis3lv02d e: iio_sensor_proxy_type=input-accel e: modalias=input:b0019v0000p0000e0000-e0,3,kra0,1,2,mlsfw e: name=st lis3lv02dl accelerometer e: phys=lis3lv02d/input0 e: product=19/0/0/0 e: prop=0 e: subsystem=input e: systemd_wants=iio-sensor-proxy.serviceany help regarding this would be much appreciated.edit: thought i'd add these values from looking at iio-sensor-proxy for laptop in different 90 degree orientations: y x z 0 0 1 -- home position 0 1 0 -- right-up 0 -1 0 -- left-up 1 0 0 -- bottom-up -1 0 0 -- top-upwhere 1 = max (roughly a value of 1200) and -1 = minimum (roughly a value of -1200)edit: to clarify as per first comment, orientation is not being detected correctly by iio-sensor-proxy. when i observe the output of monitor-sensor this is what is observed:expected -- realitybottom-up = bottom-up -- bottom-up = right-upright-up = right-up -- right-up = bottom-uptop-up = top-up -- top-up = left-upleft-up = left-up -- left-up = top-uptop-up == neutral position",
    "present_kp": [
      "debian",
      "cinnamon"
    ],
    "absent_kp": []
  },
  {
    "text": "javascript or get request, what is best for seo?. i small navigation bar (just 2 tabs: aluminio lacado and cobre natural) inside one of the sections of a website.i'm wondering if, in this small nav bar, i should create normal links that request the content to the server or just create a javascript code that switch the content.i like more the second option but i don't know what is better thinking in seo, since i would have to set display:none to the hidden content...javi",
    "present_kp": [
      "seo"
    ],
    "absent_kp": []
  },
  {
    "text": "how to do inter process communication using single bidirectional pipe in linux?. how do 2 processes communicate by using single bidirectional pipe, such that both the ends of the pipe could read and write.i have an assignment to do, kindly help me with this.",
    "present_kp": [
      "pipe"
    ],
    "absent_kp": [
      "ipc"
    ]
  },
  {
    "text": "guest-agent vs spice agent. which is the difference between the guest agent qemu-ga-x64.msi and the spice agent = couple vdservice + vdagent for a windows guest ?are they exclusive ou complementary ?",
    "present_kp": [
      "qemu",
      "spice"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i move a client from ui mockups to a set of real requirements?. say you are given a mock-up of 25 screens of the visual states of your application. the expectation is that this is enough for us to be confident we can develop and hand it to the original stakeholder or customer as a finished application, and they will be satisfied. naturally, you're going to end up asking the stakeholders many questions over again that were used to come up with the ui, which is wasteful.however, i have many many times found that this is very much not enough, in the course of developing the application the requirements become blurred by the fact that we are replicating an interface and in the end the customer is not as happy as they first seemed when we asked them for all the info to create the ui.i am just not sure what else to ask for, i have tried to be specific and ask for requirements and an understanding of the overall goal, but i don't know what i should ask for. if i just start now, lots of time is going to be wasted re-hashing all the info that lead up to the ui and during this phase many important reasons the customer originally had will be lost.how can i get people to understand that we cannot lock down requirements based on ui mock-ups by asking for something actionable they can create for me?what would you ideally start with in order to properly execute the task of developing an application for end users?",
    "present_kp": [],
    "absent_kp": [
      "design",
      "specifications"
    ]
  },
  {
    "text": "example sites which use ucc certificates. can anyone point me to a few sites that make use of a ucc (san) certificates? i tried to search for this but found a lot of information about ucc certficates without any examples. as a sanity check before buying/configuring a ucc certificate, i wish to do some basic testing to determine exactly how the certificate will look in different browsers.yes, i realize i could just use makecert instead. i would rather just look at them in the wild.",
    "present_kp": [
      "ucc certificate"
    ],
    "absent_kp": [
      "https",
      "security certificate"
    ]
  },
  {
    "text": "google contacts date format for birthdays, without the year, which date formats work?. for example, if you enter the birthday in google contacts as 13 may or may 13 or 13/5 or 1305 or 13.05will the birthday flow through to google calendars?",
    "present_kp": [
      "google calendar",
      "google contacts"
    ],
    "absent_kp": []
  },
  {
    "text": "fast c++ library to solve very big sparse systems. i am working on a project with electrical circuits, where i am trying to compute the voltages at all the nodes of an electrical circuit. i know that the electrical circuit is a perfect grid, so each node only touches at most 8 other nodes. which means that i endup trying to solve a system:l v = iwhere l is at least a 1000x1000 matrix where each row has only 9 non-zeros. so, it's really really sparse.i have tried solving it using soplex, lapack and superlu (these last 2 through armadillo). but all are too slow. on a 10000x10000 the best i have is 18s.i know there is another software that does the same task as mine, written in python that uses scipy (scipy.sparse.linalg to be precise) that is ridiculously fast (can solve those systems in less than one second). is there a library that is equivalent to scipy or a way of porting scipy to c++? i need to write the software in c++, for other reasons...edit: my code to call superlu/lapack through armadillo is simply:voltages[i] = spsolve(laplacians[i],iflow[i],lapack);or voltages[i] = spsolve(laplacians[i],iflow[i],superlu);no options have been given before.",
    "present_kp": [
      "sparse",
      "scipy",
      "lapack"
    ],
    "absent_kp": [
      "linear solver"
    ]
  },
  {
    "text": "turn over cards in minimum number of steps. imagine you're given an array of cards. some of them are facing down (0), while some of them are facing up (1). is it possible for given fixed k to turn all the cards face-up by turning over any k consecutive cards? if it's possible what's the minimum number of steps?for example:n=6; k=3;1 0 0 1 0 0it is possible to make all the cards facing up, by first turning over cards 2-3-4 and then turning over cards 4-5-6. and the minimum number of steps is 2.my idea was to iterate through the sequence and when i'll find a 0 then i flip the next k cards (if it's possible), including the 0. but it seems that this idea doesn't work always. for example:n=56; k=50 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0is one counter-example. since after i perform the above-mentioned algorithm i end up with all the cards faced up, except for the last one.this is a contest problem, so one of the test cases is:1000 250 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0the supposed right answer is 441, while my algorithm says is 443.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "problem solving"
    ]
  },
  {
    "text": "using libraries with gpl license. this may be a simple question, but when using libraries that are licensed under gpl, i'm not sure what part of the license applies.i have two separate libraries in a jar file that i'm using that i'm distributing with my software. neither libraries came with a license file. i modified one of the libraries by removing some of the files from the jar (examples, tests, etc). my software is also open source but is not licensed.is there anything else i need to do to abide by the gpl license of the libraries i'm using?",
    "present_kp": [
      "gpl"
    ],
    "absent_kp": []
  },
  {
    "text": "invent custom filename extension for derived format. say i use a predefined serialization format x for certain data. should i indicate the application in a custom filename extension or not? it is quite commonpk3 is a zip archivexsl, svg and many others are xml filessome files are ini filesit is practical to denote the purpose of the file, buti am unhappy to invent another filename extension (there are already too many)it hides the fact that the user can use any program that can read and write x can be used to manipulate data (obfuscation)i am interested in what is recommended in the following scenarios:program configuration datainput files for code generation scriptssaved program stateplug-in bundle zip archive",
    "present_kp": [],
    "absent_kp": [
      "programming practices",
      "conventions"
    ]
  },
  {
    "text": "exact answer for what is j2ee? - job interview. i'd like to ask if someone of you knows the exact meaning of jee. that's because a collegue of mine was asked this question in a job interview, and was unable to answer properly... to speak with his interwiewer's words. and when he told me what he said to his interviewer i got really surprised, since it was more or less what i would have answered myself - in a concise form, the first paragraph of this article.j2ee (java 2 platform, enterprise edition) is a java platform designed for the mainframe-scale computing typical of large enterprises. sun microsystems (together with industry partners such as ibm) designed j2ee to simplify application development in a thin client tiered environment. j2ee simplifies application development and decreases the need for programming and programmer training by creating standardized, reusable modular components and by enabling the tier to handle many aspects of programming automatically.that seems not to be enough, since the interviewer asked for more precise and less general definition.is there really a more precise definition for jee? or did my colleague just find the fussiest-interviewer-ever? :)",
    "present_kp": [
      "java",
      "interview"
    ],
    "absent_kp": [
      "java ee"
    ]
  },
  {
    "text": "facebook chat contacts mixed up. earlier this week, my chat contacts on facebook's sidebar got mixed up. the upper part, where my most frequently contacted friends are usually located, was replaced by the bottom part, that is, more friends online. and the bottom part was replaced by the top part. a bit later then, i completely lost any sight on my most contacted friends. now both my sections are filled with people i don't really talk to. the second section is always online. this happens on different computers (work / home) and different browsers on each of these computers. this is the second time that this happens to me. the last time it corrected itself after a week or so. i'd like to find what is causing it and a way to fix it.",
    "present_kp": [
      "facebook",
      "chat",
      "contacts"
    ],
    "absent_kp": []
  },
  {
    "text": "clustering algorithm for a congruence relation?. say we are given a congruence relation$~\\sim$ in a dataset with $n$ elements. i am looking for an algorithm for optimally sorting the $n$ elements into $m$ clusters according to given congruence relations. for instance if the data contains ${a,b,c,d,e,f,g,h}$, and: $$a\\sim b,\\ d\\sim b,\\ e \\sim h,\\ f \\sim c$$ the data should be sorted into the following clusters:$$\\{a,b,d\\},\\ \\{c,f\\},\\ \\{e,h\\},\\ \\{g\\}$$as said i'm looking for an efficient algorithm to solve this, i am led to believe this can be done in $o(n)$, but i can't seem to work out the details.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "complexity"
    ]
  },
  {
    "text": "not getting desired output with cut command?. [root@localhost ~]# ps aux | grep ataroot 19 0.0 0.0 0 0 ? s 07:52 0:00 [ata/0]root 20 0.0 0.0 0 0 ? s 07:52 0:00 [ata_aux]root 1655 0.0 2.6 22144 13556 tty1 ss+ 07:53 0:18 /usr/bin/xorg :0 -nr -verbose -auth /var/run/gdm/auth-for-gdm-t1gmcu/database -nolisten tcp vt1root 3180 0.0 0.1 4312 728 pts/0 s+ 14:09 0:00 grep ata[root@localhost ~]# ps aux | grep ata | cut -d -f 2[root@localhost ~]#i would expect second column in the output; but not getting anything. any ideas ?",
    "present_kp": [
      "cut"
    ],
    "absent_kp": [
      "filter"
    ]
  },
  {
    "text": "how to develop an effective notation for a partially ordered logic?. i am developing a logic for reasoning about programs in a resource-constrained environment. my starting point is intuitionistic linear logic, but i made the following changes:in intuitionistic linear logic, environments are sets of available resources. in my logic, environments are partially ordered sets: some resources have to be consumed before others.multiplicative conjunction splits into two connectives: parallel conjunction and sequential conjunction.linear implication can only consume a resource x, if there is no other resource y that must be consumed before x.logical connectives are usually defined in terms of introduction and elimination rules. in my logic, i need a new kind of rule: usage rules, which describe how a resource can be used in a computation without destroying it.i add a new unary operator, called borrowed pointer, which denotes a non-owning reference to an existing resource.creating a borrowed pointer uses but does not consume the resource being pointed. in particular, one may always create a borrowed pointer to an existing resource x, even if there is some resource y that must be consumed before x.no resource may be consumed until all borrowed pointers to it have been consumed. this is my main motivation for introducing the notion of sequential conjunction in the first place.i want to give a formal presentation of the rules of inference of this logic using natural deduction and sequent calculus. however, i am having trouble coming up with a good notation that succinctly conveys ideas like:the environment $\\gamma$ can be split into sub-environments $\\delta, \\sigma$, where there is no resource in $\\sigma$ that must be consumed before any resource in $\\delta$.given the environment $\\gamma$ and a resource $a \\in \\gamma$, the result of adding a resource ${ m ref} a$ to $\\gamma$, in such a way that ${ m ref} a$ must be consumed before $a$.the sequential conjunction of $a$ and $b$.etc.what guidelines should i follow in order to design a good notation for this logic?",
    "present_kp": [
      "notation",
      "sequent calculus",
      "natural deduction"
    ],
    "absent_kp": [
      "lo.logic"
    ]
  },
  {
    "text": "how can options be parsed in a bash script, leaving unrecognized options after the --?. i'm looking for a way to do option parsing in a bash script (allowing for both short and long arguments as getopt does) that stops parsing at the first unrecognized argument, places a -- before that first unrecognized argument, and then copies the remaining arguments to the output string.for example, here's the behavior that i want:% options=(-u name1 --username=name2 -x a -u b c)% getopt -o u: -l username: -n programname -- ${options[@]}-u 'name1' --username 'name2' -- -x 'a' -u 'b' 'c'%the utility getopt does not work this way, and instead emits the following:programname: invalid option -- 'x'-u 'name1' --username 'name2' -u 'b' -- 'a' 'c'note that i do not want arguments that follow an unrecognized option to be reordered as if they were recognized, as is demonstrated above with the second -u option. i'm hoping that someone will have a solution that will give the results i demonstrate in the first code block above. any ideas?environment: bash 4.2.46(1), centos 7.2 @3.10.0-327.36.1.el7.x86_64.requirements: centos 7.2 minimal with no additional software to be installed with all code written in a bash script. the options passed to the options parser are not required to include -- in them (that is, the termination of parsing should be automatic).",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "shell script",
      "getopts"
    ]
  },
  {
    "text": "difference between fit and fit_transform in scikit_learn models?. i am newbie to data science and i do not understand the difference between fit and fit_transform methods in scikit learn.i have seen similar questions but i did not get intuition from answers. can anybody simply explain why we might need to transform data?what does it mean fitting model on training data and transforming to test data.does it mean for example converting categorical variables into numbers in train and transform new feature set to test data?any help would be really appreciated. please do not refer to scikit learn documentations. try to explain as simple as possible on your own words :)",
    "present_kp": [
      "scikit learn"
    ],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "advances towards proving the held-karp conjecture for tsp. i've only began my research into the held-karp conjecture and i was wondering about recent progress in proving the conjecture.the held-karp relaxation is conjectured to have an integrality gap of $ rac{4}{3}$ for symmetric tsp.there have been some recent advances in proving this conjecture. among these include the 4/3 conjecture for metric tsp was proved for cubic and subcubic graphs by boyd et. al. <url> for the class of graphs that are degree-3 bounded and are claw-free, the held-karp relaxation yields a 4/3 approximation ratio as proven by momke et. al. : <url> qian et.al. (<url>) proved that for a special case of graphs with all edges have cost $1$ or $2$, there exists a bound of 10/9. i would very much appreciate if anyone with more expertise in this research topic would point out other recent research advances in proving the held-karp conjecture. links and/or titles to research papers would be very helpful.",
    "present_kp": [
      "tsp"
    ],
    "absent_kp": [
      "graph theory",
      "np hardness",
      "approximation algorithms"
    ]
  },
  {
    "text": "efficient irreversible serialization?. suppose we have a function f that gets a complex (non-flat) object as an input, serializes it, calculates hash of serialization results (e.g. md5) and returns calculated hash.it may use some exiting serialization method, e.g. msgpack.but are there any known techniques that may be more efficient than full (reversible) serialization and preserve f's properties as a hashing function (e.g., collision probability)?",
    "present_kp": [
      "hashing",
      "serialization"
    ],
    "absent_kp": []
  },
  {
    "text": "reduce repetitive code in lotto simulator. i'm extremely new to java, and i had a bit of an attempt at making something that you could call lotto. i've still got a lot more to go on it, but things are becoming tedious, and i am sure there is a simpler way to do what i am doing. how can this code be changed to have less repetitive code/optimized?import java.util.random;import java.util.scanner;public class lotto { //pick 6 numbers from 1 to 100 //if all of your numbers gets called out, you win public static void wait (int n) { long t0,t1; t0=system.currenttimemillis(); do{ t1=system.currenttimemillis(); } while (t1-t0<1000); } public static void main(string[] args) { random rand = new random(); scanner numscan1 = new scanner(system.in); scanner numscan2 = new scanner(system.in); scanner numscan3 = new scanner(system.in); scanner numscan4 = new scanner(system.in); scanner numscan5 = new scanner(system.in); scanner numscan6 = new scanner(system.in); boolean num1cor = false; boolean num2cor = false; boolean num3cor = false; boolean num4cor = false; boolean num5cor = false; boolean num6cor = false; system.out.print(pick 6 numbers from 0 to 25. pick your first number: ); int num1 = numscan1.nextint(); system.out.println(); system.out.print(pick your second number: ); int num2 = numscan2.nextint(); system.out.println(); system.out.print(pick your third number: ); int num3 = numscan3.nextint(); system.out.println(); system.out.print(pick your fourth number: ); int num4 = numscan4.nextint(); system.out.println(); system.out.print(pick your fifth number: ); int num5 = numscan5.nextint(); system.out.println(); system.out.print(pick your final number: ); int num6 = numscan6.nextint(); system.out.println(numbers will now start to be drawn, if all of your numbers are called, you win.); while (true) { int random = rand.nextint(25); system.out.println(number + random + .); if (random == num1) { num1cor = true; system.out.println(your number, + num1 + , has been called.); } else if (random == num2) { num2cor = true; system.out.println(your number, + num2 + , has been called.); } else if (random == num3) { num3cor = true; system.out.println(your number, + num3 + , has been called.); } else if (random == num4) { num4cor = true; system.out.println(your number, + num4 + , has been called.); } else if (random == num5) { num5cor = true; system.out.println(your number, + num5 + , has been called.); } else if (random == num6) { num6cor = true; system.out.println(your number, + num6 + , has been called.); } if (num1cor == true && num2cor == true && num3cor == true && num4cor == true && num5cor == true && num6cor == true) { system.out.println(you win!!); break; } wait(100); } }}",
    "present_kp": [
      "java",
      "random"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "how to recall a previous command (without execution) in order to change it?. i can't remember the trick where i could get the last command without running it:let's say i want to be be able to access the command !1255 when pressing the up arrow key and modify the command. so what's the trick to call the command, make it be shown up in the command line but not executed and afterwards accessible via the arrow key up?i tried with putting an echo, but then i have an echo before the command, i don't remember how to do it correctly.",
    "present_kp": [
      "command line",
      "command"
    ],
    "absent_kp": [
      "terminal",
      "command history",
      "history expansion"
    ]
  },
  {
    "text": "sorting an array where half of the elements are at their correct position. by the statement of the question i am trying to generalize the structure of the array.for me being at their correct position means they can't be shifted. i tried to come up with a few examples and deducted such an array has to be 2-sorted or all the sorted elements are in the first half. for a k-sorted array we can use insertion sort or heap sort with a heap of size k, but first i need to make some generalization about the structure of the array. how do we go about proving it formally? intuitive explanation would work too.",
    "present_kp": [
      "sorting"
    ],
    "absent_kp": [
      "algorithms",
      "arrays"
    ]
  },
  {
    "text": "how to run a shell script with export command in crontab. i have a shell script that exports values of variables when executed. the same values will be used in another script.how to run this script(test.sh) in cron.#!/bin/shexport i=10echo $ii will be using root access for cron.i tried this command : */5 * * * * /home/ubuntu/backup/.test.shi checked with environment variables, nothing is updated.",
    "present_kp": [
      "shell",
      "shell script",
      "cron",
      "environment variables"
    ],
    "absent_kp": []
  },
  {
    "text": "how to show the percentage progress of script execution in unix?. suppose you run some script such as a perl or tcl. for example, $ ./script.sh; ./script.pl; source script.tcl. it takes some time to get executed and return to prompt. how to display the percentage of execution meanwhile the execution?below you can find an example ui. it displays the execution time taken for the script at the end.1% completed the exectuion of script.pl2% completed the exectuion of script.pl. . . .100% completed the the exectuion of script.plex: execution time for script.pl is :50 seconds",
    "present_kp": [],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "generic polling class and using it to poll sqlconnection. i have the following poller class that can be used to poll the required action:public class poller{ private readonly string name; private readonly action action; private readonly int pollinginterval; private readonly thread pollingthread; private readonly autoresetevent stopevent; private readonly manualreseteventslim pauseevent; private readonly object locker = new object(); private pollerstate pollerstate; public poller(string name, action action, int pollinginterval) : this(name, action, pollinginterval, true) { } public poller(string name, action action, int pollinginterval, bool isbackground) { this.name = name; this.action = action; this.pollinginterval = pollinginterval; stopevent = new autoresetevent(false); pauseevent = new manualreseteventslim(false); pollingthread = new thread(dowork) { name = name, isbackground = isbackground }; } public void start() { pollerstate = pollerstate.running; pollingthread.start(); } public void start(int duetime) { new timer(o => start(), null, duetime, timeout.infinite); } public void stop() { lock (locker) { if (pollerstate != pollerstate.running && pollerstate != pollerstate.pauserequested) log.trace(poller.stop(): stop requested on + $\\{name}\\, current state {pollerstate}); pollerstate = pollerstate.stoprequested; stopevent.set(); pauseevent.set(); } } public void pause() { lock (locker) { if (pollerstate != pollerstate.running) log.trace(poller.stop(): pause requested on + $\\{name}\\, current state {pollerstate}); pauseevent.reset(); pollerstate = pollerstate.pauserequested; } } public void continue() { lock (locker) { // applicable if job is long running or no new poll was needed since pause requested. if (pollerstate == pollerstate.pauserequested) pollerstate = pollerstate.running; else if (pollerstate != pollerstate.paused) { log.trace(poller.stop(): continue requested on + $\\{name}\\, current state {pollerstate}); } pauseevent.set(); } } private void dowork() { while (pollerstate == pollerstate.running) { try { action(); } catch (exception ex) { log.error(ex); } finally { if (stopevent.waitone(pollinginterval)) { if (pollerstate == pollerstate.stoprequested) pollerstate = pollerstate.stopped; } if (pollerstate == pollerstate.pauserequested) { pollerstate = pollerstate.paused; pauseevent.wait(); // continue only if we are still in pause mode and not stoprequested. if (pollerstate == pollerstate.paused) pollerstate = pollerstate.running; } } } log.trace($poller.stop(): exiting \\{name}\\ poller); }}public enum pollerstate{ notstarted = 0, running, pauserequested, paused, stoprequested, stopped};firstly, i want to know how this could be improved. second, i want to use this to poll whether an sqlconnection is active or has connectionstate.open. to do this i wrote a little test class to test the poller:[testclass]public class pollertests{ private sqlconnection connection; private const string connectionstring = data source=localhost;initial catalog=master;integrated security=true; + multipleactiveresultsets=true;connection timeout = 0; private manualreseteventslim connectionseveredevent; private timer severedtimer; [testinitialize] public void initialize() { connectionseveredevent = new manualreseteventslim(false); connection = new sqlconnection(connectionstring); connection.open(); } [testcleanup] public void cleanup() { connection.dispose(); } [testmethod] public void sqlconnectionstatepollertest() { poller sqlconnectionpoller = new poller(sqlconnection, testconnectionwithoutput, 10); sqlconnectionpoller.start(); connectionseveredevent.wait(); assert.istrue(connectionseveredevent.isset); assert.istrue(connection.state == connectionstate.closed); } private void testconnectionwithoutput() { bool ok = connection.testconnectionstateopen(); if (!ok) connectionseveredevent.set(); else { if (connection.state == connectionstate.open) connection.close(); } }}this does one itteration of the poller, on the second it sets the connection state to closed and the reset event is set and the test passes. the test code is:public static someutilitycalss{ public static bool testconnectionstateopen(this sqlconnection connection) { if (connection.state == connectionstate.closed) return false; string sql = select 1;; return sqlhelper.executescalar<int>(connection, commandtype.text, sql) == 1; }}any comments on this code would be appreciated. particularly, on my use of thread over task...",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "sql server"
    ]
  },
  {
    "text": "how can i prime aversion to conflict?. i'm looking for a way to prime subjects in an experiment to dislike exposure to conflict (arguments, anger between people, incivility, etc.). does anyone know of a good method for this?",
    "present_kp": [],
    "absent_kp": [
      "social psychology"
    ]
  },
  {
    "text": "anti-depressant medicine and memory loss. can anti depressant medicine cause memory loss ? seen many suffering from cognitive problems after taking anti-depressants and for some , it went worse even after medicine was stopped.what can be the possible reasons?",
    "present_kp": [
      "memory"
    ],
    "absent_kp": [
      "depression"
    ]
  },
  {
    "text": "how can i create a restful-style website if html forms only allow to use get and post?. let's say that i want to create a website where users will be able to create, edit and delete some kind of resources, for example posts.i have created a restful api, so user can create a post by sending a put request to <url> delete it by sending delete request, etc.but most users don't know anything about http requests. they want to click a new post button and have the new post created. but html only allows me to use get and post. how can i create a new post button that will send a put request? or is restful creation/deletion implemented in a totally different way?let's say i'm using spring + thymeleaf.",
    "present_kp": [
      "rest"
    ],
    "absent_kp": []
  },
  {
    "text": "pass the background flag (&) through expect and ssh. my command line/bash fu is extremely weak, but i'm trying to hone my abilities. hopefully someone can help.i wrote a super simple expect script so that i can ssh in to a headless box we're using at work, while also sending in the password (for reasons that i am unable to expand upon, we can't use public keys to automate logging in). the script:#!/usr/bin/expect -fset timeout 30spawn ssh -x ***@10.101.0.133 $argvmatch_max 100000expect *?assword:*send -- *** interactthe box has a developer environment and eclipse installed; most of the time that i'm connecting to it, i will end up tunneling straight in to eclipse to work on some code that we keep on this box, so i usually end up using script eclipse.how can i pass the & flag in to expect so that it sees the ampersand as an argument for the ssh session i'm spawning ? when i use script eclipse & it just backgrounds script on my machine instead of doing something on the remote machine, but i'd like to be able to send the & in to script so that when eclipse launches on the remote box i can still use the box's shell.this is probably an incredibly silly question, but any help would be greatly appreciated.update: i figured out escaping the ampersand (which was definitely a no duh moment for me... meh). but this leads to a new problem. it seems that when i pass any arguments to my script, the expect command never allows me to interact; once the passed command executes the ssh session terminates. i'm guessing that this isn't a limitation of expect but a part of the behavior of ssh. thanks for your answers though.update 2: just for the sake of posterity, i got the behavior i wanted by modifying the script to look like this:#!/usr/bin/expect -fset timeout 30spawn ssh -x ***@10.101.0.133match_max 100000expect *?assword:*send -- *** send $argvsend -- interact",
    "present_kp": [
      "shell",
      "ssh",
      "expect"
    ],
    "absent_kp": []
  },
  {
    "text": "recover the contents of a formatted disk?. i've been setting up a new system, and recovering backups from my formatted external hard drive. i was able to get most of what i needed from it, but the btrfs partition was somehow reformatted as swap. in an attempt to fix the issue, i reformatted it again as btrfs (using gparted), but this did not recover any of the old data. as i have not written to the drive (beyond the format changes), i assume all of the information is still there, but inaccessible.is there a way i can recover this data? in other words, is there a way to latch on to the old metadata (and root) of the original btrfs partition?what could have caused the partition to be reformatted to swap in the first place?note: this whole situation could have been due to error on my own part, as i was trying to fix some swap issues. however, i was unable to find the command that would have formatted the partition as swap (mkswap /dev/sdb1) in my bash history.",
    "present_kp": [
      "partition",
      "btrfs",
      "gparted"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a specific term for false justifications?. i'm not sure false justifications is the right term, but it's the closest i can think of. i'm referring to a situation in which a person has already made up his mind for reasons he won't publicly disclose, then tries to justify using specious excuses that don't hold up under scrutiny.for example, let's suppose a new manager wants to fire an employee for reasons that would be illegal. instead, he comes up with a laundry list of legal reasons (tardiness, improper dress, poor attitude, lack of productivity). taken as a whole and unexamined, the list seems overwhelming and thus the dismissal justifiable. but if given the opportunity, the employee could refute each reason individually (has never actually been late, dresses the same as others in the office, is meeting all quotas and agreements, etc).similarly, in political conversations a person's argument may be based on a conclusion driven by passions and beliefs, but not data. then data is cherrypicked to prove the argument rather than forming an argument based on the data.i'm looking for ways to describe this sort of pre-determination. is there a language for this?",
    "present_kp": [],
    "absent_kp": [
      "terminology"
    ]
  },
  {
    "text": "why doesn't monit like this syntax. i am trying to setup monit for my debian server. i have a main monitrc file in /etc/monit which at the end has include /etc/monit/conf.d/*.in conf.d i have two files for my apache and mysql servers:# ls -al /etc/monit/conf.dtotal 16drwxr-xr-x 2 root root 4096 apr 15 16:03 .drwxr-xr-x 3 root root 4096 apr 15 16:02 ..-rwx------ 1 root root 272 apr 15 15:38 apache2.conf-rwx------ 1 root root 264 apr 15 15:47 mysql.confwhen i run monit -t (to test the configuration syntax) i get:/etc/monit/conf.d/apache2.conf:1: error: syntax error 'check process 'the same error occurs for the mysql configuration file if i delete/move the apache2.conf file.# cat apache2.confcheck process apache2 with pidfile /var/run/apache2.pid start program = /usr/sbin/service apache2 start stop program = /usr/sbin/service apache2 stop if failed host localhost port 80 protocol http request /catalog/ then restart and alertand the contents of mysql.conf# cat mysql.conf check process mysqld with pidfile /var/run/mysqld/mysqld.pid group database start program = /usr/sbin/service mysqld start stop program = /usr/sbin/service mysqld stop if failed host localhost port 3306 protocol mysql then restart and alerti have:tried many variations of the conf filelooked at the documentation 20 times oversubstituting in a mysqld.conf file from a public repository of common monit config files and removing the apache2 config filelooked over the files in hex, there's no funny characters.tried both tabs and spaces. removing all but the first line. double-checked that /var/run/mysqld/mysqld.pid does indeed exist. made sure the permissions on both monitrc and both conf.d file are 0700. at this point i am completely perplexed as to what could possibly be causing the (not very helpful) error message, /etc/monit/conf.d/apache2.conf:1: error: syntax error 'check process '",
    "present_kp": [
      "debian",
      "monit"
    ],
    "absent_kp": [
      "monitoring"
    ]
  },
  {
    "text": "why does python use hash table to implement dict, but not red-black tree?. why does python use hash table to implement dict, but not red-black tree?what is the key? performance?",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "data structures"
    ]
  },
  {
    "text": "why is it bad to use inline styling in html for generic styles?. given<div> <textarea></textarea></div>why is this<div> <textarea class=width90></textarea></div>.width90{ width:90%;}any better than this?<div> <textarea style=width:90%;></textarea></div>edit:i updated my example better. my question should be more related to generic styles like widths, text align, etc.",
    "present_kp": [
      "html"
    ],
    "absent_kp": [
      "css"
    ]
  },
  {
    "text": "what to do when a service asks for your gmail password?. on many services, there is the request to connect to your gmail (or other webmail service) account in order to retrieve your contacts information (so to add them to your network in the new service).this is obviously not secure.so in such a case, what should you do?(i made a second gmail account, copied my contacts there, and used that - but that is not optimal.)",
    "present_kp": [
      "gmail",
      "contacts"
    ],
    "absent_kp": [
      "security",
      "passwords"
    ]
  },
  {
    "text": "functions in ~/.bash_profile not found in an interactive shell. i thought that whatever lies in .bash_profile(or .profile) which is sourced in a login-shell, is available in an interactive shell.my goal is to have available a list of functions, either in a login shell or in an interactive shell.i am using ubuntu 14.04.1, and i don't use .profile, but instead .bash_profile.(.profile has been renamed)so currently what i have done, i have inserted the functions in .bash_profile, but when opening an interactive terminal they are not available, only if i use bash -l.",
    "present_kp": [
      "bash",
      "profile"
    ],
    "absent_kp": []
  },
  {
    "text": "search in a sourceforge mailing list. here is a mailing list archive in sourceforge.how do i search for all messages that contain unicorn?i must be dumb because i can't find any button to search messages...",
    "present_kp": [
      "sourceforge"
    ],
    "absent_kp": []
  },
  {
    "text": "what should i put on the paper to show the correctness and convergence of my solution?. i am using fem to do an assignment on a heat conduction problem on a complex domain, which needs me to get the variation of the temparature distribution subject to the variation of boundary conditions, and its exact solution is unknown. also i have to show the correctness and convergence of my solutions numerically. i am considering to compute the mean temperature over the whole domain, and then with the time variation of this mean value, i can get a curve denoting the evolvement of mean temparature. then using different refinement levels, i can get a bounch of these curves. in order to show its convergence, could i just put these curves on the paper with some description like this:obviously, it can be seen from the figure that with the increasing refinement level, the mean temparature variation is converging. or do i have to compute the mean differences of these curve?in addition, i am not sure whether it's appropriate to use this mean temparature variation as a way to verify the correctness of my solution. even though i can show the convergence, it is still not necessary to be correct because i don't have the exact solution. also, even if the mean value is correct, i still can't show the correctness on the whole domain. maybe the values at some points are larger while smaller elsewhere. who knows? (after all, no correct solution can be refered to.)anyone have some good suggestions?",
    "present_kp": [
      "convergence"
    ],
    "absent_kp": [
      "numerical analysis",
      "error estimation",
      "verification"
    ]
  },
  {
    "text": "is there an easy way to clean up useless files?. is there a command or an application i can download or run that would clean up and uninstall useless and unused files? i just want to free up some space on my machine, and that is my main goal.",
    "present_kp": [],
    "absent_kp": [
      "debian",
      "gnome"
    ]
  },
  {
    "text": "how can i click on an email in gmail to select it instead of open it?. i would like to select an email by clicking on it instead of opening it to be able to perform an action, such as archiving or deleting it.",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the period of n xored identical random number generators, with differing seeds?. this question is a kinda spin off from why do we not combine random number generators?if for example we had n identical type random number generators, with n different seeds, what would the period be if their outputs were xored together? would it be period, n x period or period (power n)?so a numerical example would be:2 linear feedback shift registers of 10 bits.1 lfsr's period = 1023.2 xored lfsrs' period = 1023, 2046 or <phone>?(i have a sense that it's period but i can't overcome that fact that the state size is so much bigger.)",
    "present_kp": [],
    "absent_kp": [
      "pseudo random generators"
    ]
  },
  {
    "text": "what to call a variable that is used for indentation?. what should i call a variable that is used for indentation?private string _indentstring = ; // can be set to or , etc.is the purpose of the variable clear from the name?",
    "present_kp": [],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "maximum non-intersecting subset of circles. we are given a set of circles, stored by their center points in an array $a$. in particular, the center of the $i$th circle is at coordinates $(a[i].x, a[i].y)$. all the circles have radius of $k$.i want to find a subset of circles such that no circles in this subset intersect with each other, such that this subset is as large as possible. i'm asked to find a way to solve this using a backtracking algorithm. rather than to do it with brute force, is there a effective way to prune some of the branches?",
    "present_kp": [
      "backtracking"
    ],
    "absent_kp": [
      "algorithms",
      "np hard"
    ]
  },
  {
    "text": "reserve pts range for some users. is possible to reserve pseudo terminal range ids for some users ?consider an user which should get preferable (or exclusively) pts id from 500 to 600, other from 0 to 400, and so on.",
    "present_kp": [
      "terminal"
    ],
    "absent_kp": [
      "tty"
    ]
  },
  {
    "text": "are there samples of false but beneficial beliefs?. many people have false beliefs.the fact that they have those shows that those beliefs may carry some evolutionary advantage.if so, how?how can false beliefs be profitable?",
    "present_kp": [],
    "absent_kp": [
      "personality"
    ]
  },
  {
    "text": "puppy linux internet connection is so slow. i am running puppy linux from usb and i am using my phone as modem. i have 10 mbps connection in my phone but puppy linux is loading pages with 10-20 kb/s speed in chrome.i've used frisbee to connect internet. why is loading so slow?",
    "present_kp": [
      "internet",
      "puppy linux"
    ],
    "absent_kp": []
  },
  {
    "text": "fedora upgrade error. i was trying to upgrade to fedora 16 (i had f14) using preupgrade. however,it fails at the end (after saying: preparing transaction from installation source) and gives the following error:a fatal error occurred when installing the file system package. this could indicate errors when reading the installation media.installation cannot continue.",
    "present_kp": [
      "fedora",
      "upgrade"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "how to better remember your dreams?. often times, i wake up with an amazing, yet fleeting glimpse of a dream i had. i would like to recollect those events i had in my dream, and try to adopt ways to better remember those dreams.there are a few (random) ways that i have tried, but i would like to know if there are studied ways of accomplishing this. how can i easier remember my dreams and record them for the future?",
    "present_kp": [
      "dreams"
    ],
    "absent_kp": [
      "memory"
    ]
  },
  {
    "text": "geany plugins by command line. i am using geany 1.27 with a plugin to export as html.since i have a lot of sh files, is it possible to run the geany plugin on console to export in batch mode?",
    "present_kp": [
      "plugin",
      "geany"
    ],
    "absent_kp": []
  },
  {
    "text": "what are the challenges in building a scalable real-time web app?. i'm looking into real-time web applications using websockets and node.js. i'm interested to see what are some technical challenges with scaling such a setup.one such problem i've heard is that each socket requires a unix file descriptor, and epoll/select takes time linear to the number of open file descriptors.anyone have other insights into scaling?",
    "present_kp": [
      "node.js"
    ],
    "absent_kp": [
      "scalability",
      "real time"
    ]
  },
  {
    "text": "restricting access to just cvs and git commands. at work we have a server which hosts our cvs repository and in order to restrict shell access to this system, i have deployed rssh which has worked well for a number of years.we are now converting part of our repository to git and using this existing server to host a centralized bare git repository. i would like to extend these restrictions to git commands as well, but rssh does not support git. i know that git has git-shell which does a similar thing for git (though i haven't used it) but i don't think it understands cvs.given that both approaches use the mechanism of setting the user's shell to one of these, i can't use them both at the same time.we still need to use the cvs repository so is there any mechanism that would work for both cvs and git?my options at the moment are:do nothing (not really an option).find a way to make them both work (hence this question).forget security and just give everyone shell access.abandon the idea and put the central git repository on another server (probably virtual) and use git-shell.something else which i haven't thought of.",
    "present_kp": [
      "git",
      "cvs"
    ],
    "absent_kp": [
      "account restrictions",
      "oracle linux"
    ]
  },
  {
    "text": "is there a temporary copyleft license?. suppose i produce some work, and i want all derivative works released before the year 2030 to be open source under the same license, but during and after the year 2030 i wish to allow derivative works to be released with merely an attributionin other words, i want a license that becomes more permissive over time.does such a license exist? if not, are there any reasons why a license like this could not exist?",
    "present_kp": [
      "copyleft"
    ],
    "absent_kp": [
      "licensing",
      "license compatibility",
      "license recommendation"
    ]
  },
  {
    "text": "logwatch is not sending mail to my email address on centos. i assume logwatch is using postfix because this is what i see in the log files..2014-11-03t15:01:35.509850+11:00 workshop2 postfix/smtpd[7048]: disconnect from ami[127.0.0.1]2014-11-03t15:01:42.246241+11:00 workshop2 postfix/smtp[7052]: 7a5a5408f0: to=<<email>, relay=gmail-smtp-in.l.google.com[74.125.20.27]:25, delay=6.8, delays=0.01/0.02/0.84/5.9, dsn=2.0.0, status=sent (250 2.0.0 ok <phone> lr3si14396502pab.140 - gsmtp)2014-11-03t15:01:42.246503+11:00 workshop2 postfix/qmgr[5976]: 7a5a5408f0: removed/etc/hosts127.0.0.1 ami ami.workshop2192.168.56.102 khadija.ahlanwsahlan.com khadija127.0.0.1 localhost hol localhost.localdomain localhost4 localhost4.localdomain4::1 localhost hol localhost.localdomain localhost6 localhost6.localdomain6/etc/postfix/main.cf#myorigin = khadija.ahlanwsahlan.commyorigin = ahlanwsahlan.comi can telnet to the mail server at gmail-smtp-in.l.google.com on port 25i have changed inet_protocols = all to inet_protocols = ipv4 in /etc/postfix/main.cfone thing which i am not sure about is when mail is being sent from my local linux server, what will the sending email address be?note that ahlanwsahlan.com is not a real domain.mail -s test subject <email> < message.txtsendmail <email> < ~/message.txt the above commands do not send any mail either.many thanks.",
    "present_kp": [
      "postfix",
      "logwatch"
    ],
    "absent_kp": []
  },
  {
    "text": "mounting ext3 in linux different user. i am trying to mount an ext3 based memory stick in linux based development board.i used mount with -u and -g for mounting the fat based memory stick with different user.when i tried the same command for ext3, it failed.i read in help that ext3 doesn't support -g and -u.after reading about bindfs, i've built the bindfs for arm and was able to mirror the already mounted ext3 fs with a different user.now the issue is the removal of the memory stick, which has to unbind and unmount the fs before removal. otherwise the os keeps showing that the ext3 fs is mounted and mirrored. it also hangs the system.unbinding and unmounting can be done as root only.is there any other way to mount ext3 without being root?using chown is not an option.",
    "present_kp": [
      "mount",
      "ext3"
    ],
    "absent_kp": [
      "not root user"
    ]
  },
  {
    "text": "safe removal of flash disk. in ubuntu 16.04, i try to safely remove the flash disk from the command line. when i run the following script (from the eject / safely remove vs umount):udisksctl unmount -b /dev/sdb1udisksctl power-off -b /dev/sdb1it says:error powering off drive: error opening /sys/devices/pci0000:00/0000:00:1a.0/usb1/1-1/1-1.1/remove: no such file or directory (udisks-error-quark, 0)when i type these commands from the keyboard, i don't get the error.why, and how should i make the script running?",
    "present_kp": [
      "command line",
      "eject"
    ],
    "absent_kp": [
      "debian"
    ]
  },
  {
    "text": "why is the color in the cube being weirdly swapped?. i am implementing a trackball, i.e. a camera orbiting about a fixed point, in my case the origin. when i do left click with the mouse and start moving it, i compute delta values for the angles of a sphere centered at the origin given the displacement in x and y directions of the mouse. my implementation is as followsvoid simpleperspectivecamera::mousemove(const double& mousex, const double& mousey){ if(m_setpan) { float sensitivity = 0.0075f; float newx = (mousex - m_prevx) * sensitivity; float newy = (mousey - m_prevy) * sensitivity; // todo: understand if it is necessary to reset the up vector to (0,1,0) m_up = vector(0.0f, 1.0f, 0.0f); setlookat(m_lookat + vector(-newx, newy, 0.0f)); setposition(m_position + vector(-newx, newy, 0.0f)); m_prevx = mousex; m_prevy = mousey; } if(m_setrotate) { float sensitivity = 0.005f; float newphi = (mousex - m_prevx) * sensitivity; float newtheta = (mousey - m_prevy) * sensitivity; // transform to spherical coordinates to use mouse move as deltas for // the angles. float r = m_position.norm(); float theta = std::acos(m_position.y / r); float phi = std::atan(m_position.x / m_position.z); theta += newtheta; phi += newphi; m_up = vector(0.0f, 1.0f, 0.0f); vector newposition(r*std::sin(theta)*std::sin(phi), r*std::cos(theta), r*std::sin(theta)*std::cos(phi)); setposition(newposition); m_prevx = mousex; m_prevy = mousey; }}what i was expecting is to be able to rotate the camera around the cube in the scene so that i can see all around it. my code almost achieves this, but i don't understand why after rotating a certain amount the camera jumps to the exact opposite side of the cube.you can check what weird swap i am talking about this linkwhat am i missing so that the rotation around the object goes all the way around it?",
    "present_kp": [
      "trackball"
    ],
    "absent_kp": [
      "transformations"
    ]
  },
  {
    "text": "how to improve code that has to handle list-objects in general and special cases?. i do have an implementation issue that i condensed to the following code snippet, because the real code is much more complicated. the core problem is that i do have a container object that has a mixed list of persons, for example managers and engineers:interface person {}class manager implements person {}class engineer implements person {}in the most cases i have to access the list of persons without knowing the concrete subclass of a person. but in some methods i have to know the concrete type of the members, for example to count the members or to add the members. in both implementations i do have ugly code:in implementation a it's the code to separate the person-types for counting.class enterprisea { private final list<person> members = new arraylist<person>(); public void addmember(person person) { this.members.add(person); } public void dosomethingwithmanagers() { // separate by instanceof } public void dosomethingwithengineers() { // separate by instanceof }}in implementation b it's the code to add a person to the right list of manager or engineer.class enterpriseb { private final list<manager> managers = new arraylist<manager>(); private final list<engineer> engineers = new arraylist<engineer>(); public void addmember(person person) { if (person instanceof manager) { this.managers.add((manager) person); } else if (person instanceof engineer) { this.engineers.add((engineer) person); } } public void dosomethingwithmanagers() { // iterate over the managers. } public void dosomethingwithengineers() { // iterate over the engineers. }}how can i improve the code and avoid the ugly code in addmember() and countmanagers() respectively? smart suggestions are welcome.which alternative would you prefer? please give reasons, in which cases you would prefer which solution.",
    "present_kp": [],
    "absent_kp": [
      "class design",
      "clean code"
    ]
  },
  {
    "text": "implementing haskell#lines. learn you a haskell shows the lines function:it takes a string and returns every line of that string in a separate list.example:>lines' hello world howareyou[hello,world,howareyou]here's my implementation:lines' :: string -> [string]lines' [] = []lines' xs = lines'' xs [] where lines'' [] ys = ys : [] lines'' (x:xs) ys | x == ' ' = ys : lines'' xs [] | otherwise = lines'' xs (ys ++ [x])please critique it. also, when using an accumulator value (such as ys in lines''), i don't know how to use the : function instead of ++.",
    "present_kp": [
      "haskell"
    ],
    "absent_kp": [
      "reinventing the wheel"
    ]
  },
  {
    "text": "space to allocate before sprintf. i just finished chasing a heisenbug that was entirely my fault. i'd like to avoid it happening again.i have a function which formats a date to a certain preset format. turns out i was not allocating enough space:char* formatdate(dt datetime){ char* formatteddate; formatteddate = (char*)malloc( 6 //that was my bug, i had 5. for the record, i forgot a comma, not the terminal null... + numlen(datetime.year) + numlen(datetime.month) + numlen(datetime.day) + numlen(datetime.hour) + numlen(datetime.minute) + numlen(datetime.second) ); sprintf(formatteddate,%d,%d,%d,%d,%d,%d, datetime.year, datetime.month, datetime.day, datetime.hour, datetime.minute, datetime.second); return formatteddate;}numlen calculates the number of characters the number would take if printed in %d format.and yes, the calling function has the duty to free the response.what i'd like to know is how to avoid having the hardcoded 6, which arguably could change. sprintf does return the numbers of characters written, but that's a lot like the chicken and the egg... is there another approach with pre-allocating that's safe? and not, say allocate a space of 250 just to make sure anything fits.",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "memory management"
    ]
  },
  {
    "text": "best datatype to store a ternary, or three-state variable. disclaimer: i know that datatypes are a little bit subjective to which scripting/programming language you are using, i like to write in python as a matter of preference; though i am happy to hear about any lanugage/implementation.what is the best datatype to store a three-state variable? something capable or representing positive, neutral, and negative.example: integers -1, 0, 1. pro: very concise.pro: potentially efficient, could be stored as a single 2-bit signed integer.pro: could be used as a scale, such as a floating point multiplier.example 2: 0, null, 1 (or any permutation)pro: non-neutral use case can be binary.con: requires dynamic datatype con: potentially not concise.example 3: +, (empty string), -pro: very concise.con: may utilize string logic to determine state.pro?: intuitive graphical representation. perhaps there is some clever binary logic that can do something clever that i can't even imagine, perhaps there relies too much considerations of the use case.also, are there any considerations when adapting a ternary state to store in a database engine? like innodb for reference.",
    "present_kp": [
      "data"
    ],
    "absent_kp": [
      "variables",
      "data types"
    ]
  },
  {
    "text": "running tasks in parallel. i've just started writing asynchronous methods for the first time having watched some tutorials.i have a method where i run two tasks in parallel (notifysales, insertdownload):task insertdownload = _downloadservice.insertdownloadrequestasync(model, request.useragent);if (product.notifysalesbyemail){ task notifysales = _downloadservice.emaildownloadrequestasync(model); await task.whenall(insertdownload, notifysales);}else{ await insertdownload;}as you can see, the task notifysales only gets run if product.notifysalesbyemail is true. this task, as well as task insertdownload can be run in parallel.i'm not sure i like the way in which i have said 'if true await both else just await one'.would a better way to be to create a task[] array, add the tasks that are required to run and then await the array?",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "async await"
    ]
  },
  {
    "text": "can files with different inum be hard linked?. i am a new linux user learning from arch linux and recently linux from scratch (7.7). i set up a new installation of al to be my lfs host; i manually (and also with the provided bash script) checked prerequisite packages on my host. in my case, i am confident i resolved all discrepancies except for linking /usr/bin/yacc to /usr/bin/bison.the provided script results in yacc is bison (gnu bison) 3.0.4, as opposed to /usr/bin/yacc -> /usr/bin/bison. because the latter was the output format for checked symbolic links, i assumed the script was telling me yacc is prepared but employing a different kind of link. i investigated more about linux file systems and took away a cursory understanding that actual data is described by inodes (metadata), which are in turn pointed to by the (abstract) files we interact with. files that simply point to the same inode are considered hard links (although, i think the files are independent of each other). i ran sudo ls -il /usr/bin | less and found yacc and bison had slightly different inode numbers (152077 and 152078, respectively). does this mean they are not hard linked, or am i misinterpreting the script output and require a fix?edit: relevant commands from bash script:bison --version | head -n1if [ -h /usr/bin/yacc ]; then echo /usr/bin/yacc -> 'readlink -f /usr/bin/yacc';elif [ -x /usr/bin/yacc ]; then echo yacc is '/usr/bin/yacc --version | head -n1'else echo yacc not found fi",
    "present_kp": [
      "arch linux",
      "hard link"
    ],
    "absent_kp": [
      "symlink"
    ]
  },
  {
    "text": "thread-safe singleton class using std::shared_ptr in c++(11). what i am trying to accomplish is to create an efficient thread-safe singleton base class (as stated in the title).so this is my singleton class, which is used via inheritance (see below).#pragma once#ifndef singleton_header_included#define singleton_header_included#include <memory>template <class t>class singleton{public: static t *get_instance(void) { if(instance.get() == 0 || instance == (null && 0) || !instance) { instance = std::shared_ptr<t>(new t()); } return instance; } static delete_instance(void) { delete instance; instance = (null && 0); return; }protected: singleton(void); virtual ~singleton(void);private: singleton(const singleton&); singleton& operator = (const singleton&); static volatile std::shared_ptr<t> instance;};template <class t> template *singleton<t>::instance = 0;#endifhere is the class in use:#include singleton.hppclass opengl_renderer : public singleton<opengl_renderer>{ friend class singleton<opengl_renderer>; etc...};so basically, i am looking for some tips and reviews on my class -> i feel as if it isn't working the way i imagine it should. but it is functional at its current state.",
    "present_kp": [
      "c++",
      "singleton"
    ],
    "absent_kp": [
      "c++11"
    ]
  },
  {
    "text": "can i rent a domain name to somebody for web publishing while still retaining ownership and using other aspects of it?. i was wondering that is it possible to rent a domain for someone without losing ownership and possibility to use it for some own purposes.what i mean is that is that if i don't myself need that domain for web publishing could i rent it to somebody else to use it for web publishing and still use it for other purposes of my own?",
    "present_kp": [],
    "absent_kp": [
      "domains",
      "dns",
      "web development"
    ]
  },
  {
    "text": "web-based samba client interface for headless system. i run a file server on a raspberry pi at home. also at home on another raspberry pi; i'm running openelec kodi.the instance that i'm envisioning is where my (not-very-tech-savvy) wife is at home wanting to watch a video clip that i have on my file server. i'm at work and want to copy it from the file-server to the kodi for her. the problem is that i need now to copy the file over the network to the other pi running kodi. ideally i'd like to use the samba to achieve this.the file server is running a headless jessie (raspbian) install. i have a number of other things running on it: a web server, owncloud, transmission and a few other scripts.what i'd like to have is a web interface to a commander-like (think norton commander / total commander / etc) interface that i could use to copy/move/delete files between a samba server and the local os (preferably running on a non-commonly-used port).needsbrowser interfacecopy/move files from local os to remote pcmust be user controlled (not a periodically run rsync)interface must run on a non-standard port (i'm using 80 for something already)wantsi'd prefer it to use samba, but ftp would also be okprogress bars!does this exist?",
    "present_kp": [
      "samba",
      "browser",
      "headless"
    ],
    "absent_kp": [
      "user interface"
    ]
  },
  {
    "text": "is developing for a niche tablet market worth it?. as an avid fan of tablets, i finally bought a nook color a while back. since it's based on android and i have java experience, i'm intrigued by the possibility of developing for it. i've seen that it has an estimate of a few million units shipped (those stats were fairly recent), and the app market is rather small at this time (which i presume would be an advantage to a new app).what i'm wondering is, what are the advantages and disadvantages of developing for such a small, reading-based market - in terms of app popularity and use? am i wrong in assuming the small app market is an advantage? does developing for a niche tablet have any synergy with the larger phone market, in terms of cross-development or promotion?",
    "present_kp": [
      "android",
      "tablets"
    ],
    "absent_kp": []
  },
  {
    "text": "difference between system calls, system call interface and api?. lets take posix, whats the difference between posix api, libc and actual system calls?",
    "present_kp": [],
    "absent_kp": [
      "terminology",
      "operating systems"
    ]
  },
  {
    "text": "am i implementing bdd correctly?. i'm writing a utility that validates fields. i decided to try my hand at behaviour driven development (bdd). the validator utilises rules to determine if field is valid.three different types of rules exist:regexrule a field conforms to specific pattern(s)requirerule a value is presentequalityrule a field's value equals another's valuea rule is tested against a value. if the value does not conform to the rule, a flag is set which marks the rule as erroneous. calling geterror() on an erroneous rule returns a string that details the error. furthermore, the rule is reset (no longer erroneous).is this the correct manner of implementing bdd on this class? i'd greatly appreciate advice on how i could improve on this.describe('requirerule', function() { var nameerr = 'the name field is required'; beforeeach(function() { this.r = new requirerule('name', nameerr); }); describe('test()', function() { it('should return false when value provided is null or undefined', function() { expect(this.r.test('asd')).to.equal(true); }); it('should return true when value provided is not null or undefined', function() { expect(this.r.test(null)).to.equal(false); }); }); describe('iserroneous()', function() { it('should become erroneous when value tested is null or undefined', function() { r.test(null); expect(this.r.iserroneous()).to.equal(true); }); it('should not be erroneous when value tested is not null or undefined', function() { r.test('asd'); expect(this.r.iserroneous()).to.equal(false); }); }); describe('geterror()', function() { it('should return null when the test() succeeded', function() { r.test('asd'); expect(this.r.geterror()).to.equal(null); }); it('should return the error string when the test() failed, and set erroneous to false', function() { r.test(null); expect(this.r.geterror()).to.equal(nameerr); expect(this.r.iserroneous()).to.equal(false); }); });});the test framework is mocha.",
    "present_kp": [
      "bdd",
      "mocha"
    ],
    "absent_kp": [
      "javascript",
      "unit testing",
      "validation"
    ]
  },
  {
    "text": "is there a script to update (almost) any linux distribution?. i know of apt-get update and yum update, but i'm wondering what others there are to update other linux oses.could all these be combined into a script which could be run on any linux distro?",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "upgrade"
    ]
  },
  {
    "text": "how to i remove auto generated frameset in iis?. i have a website where a redirect has been setup to use a frameset.for example. my main site is x-site.com there is a redirect setup somewhere so that xsite.com redirects to x-site.com, but it does so by creating a frameset and placing x-site.com within there.this causes problems for users to login, and we don't need it to function in this fashion.i tried writing some simple .net code to redirect the user to x-site.com, but it doesn't seem to work. this leads me to believe that there is something in iis doing the redirect before the code can execute.how do i remove the frameset redirect?",
    "present_kp": [
      "redirects",
      "iis",
      "frameset"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a xdotool rpm available for centos linux?. it seems to be extremely difficult to install xdotoolon centos because of it's requirements. such asyum groupinstall 'development tools' -yyum install libxi-devel libxtst-devel libxinerama-devel -ythe top one especially is difficult to move to a folder and installlocally. ( without internet ). ( for extra speed ).currently i have to run those two commands and then i have to run thesein order to install xdotool on centos linux.cat > /etc/ld.so.conf << eof/usr/local/libeof# rm -rf xdotool-2.20110530.1# tar -xvf xdot*cd xdot*make installi tried adding epel and rpmforge repos to my yum and then i searched for xdotool nothing was found.i was wondering if there is a known rpm version so that installing it would be simple on centos linux.",
    "present_kp": [
      "linux",
      "yum",
      "rpm"
    ],
    "absent_kp": [
      "bash",
      "repository"
    ]
  },
  {
    "text": "is haskell/clojure actually unsuited for dynamic systems such as particle simulation?. i've been told in previous questions that functional programming languages are unsuited for dynamic systems such as a physics engine, mainly because it's costly to mutate objects. how realistic is this statement, and why?",
    "present_kp": [
      "functional programming",
      "haskell",
      "clojure"
    ],
    "absent_kp": [
      "immutability"
    ]
  },
  {
    "text": "how to manage fugitive commit with a git pre-commit hook?. when working on a git project in vim, i use the fugitive plugin.i like to open a :gstatus split, press - to add file and then press c to commit my changes. i also have a git pre-commit hook, it runs some test. in case of an error, it prompts meto make sure if i still want to commit.but, when following this pattern, i don't see the output for the tests, neither the final prompt. instead, vim freezes while the tests are running.how would i make fugitive and a pre-commit hook get along together smoothly?update: this is the prompt in the git pre-commit hook:#!/bin/bashexec < /dev/ttywhile true; do read -p there were some errors in the test, do you still want to commit? (y/n) yn if [ $yn = ]; then yn='y' fi case $yn in [yy] ) break;; [nn] ) exit;; * ) echo answer y or n.;; esacdone",
    "present_kp": [
      "git"
    ],
    "absent_kp": [
      "plugin fugitive"
    ]
  },
  {
    "text": "what is total in the output of ls command. possible duplicate:ls command: what does the first line mean? i have an empty directory.i am using following command to view the contents of that directory.ls -lartthe output i get is below.total 12drwxr-xr-x 5 root root 4096 oct 2 12:26 ..drwxr-xr-x 2 apx aim 4096 nov 29 18:40 .i don't have any files in this directory,then what counts out to 12 here ( total 12 ) ?",
    "present_kp": [
      "ls"
    ],
    "absent_kp": []
  },
  {
    "text": "how to assign a variable within a pipe. i'm building a one liner in bash.if making a script or writing temp files were an option, i wouldn't need to ask.i need to assign a variable in the middle of a set of pipes to use down the line. cat list | awk '{print $1.modifications_to_name' | (capture $name and pass $name down pipe) \\ | checkstatus | grep pertinentinfo | cleanupformatofpertinentinfo | sendalert $name",
    "present_kp": [
      "bash",
      "pipe"
    ],
    "absent_kp": [
      "shell script",
      "environment variables"
    ]
  },
  {
    "text": "bonding wireless and 3g on fedora 15. i have access to the internet through either wireless or a 3g cdma card. is it possible to bond both connections and join the bandiwdth and have a failover?",
    "present_kp": [
      "internet",
      "bonding",
      "3g"
    ],
    "absent_kp": [
      "wifi",
      "mobile"
    ]
  },
  {
    "text": "bugs showing up with merge on the release branch. when trying to follow the the gitflow model, we have a branch for the releases. however, we've had complicated merges when trying to merge from develop and bugs have crept in to that branch from this.what are we doing wrong and how do we keep these merge bugs from showing up?our git tree looks like:d r m| | |o | ||\\ | || \\| || 1 |o | || 2 || | |o 3 || /|\\ ||/ | \\|o | 4|\\ | || \\| || 5 |where the o is a change on the development branch. 1 is where the development branch was merged into release, 2 and 3 are commits to fix bugs in the release branch, and then 4 is the release on master. this then continues with 5 being the merge of development into the release branch again.",
    "present_kp": [
      "git",
      "gitflow"
    ],
    "absent_kp": [
      "branching"
    ]
  },
  {
    "text": "extracting ddrescue image file after pass 1. i am trying to recover data from a failing usb hard disk using ddrescue. i ran ddrescue for about 4 days at the end of which it completed pass 1. sometime after it began with pass 2, i interrupted the process to give the laptop and hard disks a break as they were getting heated up. when i restarted ddrescue, i found that it had resumed at the spot it had left previously, but with pass 1 counting upwards again and not with pass 2 (counting down). moreover the second pass was painfully slow covering only 5 gb for the next 2 days. the current status shows 0 errors and errsize as 0b and rescued as 769755 mb which is roughly the amount of data i remember being on the drive. my question is can i assume that ddrescue has already recovered the data there is to be recovered and that it is safe to extract the contents of the image file to another usb drive? or is it necessary/mandatory to let ddrescue run the remaining two passes as well?p.s chkdsk failed with usb hard disk with an unspecified error occured message. i am hoping to extract the image file to a new hard disk and run chkdsk again to see if that can fix it. tried mounting the image file in linux, but it came back with ntfs signature missing.",
    "present_kp": [
      "ddrescue"
    ],
    "absent_kp": [
      "corruption"
    ]
  },
  {
    "text": "how can i prove property rights to script?. i just programmed a file sharing script but i can't sell it because i don't know how to prove that i'm the programmer.",
    "present_kp": [
      "script"
    ],
    "absent_kp": [
      "copyright"
    ]
  },
  {
    "text": "parallel algorithms to color interval graphs. several np-hard graph problems get easy if we consider interval graphs. there is a greedy algorithm to color optimally an interval graph. just sort the intervals according their left endpoints and color each interval with the last freed color.every coloring algorithm especially every efficient parallel algorithm i see, use the endpoints of intervals to get an optimal coloring. with efficient parallel i mean that the problem is in the complexity class nc. there is a possibility to use only the structure of the graph to color the interval graph but this uses a maximum matching in a bipartite graph which isn't known to be in nc.is there any efficient parallel algorithm that doesn't use the endpoints of the intervals and just uses the structure of the graph to color an interval graph?",
    "present_kp": [],
    "absent_kp": [
      "ds.algorithms",
      "graph algorithms",
      "dc.parallel comp",
      "graph colouring"
    ]
  },
  {
    "text": "plan 9 rio script to tile windows. here is my window tiling script for rio window manager in plan 9. it fetches the current screen size and calculates the locations based on the layout given. how can i improve this program? am i missing any idioms in rc?#!/bin/rc# usage:# first save the current windows# ./tile.rc save >saved.s# next switch to tall# ./tile.rc tall |tee tall.s |rc# can go back if you want# cat saved.s |rc# get the position from the image inputfn winpos { dd -bs 1 -skip 20 -count 40 -quiet 1}# get just width and heightfn winsize { winpos | awk '{print ($3-$1),($4-$2)}'}# of the screenfn screen { cat /mnt/wsys/screen | winsize}# get the width of the current windo. we use this# for wall - where the width of current window# is kept unchanged.fn getwidth { w='{cat /mnt/wsys/window | winsize} echo $w(1)}# generate a move command for the input# move -r minx miny maxx maxy does not seem# to work. (see save cmd). so until thenfn movcmd { mx='{echo $2 $4 + p|dc} my='{echo $3 $5 + p|dc} echo (echo resize -r $2 $3 $mx $my '>' $1/wctl)}# print the commands to get the windows back to# the original positions. this does not seem to# work always. (can use wloc too.)fn savewin { windows=/dev/wsys/* for (i in $windows) { loc='{cat $i/window | winpos} echo (echo resize -r $loc '>' $i/wctl) }}# tall configuration, with a main window, on one# half of the screen, and child windows on the other# the main window is the window from which command is# invokedfn tall { maxx=$1 maxy=$2 mywin=$3 windows=/dev/wsys/* childht='{echo $maxy $#windows 1 - / p| dc} ylast=0 xhalf='{getwidth} halfx='{echo $maxx $xhalf - p| dc} for (i in $windows) { switch ($i) { case /dev/wsys/$mywin movcmd $i 0 0 $xhalf $maxy case * movcmd $i $xhalf $ylast $halfx $childht ylast='{echo $ylast $childht + p| dc} } }}# rows configurationfn rows { maxx=$1 maxy=$2 windows=/dev/wsys/* childht='{echo $maxy $#windows / p| dc} ylast=0 for (i in $windows) { movcmd $i 0 $ylast $maxx $childht ylast='{echo $ylast $childht + p| dc} }}fn main { myscreen='{screen} mywin='{cat /mnt/wsys/winid} switch ($1) { case rows rows $myscreen $mywin case tall tall $myscreen $mywin case save savewin case * echo (supported: tall rows save) } # for some reason, this line does not # really get the original window focus. echo (echo current '>' /dev/wsys/$mywin/wctl)}main $*",
    "present_kp": [
      "rc"
    ],
    "absent_kp": []
  },
  {
    "text": "github network page: how to center on last commit (not just last commit to master). i use github's network page a lot:<url> it centers on the latest commit to master, and we do most of the work in branches, so the latest commits are usually pages away, and i have to scroll a lot to the right.is there any trick to center on the latest commit instead?(last commit in any branch, not just last commit in master)",
    "present_kp": [
      "github"
    ],
    "absent_kp": []
  },
  {
    "text": "text tokenizer - extract words and positions from text. i have set of character delimiters (delimiters), eg . , etc. using this i want to split text and get words with their position in text. string.split() works fine if you want only words. the same with stringtokenizer. wrote some simple method to deal with this, but maybe there is a better way to achieve this result?public list<string> extractwords(string text){ list<string> words = new arraylist<>(); list<wordpos> positions = new arraylist<>(); int wordstart = -1; for(int i=0; i < text.length(); i++){ if(delimiters.contains(text.charat(i))){ if(wordstart >=0){ //word just ended string word = text.substring(wordstart, i); positions.add(new wordpos(wordstart, i)); words.add(word); } wordstart = -1; }else{ //not delimiter == valid word if(wordstart < 0){ //word just started wordstart = i; } } } return words;}// inner static class for words positionspublic static class wordpos{ int start; int end; public wordpos(int start, int end){ this.start = start; this.end = end; }}",
    "present_kp": [],
    "absent_kp": [
      "java",
      "strings"
    ]
  },
  {
    "text": "is it costly to leave the console and script features enabled in firebug?. for some time now, i've run firebug constantly enabled to do quick dom inspections, leaving the console and script panels disabled.i'm just starting to use these two features so i don't have to keep using alerts for testing and debugging. i enable them while i use them and turn them back off when i'm done.i'd like to know if these particular features can slow things down such that they shouldn't be left on round-the-clock. like do they slow down page loads, use inordinate chunks of memory or something?i don't see anything about it in the firebug wiki.",
    "present_kp": [
      "testing"
    ],
    "absent_kp": [
      "firefox",
      "development"
    ]
  },
  {
    "text": "date composition from day, month and year input. i need to concatenate 3 input fields into a string which is formatted as a date dd-mm-yyyy, using type=date or new date() will not work in my scenario because firebase doesn't allow it for some reason. i came up with a rather ugly solution, but i'm not quite sure how to improve it. delete is bad for performance, but i think that it is needed because i need to completely remove the properties from the object once they've been used. $scope.addweek = function(week) { var startdate = '' + week.startdate.day + '-' + week.startdate.month + '-' + week.startdate.year, enddate = '' + week.enddate.day + '-' + week.enddate.month + '-' + week.enddate.year; week.startdate = startdate; week.enddate = enddate; delete week.startdate.day; delete week.startdate.month; delete week.startdate.year; delete week.enddate.day; delete week.enddate.month; delete week.enddate.year;}the week object looks like this:week = { number: 32, startdate: { day: 01, month: 07, year: 2015 }, enddate: { day: 08, month: 09, year: 2016 }}after we're done it needs to look like this:week = { number: 32, startdate: 01-07-2015, enddate: 08-09-2016}any suggestions on how to improve it?",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "datetime"
    ]
  },
  {
    "text": "calendar in html + css + js. as i'm new to html + css + js i've been building a calendar (which i think anyone can use as a basis) but would like to get your suggestions on how i could improve my code specifically from the perspectives of:adherence to best practices in html + css + js.usability.browser compatibility.note: the console logging in the javascript is only for debugging, not the final version.var calendar = function(o) { //store div id this.divid = o.parentid; // days of week, starting on sunday this.daysofweek = o.daysofweek; console.log(this.daysofweek == , this.daysofweek) // months, stating on january this.months = o.months; console.log(this.months == , this.months) // set the current month, year var d = new date(); console.log(d == , d) this.currentmonth = d.getmonth(); console.log(this.currentmonth == , this.currentmonth); this.currentyear = d.getfullyear(); console.log(this.currentyear == , this.currentyear); var f=o.format; console.log(o == , o); console.log(f == , f); //this.f = typeof(f) == 'string' ? f.charat(0).touppercase() : 'm'; if(typeof(f) == 'string') { this.f = f.charat(0).touppercase(); } else { this.f = 'm'; } console.log(this.f == , this.f);};// goes to next monthcalendar.prototype.nextmonth = function() { console.log(calendar.prototype.nextmonth = function() {); if ( this.currentmonth == 11 ) { console.log(this.currentmonth == , this.currentmonth); this.currentmonth = 0; console.log(this.currentmonth == , this.currentmonth); console.log(this.currentyear == , this.currentyear); this.currentyear = this.currentyear + 1; console.log(this.currentyear == , this.currentyear); } else { console.log(this.currentmonth == , this.currentmonth); this.currentmonth = this.currentmonth + 1; console.log(this.currentmonth + 1 == , this.currentmonth); } this.showcurrent();};// goes to previous monthcalendar.prototype.previousmonth = function() { console.log(calendar.prototype.previousmonth = function() {); if ( this.currentmonth == 0 ) { console.log(this.currentmonth == , this.currentmonth); this.currentmonth = 11; console.log(this.currentmonth == , this.currentmonth); console.log(this.currentyear == , this.currentyear); this.currentyear = this.currentyear - 1; console.log(this.currentyear == , this.currentyear); } else { console.log(this.currentmonth == , this.currentmonth); this.currentmonth = this.currentmonth - 1; console.log(this.currentmonth - 1 == , this.currentmonth); } this.showcurrent();};// calendar.prototype.previousyear = function() { console.log( ); console.log(calendar.prototype.previousyear = function() {); console.log(this.currentyear == + this.currentyear); this.currentyear = this.currentyear - 1; console.log(this.currentyear - 1 i.e. this.currentyear == + this.currentyear); this.showcurrent();}// calendar.prototype.nextyear = function() { console.log( ); console.log(calendar.prototype.nextyear = function() {); console.log(this.currentyear == + this.currentyear); this.currentyear = this.currentyear + 1; console.log(this.currentyear - 1 i.e. this.currentyear == + this.currentyear); this.showcurrent();} // show current monthcalendar.prototype.showcurrent = function() { console.log( ); console.log(calendar.prototype.showcurrent = function() {); console.log(this.currentyear == , this.currentyear); console.log(this.currentmonth == , this.currentmonth); this.calendar(this.currentyear, this.currentmonth);};// show month (year, month)calendar.prototype.calendar = function(y,m) { console.log( ); console.log(calendar.prototype.calendar = function(y,m){); typeof(y) == 'number' ? this.currentyear = y : null; console.log(this.currentyear == , this.currentyear); typeof(y) == 'number' ? this.currentmonth = m : null; console.log(this.currentmonth == , this.currentmonth); // 1st day of the selected month var firstdayofcurrentmonth = new date(y, m, 1).getday(); console.log(firstdayofcurrentmonth == , firstdayofcurrentmonth); // last date of the selected month var lastdateofcurrentmonth = new date(y, m+1, 0).getdate(); console.log(lastdateofcurrentmonth == , lastdateofcurrentmonth); // last day of the previous month console.log(m == , m); var lastdateoflastmonth = m == 0 ? new date(y-1, 11, 0).getdate() : new date(y, m, 0).getdate(); console.log(lastdateoflastmonth == , lastdateoflastmonth); console.log(print selected month and year.); // write selected month and year. this html goes into <div id=year></div> //var yearhtml = '<span class=yearspan>' + y + '</span>'; // write selected month and year. this html goes into <div id=month></div> //var monthhtml = '<span class=monthspan>' + this.months[m] + '</span>'; // write selected month and year. this html goes into <div id=month></div> var monthandyearhtml = '<span id=monthandyearspan>' + this.months[m] + ' - ' + y + '</span>'; console.log(monthandyearhtml == + monthandyearhtml); var html = '<table>'; // write the header of the days of the week html += '<tr>'; console.log( ); console.log(write the header of the days of the week); for(var i=0; i < 7;i++) { console.log(i == , i); console.log(this.daysofweek[i] == , this.daysofweek[i]); html += '<th class=daysheader>' + this.daysofweek[i] + '</th>'; } html += '</tr>'; console.log(before conditional operator this.f == , this.f); //this.f = 'x'; var p = dm = this.f == 'm' ? 1 : firstdayofcurrentmonth == 0 ? -5 : 2; /*var p, dm; if(this.f =='m') { dm = 1; p = dm; } else { if(firstdayofcurrentmonth == 0) { firstdayofcurrentmonth == -5; } else { firstdayofcurrentmonth == 2; } }*/ console.log(after conditional operator); console.log(this.f == , this.f); console.log(p == , p); console.log(dm == , dm); console.log(firstdayofcurrentmonth == , firstdayofcurrentmonth); var cellvalue; for (var d, i=0, z0=0; z0<6; z0++) { html += '<tr>'; console.log(inside 1st for loop - d == + d + | i == + i + | z0 == + z0); for (var z0a = 0; z0a < 7; z0a++) { console.log(inside 2nd for loop); console.log(z0a == + z0a); d = i + dm - firstdayofcurrentmonth; console.log(d outside if statm == + d); // dates from prev month if (d < 1){ console.log(d < 1); console.log(p before p++ == + p); cellvalue = lastdateoflastmonth - firstdayofcurrentmonth + p++; console.log(p after p++ == + p); console.log(cellvalue == + cellvalue); html += '<td id=prevmonthdates>' + '<span id=cellvaluespan>' + (cellvalue) + '</span><br/>' + '<ul id=cellvaluelist><li>apples</li><li>bananas</li><li>pineapples</li></ul>' + '</td>'; // dates from next month } else if ( d > lastdateofcurrentmonth){ console.log(d > lastdateofcurrentmonth); console.log(p before p++ == + p); html += '<td id=nextmonthdates>' + (p++) + '</td>'; console.log(p after p++ == + p); // current month dates } else { html += '<td id=currentmonthdates>' + (d) + '</td>'; console.log(d inside else { == + d); p = 1; console.log(p inside } else { == + p); } if (i % 7 == 6 && d >= lastdateofcurrentmonth) { console.log(inside if (i % 7 == 6 && d >= lastdateofcurrentmonth) {); console.log(i == + i); console.log(d == + d); console.log(z0 == + z0); z0 = 10; // no more rows } console.log(i before i++ == + i); i++; console.log(i after i++ == + i); } html += '</tr>'; } // closes table html += '</table>'; // write html to the div //document.getelementbyid(year).innerhtml = yearhtml; //document.getelementbyid(month).innerhtml = monthhtml; document.getelementbyid(monthandyear).innerhtml = monthandyearhtml; document.getelementbyid(this.divid).innerhtml = html;};// on load of the windowwindow.onload = function() { // start calendar var c = new calendar({ parentid:divcalendartable, daysofweek:[ 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun' ], months:['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec' ], format:'dd/mm/yyyy' }); c.showcurrent(); // bind next and previous button clicks getid('btnprev').onclick = function(){ c.previousmonth(); }; getid('btnprevyr').onclick = function(){ c.previousyear(); }; getid('btnnext').onclick = function(){ c.nextmonth(); }; getid('btnnextyr').onclick = function(){ c.nextyear(); }; }// get element by idfunction getid(id) { return document.getelementbyid(id);}html, body { margin: 0; padding: 0; }table { border-collapse: collapse; font-family: georgia, times, serif;}th { border: 1px solid #a8a8a8; vertical-align: top;}td { height: 150px; width: 150px; padding: 10px; border: 1px solid #a8a8a8; vertical-align: top;}.divcalendar { padding: 15px; float:left; /*background-color: #ffcc00;*/}/* wrapper div. that makes the inner div into an inline element that can be centered with text-align.*/#calendaroverallcontrols { text-align: center;}/* this is a fluid div as width will be changing */#calendarmonthcontrols { display: inline-block; /*background-color: #ff0000;*/}#calendarmonthcontrols > div, #calendarmonthcontrols > a { display: inline-block;} #btnprevyr { text-decoration: none; font-size: 35px; vertical-align: middle; /*background: #00ffcc;*/ }#btnprev { text-decoration: none; font-size: 35px; margin-left: 20px; vertical-align: middle; /*background: #00ffcc;*/} /*.yearspan { font-size: 20px; font-weight: bold; float: left; margin-left: 5px; margin-right: 5px;}.monthspan { font-size: 20px; font-weight: bold; float: left; margin-left: 5px; margin-right: 5px;}*/#monthandyearspan { width: 50px; font-size: 25px; font-weight: bold; margin-left: 20px; margin-right: 20px; vertical-align: middle; /*background: #00ffcc;*/} #monthandyear { vertical-align: middle;}#btnnext { text-decoration: none; font-size: 35px; margin-right: 20px; vertical-align: middle; /*background: #00ffcc;*/}#btnnextyr { text-decoration: none; font-size: 35px; vertical-align: middle; /*background: #00ffcc;*/} #divcalendartable { clear: both;}.daysheader { background: #c0c0c0; height: auto; text-align: center;}#prevmonthdates { background-color: #e0e0e0;}#nextmonthdates { background-color: #e0e0e0;}#currentmonthdates { background-color: #ffffff;}#cellvaluespan { background: #ff0000;}#cellvaluelist { background: #ffcc00;} .swim { font-family: arial, helvetica, sans-serif; font-size: 80%; text-align: center; background: #445511; color: #f5f5f5; margin-bottom: 5px; padding: 5px;}.chrono { font-family: arial, helvetica, sans-serif; font-size: 80%; text-align: center; background: #778899; color: #f5f5f5; margin-bottom: 5px; padding: 5px;}<div class=divcalendar><div id=calendaroverallcontrols> <!-- <div id=year></div> --> <div id=calendarmonthcontrols> <a id=btnprevyr href=# title=previous year><span><<</span></a> <a id=btnprev href=# title=previous month><span><</span></a> <!-- <input type=button src=images/btnprevmonth.png alt=submit id=btnprev/>--> <!-- <div id=month></div>--> <div id=monthandyear></div> <!--<input type=button src=images/btnnextmonth.png alt=submit id=btnnext/>--> <a id=btnnext href=# title=next month><span>></span></a> <a id=btnnextyr href=# title=next year><span>>></span></a> </div></div><div id=divcalendartable></div>",
    "present_kp": [
      "javascript",
      "html",
      "css"
    ],
    "absent_kp": [
      "datetime"
    ]
  },
  {
    "text": "setting up a second domain to my web server. i have a domain name which points to my web server, and we added a secondary domain for short urls, which points to the same ip address, however with the new domain, it is giving forbiddenyou don't have permission to access /s/mw-- on this server.where /s/mw-- is the short url parameters.i have a conf file for the new vhost and i have it like this<virtualhost *:80> servername dom.ain serveralias <url> documentroot /var/www/html/git/project/app errorlog ${apache_log_dir}/error.log customlog ${apache_log_dir}/access.log combined </virtualhost>",
    "present_kp": [],
    "absent_kp": [
      "domains",
      "apache2",
      "403 forbidden"
    ]
  },
  {
    "text": "determine the index where two lists diverge. backgrounda class provides an api to determine the index where two string lists diverge.import java.util.linkedlist;import static java.lang.system.out;/** * provides the ability to determine the index whereat two lists begin * to differ in content. both this list and the list to comapre against * must not contain null strings. */public class divergentlist extends linkedlist<string> { /** * answers the index at which the strings within this list differ from * the strings in the given list. * * @param list the list to compare against. * * @return -1 if the lists have no common strings. */ public int diverges( divergentlist list ) { int index = -1; if( valid( list ) && valid( this ) ) { while( equals( list, ++index ) ); } return index; } /** * answers whether the element at the given index is the same in both * lists. this is not null-safe. * * @param list the list to compare against this list. * @return true the lists have the same string at the given index. */ private boolean equals( divergentlist list, int index ) { return (index < size()) && (index < list.size()) && get( index ).equals( list.get( index ) ); } /** * answers whether the given element path contains at least one * string. * * @param list the list that must have at least one string. * @return true the list has at least one element. */ private boolean valid( divergentlist list ) { return list != null && list.size() > 0; } /** * test the functionality. */ public static void main( string args[] ) { divergentlist list1 = new divergentlist(); list1.addlast( name ); list1.addlast( first ); list1.addlast( middle ); list1.addlast( last ); list1.addlast( maiden ); divergentlist list2 = new divergentlist(); list2.addlast( name ); list2.addlast( middle ); list2.addlast( last ); // prints 1 out.println( list2.diverges( list1 ) ); list1.clear(); list1.addlast( name ); list1.addlast( middle ); list1.addlast( last ); list2.clear(); list2.addlast( name ); list2.addlast( middle ); list2.addlast( last ); list2.addlast( maiden ); list2.addlast( honorific ); // prints 3 out.println( list2.diverges( list1 ) ); list1.clear(); list2.clear(); // prints -1 out.println( list1.diverges( list2 ) ); list1.add( name ); list2.add( address ); // prints 0 out.println( list1.diverges( list2 ) ); list2.addfirst( name ); // prints 1 out.println( list1.diverges( list2 ) ); }}questionsa few questions:how can the code be simplified (e.g., use a different structure)?how can the code be improved (e.g., use generics; change the name, etc.)?how would you make the code null-safe (e.g., override all add methods)?how would you optimize the code?",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "performance",
      "algorithm",
      "linked list"
    ]
  },
  {
    "text": "levenberg-marquardt: how to calculate the jacobian with fixed parameters. so i'm working on a fitting algorithm using the levenberg-marquardt algorithm and i'm a bit stumped as to how to handle fixed parameters. looking around at other code, like the minpack version of the l-m algorithm, it looks like they are just setting the columns of the jacobian for fixed parameters to be 0.0, which makes sense as they are not changing. $j$ is being computed numerically and is working fine if there are not any fixed parameters. the problem is that i always get a singular uninvertible matrix for $j^tj$ when i do this, for example something like[[ 1005, 0, -110500], [ 0, 0, 0], [ -110500, 0, 3.013e7]] (the 2nd parameter was held fixed in this case...)does anyone have some experience with the l-m algo? any ideas as to how handle the fixed parameters in the jacobian? should i just create a jacobian that only has the free parameters and patch in the fixed parameters somewhere down the line later?",
    "present_kp": [
      "jacobian"
    ],
    "absent_kp": [
      "optimization"
    ]
  },
  {
    "text": "solving recurrence relations 'chip & conquer'. i've been tasked with solving some recurrence relations, and i've been running into trouble with so called 'chip & conquer' relations.here are some example problems:$$t(n) = t(n-5) + cn^2$$and$$t(n) = t(n-2) + \\log{n}$$i'm supposed to be giving an answer in $\\theta$ notation. how do i go around and solving relations like these?",
    "present_kp": [
      "recurrence relation"
    ],
    "absent_kp": [
      "asymptotics"
    ]
  },
  {
    "text": "hostname for computers in lan. i am using raspbian (like debian) and i used this tutorial <url> to setup my raspbian as a wifi access point. clients can connect to ap successfuly. but how can i do this - client should be able to open page http://local and it should point to my apache on ap. i don't want to set /etc/hosts on clients (they can vary) so i need to set it on ap directly and it should serve the right ip to clients when they open http://local. i followed dnsmasq this how to make a machine accessible from the lan using its hostname but it is not working (it worked for a while but then it stopped working)how should i set my ap to serve the right name ip translation?",
    "present_kp": [
      "debian"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "looping through an array of strings containing approximately 3 million elements. i have a function that loops through an array of strings containing approximately 3 million lines of strings. my problem is this loop is running too slowly and i want to know how to make it faster.string[] words = { hello, world, !, my, name, is, something, .}; list<myclass> result = new list<myclass>(); for (int i = 0; i < words.length; i++) { if (words[i] == &&&) { } else if (words.length > i + 2 && filecontains(words[i] + + words[i + 1] + + words[i + 2])) { result.add(new myclass(words[i] + + words[i + 1] + + words[i + 2])); words[i + 1] = &&&; words[i + 2] = &&&; } else if (words.length > i + 1 && filecontains(words[i] + + words[i + 1])) { result.add(new myclass(words[i] + + words[i + 1])); words[i + 1] = &&&; } else result.add(new myclass(words[i], parent)); }and my filecontains function which loops through the array of strings:public static bool filecontains(string text){ foreach (string line in arrayofwords) // approximately 3 million strings { if (text.tolower() == line.substring(0, line.lastindexof('|'))) { return true; } } return false;}",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "c#",
      "performance",
      "multithreading"
    ]
  },
  {
    "text": "handler for incoming network packages. i want to let you look through my nethandler which is basically the component which gets notified when a full packet arrived (not like tcp-packet but my own type of packets) and handles it.first of all, the handle method which gets called from the networkingvoid nethandler::handle(int id, char* data, int len) {#define p(id, type) case id: try_handle<type>(data, len); break switch (id) { p(0, game::networking::packets::hello); p(1, game::networking::packets::disconnect); p(2, game::networking::packets::chat); default: unhandled(id); }#undef p}yeah... as you can see, a little define to create a case for me. unhandled just prints out an error.next, the try_handle<>()template<typename t>void try_handle(char* data, int len) { t packet; if (!packet.parsefromarray(data, len)) { bad_packet(packet.gettypename(), len); return; } handle(packet);}it creates the actual corresponding packet and parses it (i use google protobuf). bad_packet, again, just prints an error. now the handle#define stub(type) virtual void handle(type& type) { unhandled(type::default_instance().gettypename()); } stub(game::networking::packets::hello) stub(game::networking::packets::disconnect) stub(game::networking::packets::chat)#undef stubi create a virtual method for every packet-type which calls unhandled. in my application i can now subclass this nethandler and override the handler-methods for all packets i expect.now the other direction, send packets. i actually wanted a single send-method which takes every possible packet and just sends it. but it needs to send the id along with it, so i created a packetregistryclass packetregistry {public: packetregistry() { for (int i = 0; i < 256; i++) messages[i] = nullptr; reg<game::networking::packets::hello>(0); reg<game::networking::packets::disconnect>(1); reg<game::networking::packets::chat>(2); } template<typename t> void reg(int id) { messages[id] = t::default_instance().getdescriptor(); } int getid(const google::protobuf::message& message) { const google::protobuf::descriptor* ptr = message.getdescriptor(); for (int i = 0; i < 256; i++) { if (messages[i] == ptr) return i; } return -1; } const google::protobuf::descriptor* messages[256];};as you can see, this is the third time i need to add every packet manually.i tried to come up with some template-magic, but i'm not that experienced yet.something like//in nethandlertemplate<typename t>void handle(t& packet) { unhandled(t::default_instance().gettypename()); }//in a subclasstemplate<>void handle<game::networking::packets::chat>(game::networking::packets::chat& chat) { }unfortunately doesn't work because... well... templates and virtual don't really like each other.any ideas how i can let the template-magic do more of the dirty work instead of defining methods, cases, and so on for every existing packet?",
    "present_kp": [
      "template"
    ],
    "absent_kp": [
      "c++"
    ]
  },
  {
    "text": "systemd-networkd .network ignored within systemd-nspawn container. i'm fiddling with systemd-nspawn containers on my raspberrypi. so far booting works fine. i use the --network-veth and --network-bridge=br0 options and bridging did work well with a kvm virtual machine.now i want to configure the container ip to a specific address and created a /etc/systemd/network/host.network file which seems to be ignored as the container gets its ip via dhcp.this is the file.[match]name=host0[network]dhcp=noaddress=192.168.0.16/24gateway=192.168.0.1dns=8.8.8.8systemd-networkd is running:root@bluehost-debian:~# systemctl status systemd-networkd.service systemd-networkd.service - network service loaded: loaded (/lib/systemd/system/systemd-networkd.service; enabled) active: active (running) since do 2016-09-01 21:10:54 utc; 12min ago docs: man:systemd-networkd.service(8) main pid: 69 (systemd-network) status: processing requests... cgroup: /machine.slice/machine-bluecloud.scope/system.slice/systemd-networkd.service 69 /lib/systemd/systemd-networkdsep 01 21:10:54 bluehost-debian systemd-networkd[69]: host0 : link configuredsep 01 21:10:54 bluehost-debian systemd[1]: started network service.sep 01 21:10:55 bluehost-debian systemd-networkd[69]: host0 : gained carriersep 01 21:10:58 bluehost-debian systemd-networkd[69]: host0 : dhcpv4 address 192.168.0.143/24 via 192.168.0.1sep 01 21:10:58 bluehost-debian systemd-networkd[69]: host0 : link configuredudev tells me that my value for the name field should be ok. why is it ignored?udevadm info /sys/class/net/host0p: /devices/virtual/net/host0e: devpath=/devices/virtual/net/host0e: ifindex=2e: interface=host0e: subsystem=netotherwise the network works ok. tried /etc/network/interfaces but this did not work in startup but only with ifup... (allow-hotplug host0 ...)i'm a little stuck so help is appreciated.",
    "present_kp": [],
    "absent_kp": [
      "systemd networkd",
      "systemd nspawn"
    ]
  },
  {
    "text": "in mvp pattern should the view instantiate a model object based on ui contents, or just pass these contents as parameters to the presenter?. i'm using mvp pattern in an android app that i'm developing. i have basically 4 elements:the adduserview where a new user can be added:the adduserpresenterthe userinfo (the pojo)the userinfomanager ( businness logic and storage manager)my question is:when i press the add button in the adduserview, it should get the content of the textviews, instantiate a new userinfo and pass it to the presenter. or should the adduserview just get the textviews contents and pass them to the adduserpresenter, which will in fact instantiate the userinfo and pass it to the userinfomanager?",
    "present_kp": [
      "android",
      "mvp"
    ],
    "absent_kp": [
      "java",
      "architecture"
    ]
  },
  {
    "text": "how to tell package manager that dependencies are already installed?. i'm running arch linux, and i have texlive 2013 installed from ctan, not from repositories. now when i try to install lilypond via pacman, it wants texlive-bin-2013.30973-7 and texlive-core-2013.31589-1 as dependencies.i guess there must be a way to point to my existing texlive, but what is it exactly?these threads (installing from source. how to resolve dependencies without destroying the package manager., package installation and dependancies - how to prevent installation of existing libraries?) don't seem to answer my question. do i need to involve into something like link a dependency in synaptic to the one already installed from source?",
    "present_kp": [
      "arch linux",
      "dependencies",
      "pacman"
    ],
    "absent_kp": [
      "software installation"
    ]
  },
  {
    "text": "rm: cannot remove input/output error in part of folder in a permanently mounted ntfs drive. i was experimenting with hdf5 installation from a permanently mounted ntfs data partition so lots of deletion etc. now part of the folder (containing some codes etc.) is not deleting and showing the above error. i have already ntfs-3g etc. but only have windows on virtualbox (from which also can not delete).thanks for all the help!i am on centos 7.",
    "present_kp": [
      "rm",
      "ntfs",
      "input"
    ],
    "absent_kp": [
      "ntfs 3g"
    ]
  },
  {
    "text": "edit .htaccess so that homepage of laravel site mirrors homepage blog. i have a laravel site at example.com and a wordpress site at blog.example.com.everything works well except that i'd love to have the root (index page) of example.com show (but not redirect to) the root of blog.example.com.my laravel .htaccess file is below.how can i change this (or what else should i do if not editing .htaccess) so that the homepage of my laravel site mirrors the homepage of my blog?both sites are hosted on the same cloudways server.<ifmodule mod_rewrite.c> <ifmodule mod_negotiation.c> options -multiviews </ifmodule> rewriteengine on #-------- # remove www subdomain (<url>) rewritebase / rewritecond %{http_host} ^www\\.(.*)$ [nc] rewriterule ^(.*)$ http://%1/$1 [r=301,l] #-------- # redirect trailing slashes if not a folder... rewritecond %{request_filename} !-d rewriterule ^(.*)/$ /$1 [l,r=301] # handle front controller... rewritecond %{request_filename} !-d rewritecond %{request_filename} !-f rewriterule ^ index.php [l] # handle authorization header rewritecond %{http:authorization} . rewriterule .* - [e=http_authorization:%{http:authorization}] </ifmodule>",
    "present_kp": [
      "htaccess",
      "subdomain",
      "mirror"
    ],
    "absent_kp": [
      "apache"
    ]
  },
  {
    "text": "can the same ext4 disk be mounted from two hosts, one readonly?. i know that mounting the same disk with an ext4 filesystem from two different servers (it's an iscsi vloume) will likely corrupt data on the disk. my question is will it make any difference if one of the servers mounts the disk read-only while the other mounts it read-write?i know ocfs2 or the likes could be used for this and that i could export the disk with nfs to be accesible to the other server, but i would like to know if the setup i propose will work.",
    "present_kp": [
      "mount",
      "ext4"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "why csv is consuming more file size in my unix script?. i'm using this unix script which it is fetching records in the form of csv. i have a sql query used for this purpose. it contains below information set pagesize 5000set colsep ,set linesize 2000set feedback offset newpage noneset underline offis it due to pagesize it is consuming more space?the script returns 4mb of csv(obtm.csv) file whereas if i'm converting the same to (obtm.xlsx) it is 48kb.kindly clarify my query",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "solaris",
      "ksh",
      "database"
    ]
  },
  {
    "text": "polymorphic (owned) reference wrapper for class hierarchies. rationale: i often have the requirement to own object instances, while preserving polymorphic behavior (i.e. own the object and hold it by pointer, or reference).this is usually expressed as a pointer (most of the times, std::unique_ptr<t>), but when the pointer is stored in a std:: container, client syntax becomes tricky (with - for example - vector iterators being dereferenced to a pointer - instead of a reference).to avoid this, i have implemented a polymorphic wrapper for a (base) class, that holds a pointer to the base class, and allows it's population using a specialization.the wrapper allows implicit conversion to the held type (as a base [const] reference) and implements fast, non-intrusive cloning, for the held type. this is based on copy construction of the specialized type and stdex::details::polymorphic_clone<base,specialized> template specialization, to clone the correct specialized type).please review the code, and let me know if there are any pitfalls or design/implementation problems with it (one known limitation is described at the end).#pragma once#include <memory>#include <cassert>#include <functional>#include <stdexcept>#include <vector>namespace stdex { inline namespace details { /// @brief deep copy construct from (specialized&)*src /// /// @retval nullptr if src is nullptr /// @retval specialized clone of *src /// /// @note undefined behavior if src does not point to a specialized* template<typename base, typename specialized> base* polymorphic_clone (const base* src) { static_assert(std::is_base_of<base, specialized>::value, specialized is not a specialization of base); if (src == nullptr) return nullptr; return new specialized{ static_cast<const specialized&>(*src) }; } } /// @brief polymorphic reference interface over a base class /// /// respects polymorphic behavior of class ref. /// instances have deep copy semantics (clone) and /// [const] base& interface /// /// @note not regular: no trivial way to implement non-intrusive equality /// /// @note safe to use with standard containers template<typename base> class polymorphic final { public: /// functor capable to convert a base* to it's specialized type /// and clone it (intrusive implementation can be used) /// /// example intrusive implementation (if supported by base): /// []( const base* src ) { return src->clone(); } typedef std::function<base* (const base*)> clone_functor; /// @brief construct (takes ownership of ptr) template<typename specialized, typename clonespecialized> polymorphic(specialized* ptr, clonespecialized functor) noexcept : instance_{ptr}, clone_{std::move(functor)} { static_assert(std::is_base_of<base, specialized>::value, specialized is not a specialization of base); static_assert( std::is_constructible<clone_functor, clonespecialized>::value, clonespecialized is not valid for a clone functor); } // not implemented: ub cloning in case client provides specialized ptr // polymorphic(base* ptr); // @note empty constructor for std:: containers support polymorphic() = default; polymorphic(polymorphic&&) = default; polymorphic(const polymorphic& other) // : polymorphic{std::move(other.clone())} : polymorphic{ other.clone() } // comment by @dyp { } // polymorphic& operator=(polymorphic other) polymorphic& operator=(polymorphic other) noexcept // comment by @dyp { std::swap(instance_, other.instance_); std::swap(clone_, other.clone_); return *this; } ~polymorphic() = default; /// @brief cast to contained type /// @pre instance not moved /// @pre *this initialized with valid instance operator base&() const { assert(instance_.get()); return *instance_.get(); } /// @brief cast to contained type /// @pre instance not moved /// @pre *this initialized with valid instance operator const base&() const { assert(instance_.get()); return *instance_.get(); } private: polymorphic clone() const { return { clone_(instance_.get()), clone_functor{clone_} }; } std::unique_ptr<base> instance_; clone_functor clone_; }; // edited after comment by @dyp template<typename base, typename specialized, typename cf> polymorphic<base> to_polymorphic(specialized&& temp, cf functor) { return { new specialized{std::move(temp)}, typename polymorphic<base>::clone_functor{std::move(functor)} }; } template<typename base, typename specialized> polymorphic<base> to_polymorphic(specialized&& temp) { static_assert(std::is_base_of<base, specialized>::value, specialized is not a specialization of base); return to_polymorphic<base,specialized>( std::move(temp), polymorphic_clone<base,specialized> ); } template<typename base, typename specialized, typename ...args> // polymorphic<base> to_polymorphic(args ...args) polymorphic<base> to_polymorphic(args&& ...args) // comment by @dyp { static_assert(std::is_constructible<specialized, args...>::value, cannot instantiate specialized from arguments); return to_polymorphic<base,specialized>( std::move(specialized{std::forward<args...>(args...)})); } template<typename base> using polymorphic_vector = std::vector<polymorphic<base>>; template<typename base, typename ...args> polymorphic_vector<base> to_polymorphic_vector(args&& ...args) { // comment by @dyp (add std::forward) return { to_polymorphic<base>(std::forward<args>(args))... }; }} // stdexexample use (using a class hierarchy based on view, a generic responder for http requests - the implementation of view is not important here, i just had it in existing code):stdex::polymorphic_vector<view> views = // explicit type for clarity stdex::to_polymorphic_vector<view>( echo_view{/echo}, // class echo_view : public view directory_view{/static_files, ~/http-server/static} // class directory_view : public view );for(auto& v: views) if(v.matches(reuqest.url())) // bool view::matches(...); auto response = v.handle(request); // virtual view::handle(...) = 0;limitations of this implementation:if you use multiple inheritance do not use stdex::details::polymorphic_clone. write an implementation based on dynamic_cast instead, and use to_polymorphic(specialized&& temp, cf functor).",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "c++11",
      "polymorphism"
    ]
  },
  {
    "text": "find biggest files and delete automatically. i run this command to find the biggest files:du -sh | sort -rh | head -5then i do -rm rf somefile.is there a way to automatically delete the files found from the former command?",
    "present_kp": [],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "setting the topcolors environment variable. i don't seem to be able to find any examples on the internet for this environment variable, which top will apparently read and use to display colours.how would i set this variable correctly so top used alternate colours in its output?i have solaris top version 3.5beta9.",
    "present_kp": [
      "top"
    ],
    "absent_kp": [
      "environment variables"
    ]
  },
  {
    "text": "how to export a private pgp email key. i have made a keypair for my email address using gnupg. i thought that i should probably keep a backup of it so that if i lose my desktop computer i can continue using the same key.is this the correct thinking?how can i export my private key / the whole pair?",
    "present_kp": [],
    "absent_kp": [
      "security",
      "encryption",
      "key authentication",
      "gpg"
    ]
  },
  {
    "text": "useradd command not found. i'm trying to make a script where it makes a test user with a home dir and the rights he needs but everytime i run the script i get the following error:/home/thomas/scripts/createuser.sh: line 2: useradd: command not foundpasswd: user 'password' does not exist/home/thomas/scripts/createuser.sh: line 4: mkhomedir_helper: command not foundchmod: cannot access /home/test/: no such file or directoryscript:#!/bin/bashuseradd test passwd passwordmkhomedir_helper testchmod 700 /home/test/i'm new to linux so i don't know why this happens, any solutions?",
    "present_kp": [
      "linux",
      "useradd"
    ],
    "absent_kp": [
      "shell script",
      "opensuse"
    ]
  },
  {
    "text": "what's the original image address from a adobe scene 7 site?. initially i would like to find out an image from nike store, then i found this:<url> nike uses adobe scene7 for its dynamic imaging.how could i grab the original file from it?some useful links <url> <url>",
    "present_kp": [],
    "absent_kp": [
      "images"
    ]
  },
  {
    "text": "how to auto-mount all usb-devices at same usb socket to same mountpoint. i have a small computer with 2 usb sockets : a and b.i want any external usb disk, attached to socket a - to be mounted as deviceai want any external usb disk, attached to socket b - to be mounted as devicebexpecially: any amount of different disks may be attached to socket a. they all shall be mounted as devicesa. because of this case i can not use uuids of disks and have to identify the sockets.i am using udev rules to automount the disks.how would i implement that?",
    "present_kp": [],
    "absent_kp": [
      "ubuntu",
      "debian",
      "usb drive",
      "automounting"
    ]
  },
  {
    "text": "developing using a non-official kit on the android?. i have been doing some research on developing on the android platform and found that the only way to develop an app using c++ is using the ndk. i also came to know that the ndk has limited support to c/c++, with c++ having even lesser support than c.here's the problem. i need to develop using c++ as i'm not very familiar with java. in fact, not familiar at all. i'm still 18, so i don't have much experience with many programming languages. after doing some more research i have found a non-official ndk, called the ndk-crystax that implements more support for c/c++ than the official ndk. before i start using i have to know if it would be legal to use this custom ndk in an android app and still be able to sell it on the android marketplace. is it? or is it not?another solution would be if the newer releases of the ndk had full support for c/c++. but i'm not sure of that either, so i'm seeking your generosity again and asking you to share your knowledge on this too.",
    "present_kp": [
      "c++",
      "android"
    ],
    "absent_kp": []
  },
  {
    "text": "software updater waiting for q key press. a few days ago ubuntu's software updater awaits user input (q to quit). i have attached a screenshot with the problem. i think this is related with fake sync from debian.what does this mean and how to fix this ?",
    "present_kp": [
      "ubuntu"
    ],
    "absent_kp": [
      "apt",
      "upgrade"
    ]
  },
  {
    "text": "iptables and ip forwarding for failover. hi i have an ethernet nic interface with 4 additional virtual interfaces (failovers) all configured with public ip4 (ip-1 to ip-5) / netmask 255.255.255.255 / broadcast addr same as ip:eth0 -> ip-1eth0:0 -> ip-2eth0:1 -> ip-3eth0:2 -> ip-4eth0:3 -> ip-5the primary network interfaceauto eth0iface eth0 inet static address ip-1 netmask 255.255.255.255 broadcast ip-1 post-up route add isp-gw dev eth0 post-up route add default gw isp-gw post-up ip addr add 192.168.100.254/24 dev eth0 post-down route del isp-gw dev eth0 post-down route del default gw isp-gw post-down ip addr del 192.168.100.254/24 dev eth0failover 5auto eth0:3iface eth0:3 inet static address ip-5 netmask 255.255.255.255 broadcast ip-5& bridge with local ip (ip-b) used by lxcauto br0iface br0 inet static network 192.168.100.0 address 192.168.100.100 # ip-b gateway 192.168.100.254 $ ip-gw broadcast 192.168.100.255 netmask 255.255.255.0 bridge_ports none bridge_maxwait 0test:# ping lcx container # $ ping 192.168.100.1 ping 192.168.100.1 (192.168.100.1) 56(84) bytes of data. 64 bytes from 192.168.100.1: icmp_seq=1 ttl=64 time=0.161 ms 64 bytes from 192.168.100.1: icmp_seq=2 ttl=64 time=0.075 ms# ping bridge br0# $ ping 192.168.100.100 ping 192.168.100.100 (192.168.100.100) 56(84) bytes of data. 64 bytes from 192.168.100.100: icmp_seq=1 ttl=64 time=0.113 ms 64 bytes from 192.168.100.100: icmp_seq=2 ttl=64 time=0.056 ms# pink gatway / alias eth0 ip-1# $ ping 192.168.100.254 ping 192.168.100.254 (192.168.100.254) 56(84) bytes of data. 64 bytes from 192.168.100.254: icmp_seq=1 ttl=64 time=0.048 ms 64 bytes from 192.168.100.254: icmp_seq=2 ttl=64 time=0.090 msand i want now to route traffic from eth0 ip5 (eth0:3) <-> br0 ip-b and other traffic to stay at eth0 how to set netfilter rules to achieve that ? i know that i must add iptables -t nat -a postroutingiptables -t nat -a prerouting rules something like ?# change public host ip-5 to private ip-b# $ iptables -t nat -a prerouting -d ip-5 -j dnat --to ip-b## change private ip-b to public ip-5 use snat instead of masquerade for static ip# $ iptables -t nat -a postrouting -s ip-b -j snat --to ip-5## force to send reply to gateway where ip-gw = 192.168.100.254/16# $ iptables -t nat -a postrouting -o br0 -s ip-gw -d ip-5 -j snat --to ip-band i have enabled also forwarding in sysctl lxc container is debianlxc.network.type = vethlxc.network.name = veth0lxc.network.flags = uplxc.network.link = br0lxc.network.veth.pair = veth0-sidlxc.network.ipv4 = 192.168.100.1/24lxc.network.ipv4.gateway = 192.168.100.254lxc container route kernel ip routing tabledestination gateway genmask flags metric ref use ifacedefault 192.168.100.254 0.0.0.0 ug 0 0 0 veth0192.168.100.0 * 255.255.255.0 u 0 0 0 veth0veth0 link encap:ethernet hwaddr xx:xx:xx:xx:xx:xx inet addr:192.168.100.1 bcast:192.168.100.255 mask:255.255.255.0server is ubuntu 15.10kernel ip routing tabledestination gateway genmask flags metric ref use ifacedefault isp gw 0.0.0.0 ug 0 0 0 eth0default 192.168.100.254 0.0.0.0 ug 0 0 0 br0isp gw * 255.255.255.255 uh 0 0 0 eth0192.168.100.0 * 255.255.255.0 u 0 0 0 br0when i ping ip-5 from outside tcpdump on br0 is not receiving any icmp do i need add some how gateway or static route ? what im doing wrong ?# on lcx container # $ apt update err <url> jessie release.gpg could not resolve 'http.debian.net' w: failed to fetch <url> could not resolve 'http.debian.net'# on host :# $ tcpdump -vi br0 tcpdump: listening on br0, link-type en10mb (ethernet), capture size 262144 bytes 01:54:21.370892 ip (tos 0x0, ttl 64, id 59200, offset 0, flags [df], proto udp (17), length 71) 192.168.100.1.58916 > cdns.ovh.net.domain: 46783+ a? security.debian.org.local. (43) 01:54:21.371049 ip (tos 0x0, ttl 64, id 59201, offset 0, flags [df], proto udp (17), length 71) 192.168.100.1.58916 > cdns.ovh.net.domain: 65501+ aaaa? security.debian.org.local. (43)# host ping and tcpdump # $ ping 192.168.100.1 ping 192.168.100.1 (192.168.100.1) 56(84) bytes of data. 64 bytes from 192.168.100.1: icmp_seq=1 ttl=64 time=0.118 ms $ tcpdump -vibr0 tcpdump: listening on br0, link-type en10mb (ethernet), capture size 262144 bytes 02:07:47.168384 ip (tos 0x0, ttl 64, id 24937, offset 0, flags [df], proto icmp (1), length 84) ip-5 > 192.168.100.1: icmp echo request, id 5199, seq 1, length 64 02:07:47.168460 ip (tos 0x0, ttl 64, id 2157, offset 0, flags [none], proto icmp (1), length 84) 192.168.100.1 > ip-5: icmp echo reply, id 5199, seq 1, length 64 $ ping from outside ip-5 -> tcpdump on br0 no packet captured create routing table# take my nic to world # $ ip route add isp-gw dev eth0 $ ip route add default via isp-gw $ ip r default via isp-gw dev eth0 isp-gw dev eth0 scope link $ ping ip-1 from outside ok! # add bridge br0 route via gateway (alias of ip-1 = ip-gw) # $ ip route add 192.168.100.100 via 192.168.100.254 $ ip r default via isp-gw dev eth0 isp-gw dev eth0 scope link 192.168.100.100 via 192.168.100.254 dev eth0 one big question ?should i receive icmp from ip-5 from outside if i set dnat and bring down br0 ?",
    "present_kp": [
      "iptables",
      "routing",
      "netfilter"
    ],
    "absent_kp": [
      "iptables redirect"
    ]
  },
  {
    "text": "what kind of object relational mapping is appropriate here?. in my database i have a table that looks like this master(id, name, attr1...). every id will have at least 1 entry in additional tables that have additional attributes. those tables specialize the master table.spec1(masterid, attr2,...)spec2(masterid, attr3,...)...so, not sure how to map this to object oriented design. if every id could have just one specialization then it would be easy, master would be abstract class and specializations would be concrete inherited classes but in this scenario, single id can have all specializations and they could be added or removed during his lifetime in the database. each specialization has unique business rules ofc.",
    "present_kp": [
      "object oriented design"
    ],
    "absent_kp": [
      "c#",
      "orm"
    ]
  },
  {
    "text": "vimscript-python support not working in terminal. when starting vim in a mingw64 terminal emulator on windows, the command :py print(1) fails, sayingcould not load library msys-python2.7.dllsorry, this command is disabled, the python library could not be loaded.my vim installation does have python support, as vim --version shows both python/dyn as python3/dyn. also, when executing the same command in gvim, no problems.(needless to say, i have python installed, both 2 and 3)what could be the cause of this problem?",
    "present_kp": [
      "terminal"
    ],
    "absent_kp": [
      "microsoft windows",
      "vimscript python"
    ]
  },
  {
    "text": "resize mdadm/software raid underlying partition and filesystem. i am running out of space on my root partition and would like to steal some from a different partition. the drives are 2x120gb with mdadm software raid.i am using centos 6.5 64-bit. i used the centos installer guided raid setup.it seems like most of the howtos are gearing me towards not having the underlying partitions. so others would have just /dev/md0. they would perform a resize2fs /dev/md0 25g (reducing from 50g for example) and then use mdadm to resize it, etc.the layout is:filesystem size used avail use% mounted on/dev/md0p5 9.7g 7.1g 2.1g 78% /tmpfs 16g 0 16g 0% /dev/shm/dev/md0p1 194m 99m 86m 54% /boot/dev/md0p2 68g 7.2g 57g 12% /var/wwwcat /proc/mdstat:personalities : [raid1] md0 : active raid1 sdb[1] sda[0] 117220736 blocks [2/2] [uu]unused devices: here is the fdisk:fdisk -ldisk /dev/sda: 120.0 gb, <phone> bytes255 heads, 63 sectors/track, 14593 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0x00035afc device boot start end blocks id system/dev/sda1 * 1 26 204800 83 linuxpartition 1 does not end on cylinder boundary./dev/sda2 26 8950 71680000 83 linux/dev/sda3 8950 11039 <phone> 82 linux swap / solaris/dev/sda4 11039 14594 28557312 5 extended/dev/sda5 11039 12314 <phone> 83 linuxdisk /dev/sdb: 120.0 gb, <phone> bytes255 heads, 63 sectors/track, 14593 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0x00035afc device boot start end blocks id system/dev/sdb1 * 1 26 204800 83 linuxpartition 1 does not end on cylinder boundary./dev/sdb2 26 8950 71680000 83 linux/dev/sdb3 8950 11039 <phone> 82 linux swap / solaris/dev/sdb4 11039 14594 28557312 5 extended/dev/sdb5 11039 12314 <phone> 83 linuxdisk /dev/md0: 120.0 gb, <phone> bytes2 heads, 4 sectors/track, 29305184 cylindersunits = cylinders of 8 * 512 = 4096 bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0x00035afc device boot start end blocks id system/dev/md0p1 * 257 51456 204800 83 linuxpartition 1 does not end on cylinder boundary./dev/md0p2 51457 <phone> 71680000 83 linuxpartition 2 does not end on cylinder boundary./dev/md0p3 <phone> 22165760 <phone> 82 linux swap / solarispartition 3 does not end on cylinder boundary./dev/md0p4 22165761 29305088 28557312 5 extendedpartition 4 does not end on cylinder boundary./dev/md0p5 22166273 24726272 <phone> 83 linuxso what can i do to grow the root partition and shrink the /var/www partition?",
    "present_kp": [
      "centos",
      "raid",
      "mdadm",
      "software raid"
    ],
    "absent_kp": []
  },
  {
    "text": "clickable pdfs in rxvt. i would like to open pdfs (say, with evince) by clicking in the terminal.the setup is urxvt in fedora 19 here, but if urxvt cannot do this, can you let me know which terminal emulators can. i got url detection working by putting:urxvt*perl-lib: /usr/libi64/urxvt/perl/urxvt*perl-ext-common: default,matcherurxvt*matcher.button: 1urxvt*url-launcher: /usr/bin/xdg-openinto my ~/.xdefaults and running xrdb -load ~/.xdefaults, so hopefully there is some similar solution for the problem at hand.",
    "present_kp": [
      "pdf",
      "rxvt",
      "evince"
    ],
    "absent_kp": []
  },
  {
    "text": "copy modified files from one server to other. scenario:2 servers (*.12 and *.13)cakephp application on both of them.*.12 is production server*.13 is development servernow i want to copy all files modified the last 2 days from test server to production server without the directory ./tmpi can find them on production server with:find ./ -type d -name tmp -prune -o -mtime -2 -exec ls {} \\;on both servers i have only ssh access.",
    "present_kp": [
      "ssh",
      "find",
      "copy"
    ],
    "absent_kp": [
      "ubuntu"
    ]
  },
  {
    "text": "how to log all system calls made by a process and all its descendants with auditd. i can doauditctl -a always,exit -s all -f pid=1234to log all the system calls done by pid 1234 and:auditctl -a always,exit -s all -f ppid=1234for its children, but how do i cover the grand-children and their children as well (current and future)?i cannot rely on (e)uid/(e)gid that do change.(note that using strace is not an option either)",
    "present_kp": [
      "audit"
    ],
    "absent_kp": [
      "linux",
      "linux audit"
    ]
  },
  {
    "text": "in tensorflow, what kind of neural network should i use?. i am doing tensorflow tutorial, getting what tf is. but i am confused about what neural network should i use in my work. i am looking at single layer neural network, cnn, rnn, and lstm rnn.-----------------------what i'm going to do is...-----------------------there is a sensor which measures something and represents the result in 2 boolean ways. here, they are blue and red, like this:the sensor gives result values every 5minutes. if we pile up the values for each color, we can see some patterns: number inside each circle represents the sequence of result values given from sensor. (for example, 107 was given right after 106) when you see from 122 to 138, you can see decalcomanie-like pattern. i want to predict the next result value, before the sensor imparts the result, with probability. machine has to know what the next will be, based on patterns from past results.i may do supervised learning using past results. but i'm not sure which neural network or method is suitable. thinking that this work needs pattern using past results (have to see context), and memorize past results, maybe lstm rnn (long-short term memory recurrent neural network) would be suitable one.could you tell me which one is suitable for this work?",
    "present_kp": [
      "neural network",
      "tensorflow",
      "rnn"
    ],
    "absent_kp": []
  },
  {
    "text": "what is a good tool to restore files within their path when you rm -r from root?. title said it all. xdtried foremost but as far as i can see it only recovers the files itself.is there some tool which reproduces the directory tree? i mean according to path of a file. does the ext4 filesystem even keep path when removing the file? i know next to nothing about this xd...also sorry for this silly thing.",
    "present_kp": [],
    "absent_kp": [
      "filesystems",
      "data recovery"
    ]
  },
  {
    "text": "google maps: find level above sea of a place. does google maps (or any other public gis) have info of the level above sea of ground?if so, how can i get it?",
    "present_kp": [
      "google maps"
    ],
    "absent_kp": [
      "google earth"
    ]
  },
  {
    "text": "why is one traversal sufficient for the kuhn's maximal matching problem algorithm?. in kuhn's algorithm for the maximum bipartite matching problem we iterate through the vertices of one partite set and try to build the increasing chain, starting with the current vertex. once the traversal is completed, we claim that the maximal matching is found. but why don't we need to check again the vertices for which we weren't able to build the increasing chain? how can we prove that if for some vertex v it was not possible to build the increasing chain starting with v during the traversal, then we don't need to check v again? why shouldn't we perform the second traversal?",
    "present_kp": [
      "bipartite matching"
    ],
    "absent_kp": [
      "graphs"
    ]
  },
  {
    "text": "adsense is adding a meta robots tag with noindex,nofollow - would this negatively affect my seo?. when i add adsense code to my webpage, i noticed that adsense has a meta robots tag like below:<meta content=noindex,noarchive,nofollow name=robots>my page has no other meta robots tags. would this negatively affect seo for my page?should i add a meta robots tag with index,follow to my page?",
    "present_kp": [
      "seo",
      "meta robots"
    ],
    "absent_kp": [
      "google adsense"
    ]
  },
  {
    "text": "shortening url to cms. hiwe have a cms application that lets people create websites under our domain.the system was built a few years ago and it used a method that transfers parameters such as website id, folder code and more using the url. this method created a giant url for every item in the website for example:my domain is <url> users website on my domain is <url> every time that a user enters his website he gets a link like thiswww.domain.com/page.aspx?code=blablasdsdsdsdsds&folder=blablablablablabla and more.we are trying to reduce the string size in the url.what are our options? can we show the user one url like a virtual one and still work the same with the old url?we are trying to locate a solution that wont make us rewrite our entire application.the application is built in c# and the web server is iis 6.thanks",
    "present_kp": [],
    "absent_kp": [
      "shortcuts"
    ]
  },
  {
    "text": "is there a standard recently-used algorithm based on time and usage count?. everyone is familiar with most recently used files lists in software and in oss like windows.some programs just sort by time. i've always been fairly annoyed at this. others like windows take usage count into consideration. some move the item halfway to the top each time it is used, which seems to make sense.rather than me blindly guessing at what combination of calculations might be nicest for my end users, is there some well-known most helpful standard for end-user recently-used lists?(my searches turn up information about mru caching, but i can't tell how applicable any of that is; it's server efficiency facing vs user efficiency facing.)",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "data structures",
      "sorting"
    ]
  },
  {
    "text": "parted: create new partition. i have a 3tb disk, and i understand i have to use parted if i want to create a partition bigger than 2tb. all right then.parted /dev/sdb(parted) mklabel gpt(parted) mkpart primary file system type? [ext2]?say what? it does not let me to create a partition without specifying a fs type. why does parted insist on specifying a fs type. afaiu, a fs type is completly independent from a partition. in man parted, i read that:fs-type can be one of fat16, fat32, ext2, linux-swap, or reiserfs.i don't want any of these. i want to create a partition to be used as luks partition. what should i select?",
    "present_kp": [
      "luks",
      "parted"
    ],
    "absent_kp": []
  },
  {
    "text": "routing between two private networks (nics). i have two private networks say: 10.0.1.0/8 and 192.168.0.0/24i have two machines with two nics per each machine.machine1 nic1: 192.168.0.10machine1 nic2: 10.0.1.10machine2 nic1: 192.168.0.11machine2 nic2: 10.0.1.11how to configure the routing so that from machine1 to machine2, it would use actually machine1 nic2?the thing is that 10.0.1.0 network is gigabit and 192 one is fast ethernet (100mbit).my goal is to communicate between those two through the fastest connection (i.e: nic2) even if they are trying to access by nic1's ip.",
    "present_kp": [
      "routing",
      "ethernet"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "displaying number of unread posts for a message board. i am working on a rails 3.2.6 app for a friend which implements some message board functionality. users can post messages into a categories. each user also has a list of other users they have friended.i got a feature request recently to display the number of unread posts made by the current user's friends next to each category. this is tracked on a category basis, not a per post basis, since the posts are displayed on a main newsfeed and you can't read a single post. so the feature request states that when a user clicks a category, which filters posts by that category, it will reset the unread count for that category.i've implemented the unread counter by adding a database table that tracks the last time a user read all the messages. the table contains user_id, category_id, and last_read_time.now i am trying to implement the unread counters. i set up some scopes in my post model (some of these are used in different places, which is why they are separate scopes):scope :by_users, lambda { |users| where(user_id in (?), users) unless users.nil? }scope :by_categories, lambda { |categories| where(category_id in (?), categories) unless categories.nil? }scope :since, lambda { |date| where(updated_at > ?, date) unless date.nil? }here is my first crack at an unread method (also in the post model):def self.unread_count(user, category) read_time = readstatus.where(user_id = ? and category_id = ?, user.id, category.id).first if read_time.nil? #handle it end #if user has no friends, there will be no unread posts displayed if user.friends.count == 0 return else friends = user.friends end unread = by_users(friends).since(read_time.last_read_time).by_categories(category.id).count unless unread == 0 ( + unread.to_s + new) endendthis works fine, but i would like to make this more efficient. right now, there are 81 categories users can post in. this means when the homepage loads there are 81 count queries firing off, and this is repeated anytime the homepage is re-loaded. i can't think of any way to cache this value or eliminate these queries, since the unread count can change at any given moment and needs to be refreshed when the page is reloaded.any tips/tricks/rails pixie dust to make this better? every solution i think of either results in stale counter values or a large db hit (for what i feel is a fairly trivial feature).",
    "present_kp": [],
    "absent_kp": [
      "ruby",
      "ruby on rails"
    ]
  },
  {
    "text": "structural fem analysis: transiet response vs frequency response. i am running 2 simulations on a cantilever plate in nastran: one is a transient analysis (time domain) and the other one is a frequency response analysis.the transient analysis computes the response to time-varying excitations explicitly defined in the time domain. the equation it has to solve is$m \\ddot{u}(t) + c \\dot{u}(t) + k u(t) = p(t)$where $m,c,k$ are matrices and $u,p$ are vectors. the equations is solved by numerical integration (central difference method). $p(t)$ is a sinusoid at frequency equal to the $1^{st}$ natural frequency of the plate.the frequency response compute the response to oscilatory excitation explicitly defined in the frequency domain. the computed responses are given as magnitude/phase (with respect to the forcing) or as real/imaginary components. the equation is$[-\\omega^2 m +i \\omega c+k] u(\\omega) = p(\\omega)$the forcing function is defined in the range $20-150 \\ hz$ to excite the first mode only.running the 2 analysis i would expect to obtain the same results in terms of maximum displacement (since i am considering only the first mode in both cases), but it is not so. the amplitudes in the time plot and in the magnitude plot do not match at all. where the problem could be? am i missing something? but if i plot the real/imaginary components, the amplitude of the real part (picture on the left) matches the time domain amplitude. how should i interpreted it?",
    "present_kp": [],
    "absent_kp": [
      "finite element",
      "time integration"
    ]
  },
  {
    "text": "set umask for sshfs-mounted filesystem. i have a remote sshfs filesystem mounted on /mnt/data. following is the relevant line in /etc/fstab:<email>/var/www/ /mnt/data fuse.sshfs rw,noauto,nodev,nosuid,noexec,_netdev,allow_other,default_permissions,uid=martin,gid=martin 0 0the files in /var/www/ on the remote system are owned by user www-data, but i am using uid=martin,gid=martin to map the ownership on the mounted filesystem to uid 1000.when i cd to /mnt/data/ as martin, i have the correct file permissions/ownership, but i need to change the umask.on the remote filesytem, the user www-data has umask 0027. on my local filesystem, the user martin has umask 0077. i want to keep the umask 0077 on my local files, but use 0027 on the sshfs mounted files (ie all files in /mnt/data/).is this even possible ?i have tried setting acl permissions on the whole directory on the remote filesystem:setfacl -d -m g::rx /var/www/setfacl -d -m o::--- /var/www/but this has no effect on the sshfs mounted share.",
    "present_kp": [
      "permissions",
      "mount",
      "sshfs",
      "umask"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "expand kde activities concept to the shell. sometimes, i use kde, and one of the things that i like the most in kde 4 is the activity concept. at work, it is very useful because i often work on several different projects during one day. switching to another activity enables me to change the widgets, so that i can have access to folders related to the current project, for instance.i've decided to use this concept in the shell, so i have coded a small bash function called switch, which sets aliases useful for the current project, e.g. alias cdwww=~/public_html/current_project/www , and so on.my question is : is there a way i can synchronise kde activities with shell activities, that is calling 'switch myproj' on every opened terminal when switching to activity 'myproj' through kde and vice versa (bonus question)?another question : how do i make my newly created aliases work in all consoles? is there a way i can detect every opened terminal in konsole or in gnome-terminal and execute my function in it?edit: here is the switch function, located at the end of my .bashrc file, feel free to comment:function switch() { if [ ! -d ~/.switch ] then mkdir ~/.switch fi if [ ! -f ~/.switch/proj.save ] then touch ~/.switch/proj.save fi echo $1 > ~/.switch/proj.save case $1 in meddispar ) echo switching to meddispar... echo setting cdproj alias alias cdproj=cd ~/public_html/onp/ echo setting cdwww alias alias cdwww=cd ~/public_html/onp/www/ echo setting cc alias alias cc=cdwww && php bin/php/ezcache.php --clear-all --purge && cd - ;; darjeeling ) echo switching to darjeeling... echo setting cdproj alias alias cdproj=cd ~/public_html/darjeeling/ echo setting cdwww alias alias cdwww=cd ~/public_html/darjeeling/www/ echo setting cc alias alias cc=rm -rf ~/public_html/darjeeling/www/var/cache/* ;; * ) echo '$1'? wtf? rm ~/.switch/proj.save ;; esac}if [ -f ~/.switch/proj.save ]then switch 'cat ~/.switch/proj.save'fias per gilles' answer, here is what i have got:greg@tiny :) ~ > qdbus |ack ctivity org.kde.activitycontroller-1949 org.kde.activitymanagergreg@tiny :) ~ > qdbus org.kde.activitymanager //activitymanager/mainapplication/statusnotifierwatcher/connections/kbuildsycoca/kded/kxkb/modules/modules/statusnotifierwatcher/modules/activitymanager/modules/device_automounter/modules/dnssdwatcher/modules/favicons/modules/freespacenotifier/modules/keyboard/modules/khotkeys/modules/kpackagekitd/modules/kremotecontroldaemon/modules/ktimezoned/modules/kwrited/modules/nepomuksearchmodule/modules/networkmanagement/modules/networkstatus/modules/powerdevil/modules/randrmonitor/modules/remotedirnotify/modules/solidautoeject/modules/statusnotifierwatcher/org/org/freedesktop/org/freedesktop/powermanagement/org/freedesktop/powermanagement/inhibit/org/kde/org/kde/networkmanagement/org/kde/networkmanagement/activatable/org/kde/networkmanagement/activatable/10/org/kde/networkmanagement/activatable/11/org/kde/networkmanagement/activatable/12/org/kde/networkmanagement/activatable/13/org/kde/networkmanagement/activatable/14/org/kde/networkmanagement/activatable/15/org/kde/networkmanagement/activatable/16/org/kde/networkmanagement/activatable/17/org/kde/networkmanagement/activatable/2/org/kde/networkmanagement/activatable/3/org/kde/networkmanagement/activatable/4/org/kde/networkmanagement/activatable/5/org/kde/networkmanagement/activatable/6/org/kde/networkmanagement/activatable/7/org/kde/networkmanagement/activatable/8greg@tiny :) ~ > qdbus org.kde.activitymanager /activitymanagermethod qstringlist org.kde.activitymanager.activitiesforresource(qstring uri)method qstring org.kde.activitymanager.activityicon(qstring id)method qstring org.kde.activitymanager.activityname(qstring id)signal void org.kde.activitymanager.activitynamechanged(qstring id, qstring name)method qstring org.kde.activitymanager.addactivity(qstring name)method qstringlist org.kde.activitymanager.availableactivities()method qstring org.kde.activitymanager.currentactivity()signal void org.kde.activitymanager.currentactivitychanged(qstring id)method bool org.kde.activitymanager.isbackstoreavailable()method void org.kde.activitymanager.registeractivitycontroller(qstring service)method void org.kde.activitymanager.registerresourcewindow(uint wid, qstring uri)method qstringlist org.kde.activitymanager.registeredactivitycontrollers()method void org.kde.activitymanager.removeactivity(qstring id)method void org.kde.activitymanager.setactivityicon(qstring id, qstring name)method void org.kde.activitymanager.setactivityname(qstring id, qstring name)method bool org.kde.activitymanager.setcurrentactivity(qstring id)method void org.kde.activitymanager.unregisterresourcewindow(uint wid, qstring uri)method qstring org.kde.activitymanager._allinfo()method qstring org.kde.activitymanager._serviceiteration()method qdbusvariant org.freedesktop.dbus.properties.get(qstring interface_name, qstring property_name)method qvariantmap org.freedesktop.dbus.properties.getall(qstring interface_name)method void org.freedesktop.dbus.properties.set(qstring interface_name, qstring property_name, qdbusvariant value)method qstring org.freedesktop.dbus.introspectable.introspect()greg@tiny :) ~ > qdbus org.kde.activitycontroller-1949 /activitycontroller method void org.kde.activitycontroller.activityadded(qstring id)method void org.kde.activitycontroller.activityremoved(qstring id)method void org.kde.activitycontroller.resourcewindowregistered(uint wid, qstring uri)method void org.kde.activitycontroller.resourcewindowunregistered(uint wid, qstring uri)method qdbusvariant org.freedesktop.dbus.properties.get(qstring interface_name, qstring property_name)method qvariantmap org.freedesktop.dbus.properties.getall(qstring interface_name)method void org.freedesktop.dbus.properties.set(qstring interface_name, qstring property_name, qdbusvariant value)method qstring org.freedesktop.dbus.introspectable.introspect()edit : i completely rewrote my script using python, and now the whole project is available here : <url>",
    "present_kp": [
      "bash",
      "kde",
      "kde activities"
    ],
    "absent_kp": []
  },
  {
    "text": "a humble converter between calendars. for a special writing and/or worldbuilding project i have, i created a special program.in the story, different factions have different ideas on what should be considered the first year of their calendar system. for the sake of simplicity, the years are equally long, but the first year declarations are different.this html-javascript program uses a dynamically selected pair of lists where you can select conversion calendars. you then enter a year, hit a button, and the conversion happens.the numbers are already tested by me and aside of one year of difference, are perfect.what i ask is to give some insights of readibility, cleanness, and, if possible and conventient, any optimization.html:<!doctype html><html> <head> <script <script src='/files/terminus-nation/convertdate.js'></script> </head> <body> <!-- a simple date calculator --> <div class=heading> <div class=datecalc> <h1> tn date calculator </h1> <h2>what a given year in a calendar system corresponds to, in another one?</h2> <input type=number id=in_d style=width:100px;> in <select id=in_c></select> to <select id=ou_c></select> <button id=action onclick=convertdate_onclick()>convert</button> <p id=result></p> </div> </div> </body> <script src='/files/terminus-nation/date-calc/main_js.js'></script></html>convertdate.js, the conversion function, separated for flexibility:var calendars = [ [by, beacon year], [kw, kvahk'er'weplec], [rd, republic date], [ry, resistance year], [ic, initial contact], [cd, cyberdomini], [ud, union day]];//the corefunction convertdate(in_cal, in_date, out_cal){ in_date = parseint(in_date); var orig = in_date; //each number shows, when a certain calender started compared to the others //e.g. 563159 in by equals to 1 in kw and 100325 in kw equals to 1 in rd var dateorder = [563159, 100325, 3426, 1406, 2036, 1042]; var in_id = -1; var ou_id = -1; function minorconvert(string){ var output = -2; for(i=0;i<calendars.length;i++){ if(string==calendar[i][0]){ output = i-1 }} return output; } in_id = minorconvert(in_cal); ou_id = minorconvert(out_cal); //-2 serves as an error code //it was implemented, when calendar wasn't added yet, but i'm afraid to eliminate if (in_id > -2 && ou_id > -2){ //if the calendars different, it iterates through the calendar array //if the calendars are identical, it doesn't change the input if (in_id != ou_id){ if(in_id<ou_id) { for(s=in_id;s<ou_id;s++){ in_date-= dateorder[s+1]; } }else{ for(s=ou_id;s<in_id;s++){ in_date+= dateorder[s+1]; } }; }; }else{ window.alert(in_cal + to + out_cal + doesn't seem to be a valid conversation.) }; //input is the returning value, either changed or unchanged (see comments at the condition above) return in_date;}main_js.js, the only file affecting the html directly://initializationfilllist(in_c);filllist(ou_c);//for select-list autocompletefunction filllist(id){ //first already added, now add the rest for(i=0;i<calendars.length;i++){ var option = document.createelement(option); option.value = calendars[i][0]; option.text = calendars[i][1]; document.getelementbyid(id).appendchild(option); }}//called by button clickfunction convertdate_onclick(){ var in_c = document.getelementbyid(in_c).value; var in_d = document.getelementbyid(in_d).value; var ou_c = document.getelementbyid(ou_c).value; document.getelementbyid(result).innerhtml = in_d + in + in_c + equals to + convertdate(in_c, in_d, ou_c) + in + ou_c;}i omitted css dependency as apparently the file works without that.",
    "present_kp": [
      "javascript",
      "html"
    ],
    "absent_kp": []
  },
  {
    "text": "how much data space is used by all scientific articles?. i was wondering if there is any research or study made to calculate the volume of space is used by all scientific articles. it could be in pdf, txt, compressed, or any other format. is there even a way to measure it?can some one point me towards realizing this study?regards and thanks.",
    "present_kp": [
      "research"
    ],
    "absent_kp": [
      "bigdata"
    ]
  },
  {
    "text": "how to put the specific files from a directory in an array in bash?. suppose i have a directory under which there are 3 files named: file1.txt,file2.txt and file3.txt.now how can i fill an array with those file names(i just know that all the files have certain prefix, i.e. file, after file it can be 1,2,3 etc.",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "filenames",
      "wildcards"
    ]
  },
  {
    "text": "what does linus mean here in kernel coding style documentation?. i'm reading the linux kernel coding style, where linus wrote something like this(chapter 1 indentation):dont put multiple statements on a single line unless you have something to hide:if (condition) do_this; do_something_everytime;......outside of comments, documentation and except in kconfig, spaces are never used for indentation, and the above example is deliberately broken.what does he mean by something to hide? is it a sarcasm? cuz i don't see any point of coding in such format, not to mention hide something.and another question, what doesthe above example is deliberately broken.mean? does it meanthe above example is deliberately breaking this (no space) rule.thanks : )",
    "present_kp": [
      "linux",
      "linux kernel"
    ],
    "absent_kp": []
  },
  {
    "text": "view a directories groups and setup www-data as an admin of a directory to allow content deletes. i am trying to to view the groups that belong to a directory and to enable www-data to be an admin of a directory so i am able to delete files that are within it using php unlink functionality. i have looked on the net and tried a number of things which chgrp and chmod etc but i am not getting anywhere. could someone point me in the right direction. i believe i am just doing things in the wrong order and need some guidance. i know a little bit of linux but not a great deal and i think this is my trouble.context:the folder is within a nas drive. apache is setup to point to the nas drive and content is served as expected. however, when it comes to deleting files from a sub folder i recieve the unlink permission denied error within php (assuming this is due to www-data not having access to delete from the folder)",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "apache httpd"
    ]
  },
  {
    "text": "display catalog product quantity. i have a simple quantity display function that runs for every product displayed in our catalog. the maxqtydisplay value is set in our web.config file. part of me thinks the function is as streamlined as possible and part of me thinks it can be improved upon somewhere. because this function is called many, many times in our web application i would like it be optimized as best it could.what could be done to improve it?private shared function calculateqtydisplay(byval x as double, byval y as double) as double dim q as double = x - y if q > 0 and q <= my.settings.maxqtydisplay then return q elseif q > my.settings.maxqtydisplay then return my.settings.maxqtydisplay else return 0 end ifend function",
    "present_kp": [],
    "absent_kp": [
      "asp.net",
      "vb.net"
    ]
  },
  {
    "text": "how do i perform the same set of commands within multiple subdirectories, in a numerical order?. within my parent_directory, i have subdirectories labeled e-11_g, and e-10_g. within each of those subdirectories, i have more subdirectories labeled e-2_u, e-1_u, and e0_u. in each of those folders, i'm performing commands on these files: ander, ander.band, ander.data, ander.in, and ander.log.here's a better picture: parent_directory e-11_g/ e-10_g/ e-2_u/ e-1_u/ e0_u/ ander ander.band ander.data ander.in ander.logi want to write a more efficient version of this: #!/bin/bashcd parent_directory/e-11_g/e-2_u/; ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;cd ../e-1_u;ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;cd ../e0_u;ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;cd ../../e-10_g/e-2_u/;ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;cd ../e-1_u;ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;cd ../e0_u;ls -l ander ander.band ander.data;cat ander.in;cat ander.log;pwd;i've already been able to successfully run this script as is, however, i really need a much more simpler and efficient way of writing it because i'm actually working with a lot more directories than i presented. my reason for doing this is because i need to keep certain records of each of those 'ander' files for each subdirectory. i'm basically planning on running this script and exporting everything that shows up onto the terminal window into a text file using shell > export text as. this is why i want the records for each directory in numerical order.how can i make my script more efficient? this is the kind of thing i'm aiming for:#!/bin/bashcd parent_directory/;do i= -11, -10 do j= -2, 0 cd e-i_g/e-j_u/; ls -l ander ander.band ander.data; cat ander.in; cat ander.log; pwd; endendi know thats pretty much written in fortran, but is there anything equivalent or similar to this in bash scripting? i've been trying to use 'for loops', but i just can't seem to write them in a way that would give me the same results as my first script.",
    "present_kp": [
      "for"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "sorting a list of first names from a text file. i applied for a job as a c#/.net junior developer, and had a test to do::using names.txt (right click and 'save link/target as...'), a 46k text file containing over five-thousand first names, begin by sorting it into alphabetical order. then working out the alphabetical value for each name, multiply this value by its alphabetical position in the list to obtain a name score.for example, when the list is sorted into alphabetical order, colin, which is worth 3 + 15 + 12 + 9 + 14 = 53, is the 938th name in the list. so, colin would obtain a score of 938 53 = 49714. what is the total of all the name scores in the file?i'm looking for some constructive comments on how i could have done it better.using system;using system.collections.generic;using system.configuration;using system.io;using system.linq;using system.text;using system.text.regularexpressions;namespace name.data.retrievenames{ public class names { public string name { get; set; } } public static class retrievelistofnames { public static ienumerable<names> lstofnames() { //********************************** // //file location is stored in app.config file, //this allows for ease in case the file needs //to be moved somewhere else. //so 1st check that it exists // //********************************** var fileexists = file.exists(configurationmanager.appsettings[locationofnamesfile]); //********************************** // //if file does not exist, throw file not found exception, as no point in continuing // //********************************** if (!fileexists) throw new filenotfoundexception(filenotfound check appsettings location); //********************************** //set buffer size, on huge file this can help with performance // //********************************** const int buffersize = 1024; //********************************** // //here we create the list and open the file and read all the names // //********************************** var data = new list<names>(); using (var filestream = file.openread(configurationmanager.appsettings[locationofnamesfile])) using (var streamreader = new streamreader(filestream, encoding.utf8, true, buffersize)) { string line; while ((line = streamreader.readline()) != null) { //split the string on the comma string[] namesarray = regex.split(line, ,); //sort the names a-z array.sort(namesarray); //loop over all names and add to list data.addrange(namesarray.select(names => new names { name = names.tolower() })); } } //finally return the names return data; } }}using system;using system.collections.generic;using system.diagnostics;using system.linq;using system.text.regularexpressions;using name.data.retrievenames;namespace name.ui{ class program { //******************************************************************** //names scores //problem 22 //using names.txt (right click and 'save link/target as...'), a 46k text file containing over five-thousand first names, begin by sorting it into alphabetical order. //then working out the alphabetical value for each name, multiply this value by its alphabetical position in the list to obtain a name score. //for example, when the list is sorted into alphabetical order, colin, which is worth 3 + 15 + 12 + 9 + 14 = 53, is the 938th name in the list. //so, colin would obtain a score of 938 53 = 49714. //what is the total of all the name scores in the file? // //******************************************************************** static void main(string[] args) { try { //******************************************************************** //list of names returned from text file //******************************************************************** var data = retrievelistofnames.lstofnames().tolist(); //******************************************************************** //my own interest to see how long it takes to run code stopwatch timer = new stopwatch(); //******************************************************************** //create list to hold the values //******************************************************************** list<string> sumoffallnames = new list<string>(); timer.start(); //******************************************************************** //loop over names replacing a-z with numbers 1-26, make all letters lowercase //******************************************************************** list<string> listofnames = data.select(v => regex.replace(v.name.trim('').tolower(), a, 1,) .replace(b, 2,) .replace(c, 3,) .replace(d, 4,) .replace(e, 5,) .replace(f, 6,) .replace(g, 7,) .replace(h, 8,) .replace(i, 9,) .replace(j, 10,) .replace(k, 11,) .replace(l, 12,) .replace(m, 13,) .replace(n, 14,) .replace(o, 15,) .replace(p, 16,) .replace(q, 17,) .replace(r, 18,) .replace(s, 19,) .replace(t, 20,) .replace(u, 21,) .replace(v, 22,) .replace(w, 23,) .replace(x, 24,) .replace(y, 25,) .replace(z, 26,) + 0).tolist(); //******************************************************************** //variable for name row int nameid = 1; //******************************************************************** //loop over all rows returned from above foreach loop and add up each value to get total for name //then times that by position in table //as all names are in alphabetical order, the variable nameid will increment by 1 on every loop //so i can use that to muliple total name value //******************************************************************** foreach (var s in listofnames) { var sumarray = string.join(, s.toarray()); var sumofname = (sumarray.split(',').sum(x => int.parse(x)) * nameid++).tostring(); sumoffallnames.add(sumofname); //console.writeline(namenumber); } //******************************************************************** //turn list sumoffallnames into string //then add all values up to get total //******************************************************************** string characterarray = string.join(,, sumoffallnames.toarray()); int number = characterarray.split(',').sum(x => int.parse(x)); timer.stop(); //******************************************************************** //ok done display total and number of names and time to run code console.writeline(total is {0} from {1} names, time taken {2} seconds, number.tostring(##,000), data.count.tostring(##,000), ((float)timer.elapsedticks)/stopwatch.frequency); console.read(); } catch (exception e) { console.writeline(e.message); console.read(); } } }}",
    "present_kp": [
      "c#",
      "file"
    ],
    "absent_kp": [
      "programming challenge"
    ]
  },
  {
    "text": "simple login and authentication app. for school i had to do a real simple login and authentication system on an android app, and i'm wondering how my code can be optimised to reduce code duplication and how it can be made more object oriented?all the app does is make an api call to my slim restful web service using asynchttpclient library and stores the authkey, name, and surname of the logged in user to shared preferences.loginscreen.java:public class loginscreen extends actionbaractivity { private string username; private string password; private progressdialog prgdialog; private string localhosturl = http://10.0.3.2/diploma/cloud_computing/tutorials/tutorial2/; private string vkey;// private string localhosturl = http://10.0.2.2/diploma/cloud_computing/tutorials/tutorial2/; stringentity entity = null; stringentity authvkeyentity = null; //will store our post data jsonobject params = new jsonobject(); jsonobject paramsauth = new jsonobject(); //shared pref vars public static final string mypreferences = myprefs; public static final string surname = surname; public static final string firstname = firstname; public static final string vkey = vkey; public static sharedpreferences sharedpreferences; @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); setcontentview(r.layout.activity_login_screen); checkifloggedin(); //register assets button btnlogin = (button) findviewbyid(r.id.btnlogin); final edittext txtusername = (edittext) findviewbyid(r.id.txtusername); final edittext txtpassword = (edittext) findviewbyid(r.id.txtpassword); //progress dialog initiation prgdialog = new progressdialog(this); // instantiate progress dialog object prgdialog.setmessage(please wait...); // set progress dialog text prgdialog.setcancelable(false); // set cancelable as false btnlogin.setonclicklistener( new view.onclicklistener() { @override public void onclick(view v) { //get username & password username = txtusername.gettext().tostring(); password = txtpassword.gettext().tostring(); try { //append json object name and value (username, username) params.put(username, username); params.put(password, password); } catch (jsonexception e) { e.printstacktrace(); } try { entity = new stringentity(params.tostring()); } catch (unsupportedencodingexception e) { e.printstacktrace(); } entity.setcontenttype(new basicheader(http.content_type, application/json)); //make the request with the above params makeapirequest(entity); system.out.println(4); } }); } public void makeapirequest(stringentity entity){ // show progress dialog prgdialog.show(); // make restful webservice call using asynchttpclient object asynchttpclient client = new asynchttpclient(); context context = this.getapplicationcontext(); client.post(context, localhosturl + user, entity, application/json, new asynchttpresponsehandler() { // when the response returned by rest has http response code '200' @override public void onsuccess(string response) { prgdialog.hide(); // hide progress dialog try { jsonobject obj = new jsonobject(response); // create json object //if the object has a string named key run the following code if (obj.has(key)) { toast.maketext(getapplicationcontext(), obj.getstring(givename) + you are successfully logged in!, toast.length_long).show(); // save data to shared pref and change page savesharedpreferences(obj.getstring(surname),obj.getstring(givename), obj.getstring(key)); changetowelcomeactivity(); } else if (obj.has(pass-error)) toast.maketext(getapplicationcontext(), your password is incorrect, toast.length_long).show(); else if((obj.has(account-error))) toast.maketext(getapplicationcontext(), your account doesn't exists, toast.length_long).show(); } catch (jsonexception e) { toast.maketext(getapplicationcontext(), error occured [server's json response might be invalid]!, toast.length_long).show(); e.printstacktrace(); } } // when the response returned by rest has http response code other than '200' @override public void onfailure(int statuscode, throwable error, string content) { // hide progress dialog prgdialog.hide(); // when http response code is '404' if (statuscode == 404) { toast.maketext(getapplicationcontext(), requested resource not found, toast.length_long).show(); } // when http response code is '500' else if (statuscode == 500) { toast.maketext(getapplicationcontext(), something went wrong at server end, toast.length_long).show(); } // when http response code other than 404, 500 else { toast.maketext(getapplicationcontext(), unexpected error occcured! [most common error: device might not be connected to internet or remote server is not up and running], toast.length_long).show(); } } }); } public void savesharedpreferences(string surname, string firstname, string key){ // set up preferences collection sharedpreferences = getsharedpreferences(mypreferences, context.mode_private); //save vkey, firstname, and vkey sharedpreferences.editor editor = sharedpreferences.edit(); editor.putstring(surname, surname ); editor.putstring(firstname, firstname ); editor.putstring(vkey, key ); editor.apply(); changetowelcomeactivity(); } public void checkifloggedin(){ // get vkey shared pref and assign to variable validatesharedpreferenceauthkeyapirequest(); log.d(checkifloggedin, ???); log.d(vkey, vkey); // if vkey is not empty, then don't run api request if(vkey != ) { validatesharedpreferenceauthkeyapirequest(); log.d(in vkey = \\, 'vkey is not empty'); } // if vkey is empty then do nothing else return; } // get shared pref vkey and assign to vkey variable public void getsharedpref(){ sharedpreferences prefs = this.getsharedpreferences(mypreferences, context.mode_private); vkey = prefs.getstring(vkey, ); log.d(in shared pref = \\, vkey); } // create the json auth params that will be sent via the post http public void createauthjsonrequestparams(){ try { //append json object/string name and value (auth, vkey) paramsauth.put(auth, vkey); log.d(increatejsonreques, vkey); } catch (jsonexception e) { e.printstacktrace(); } try { authvkeyentity = new stringentity(paramsauth.tostring()); } catch (unsupportedencodingexception e) { e.printstacktrace(); } authvkeyentity.setcontenttype(new basicheader(http.content_type, application/json)); } // validate the auth key by sending post key of auth and receiving a true or false value public void validatesharedpreferenceauthkeyapirequest(){ // create the json object that is used below getsharedpref(); createauthjsonrequestparams(); // make restful webservice call using asynchttpclient object asynchttpclient client = new asynchttpclient(); context context = this.getapplicationcontext(); client.post(context, localhosturl + user/auth/, authvkeyentity, application/json, new asynchttpresponsehandler() { // when the response returned by rest has http response code '200' @override public void onsuccess(string response) { prgdialog.hide(); // hide progress dialog try { log.d(in authenticated = \\, hiihihihi); jsonobject obj = new jsonobject(response); // create json object //if the object has a string named authenticated run the following code if (obj.has(authenticated)) { toast.maketext(getapplicationcontext(), valid verification key!, toast.length_long).show(); log.d(in authenticated = \\, vkey); changetowelcomeactivity(); } // if the vkey is incorrect then post this else if (obj.has(error_authenticated)) toast.maketext(getapplicationcontext(), something has gone wrong, invalid authentication key, toast.length_long).show(); } catch (jsonexception e) { toast.maketext(getapplicationcontext(), !error occured [server's json response might be invalid]!, toast.length_long).show(); e.printstacktrace(); } } // when the response returned by rest has http response code other than '200' @override public void onfailure(int statuscode, throwable error, string content) { // hide progress dialog prgdialog.hide(); // when http response code is '404' if (statuscode == 404) { toast.maketext(getapplicationcontext(), requested resource not found, toast.length_long).show(); } // when http response code is '500' else if (statuscode == 500) { toast.maketext(getapplicationcontext(), something went wrong at server end, toast.length_long).show(); } // when http response code other than 404, 500 else { toast.maketext(getapplicationcontext(), unexpected error occcured! [most common error: device might not be connected to internet or remote server is not up and running], toast.length_long).show(); } } }); } // change from current activity to welcome.class activity public void changetowelcomeactivity(){ //change to welcome page intent myintent = new intent(this.getapplicationcontext(), welcome.class); startactivity(myintent); }welcome.java:public class welcome extends actionbaractivity { @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); setcontentview(r.layout.activity_welcome); textview txtwelcome = (textview) findviewbyid(r.id.txtwelcome); log.d(in welcome, eee); if(getpreferences() == 1) txtwelcome.settext(welcome + loginscreen.sharedpreferences.getstring(loginscreen.firstname, ) + + loginscreen.sharedpreferences.getstring(loginscreen.surname, )); else txtwelcome.settext(not logged in); } // custom method to get preferences public static int getpreferences(){ int returned; if (loginscreen.sharedpreferences.contains(loginscreen.surname)) returned = 1; else returned = 0; return returned; }",
    "present_kp": [
      "java",
      "object oriented",
      "android",
      "authentication"
    ],
    "absent_kp": []
  },
  {
    "text": "hiding a post in piazza. i am listed as an instructor in a piazza class. is there any way to hide a post (i.e. not deleting it)?",
    "present_kp": [
      "piazza"
    ],
    "absent_kp": []
  },
  {
    "text": "deduplication on partition level. what are available solutions for block level or more detailed deduplication ?there are file-based ones - with copy-on-write approach.i'm looking for block level copy-on-write, so i could periodically look for common blocks, or - preferably - parts of files, merge them and flag for cow use manner.is there something like this available, or does it still need to be created ?i am not sure if btrfs deduplication is block/file/subpart level ?there is lessfs, but i'am not sure what level of deduplication does it provide ? maybe other solution?",
    "present_kp": [
      "deduplication"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "vim youcompleteme not working. currently i'm working on node.js and i wanted some additional plugins which can help me learning this new technology. i installed tern_for_js and youcompleteme from vundle. i also compiled ycm, but i don't see any auto-completion or any javascript support. here is my .vimrc:syntax onset numberset laststatus=2set nocompatibleset expandtabset shiftwidth=2set smartindentset rtp+=~/.vim/bundle/vundle.vimcall vundle#begin()plugin 'vundlevim/vundle.vim'plugin 'bling/vim-airline'plugin 'scrooloose/nerdtree'plugin 'ternjs/tern_for_vim'plugin 'valloric/youcompleteme'call vundle#end():map <f2> :echo 'current time is ' . strftime('%c')<cr>set guifont=proggycleantt:h18colorscheme tortenerdtreecan anybody tell me what i'm doing wrong. or did i miss something? is there some extra configuration that have to be made?",
    "present_kp": [],
    "absent_kp": [
      "macvim",
      "plugin you complete me"
    ]
  },
  {
    "text": "why does p/poly can also receive bad advice?. (from my class's slides)np and p/poly both use an external string for computation. however, for l in np, any witness is rejected if x $ otin$ l. for l in p/poly, there can be bad advice!i'm having a hard time understanding why this is true. my intuition is that if there are indeed 'bad advice', i.e advice that make the turing machine return bad answers, doesn't it mean that a situation where all of the advice are 'bad' is technically possible?",
    "present_kp": [],
    "absent_kp": [
      "complexity theory",
      "complexity classes"
    ]
  },
  {
    "text": "multiple mirror sites and seo. i have one master website website.com/master and many mirror sites website.com/rep1, website.com/rep2, etc.the content, except for the contact information, is identical on all of them.we make it this way so that every representative has his own website and stats.i already use the canonical url tag to inform google that all the mirrors are duplicates of website.com/master.now, my problem is that one of the mirrors, let's say website.com/rep4, appears first in google ranking. how can i make sure the master website (website.com/master) will always appear first?i've looked everywhere on many occasions and never found any topic that would cover my case.can anyone help? i would be most grateful.",
    "present_kp": [
      "seo",
      "canonical url"
    ],
    "absent_kp": [
      "google analytics"
    ]
  },
  {
    "text": "checking whether a game board is full. i have a method in scala that checks if a game board is full or not. to speed this method up, i return inside the nested for loop to break out of both of them and stop execution. how would i achieve this in scala in an idiomatic way?def isfull: boolean = { for (x <- getgrid.indices) { for (y <- getgrid(x).indices) { if (getgrid(x)(y).getstate.isinstanceof[undecided]) { return false } } } true}",
    "present_kp": [
      "scala"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "tmux detach session remote. i run at first terminal tmux, then i run another terminal with tmux and attach to session which i run at first terminal. first is smaller than second and i can't go to it to do something. how to detach session from first and attach at second terminal using only that second one?",
    "present_kp": [
      "terminal",
      "tmux"
    ],
    "absent_kp": []
  },
  {
    "text": "system messages in vim. o/s: arch linux (kernel 4.3.3-2-arch)while editing files with vim 7.4 it occassionally happens that system messages appear on the screen, ruining my workflow but obviously not altering the contents of the file. the strings seem to be return values or error messages/warnings from other background processes (e.g. thunderbird &). is there any way to suppress these? additionally, i'd really like to know why this happens..",
    "present_kp": [
      "arch linux",
      "vim"
    ],
    "absent_kp": [
      "shell",
      "stdout"
    ]
  },
  {
    "text": "mediator pattern implementation for game messaging. i am building out a mud game engine and want my objects to communicate with each other. there is a wide range of message types that will be sent around, all of which implement imessage. i adopted the mediator pattern to facilitate passing the messages around to objects that have subscribed for publications. is the pattern being used properly here?inotificationcenter and implementationthe interface represents what objects will interact with when they want to subscribe to publications for a specific imessage type. the chatcenter is implemented as a singleton and will ultimately end up with the dictionary being changed to a concurrentdictionary for thread-safety.public interface inotificationcenter{ isubscriptionhandler subscribe<t>() where t : class, imessage; void publish<t>(t message) where t : class, imessage;}/// <summary>/// the mediator for all messaging/// </summary>public class chatcenter : inotificationcenter{ /// <summary> /// collection of subscribed listeners /// </summary> private dictionary<type, list<isubscriptionhandler>> listeners = new dictionary<type, list<isubscriptionhandler>>(); private static chatcenter _centersingleton = new chatcenter(); private chatcenter() { } /// <summary> /// subscribe publications for the message type specified. /// </summary> /// <typeparam name=t></typeparam> /// <returns></returns> public isubscriptionhandler subscribe<t>() where t : class, imessage { type messagetype = typeof(t); if (!listeners.containskey(messagetype)) { listeners.add(messagetype, new list<isubscriptionhandler>()); } // todo: move instancing of the handler in to a factory that does a lookup on <t> and returns the right handler. var handler = new chatmessagehandler(); listeners[messagetype].add(handler); return handler; } public static chatcenter currentcenter { get { return _centersingleton; } } /// <summary> /// publishes the specified message to all subscribers /// </summary> /// <typeparam name=t></typeparam> /// <param name=message>the message.</param> public void publish<t>(t message) where t : class, imessage { if (!listeners.containskey(typeof(t))) { return; } foreach (var handler in listeners[typeof(t)]) { message.dispatch(handler); } } internal void unsubscribe<t>(isubscriptionhandler handler) where t : class, imessage { if (!listeners.containskey(typeof(t))) { return; } listeners.remove(typeof(t)); }}isubscriptionhandler and implementation.the subscription handlers are what are used to define what happens when a publish happens. at the moment, they just provide predicates and an action to invoke. a non-generic type is used so that my chatcenter does not have to be generic. there are different types of chat messages that can be used./// <summary>/// provides a contract to types wanting to subscribe to published messages /// with conditions and a callback./// </summary>public interface isubscriptionhandler{ isubscriptionhandler if(func<imessage, bool> condition); isubscriptionhandler dispatch(action<imessage> message); void unsubscribe();} /// <summary>/// processes a subscription message./// </summary>/// <typeparam name=tmessagetype>the type of the message type.</typeparam>public interface isubscriptionprocessor<tmessagetype> : isubscriptionhandler{ void processmessage(tmessagetype message);}/// <summary>/// handles chat message subscriptions/// </summary>public class chatmessagehandler : isubscriptionprocessor<chatmessage>{ private list<action<imessage>> callbacks = new list<action<imessage>>(); private list<func<imessage, bool>> conditions = new list<func<imessage, bool>>(); /// <summary> /// registers a callback for when a chat message is published by the messagecenter /// </summary> /// <param name=message>the message.</param> /// <returns></returns> public isubscriptionhandler dispatch(action<imessage> message) { this.callbacks.add(message); return this; } /// <summary> /// provides conditional values that will be evaluated upon a publish from the messagecenter. /// if any of the results return false, the callbacks will not be dispatched. /// </summary> /// <param name=condition>the condition.</param> /// <returns></returns> public isubscriptionhandler if(func<imessage, bool> condition) { this.conditions.add(condition); return this; } public void unsubscribe() { this.callbacks.clear(); this.conditions.clear(); chatcenter.currentcenter.unsubscribe<chatmessage>(this); } /// <summary> /// processes the message by verifying the callbacks can be invoked, then invoking them. /// </summary> /// <param name=message>the message.</param> public void processmessage(chatmessage message) { // if any of the conditions fail, don't process. if (conditions.any(condition => !condition(message))) { return; } // invoke each callback. foreach (var callback in this.callbacks) { callback(message); } }}imessage and implementationlastly is the imessage interface and a sample implementation for a chat message./// <summary>/// a contract for objects wanting to dispatch message notifications./// </summary>public interface imessage{ void dispatch(isubscriptionhandler handler);}/// <summary>/// provides methods for dispatching notifications to subscription handlers/// </summary>/// <typeparam name=tmessagetype>the type of the message type.</typeparam>public class messagebase<tmessagetype> : imessage where tmessagetype : class, imessage{ /// <summary> /// dispatches this message instance to the given handler for processing. /// </summary> /// <param name=handler>the handler.</param> public void dispatch(isubscriptionhandler handler) { // we must convert ourself to our generic type. var msg = this as tmessagetype; if (msg == null) { return; } var target = handler as isubscriptionprocessor<tmessagetype>; if (target == null) { return; } // dispatch ourself strongly typed to a protected version // of the dispatch method. this.dispatch(target, msg); } /// <summary> /// dispatches the given message to the given handler. /// children classes can override this method to perform custom dispatching /// if needed. /// </summary> /// <param name=target>the handler.</param> /// <param name=message>the message.</param> protected virtual void dispatch(isubscriptionprocessor<tmessagetype> target, tmessagetype message) { // let the handler process this message. target.processmessage(message); }}/// <summary>/// a chat message./// </summary>public class chatmessage : messagebase<chatmessage>{ public chatmessage(string message) { this.message = message; } public string message { get; private set; }}unit test demonstrating usage.[testclass]public class subscriptionresulttests{ [testmethod] public void conditions_for_publish_are_met_and_dispatched() { // arrange var chathandler = new chatmessagehandler(); int x = 1; int y = 2; int z = 3; var center = chatcenter.currentcenter; // subscribe center.subscribe<chatmessage>() .if(msg => x == 1) .if(msg => y == 2) .if(msg => z == 3) .dispatch(msg => x = 3) .dispatch(msg => { y = 10; z = 15; }); // act center.publish(new chatmessage(string.empty)); // assert assert.areequal(3, x); assert.areequal(10, y); assert.areequal(15, z); } [testmethod] public void object_can_unsubscribe() { // arrange var chathandler = new chatmessagehandler(); int y = 2; var callback = new action<imessage>(msg => y = 10); // subscribe isubscriptionhandler handler = chatcenter.currentcenter.subscribe<chatmessage>() .dispatch(callback); handler.unsubscribe(); // act chatcenter.currentcenter.publish(new chatmessage(string.empty)); // assert assert.areequal(2, y); }}one of the downsides of how i've built it is that my callback's are not strongly typed to the subscribed imessage implementation, so i can't access any custom properties within each imessage implementation during a dispatch.",
    "present_kp": [
      "mediator"
    ],
    "absent_kp": [
      "c#",
      "design patterns"
    ]
  },
  {
    "text": "slow 8/15-puzzle ida*. i am trying to find the optimal solution for a given 15-puzzle. so far as i can tell, the algorithm works (on simple instances of 8-puzzle), but is extremely slow for complex starting states (order of 100 seconds), and practically unsolvable with 15 tiles.i know finding the optimal solution is hard but i think i may be using the language in an efficient way here.idastarsolver.solve() contains the starting point for computing the solution, although most of the operations are done in the board class.this is the class containing the solver:import sysfrom heapq import heappop, heappushfrom src.state import stateclass idastarsolver: def __init__(self, board, heuristic='manhattan'): self.solution = [] self.initial = board self.heuristic = heuristic def solve(self): bound = getattr(self.initial, self.heuristic) while true: t = self.search(self.initial, 0, bound) if t == 'found': return bound if t == sys.maxsize: return 'not_found' bound = t def search(self, node, g, bound): f = g + getattr(node, self.heuristic) if f > bound: return f if getattr(node, self.heuristic) == 0: return 'found' minimum = sys.maxsize for neighbour in node.neighbours(): t = self.search(neighbour, g + 1, bound) if t == 'found': self.solution.append(node) return 'found' if t < minimum: minimum = t return minimum def moves(self): return len(self.solution)and the board is represented as follows:from copy import copyimport numpy as npclass board: a nxn board for with n^2 - 1 tiles def __init__(self, tiles=none, size=3): if tiles is none: self.dim = size self.tiles = self.generate_board(size) while not self.is_solvable(): self.tiles = self.generate_board(size) else: self.dim = len(tiles) self.tiles = tiles self.zero_row = np.where(self.tiles == 0)[0][0] self.zero_column = np.where(self.tiles == 0)[1][0] self.manhattan = self._manhattan() def __copy__(self): cls = self.__class__ new_copy = cls.__new__(cls) new_copy.tiles = np.copy(self.tiles) new_copy.manhattan = self.manhattan new_copy.dim = self.dim new_copy.zero_row = self.zero_row new_copy.zero_column = self.zero_column return new_copy def _manhattan(self): manhattan = 0 for i in range(self.dim): for j in range(self.dim): if self.tiles[i][j] != 0: row = (self.tiles[i][j] - 1) // self.dim column = (self.tiles[i][j] - 1) % self.dim manhattan += abs(i - row) + abs(j - column) return manhattan def equals(self, board): :param board board: test board return np.array_equal(board.tiles, self.tiles) def swap_zero(self, i0, j0): swaps tile at i0, j0 with the zero tile # recalculate manhattan distance row = (self.tiles[i0][j0] - 1) // self.dim column = (self.tiles[i0][j0] - 1) % self.dim self.manhattan -= abs(i0 - row) + abs(j0 - column) self.manhattan += abs(self.zero_row - row) + abs(self.zero_column - column) # swap tiles self.tiles[i0][j0], self.tiles[self.zero_row, self.zero_column] = \\ self.tiles[self.zero_row, self.zero_column], self.tiles[i0, j0] # update zero row and column self.zero_row = i0 self.zero_column = j0 def neighbours(self): neighbours = [] # the zero tile can be swapped with tile above if self.zero_row > 0: neighbour = copy(self) neighbour.swap_zero(self.zero_row - 1, self.zero_column) neighbours.append(neighbour) # the zero tile can be swapped with tile below if self.zero_row < self.dim - 1: neighbour = copy(self) neighbour.swap_zero(self.zero_row + 1, self.zero_column) neighbours.append(neighbour) # the zero tile can be swapped with the tile to its left if self.zero_column > 0: neighbour = copy(self) neighbour.swap_zero(self.zero_row, self.zero_column - 1) neighbours.append(neighbour) # the zero tile can be swapped with the tile to its right if self.zero_column < self.dim - 1: neighbour = copy(self) neighbour.swap_zero(self.zero_row, self.zero_column + 1) neighbours.append(neighbour) return neighbours def is_solved(self): checks if the board is the goal position return self.manhattan() == 0 def is_solvable(self): checks if the board is solvable tiles = np.ndarray.flatten(self.tiles) dim = self.dim * self.dim inversions = 0 for i in range(dim): for j in range(i, dim): if tiles[i] != 0 and tiles[j] != 0 and tiles[i] > tiles[j]: inversions += 1 return inversions % 2 == 0 @staticmethod def generate_board(size): arr = np.arange(size ** 2) np.random.shuffle(arr) arr = arr.reshape(size, size) return arr def __str__(self): return np.array_str(self.tiles)and the state:import <email>_orderingclass state: def __init__(self, current, previous, moves): :param current: the current board position :param previous: the previous board position :param moves: the number of moves made to get to the current board position self.current = current self.moves = moves self.previous = previous self.score = self._score() def _score(self): return self.current.manhattan + self.moves def __lt__(self, other): return self.score < other.score def __eq__(self, other): return self.score == other.score",
    "present_kp": [],
    "absent_kp": [
      "python",
      "performance",
      "sliding tile puzzle",
      "a star"
    ]
  },
  {
    "text": "grep multiple strings at once in specific occurrence. i would like to grep the following string in exact order.x*/\\*y\\*/\\*z\\*/\\*w\\*how can i do it?grep x*/\\*y\\*/\\*z\\*/\\*w\\* <file> -> does not workexample inputxvg/cyv/dgzfdre/rwt avg/cyv/dgzfdre/rwt x/y/z/w desired outputxvg/cyv/dgzfdre/rwt x/y/z/w",
    "present_kp": [
      "grep"
    ],
    "absent_kp": [
      "regular expression"
    ]
  },
  {
    "text": "awk script to extract the argument of an option. can some one explain what the awk '{for(i=1;i<=nf;i++) if($i~/-f/) print $(i+1)}') part does in the following snippetline='/wwws/apache/apache2.4.16w-r01/instroot/bin/httpd -f /www/csbe-int-fb-na/generated/httpd.conf -c servername int-b2vusii.bmwgroup.net -c pidfile /var/tmp/apache_csbe-int-fb-na/httpd.pid'conf=$(echo $line | awk '{for(i=1;i<=nf;i++) if($i~/-f/) print $(i+1)}')o/p : /www/csbe-int-fb-na/generated/httpd.conf -cbut i need to get only /www/csbe-int-fb-na/generated/httpd.conf",
    "present_kp": [
      "awk"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "should a laptop user switch from ext4 to btrfs?. related to this.i'd like to take advantage of an os switch to upgrade to btrfs.btrfs claims to offer a lot (data-loss resiliency, self-healing if raid, checksumming of metadata and data, compression, snapshots). but it's slow when used with fsync-intensive programs such as dpkg (i know eatmydata and the crappy apt-btrfs-snapshot programs) and i won't setup a raid :p.ext4 allow metadata check-summing only and doesn't compress data.in 6 years, i had to reinstall my os twice because of hdd corruption (after flight trips). the first making the laptop unbootable, the second bunch of corruptions was identified thanks to a corrupted film and then md5sum check of the os binaries. (smart tells me the disk is sane). the lappy currently behave quite strangely. i don't know if the hardware or the software is to blame but i suspect the hardware (it all began right after a flight, once again). would you advise to switch to btrfs for a laptop because of data compression and check-summing or should i stick with ext4? (i don't care about which is best relative to whatever variable but i have almost no experience with btrfs and would like some feedback)edit:let's be clearer:btrfs is still flagged as experimental, i know, but suse says it shouldn't anymore. so does oracle (i know who oracle is). and a bunch of distributions already propose btrfs for installation and most of them are planning to switch to it in the next few months.two facts:backups of corrupted data are worthless. i don't understand why i seem to be the only one to bother. isn't that common sense? in the meanwhile:stop telling me i should do backups: i already do.stop implying backups are just enough to keep my data safe except if you are willing to give me tbs of free space to do years worth of backups.a corrupted file =/=> linux complaining. so:don't assume your system/data are sane just because the os is booting.i hope you understand that i prefer (meta)data checksumming to an over-engineered and bloated piece of software that would inconveniently do half as a good job as btrfs to check the data integrity.is that more clear now that i am not asking for which fs is better? the question is, given that i regularly do backups, is btrfs still too experimental to be used for its data-integrity checking functions or should i stick to ext4?",
    "present_kp": [
      "linux",
      "ext4",
      "btrfs"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "distributed membership approval in linkedin groups. in linkedin groups, is it possible to allow all members to approve pending membership requests?facebook has this feature and it is a great boon to group membership for restricted-entry communities (like alumni).",
    "present_kp": [
      "linkedin",
      "linkedin groups"
    ],
    "absent_kp": []
  },
  {
    "text": "umbraco examine search for full site. i have a macroscript which reads a query string for search term parameters, and then does a multiple word groupedor search through umbracoexamine / lucene.net. because this is a full site search, i have hard-coded an array of about 100 fields across the site to allow the user to search against pretty much anything on the site. is there any way to make this search more efficient? currently i'm averaging about 5 seconds (per 10,000 iterations on stopwatch) to search 100 fields on about ~2.2k nodes and returning ~600 results. note: i have removed the html / inner loop code as i've already determined that this area isn't where the search is hanging.string searchterm = string.empty;if (!string.isnullorempty(request.form[searchterm])){ searchterm = request.form[searchterm]; string[] searchtermlist = searchterm.split(new char[] { ' ' }, stringsplitoptions.removeemptyentries); string[] aliaslist = new string[]{umbracourlname, menutext, pageheading, pagesubheading, bodytext, alerts, headerquote, headerquoteattribution, officephone, officefax, officeemail, officeaddress, officecityofficestate, officezip, officeaddress2, officename, navsummary, latestjournals, frequentnumbers, searchintro, introduction, heading, introtext, smname, divisiontitle, districttitle, districtnotes, authorfirst, authorlast, articletitle, articlekeywords, associatedjournal, headline, content, rulesection, articlecategories, stafflisting, categorytitle, articleauthor, articlecategory, articleendnotes, journalvolume, journalissue, journaldate, rulecategory, casenotes, proposedopinion, opinionadopted, opinionsummary, opinionendnotes, secondarysegment, primarytitle, primarysubtitle, primaryintro, primarynote, secondarytitle, secondarysubtitle, secondaryintro, secondarynote, contactname, contacttitle, contactphone, contactemail, contactlabel, contactintro, orgmembers, faqquestion, faqanswer, eventsummary, eventvenue, eventaddress1, eventaddress2, eventcity, eventstate, eventzip, eventstartdatetime, eventenddatetime, eventcontactname, eventcontacttitle, eventcontactemail, eventcontactphone, groupmembers, pluralname, makeplural, submembers, newsdate, newslocation, newssummary, newscategory}; basesearchprovider collection = examinemanager.instance.searchprovidercollection[sitesearchsearcher]; isearchcriteria searchcriteria = collection.createsearchcriteria(indextypes.content, booleanoperation.or); isearchcriteria filter = searchcriteria.groupedor(aliaslist, searchtermlist).compile(); var searchresults = collection.search(filter).orderbydescending(n => n.score); string resulttext = searchresults.count() == 1 ? result : results; if (searchresults.count() > 0) { //removed html / printing nodes & url's }}",
    "present_kp": [
      "search"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "parse xml returned from curl within a bash script. i've been digging through stackexchange for the past few days and i've found bits and pieces of what i'm trying to accomplish, but i'm unsure how to put it all together...i'm trying to create a script that has curl calls to an api. this returns a whole bunch of xml which i want to then parse down to just certain values only. overall, i want this script to make the call, parse the values / set them as a variable, and return(display) them.i may have found a working type solution, but is this practical? #!/bin/bashtest=$(curl -k --silent <url>&name=devicename)test2=$(curl -k --silent <url>&name=devicename)variable1=$grep -opm1 (?<=<name>)[^<]+ <<< $test:)variable2=$grep -opm1 (?<=<status>)[^<]+ <<< $test:)echo $variableecho $variable2[admin]>./scriptswitchnameuphere's the xml i'm trying to dig through:<?xml version=1.0 ?><queryresponse type=accesspointdetails rooturl=https://website/webacs/api/v1/data requesturl=https://website/webacs/api/v1/data/accesspointdetails?.full=true&amp;name=devicename responsetype=listentityinstances count=1 first=0 last=0> <entity url=https://website/webacs/api/v1/data/accesspointdetails/<phone> type=accesspointdetails dtotype=accesspointdetailsdto> <accesspointdetailsdto id=<phone> displayname=<phone>> <clientcount>6</clientcount> <clientcount_2_4ghz>0</clientcount_2_4ghz> <clientcount_5ghz>6</clientcount_5ghz> <ipaddress>172.16.83.5</ipaddress> <name>devicename</name> <unifiedapinfo> ...... </unifiedapinfo> <uptime>609857</uptime> </accesspointdetailsdto> </entity></queryresponse><?xml version=1.0 ?><queryresponse type=accesspointdetails rooturl=https://website/webacs/api/v1/data requesturl=https://website/webacs/api/v1/data/accesspointdetails?.full=true&amp;name=devicename responsetype=listentityinstances count=1 first=0 last=0> <entity url=https://website/webacs/api/v1/data/accesspointdetails/<phone> type=accesspointdetails dtotype=accesspointdetailsdto> <accesspointdetailsdto id=<phone> displayname=<phone>> <name>devicename</name> <status>up</status> <unifiedapinfo> ...... </unifiedapinfo> </accesspointdetailsdto> </entity></queryresponse>",
    "present_kp": [
      "bash",
      "curl",
      "xml"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "how to use ocr from the command line in linux?. i have several thousand pages of scanned book pages. each page is saved individually as a jpg. the writing is clear, but fonts vary, and the pages do include pictures and illustrations.i need to create a list of all of the words appearing in each jpg file. is there a command line tool for scanning an image listing the words that appear? it does not need to have perfect scanning, just an estimate.",
    "present_kp": [
      "command line",
      "ocr"
    ],
    "absent_kp": []
  },
  {
    "text": "how to run commands in batch mode over ssh?. how can i run commands in batch mode over ssh? that is, what is the ssh command's equivalent of sftp -b <filename> <hostname>?i have a set of commands which i wish to run across a set of hosts connecting over ssh. over sftp, i store the commands in a file filename and connect to the host and run the commands using the previously mentioned command.is something like that possible over ssh?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "scripting",
      "solaris"
    ]
  },
  {
    "text": "variable sized type allocation. i have a type that receives serial data over a pipe:struct packet : base { // base is pod, too int foo; char data[];};in the context, where i instantiate packet, i already know how large this particular packet will be, so i write:size_t const size = sizeof(packet) + datalength;std::auto_ptr<base> p(new((void*)(new char[size])) packet());// note that it will be deleted via 'delete'is this a sensible way of doing this, or is there a more idiomatic way?",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "memory management"
    ]
  },
  {
    "text": "why does root not have /usr/local in path?. i've noticed that the default path for root on my of my vm's and servers do not include /usr/local/binsudo -s echo $path/sbin:/bin:/usr/sbin:/usr/binwhereas normal users on the server do have /usr/local/bin/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/sowen/binwhy would root not need /usr/local in the path? where is the default path for a user defined?",
    "present_kp": [
      "root",
      "path"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a lambda cube for interaction nets?. the lambda calculus is an untyped language that is often extended with logical frameworks such as the vertices of the -cube. is there something similar to it, but for interaction nets? what about interaction combinators?",
    "present_kp": [
      "lambda calculus",
      "interaction nets"
    ],
    "absent_kp": [
      "type theory",
      "type systems"
    ]
  },
  {
    "text": "how can i allow search engines to index my invite only website in ruby on rails?. i have a ruby on rails website that will be in invite-only mode for the next couple of months. currently i have it set up so visits to any page performs an authentication:before_filter :authenticate, :except => [:beta] //authenticate checks for a logged in userbut the webpage has a lot of content that i would like to see indexed by search engines, and i was wondering if there's an easy way to allow crawlers to do their work? i am not very knowledgable on seo related stuff at all, so sorry if this is an suboptimal way to phrase the question.",
    "present_kp": [
      "ruby on rails",
      "seo"
    ],
    "absent_kp": [
      "robots.txt"
    ]
  },
  {
    "text": "iterate through slicer settings and print to pdf. i have a spreadsheet with seven tables (tbl_1, tbl_2, ..., tbl_7) each controlled by its own slicer. each slicer has six buttons (10, 20, 30, 40, 50, 60) referring to team codes. i use the code below to select one team on every slicer, then create a pdf for each team / slicer setting. as of now, the code takes anywhere from 5-7min to run.sub slicerteam()dim wb as workbookdim sc as slicercachedim si as sliceritemon error goto errhandlerapplication.screenupdating = falseapplication.enableevents = falseset wb = thisworkbookfor x = 1 to 6 for i = 1 to 7 set sc = wb.slicercaches(tbl_ & i) sc.clearallfilters for each si in sc.visiblesliceritems set si = sc.sliceritems(si.name) if not si is nothing then if si.name = x * 10 then si.selected = true else si.selected = false end if else si.selected = false end if next si next icall pdfcreatenext xexithandler:application.screenupdating = trueapplication.enableevents = trueexit suberrhandler:msgbox (error in updating slicer filters.)resume exithandlerend subsub pdfcreate()dim fname as stringdim path as stringpath = s:\\myfilepath\\fname = path & sheets(detail).range(t1).value & - & [text('population detail'!b1,mmm, yyyy)] & .pdf sheets(detail).exportasfixedformat type:=xltypepdf, _ filename:=fname, quality:=xlqualitystandard, includedocproperties:=true, _ ignoreprintareas:=false, openafterpublish:=falseend sub",
    "present_kp": [],
    "absent_kp": [
      "vba",
      "excel"
    ]
  },
  {
    "text": "how do you balance between do it right and do it asap in your daily work?. i find myself pondering over this question from time to time, again and again. i want to do things the right way: to write clean, understandable and correct code that is easy to maintain. however, what i end up doing is writing patch upon a patch; just because there is no time, clients are waiting, a bug should be fixed overnight, the company is losing money on this problem, a manager is pressing hard etc., etc.i know perfectly well that in the long term i am wasting more time on these patches, but as this time spans months of work, nobody cares. also, as one of my managers used to say: we don't know if there will be a long term if we don't fix it now.i am sure i am not the only one entrapped in these endless real/ideal choice cycles. so how do you, my fellow programmers, cope with this?update:thank you all for this interesting discussion.it is sad that so many people have to choose daily between a quantity and a quality of their code. still, surprisingly many, people think it is possible to win this battle, so thank you all for this encouragement.",
    "present_kp": [],
    "absent_kp": [
      "project management",
      "programming practices",
      "management",
      "workflows",
      "software schedules"
    ]
  },
  {
    "text": "what are the implications of one site having thousands of links to yours?. using webmaster i can see the home page of a related site has 100,000 + links to my site. i assume this is because there are tons of pages on this site and a link to our site is in the footer.my question is how does google treat this? surely this must be quite common for huge sites, but does google see this as suspicious? do they rank each link or consider the site as a whole and only rank a single link?",
    "present_kp": [
      "links"
    ],
    "absent_kp": [
      "pagerank"
    ]
  },
  {
    "text": "i can't exit my local network. i have a wimax router for my internet access (192.168.15.1 on local) connected to micro hub.i have a arm archlinux odroid machine (192.168.15.2) connected to same hub.i have ubuntu pc (192.168.15.10) connected to same hub.ok for access from pc to internet.ok for access from pc to odroid with ssh because it has no screen.ok for ping 192.168.15.1 and 192.168.15.10 from odroid.but on odroid, i can't ping 8.8.8.8. i got network is unreachable.some idea?",
    "present_kp": [],
    "absent_kp": [
      "arch linux",
      "systemd"
    ]
  },
  {
    "text": "capacities on load-balancer & web servers? bandwidth + performance. i'm on digitalocean and i have a very simple scenario for my website.now having 3000 concurrent hits every minutes. (for example)currently it is directly on 1 only single apache server.the website can not be cached. (for some sensitive reason)then i am thinking for simply advanced setup, like:1x software load balancer (e.g, nginx)3x apache as web servers .. at behind lb.then suddenly my simple (but big) questions are:load balancer or web servers. which ones should have better capacities, in terms of bandwidth and perfomance.lets say lb redirects 1000 connections to each web servers. does it mean:the lb still need to consume 3000 traffic bandwidth in+out?each webserver still need to consume 1000 traffic bandwidth in+out?lb should have big processing performance? or, the webservers?to be more dummy ..something like ..do i need to buy $80 / month for lb droplet (and, leave $20 droplets for webservers)?(or) do i need to buy $40 / month 3x webserver droplets (and, leave $10 droplet for lb)?",
    "present_kp": [
      "nginx",
      "bandwidth"
    ],
    "absent_kp": [
      "apache httpd",
      "load balancing"
    ]
  },
  {
    "text": "declaring a large number of 2d arrays to be used as 2d graphic sprites. i'm creating a space invaders game, and graphics sprites in it are defined as 2d arrays of colors. it seems like it's going to be cumbersome declaring these arrays the way i currently am://this creates an inverting red/blue cross animationpublic sprite myfirstanimation(){ sprite frame1 = new sprite(new color[,] {{color.red, color.blue, color.red}, {color.blue, color.blue, color.blue}, {color.red, color.blue, color.red}}); sprite frame2 = new sprite(new color[,] {{color.blue, color.red, color.blue}, {color.red, color.red, color.red}, {color.blue, color.red, color.blue}}); animatedsprite myanimatedsprite = new animatedsprite(new sprite[] { frame1, frame2 }); return myanimatedsprite; }can you point me the the direction for a nicer way of doing this, as to make it more maintainable and readable, and less arduous?",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "why is the javascript-language different in different programs/sites?. i'm kind of new to programming and i have a question that's been bothering me for awhile.why is the javascript-language different in different programs/sites.i've used codecademy to practice and i've noticed it's different from eclipse and unity.for example, in codecademy, you use: var blabla = something to declare a variable.in eclipse though, you use: int x = 2, string x = hey.why is it like this? thanks in advance.",
    "present_kp": [
      "java",
      "javascript"
    ],
    "absent_kp": [
      "programming languages",
      "coding style"
    ]
  },
  {
    "text": "what really is the runtime environment?. this is a very basic question but is something i've never completely understood and recently, when studying .net core and asp.net 5 i felt the need of a more complete understanding of the topic.reading the article introduction to the common language runtime (clr) there we find the following piece of text:every program has a surprising number of dependencies on its runtime environment. most obviously, the program is written in a particular programming language, but that is only the first of many assumptions a programmer weaves into the program. all interesting programs need some runtime library that allows them to interact with the other resources of the machine (such as user input, disk files, network communications, etc). the program also needs to be converted in some way (either by interpretation or compilation) to a form that the native hardware can execute directly. now, this idea of runtime environment seems to be very basic, but still very important, not just when working with .net but when dealing with programming in general. it seems to be a general concept which is quite important to understand.until today i always had one intuitive and simple understanding about it: runtime environment is the environment on which the code will run. but this is a quite loose way to understand it. there is probably much more to it as can be infered from the above text. in that setting: what really is the runtime environment in general? not just for .net, but in programming in general, what is the runtime environment? is it just something conceptual or is it some piece of software, like the clr for .net? in summary, how should we properly understand the idea of runtime environment?",
    "present_kp": [
      ".net",
      "runtime"
    ],
    "absent_kp": [
      "programming languages",
      "terminology"
    ]
  },
  {
    "text": "clickable (gui) bash script?. was just finishing some script containing a choice menu and was wondering if there's a tool out there that could be called by a script, provides a 1-click-choice-menu and returns the result back to the script.impossible that such doesn't exist, but... ever tried to google bash menu click/mouse/gui/whatever?",
    "present_kp": [
      "bash",
      "gui",
      "menu"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "what is the brain power devoted to vision and haptics?. i heard a talk by vincent hayward on the sense of touch as a multi-modal system, where he claimed that the brain power devoted to haptics is at least as big as the one devoted to vision. i have found some answers with respect to vision, which claim the percentage to be between 25%-33% of the neo-cortex. the cortical homunculus shows a sensory map of the body, where i guess the eye depicted is more related to the haptic part of the eye region, rather than the vision.can you confirm the percentage for vision? what is the percentage for haptics? quotable sources would be fantastic of-course, but just a rough number would also do. i am mostly interested in the rough relative relation between the two modalities.",
    "present_kp": [
      "vision"
    ],
    "absent_kp": [
      "neurobiology",
      "sensation"
    ]
  },
  {
    "text": "integrate github branches beginning with string in a slack channel. is it possible to create a github integration for a slack channel where it only posts changes on branches beginning with some-string-*?",
    "present_kp": [
      "github",
      "slack"
    ],
    "absent_kp": []
  },
  {
    "text": "is there any credible evidence for the theory of spiral dynamics?. spiral dynamics is a developmental psychology based theory that postulates these main ideas:organisms in the universe go through a predictable set of stages of psychological development. these stages each exhibit a set of values that the organism tries to obtain. their pursuit for these values are clearly observable, i.e. it is possible to identify that the organism is trying to obtain these values. this image illustrates the different stages postulated by the theory, the characteristics of organism's behavior that are within each level, and also their overall world view.here is a table (dr. clare grave's model) that breaks down these characteristics into categories:i have heard that this theory is credible and that there is evidence for it, though i have struggled to find any.is there any evidence that strongly suggests all living organisms/creatures/life forms, in terms of mentality, consistently travel through a set of stages, where their values (and overall objectives) are respectively: gaining assurance, obtaining survival, obtaining security, obtaining independence, and then obtaining affiliation.while dr. graves himself did studies to produce this theory, his methods have been criticized heavily. at this point of time, are there any other studies that suggest that the postulate mentioned is consistent with various empirical observations?",
    "present_kp": [
      "developmental psychology"
    ],
    "absent_kp": [
      "cognitive psychology",
      "social psychology"
    ]
  },
  {
    "text": "how to repair a corrupted hfs+ partition from a damaged hard-disk?. i have a friend's mac os x disk that comes with an hfs+ partition. i am supposed to recover the personal data from this disk, and i'm not yet sure if the filesystem is corrupted or the disk is dying). background: the full symptoms are as follows. the drive gets recognized by linux and even gets automounted (using xfce here):liv@liv-hp-compaq-dc7900:~$ cat /etc/mtab | grep -i hfs/dev/sdb2 /media/macintosh hd hfsplus ro,nosuid,nodev,uhelper=udisks 0 0the kernel reports the following:[ <phone>] usb 2-5: usb disconnect, device number 2[ <phone>] usb 2-5: new high-speed usb device number 3 using ehci_hcd[ <phone>] initializing usb mass storage driver...[ <phone>] scsi6 : usb-storage 2-5:1.0[ <phone>] usbcore: registered new interface driver usb-storage[ <phone>] usb mass storage support registered.[ <phone>] scsi 6:0:0:0: direct-access asmt 2105 0 pq: 0 ansi: 6[ <phone>] sd 6:0:0:0: attached scsi generic sg2 type 0[ <phone>] sd 6:0:0:0: [sdb] 488397168 512-byte logical blocks: (250 gb/232 gib)[ <phone>] sd 6:0:0:0: [sdb] write protect is off[ <phone>] sd 6:0:0:0: [sdb] mode sense: 43 00 00 00[ <phone>] sd 6:0:0:0: [sdb] write cache: enabled, read cache: enabled, doesn't support dpo or fua[ <phone>] sdb: sdb1 sdb2[ <phone>] sd 6:0:0:0: [sdb] attached scsi disk[..][<phone>] hfs: filesystem was not cleanly unmounted, running fsck.hfsplus is recommended. mounting read-only.[<phone>] sd 6:0:0:0: [sdb] unhandled sense code[<phone>] sd 6:0:0:0: [sdb] result: hostbyte=invalid driverbyte=driver_sense[<phone>] sd 6:0:0:0: [sdb] sense key : medium error [current] [<phone>] sd 6:0:0:0: [sdb] add. sense: unrecovered read error[<phone>] sd 6:0:0:0: [sdb] cdb: read(10): 28 00 00 1e 22 e8 00 00 08 00[<phone>] end_request: critical target error, dev sdb, sector <phone>[<phone>] buffer i/o error on device sdb2, logical block 195672[<phone>] sd 6:0:0:0: [sdb] unhandled sense code[<phone>] sd 6:0:0:0: [sdb] result: hostbyte=invalid driverbyte=driver_sense[<phone>] sd 6:0:0:0: [sdb] sense key : medium error [current] [<phone>] sd 6:0:0:0: [sdb] add. sense: unrecovered read error[<phone>] sd 6:0:0:0: [sdb] cdb: read(10): 28 00 00 1e 22 e8 00 00 08 00[<phone>] end_request: critical target error, dev sdb, sector <phone>[<phone>] buffer i/o error on device sdb2, logical block 195672here's relevant output from lshw: *-scsi physical id: 3 bus info: usb@2:5 logical name: scsi7 capabilities: emulated scsi-host configuration: driver=usb-storage *-disk description: scsi disk product: 2105 vendor: asmt physical id: 0.0.0 bus info: scsi@7:0.0.0 logical name: /dev/sdb version: 0 serial: 00000000000000000000 size: 232gib (250gb) capabilities: gpt-1.00 partitioned partitioned:gpt configuration: ansiversion=6 guid=6b43402b-9887-4a33-a329-9801b59ccdc7 *-volume:0 description: windows fat volume vendor: bsd 4.4 physical id: 1 bus info: scsi@7:0.0.0,1 logical name: /dev/sdb1 version: fat32 serial: 70d6-1701 size: 199mib capacity: 199mib capabilities: boot fat initialized configuration: fats=2 filesystem=fat label=efi name=efi system partition *-volume:1 description: apple hfs partition vendor: mac os x (fsck) physical id: 2 bus info: scsi@7:0.0.0,2 logical name: /dev/sdb2 version: 4 serial: d9a741cc-8313-cc78-0000-<phone> size: 232gib capabilities: journaled bootable osx hfsplus initialized configuration: boot=osx checked=2009-09-24 02:29:07 created=2009-09-23 17:29:07 filesystem=hfsplus lastmountedby=fsck modified=2013-11-03 01:02:00 name=customer state=uncleanwhen i open the drive in thunar, i get the following error message: failed to open directory macintosh hd. error when getting information for file '/media/macintosh hd/.journal': input/output error. (i can access the mount point and some subdirs, though, if i use emelfm2.)if i try ls on the mount point, i get a bunch of i/o errors: liv@liv-hp-compaq-dc7900:/media/macintosh hd$ ls -lhals: cannot access .hotfiles.btree: input/output errorls: cannot access .journal: input/output errorls: cannot access .journal_info_block: input/output errorls: cannot access .spotlight-v100: input/output errorls: cannot access .trashes: input/output errorls: cannot access home: input/output errorls: cannot access libpeerconnection.log: input/output errorls: cannot access net: input/output errorls: reading directory .: input/output errortotal 20mdrwxrwxr-t 1 root 80 35 oct 13 22:56 .drwxr-xr-x 3 root root 4.0k jan 16 21:09 ..drwxrwxr-x 1 root 80 53 oct 18 22:07 applicationsdrwxr-xr-x 1 root root 39 sep 26 00:51 bindrwxrwxr-t 1 root 80 2 jul 9 2009 coresdr-xr-xr-x 1 root root 2 jul 9 2009 dev-rw-rw-r-- 1 501 80 16k sep 8 14:19 .ds_storelrwxr-xr-x 1 root root 11 sep 24 2009 etc -> private/etc---------- 1 root 80 0 jul 9 2009 .filedrwx------ 1 99 99 246 nov 3 00:29 .fseventsdlrwxr-xr-x 1 root 80 60 mar 20 2010 guides de lutilisateur et informations -> /library/documentation/user guides and information.localizeddr-xr-xr-t 1 root root 2 sep 24 2009 .hfs+ private directory data?d????????? ? ? ? ? ? home-????????? ? ? ? ? ? .hotfiles.btree-????????? ? ? ? ? ? .journal-????????? ? ? ? ? ? .journal_info_block-????????? ? ? ? ? ? libpeerconnection.logdrwxrwxr-t 1 root 80 58 mar 27 2013 librarydrwxrwxrwt 1 root root 4 sep 18 2012 lost+found-rw-r--r-- 1 root root 20m jun 8 2011 mach_kerneld????????? ? ? ? ? ? netdrwxr-xr-x 1 root root 2 jul 9 2009 networkdrwxr-xr-x 1 501 80 3 oct 26 2010 optdrwxr-xr-x 1 root root 6 sep 24 2009 privatedrwxr-xr-x 1 root root 67 sep 26 00:52 sbind????????? ? ? ? ? ? .spotlight-v100drwxr-xr-x 1 root root 4 jul 3 2011 systemlrwxr-xr-x 1 root root 11 sep 24 2009 tmp -> private/tmpd????????? ? ? ? ? ? .trashesdrwxr-xr-x 1 root root 2 may 18 2009 .vol-rw-r--r-- 1 501 80 70k jun 26 2013 .volumeicon.icnslastly, i already tried to install hfsprogs and run fsck.hfsplus, but without much luck: root@liv-hp-compaq-dc7900:/home/liv# fsck.hfsplus -q /dev/sdb2** /dev/sdb2quickcheck only; filesystem dirtyroot@liv-hp-compaq-dc7900:/home/liv# fsck.hfsplus -d /dev/sdb2** /dev/sdb2 using cacheblocksize=32k cachetotalblock=1024 cachesize=32768k.** checking hfs plus volume. invalid b-tree node size(8, 0)** volume check failed.volume check failed with error 7 volume type is pure hfs+ primary mdb is at block 0 0x00 alternate mdb is at block 0 0x00 primary vhb is at block 2 0x02 alternate vhb is at block 487725342 0x1d12191e sector size = 512 0x200 volumeobject flags = 0x07 total sectors for volume = 487725344 0x1d121920 total sectors for embedded volume = 0 0x00 question: from the error messages above, is the filesystem corrupted or the drive failing? how can i fix the corrupted filesystem? and if that's not the issue, how can i recover the user data from a partially failing disk?update1:given the useful input that i got from which 'smartctl -d' option should i use on this hard-disk: 'scsi' or 'ata'?, i now managed to successfully run smartctl on the hard-drive: root@liv-hp-compaq-dc7900:/home/liv# smartctl -d sat -h -i -c -a -l error -l selftest -l selective '/dev/sdb'smartctl 5.41 2011-06-09 r3365 [x86_64-linux-3.2.0-57-generic] (local build)copyright (c) 2002-11 by bruce allen, <url> start of information section ===device model: toshiba mk2555gsxfserial number: 10j9sa69slu wwn device id: 5 000039 245a067fdfirmware version: fh205buser capacity: 250,059,350,016 bytes [250 gb]sector size: 512 bytes logical/physicaldevice is: not in smartctl database [for details use: -p showall]ata version is: 8ata standard is: exact ata specification draft version not indicatedlocal time is: fri jan 17 18:02:43 2014 cetsmart support is: available - device has smart capability.smart support is: enabled=== start of read smart data section ===smart overall-health self-assessment test result: passed[..]smart attributes data structure revision number: 16vendor specific smart attributes with thresholds:id# attribute_name flag value worst thresh type updated when_failed raw_value 1 raw_read_error_rate 0x000b 100 100 050 pre-fail always - 0 2 throughput_performance 0x0005 100 100 050 pre-fail offline - 0 3 spin_up_time 0x0027 100 100 001 pre-fail always - 1031 4 start_stop_count 0x0032 100 100 000 old_age always - 16237 5 reallocated_sector_ct 0x0033 100 100 050 pre-fail always - 18 7 seek_error_rate 0x000b 100 100 050 pre-fail always - 0 8 seek_time_performance 0x0005 100 100 050 pre-fail offline - 0 9 power_on_hours 0x0032 081 081 000 old_age always - 7987 10 spin_retry_count 0x0033 253 100 030 pre-fail always - 0 12 power_cycle_count 0x0032 100 100 000 old_age always - <phone> g-sense_error_rate 0x0032 100 100 000 old_age always - <phone> power-off_retract_count 0x0032 084 084 000 old_age always - <phone> load_cycle_count 0x0032 037 037 000 old_age always - 635340194 temperature_celsius 0x0022 100 100 000 old_age always - 25 (min/max 7/49)196 reallocated_event_count 0x0032 100 100 000 old_age always - 3197 current_pending_sector 0x0032 100 100 000 old_age always - 124198 offline_uncorrectable 0x0030 100 100 000 old_age offline - 0199 udma_crc_error_count 0x0032 200 253 000 old_age always - 0220 disk_shift 0x0002 100 100 000 old_age always - 57222 loaded_hours 0x0032 087 087 000 old_age always - <phone> load_retry_count 0x0032 100 100 000 old_age always - 0224 load_friction 0x0022 100 100 000 old_age always - 0226 load-in_time 0x0026 100 100 000 old_age always - 346240 head_flying_hours 0x0001 100 100 001 pre-fail offline - 0254 free_fall_sensor 0x0032 100 100 000 old_age always - 8107smart error log version: 1ata error count: 1210 (device log contains only the most recent five errors)[..]error 1210 occurred at disk power-on lifetime: 7984 hours (332 days + 16 hours) when the command that caused the error occurred, the device was active or idle. after command completion occurred, registers were: er st sc sn cl ch dh -- -- -- -- -- -- -- 40 51 08 e8 22 1e 40 error: unc 8 sectors at lba = 0x001e22e8 = <phone> commands leading to the command that caused the error were: cr fr sc sn cl ch dh dc powered_up_time command/feature_name -- -- -- -- -- -- -- -- ---------------- -------------------- 25 da 08 e8 22 1e 40 00 00:08:36.484 read dma ext 25 da 08 e8 22 1e 40 00 00:08:32.637 read dma ext 25 da 08 00 66 22 40 00 00:08:32.637 read dma ext 25 da 08 f8 65 22 40 00 00:08:32.625 read dma ext 25 da 08 50 c3 28 40 00 00:08:32.625 read dma ext[..]smart self-test log structure revision number 1no self-tests have been logged. [to run self-tests, use: smartctl -t]smart selective self-test log data structure revision number 1 span min_lba max_lba current_test_status 1 0 0 not_testing 2 0 0 not_testing 3 0 0 not_testing 4 0 0 not_testing 5 0 0 not_testingselective self-test flags (0x0): after scanning selected spans, do not read-scan remainder of disk.if selective self-test is pending on power-up, resume after 0 minute delay.i'm not sure how to parse this output, but two things pop to my eyes: smart overall-health self-assessment test result: passedata error count: 1210 (device log contains only the most recent five errors)so how bad is it? and how should i proceed? update2:following the suggestions in the comments, i used a mac os x to run diskutil verifyvolume: mac:~ admin$ diskutil list[..]/dev/disk1#: type name size identifier0: guid_partition_scheme *250.1 gb disk11: efi 209.7 mb disk1s12: apple_hfs macintosh hd 249.7 gb disk1s2mac:~ admin$ diskutil verifyvolume /dev/disk1s2started filesystem verification on disk1s2 macintosh hdchecking journaled hfs plus volumeinvalid b-tree node sizethe volume macintosh hd could not be verified completelyerror: -9957: filesystem verify or repair failedunderlying error: 8: posix reports: exec format errorand fsck:mac:~ admin$ fsck -d /dev/disk1s2 ** /dev/rdisk1s2bad super block: magic number wronglook for alternate superblocks? [yn] ysearch for alternate super-block failed. you must use the-b option to fsck to specify the location of an alternatesuper-block to supply needed information; see fsck(8).so, how bad are these error messages? is the drive toast? update3:i played a bit more with smartctl and it seems to me (but please confirm!!) that the drive is definitely toast: # 'smartctl' -d sat,16 -h -i -c -a -l error -l selftest -l selective '/dev/sdb'smartctl 5.41 2011-06-09 r3365 [x86_64-linux-3.2.0-57-generic] (local build)copyright (c) 2002-11 by bruce allen, <url> start of information section ===device model: toshiba mk2555gsxfserial number: 10j9sa69slu wwn device id: 5 000039 245a067fdfirmware version: fh205buser capacity: 250,059,350,016 bytes [250 gb]sector size: 512 bytes logical/physicaldevice is: not in smartctl database [for details use: -p showall]ata version is: 8ata standard is: exact ata specification draft version not indicatedlocal time is: mon jan 27 15:20:57 2014 cetsmart support is: available - device has smart capability.smart support is: enabled=== start of read smart data section ===smart overall-health self-assessment test result: failed!drive failure expected in less than 24 hours. save all data.see vendor-specific attribute list for failed attributes.general smart values:offline data collection status: (0x00) offline data collection activity was never started. auto offline data collection: disabled.self-test execution status: ( 88) the previous self-test completed having the electrical element of the test failed.total time to complete offline data collection: ( 120) seconds.offline data collectioncapabilities: (0x5b) smart execute offline immediate. auto offline data collection on/off support. suspend offline collection upon new command. offline surface scan supported. self-test supported. no conveyance self-test supported. selective self-test supported.smart capabilities: (0x0003) saves smart data before entering power-saving mode. supports smart auto save timer.error logging capability: (0x01) error logging supported. general purpose logging supported.short self-test routine recommended polling time: ( 2) minutes.extended self-test routinerecommended polling time: ( 90) minutes.sct capabilities: (0x0039) sct status supported. sct error recovery control supported. sct feature control supported. sct data table supported.smart attributes data structure revision number: 16vendor specific smart attributes with thresholds:id# attribute_name flag value worst thresh type updated when_failed raw_value 1 raw_read_error_rate 0x000b 100 100 050 pre-fail always - 0 2 throughput_performance 0x0005 100 100 050 pre-fail offline - 0 3 spin_up_time 0x0027 100 100 001 pre-fail always - 1025 4 start_stop_count 0x0032 100 100 000 old_age always - 1 5 reallocated_sector_ct 0x0033 100 100 050 pre-fail always - 0 7 seek_error_rate 0x000b 100 100 050 pre-fail always - 0 8 seek_time_performance 0x0005 100 100 050 pre-fail offline - 0 9 power_on_hours 0x0032 100 100 000 old_age always - 0 10 spin_retry_count 0x0033 100 100 030 pre-fail always - 0 12 power_cycle_count 0x0032 100 100 000 old_age always - 1191 g-sense_error_rate 0x0032 100 100 000 old_age always - 0192 power-off_retract_count 0x0032 100 100 000 old_age always - 0193 load_cycle_count 0x0032 100 100 000 old_age always - 3194 temperature_celsius 0x0022 100 100 000 old_age always - 27 (min/max 26/30)196 reallocated_event_count 0x0032 100 100 000 old_age always - 0197 current_pending_sector 0x0032 100 100 000 old_age always - 0198 offline_uncorrectable 0x0030 100 100 000 old_age offline - 0199 udma_crc_error_count 0x0032 200 253 000 old_age always - 0220 disk_shift 0x0002 100 100 000 old_age always - 57222 loaded_hours 0x0032 100 100 000 old_age always - 0223 load_retry_count 0x0032 100 100 000 old_age always - 0224 load_friction 0x0022 100 100 000 old_age always - 0226 load-in_time 0x0026 100 100 000 old_age always - 353240 head_flying_hours 0x0001 001 001 001 pre-fail offline failing_now 3254 free_fall_sensor 0x0032 100 100 000 old_age always - 0error smart error log read failed: scsi error badly formed scsi parameterssmartctl: smart error log read failederror smart error self-test log read failed: scsi error badly formed scsi parameterssmartctl: smart self test log read failederror smart read selective self-test log failed: scsi error badly formed scsi parameterssmartctl: smart selective self test log read failedi could single out: smart overall-health self-assessment test result: failed! drive failure expected in less than 24 hours. save all data.240 head_flying_hours 0x0001 001 001 001 pre-fail offline failing_now 3i suspect that any solutions like testdisk or photorec on the drive itself are pretty much out of the question right now. so my only hope to rescue any data would be to get myself a bigger hard-disk and make a bit-for-bit copy of the failing drive using dd or ddrescue, and then play with photorec on the resulting image. any other ideas most welcome!update4:as inquired in recovering data from a damaged hard-drive: the freezer trick, i am posting the output of smartctl -h /dev/yourdisk and smartctl -a /dev/yourdisk:[output was misleading so i removed that. see update5.]does this allow to identify the type of failure? update5:about a week ago i foolishly ran testdisk on the disk for a night (after a couple of native mac os x fsck attempts), and the damage likely became worse than it had been when the owner simply had dropped it. at the end of the testdisk session i was clearly hearing a clicking noise (click of death?), and the drive was incapable of any further reads (all reads resulted in an error). initially i assumed that this was happening because of overheating, but now i tend to believe that the damage simply propagated and the drive is now in very bad shape.when i try to run smartctl short self-test on the drive, the test completed with electrical failure and the smartctl output is the same as in update3, including the 240 head_flying_hours 0x0001 001 001 001 pre-fail offline failing_now 3 error. i also attempted a ddrescue session, which ended with a grand total of 0 bytes rescued. root@xubuntu:/mnt/ram# ddrescue -f -n /dev/sdc /dev/sda /mnt/ram/ddrescue.logpress ctrl-c to interruptinitial status (read from logfile)rescued: 0 b, errsize: 0 b, errors: 0current statusrescued: 0 b, errsize: 250 gb, current rate: 0 b/s ipos: 65024 b, errors: 1, average rate: 0 b/s opos: 65024 b, time from last successful read: 3.5 mfinished at each read attempt the kernel was complaining in dmesg of buffer i/o error on device: [ <phone>] sd 9:0:0:0: [sdc] sense key : medium error [current][ <phone>] sd 9:0:0:0: [sdc] add. sense: unrecovered read error[ <phone>] sd 9:0:0:0: [sdc] cdb: read(10): 28 00 00 00 00 18 00 00 08 00[ <phone>] end_request: critical target error, dev sdc, sector 24[ <phone>] buffer i/o error on device sdc, logical block 3[ <phone>] sd 9:0:0:0: [sdc] unhandled sense code[ <phone>] sd 9:0:0:0: [sdc] result: hostbyte=invalid driverbyte=driver_senseso all this definitely points to hardware damage. but what is the exact type of damage? (in part, i would like to check if the freezer trick is in any way appropriate.)as suggested in a related question, i checked how to recover data when your hard drive goes belly up and it seems to me, given the symptoms that i've noticed, that it's either: your drive is spinning up and making clicking noises, oryour drives spins ups and is detected by your computer, but hangs when you try to access itso given all the additional information posted here, is it possible identify the type of failure that the disk is experiencing? and would the freezer trick be appropriate in this case? (it was suggested to me that when read write heads touch the surface of the disk, then they are toss and twist, so no read is possible anymore, and this does sound like a realistic explanation, but i'm not sure how to confirm it.)",
    "present_kp": [
      "osx",
      "hfs+"
    ],
    "absent_kp": [
      "filesystems",
      "hard disk",
      "data recovery"
    ]
  },
  {
    "text": "mpi+openmp scalability. i have a numerical code which is mpi+openmp (hybrid) parallelized and an available computational resource of 32 nodes with 16 cores on each node. the code has been tested for mpi scalability up to 16 cores on different nodes and openmp scalability on 16 cores on a single node. can i assume the hybrid parallelization to be scalable on $32 imes 16$ cores?edit: mpi+openmp is done in such a way that mpi processes are launched at the beginning itself and shared memory parallelization is done within each process using a few parallel do loops.",
    "present_kp": [
      "mpi"
    ],
    "absent_kp": [
      "parallel computing"
    ]
  },
  {
    "text": "callback functions to select the tab to the left in google chrome. i'm a javascript rookie, but i wrote a javascript function as part of a chrome extension that will activate the tab to the left of the currently active tab. the function is pretty ugly, but i couldn't figure out another way to write it.the logic is pretty simple, but i ran into problems setting variables throughout the various scopes. how would i move the functionality of the chrome api calls into individual functions that return values? can callback functions return a value?// activates the tab to the left of the currently active tabtableft = function() { var parent = this; var activetabindex; var targettabindex; // get the index of the active tab chrome.tabs.query({'active':true, 'currentwindow': true}, function(tabs) { parent.activetabindex = tabs[0].index; }); // get the count of the number of tabs in the current window chrome.tabs.query({'currentwindow': true}, function(tabs) { var tabcount = tabs.length; parent.targettabindex = (parent.activetabindex == 0) ? (tabcount - 1) : (parent.activetabindex - 1); // get the tabid of the of the tab we want to activate chrome.tabs.query({'index': parent.targettabindex}, function(tab) { var tabid = tab[0].id; // activate the target tab chrome.tabs.update(tabid, {'active': true}, function() {}); }); });};",
    "present_kp": [
      "javascript",
      "callback",
      "google chrome"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "problem with paste and standard output in linux. i have two files that i am trying to merge, one file is:linux$ cat temp2linear_0_a_b linear_0_b_a1<phone> 1<phone>464.3<phone>.2666671<phone> 1<phone>533.2<phone>.7333331<phone> 1<phone>621.5<phone>.5111111<phone> 1<phone>712.1<phone>.<phone>.5<phone>.4888891<phone> 1<phone>and the other file is:linux$ cat templinear_1_a_b linear_1_b_a1<phone> 1<phone>408.4<phone>.4444441<phone> 1<phone>627.6<phone>.<phone>.5<phone>.8888891<phone> 1<phone>469.3<phone>.3149171<phone> 1<phone>925.8<phone>.2222221<phone> 1<phone>i want to paste the columns in temp into temp2, and retain the temp2 file like this:linux$ paste temp2 templinear_0_a_b linear_0_b_a linear_1_a_b linear_1_b_a1<phone> 1<phone> 1<phone> 1<phone>464.3<phone>.266667 1<phone> 1<phone>687.4<phone>.711111 1<phone> 1<phone>533.2<phone>.733333 1<phone> 1<phone>545.0<phone>.933333 1<phone> 1<phone>621.5<phone>.511111 1<phone> 1<phone>255.7<phone>.256983 1<phone> 1<phone>712.1<phone>.139665 1<phone> 1<phone>817.5<phone>.488889 1<phone> 1<phone>701.4<phone>.200000 1<phone> 1<phone>but when i do standard output, and display temp2, the result is not the same. linux$ paste temp2 temp > temp2linux$ cat temp2 linear_1_a_b linear_1_b_a 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone> 1<phone>how to resolve??",
    "present_kp": [
      "paste"
    ],
    "absent_kp": [
      "text processing",
      "io redirection"
    ]
  },
  {
    "text": "changing keyboard layout on scientific linux 6.0 and creating new keyboard shortcuts?. i have two questions regarding keyboard input and shortcuts:is it possible to change the keyboard layout on scientific linux 6.0 and how can it be done?is it possible to define new keyboard shortcuts so that the terminal can be launched for example, with ctrl+alt+t ?",
    "present_kp": [
      "keyboard shortcuts",
      "keyboard layout",
      "scientific linux"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a license that both provides patent protection and does not require attribution?. looking at <url> we can see that there are a number of licenses that provide patent troll protection, and there are also a few licenses that that do not require attribution (cc0, unlicense, wtfpl).however, there does not seem to be any licenses that i can find (on that list or elsewhere) that both protect against patent trolls and doesn't require attribution. does anyone know if such a license exists?if not, is there some reason why the two are necessarily incompatible with each other such that no license could possible exist that provides both?if they are mutually exclusive, is there any reason i wouldn't be able to dual-license my software under unlicense and microsoft public license (to effectively create a scenario where no one needs to provide attribution, but the code is also offers protection against patent trolls?as a software engineer, i want a way to create projects that have the lowest barrier possible, for any type of user. however, when using cc0/unlicense/wtfpl i have found that some companies are unable to use my software because it doesn't provide patent protection. i would like to use a license that offers that protection while also not requiring that users go through the burden of attribution (which can be a bit of a pain when you actually follow through with it).",
    "present_kp": [
      "attribution"
    ],
    "absent_kp": [
      "licensing",
      "patents"
    ]
  },
  {
    "text": "is the longest trail problem easier than the longest path problem?. the longest path problem is np-hard. the (typical?) proof relies on a reduction of the hamiltonian path problem (which is np-complete). note that here the path is taken to be (node-)simple. that is, no vertex can occur more than once in the path. obviously it is thus also edge-simple (no edge will occur more than once in the path).so what if we drop the requirement of finding a (node-)simple path and stick to finding an edge-simple path (trail). at first glance, since finding a eulerian trail is much easier than finding a hamiltonian path, one might have some hope that finding the longest trail would be easier than finding the longest path. however, i cannot find any reference proving this, let alone one that provides an algorithm.note that i am aware of the argument made here:<url> the argument seems flawed in its current form, as it basically shows you could solve the edge-simple case by solving the node-simple case on a different graph (so the reduction is the wrong way around). it is not clear that the reduction could easily be changed to work the other way as well. (still, it does show that at the very least the longest trails problem is not harder than the longest paths problem.)so are there any known results for finding longest trails (edge-simple paths)? complexity (class)? (efficient) algorithm?",
    "present_kp": [],
    "absent_kp": [
      "graph theory",
      "graph algorithms",
      "hamiltonian paths"
    ]
  },
  {
    "text": "derivative of cost function with respect to the input. how to compute the partial derivative of the sum-squared error withrespect to the $x_i$ input ($\\partial e/ \\partial x_i$)?",
    "present_kp": [],
    "absent_kp": [
      "machine learning",
      "neural networks"
    ]
  },
  {
    "text": "given a string s and q query strings(q1,q2,...), check for each query string whether or not it is sub-sequence of s. here is my approach. subsequence is a sequence that can be derived from another sequence by deleting some elements without changing the order of the remaining elements. import java.io.inputstreamreader;import java.util.scanner;public class query {public static void main(string[] args) { scanner scanner = new scanner(new inputstreamreader(system.in)); string str=scanner.next(); int n=scanner.nextint(); while(n-->0){ string sub=scanner.next(); if(issub(str,sub)) system.out.println(yes); else system.out.println(no); }}static boolean issub(string str, string sub){ int j=0; int x=str.length(); int y=sub.length(); for(int i=0;i<x && j<y;i++){ if(str.charat(i)==sub.charat(j)) j++; } return (j==y);}}please critique my code and also suggest me how to increase efficiency of this code.",
    "present_kp": [
      "java",
      "strings"
    ],
    "absent_kp": []
  },
  {
    "text": "craft url to create google doc in specific folder?. after searching, the closest information i've found is this question. however, that answer covers just creating a google drive file, period. i would like to find out how to make that file get created in a specific folder.is this possible?",
    "present_kp": [
      "google drive",
      "url"
    ],
    "absent_kp": []
  },
  {
    "text": "find the kth prime and all the primes below it. it works by finding 2n+1 with n from 1 to k, but not where 2n+1 would be divisible by one of the already known primes. i'd like to know if the program can find every prime, and if so, how it compares to the efficiency of other algorithms.n=1k=input()primes=[2]def f(n): b, a = 1, 1 for i in primes: a=((2*n+1)%i) b=b*a return bwhile k > n: if f(n) >= 1: primes.append((2*n)+1) n=n+1 else: n=n+1 k=k+1print primes",
    "present_kp": [
      "primes"
    ],
    "absent_kp": [
      "python"
    ]
  },
  {
    "text": "gui-based credit card checker. how can i make this more readable, faster, and make the gui more appealing? creditcard class:import java.util.*;public class creditcards { private string prefix; private string length; public creditcards(string p, string l) { prefix = p; length = l; } public string getprefix() { return prefix; } public string getlength() { return length; }}mastercard class:public class mastercard extends creditcards { public mastercard(string prefix,string length) { super(prefix,length); } public boolean ismaster() { boolean pre = (getprefix().equals(55) || getprefix().equals(51))? true:false; boolean len = getlength().equals(16)? true:false; if(pre && len) { return true; } else { return false; } }}visacard class:public class visacard extends creditcards { public visacard(string pre,string len) { super(pre,len); } public boolean isvisa() { boolean pre = getprefix().equals(4) ? true:false; boolean len = (getlength().equals(16) || getlength().equals(13))? true:false; if(pre && len) { return true; } return false; }}gui:import java.util.*;import javax.swing.*; import java.awt.*;import java.awt.event.*;public class cardvalidatorgui{ jframe frame; jtextfield cardnumfield; jcombobox creditcardbox; jbutton checkbutton; jbutton clearbutton; string[] cards = {visa,mastercard}; string selected = null; public static void main(string[] args) { cardvalidatorgui r1 = new cardvalidatorgui(); r1.go(); } public void go() { frame = new jframe(); jpanel cardpanel = new jpanel(); jpanel buttonpanel = new jpanel(); cardpanel.setlayout(new gridlayout(0,2)); buttonpanel.setlayout(new gridlayout(0,2)); creditcardbox = new jcombobox(cards); cardnumfield = new jtextfield(,20); checkbutton = new jbutton(check); checkbutton.addactionlistener(new actionlistener(){ public void actionperformed(actionevent ae) { string selected = creditcardbox.getselecteditem().tostring(); if (checkcriteria(selected)){ if (checksum(cardnumfield.gettext())) { joptionpane.showmessagedialog(null, your credit card is valid); } else { joptionpane.showmessagedialog(null, your credit card is not valid); } } else { joptionpane.showmessagedialog(null, your credit card is not valid); } } }); clearbutton = new jbutton(clear); cardpanel.add(creditcardbox); cardpanel.add(cardnumfield); buttonpanel.add(checkbutton); buttonpanel.add(clearbutton); frame.getcontentpane().add(borderlayout.center,cardpanel); frame.getcontentpane().add(borderlayout.south,buttonpanel); frame.setsize(250, 200); frame.setvisible(true); frame.pack(); frame.setdefaultcloseoperation(frame.exit_on_close); } public static boolean checksum(string check){ int sum = 0; string trimcheck = check.replaceall( , ); string reverse = new stringbuffer(trimcheck).reverse().tostring(); for(int i =0;i<trimcheck.length();i++) { int checkthis = character.digit(reverse.charat(i), 10); if(i%2==0) { sum+=checkthis; } else { sum += checkthis *2; if(checkthis >=5) { sum-=9; } } } if(sum%10==0) { return true; } else { return false; } } public boolean checkcriteria(string c) { int length = cardnumfield.gettext().replaceall( ,).length(); string len = integer.tostring(length); if (c.equals(mastercard)) { string pre = cardnumfield.gettext().substring(0,2); mastercard masters = new mastercard(pre,len); if(masters.ismaster()) { return true; } } if (c.equals(visa)) { string pre = cardnumfield.gettext().substring(0,1); visacard visa = new visacard(pre,len); if (visa.isvisa()) { return true; } } return false; }}",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "validation",
      "finance"
    ]
  },
  {
    "text": "how to decrease speed/priority of file transfer (graphical)?. i regularly have big transfers of files running between two local hard drives, and at the same time some network transfers through my internet browser. the problem is that the local transfer seems to take the priority:if i let both of them run, the internet transfer hardly goes higher than 100-200kbps, often being close to 1-5kbps.if i pause the local transfer, the internet transfer jump immediately to 500-600kbps, which is my usual bandwidth.i have tried to decrease the priority of the local process and increase the priority of the browser (process priority as well as i/o priority), but nothing changes.i have seen this topic on pv, but it is about a command line transfer where pv is used to launch the transfer, so not something i can use on an existing transfer process/window:i would like to know if there is some ways to limit the local transfers launched graphically, like through dolphin or nautilus. exactly (limit transfer speed) or approximatively (limit priority-like stuff and let the system manage the details).",
    "present_kp": [
      "limit",
      "file transfer"
    ],
    "absent_kp": []
  },
  {
    "text": "domain transfer protection - need advice. i am about to purchase a domain name for a bit of money. i do not personally know the person who i am purchasing the domain name from, we have only chatted via email.the proposed process for the transfer is:the owner of the domain lowest thedomain name security and emails methe domain password, i request thetransferafter the request, i transfer the money via paypalwhen the money has been cleared the current domain name owner confirms the transfer via the link that he receives in that emaili wait for it to be transferred.the domain is currently registered with directnic - <url> this the best practice? seeing i am paying a bit of money for this domain name, i am worried that after the money has been cleared that i won't see the domain name or hear from the current domain name owner again.is there a 'domain governing body' which i can report to if this is the case?is the proposed transfer process the best solution?any advice would be awesome.thanks!jack",
    "present_kp": [],
    "absent_kp": [
      "domains"
    ]
  },
  {
    "text": "smbpasswd failed for new samba install on fresh ubuntu 11.04. i've installed samba on a fresh ubuntu install. i run the commandsudo smbpasswd -a someusernew smb password:retype new smb password:failed to add entry for user someuser.i've read that you need to setup a system user, or setup a normal user for someuser first. i have two questions.what is a system user?what the correct way to setup a vanilla smb only user with either a system user, or for someuser?",
    "present_kp": [
      "ubuntu",
      "samba"
    ],
    "absent_kp": [
      "users"
    ]
  },
  {
    "text": "simple encoder by a beginner. i decided to make a quick little encoder in python as a little challenge for myself. i decided to submit my program as i am very interested in improving my programming skills and learning better ways to code. my program simply asks for a string and for a key. the key could be +3, +4, etc. the key will add the number inputted to the number corresponding to each letter, then return the new letters.dic = {a: 0, b: 1, c: 2, d: 3, e: 4, f: 5, g: 6, h: 7, i: 8, j: 9, k: 10, l: 11, m: 12, n: 13, o: 14, p: 15, q: 16, r: 17, s: 18, t: 19, u: 20, v: 21, w: 22, x: 23, y: 24, z: 25, : 26}dic2 = {}for x,v in dic.items(): dic2[v] = xprogram = truewhile program: list = [] encodenums = [] encodestr = [] task = input(would you like to encode or decode?: ).lower() if task == encode: string = input(what would you like to encode?: ).upper() key = input(what key would you like to use?: ) for x in string: list.append(dic[x]) for x in list: encodenums.append(eval({}{}.format(x,key)) % 27) for x in encodenums: encodestr.append(dic2[x]) print(.join(encodestr))",
    "present_kp": [
      "python",
      "beginner"
    ],
    "absent_kp": [
      "python 3.x",
      "caesar cipher"
    ]
  },
  {
    "text": "what are the problems with boolean variables?. why is it that some languages don't even have a boolean type (and uses a constant true instead), but they have many other and modern types? sometimes it can be trouble if you make a boolean and then realize it can have three different values or more, then it's going to be difficult if you have old data with the boolean variable. what are some other reasons to avoid boolean variables?related question: <url> thinking more of conceptual problem like undecidable cases and synchronization problems. and that a boolean often is redaundant information and therefore it can be problems and synchronization issues. for a semaphore a boolean could be good but maybe not as an instance variable for an account whether or not the account is p since that may be different in different ways one might not have thought of, for example when you realize that there are not only two mutually exclusive states for what you are modelling.",
    "present_kp": [
      "boolean"
    ],
    "absent_kp": [
      "language agnostic"
    ]
  },
  {
    "text": "extract firmware of my camera (lumix mg5). i bought a camera (lumix gm5), but i can't change the language of it.the easy way is to send it back to amazon, but i want to try to change itby modifying the firmware before.so, i used binwalk to analyze the firmware: root@ec5b1dd5bce3:~# binwalk gm5__v11.bin decimal hexadecimal description6789427 0x679933 mysql misam compressed data file version 930718920 0x1d4bbc8 mysql isam index file version 131869478 0x1e64a26 zboot firmware header, header size: 32 bytes, load address: 0x29f4f830, start address: 0x9692295d, checksum: 0x11837327, version: 0xb1437316, image size: <phone> bytesi see that there is misam compressed data.maybe i can change the language here, maybe not.so to exract it with binwalk again i did :[root@ec5b1dd5bce3:~/_gm5__v11.bin.extracted# binwalk -d '.sql:myd:myisamchk' gm5__v11.bin which give me two files:binwalk 679933.myd decimal hexadecimal description0 0x0 mysql misam compressed data file version 923929493 0x16d2295 mysql isam index file version 125080051 0x17eb0f3 zboot firmware header, header size: 32 bytes, load address: 0x29f4f830, start address: 0x9692295d, checksum: 0x11837327, version: 0xb1437316, image size: <phone> bytesand :[root@ec5b1dd5bce3:~/_gm5__v11.bin.extracted# binwalk 1d4bbc8.myd decimal hexadecimal description0 0x0 mysql isam index file version <phone> 0x118e5e zboot firmware header, header size: 32 bytes, load address: 0x29f4f830, start address: 0x9692295d, checksum: 0x11837327, version: 0xb1437316, image size: <phone> bytesbut now when i try to use myisamchk on my new files it failed :root@ec5b1dd5bce3:~/_gm5__v11.bin.extracted# myisamchk 679933.myd myisamchk: error: '679933.myd' is not a myisam-tablei guess it's because i still have the zboot firmware header in my .myd files.so i was wondering, what is the proper way to extract only specific signatures ?thanks.",
    "present_kp": [
      "firmware"
    ],
    "absent_kp": [
      "binary analysis"
    ]
  },
  {
    "text": "do videos i like on youtube get shared to people in my circles on google+?. i would like to know because i don't want everyone seeing what i am doing. i can't find anything to help, so i am asking here. i also have a few friends who are having this problem, but they don't want to create another account, so i am asking for them.",
    "present_kp": [
      "youtube"
    ],
    "absent_kp": [
      "google plus"
    ]
  },
  {
    "text": "count number of points in a cell in paraview. i have two vtk datasets loaded in paraview. one is an unstructured grid cell dataset and the other is an unstructured grid point dataset. i would like to find a non-programmatic way to determine exactly how many points are located with a particular or several cells. so far i know how to create a selection but i cannot find a filter or combination of filters which will allow me to accomplish this.",
    "present_kp": [
      "paraview",
      "vtk"
    ],
    "absent_kp": []
  },
  {
    "text": "expanding centos_home. i have centos running on hyper -v , i expanded the virtual hard disk in hyper-v but i need help to expand centos_home partition.i need a way to increase the size of the sda3 since all the free space allocated on sda root without losing my data .this is the lsblk and df - lcommand :linux is my weakness please advise what need to be done without losing data",
    "present_kp": [
      "linux",
      "centos"
    ],
    "absent_kp": []
  },
  {
    "text": "arena memory allocator. i'm not exactly sure if this is technically an arena allocator but it serves a similar purpose: providing a fast way to allocate a lot of objects that can all be freed at once.#include <type_traits>#include <utility>#include <new>template <std::size_t blocksizein = 1024>struct blockprovidernewdelete{ static constexpr std::size_t blocksize = blocksizein; static void* allocateblock() { return ::operator new(blocksize); } static void freeblock(void *block) noexcept { ::operator delete(block); }};template <class blockproviderin>class arenaallocator{public: using blockprovider = blockproviderin;private: struct allocblock { allocblock *next; char mem[blockprovider::blocksize - sizeof(allocblock*)]; }; allocblock *base; allocblock *headblock; std::size_t headindex; void appendblock() { allocblock *newblock = static_cast<allocblock*>(blockprovider::allocateblock()); newblock->next = nullptr; headblock->next = newblock; headblock = newblock; headindex = 0; } void nextblock() { if(headblock->next) { headblock = headblock->next; headindex = 0; } else appendblock(); }public: static constexpr std::size_t blocksize = blockprovider::blocksize; static constexpr std::size_t maxallocationsize = sizeof(allocblock::mem); arenaallocator() { base = static_cast<allocblock*>(blockprovider::allocateblock()); base->next = nullptr; headblock = base; headindex = 0; } ~arenaallocator() { allocblock *cur = base, *next; while(cur != nullptr) { next = cur->next; blockprovider::freeblock(cur); cur = next; } } void reset() noexcept { headblock = base; headindex = 0; } void* allocate(std::size_t s) { if(s == 0) s = 1; if(s > maxallocationsize) return nullptr; else if(s > maxallocationsize - headindex) nextblock(); void *ptr = &headblock->mem[headindex]; headindex += s; if(headindex >= maxallocationsize) nextblock(); return ptr; } template <typename t, typename... args> t* construct(args... args) { static_assert(std::is_trivially_destructible<t>::value, type must be trivially destructible!); static_assert(sizeof(t) <= maxallocationsize, type must not be larger than max allocation size!); t *result = static_cast<t*>(allocate(sizeof(t))); new (result) t(std::forward<args>(args)...); return result; }};template <std::size_t blocksize>using arenaallocatordefault = arenaallocator<blockprovidernewdelete<blocksize>>;a caveat to this is that types allocated with the arena allocator must be trivially destructible (i.e. their memory must be reusable without destroying them first).i'm already aware of one major issue: it doesn't consider alignment. however that's a fairly easy fix, so i'd like that to be ignored in the review. i'm mostly wondering whether this invokes any undefined behavior (other than due to ignoring memory alignment).here's an example of usage (this was to test if it leaked any blocks of memory or segfaulted. it didn't.):// 2 mib block sizearenaallocatordefault<<phone>> test;for(size_t i = 0; i < 100000; ++i){ for(size_t j = 0; j < <phone>; ++j) { test.construct<char[128]>(); } test.reset();}obviously you'd want to actually use the pointer returned by the construct() method for usual purposes but this was just for testing.",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "memory management"
    ]
  },
  {
    "text": "handling large amount s of ajax/post commands. i'm currently creating a utility that is heavily ajax orientated. i have a page called ajax.php which is handling all post requests. it switches by the provided command, checks all the arguments exist then passes it off to the relevant class e.g.case 'addperson': $name = $_post['name'] ?? die('{result:0, data:name not provided}'); $email = $_post['email'] ?? die('{result:0, data:email not provided}'); try { (new person(new db()))->addperson($name, $email); } catch (exception $e) { exit({ esult\\:0, \\data\\:\\{$e->getmessage()}\\}); } exit('{result:1}');this works fine but was wondering how people generally go about handling big lists of $_post arguments. would you do the above, potentially have 20 lines of $arg = $_post['arg'] or perhaps something like,foreach (['name', 'state'] as $arg) { $$arg = $_post[$arg] ?? die({ esult\\:0, \\data\\:\\$arg not provided\\});}the other option is to not check it exists at all. list($a, $b, $c) = [$_post['a'], $_post['b'], $_post['c']];since i'm the only one working on this project, i can ensure i always provide the necessary data but this just seems bad and may create future issues (especially if i get a few helpers!)finally, what do you think about having the ajax.php confirm all arguments have been provided (not validated) rather than just checking for the command and passing off the $_post array to a class which will then confirm all arguments have been provided?",
    "present_kp": [
      "php"
    ],
    "absent_kp": []
  },
  {
    "text": "animating your facebook timeline. some users have found it's possible on google plus to animate your profile.what i'd like to know is if anyone has found a way to animate your facebook timeline, through either an animated .gif, a video or .swf file somehow?",
    "present_kp": [
      "facebook",
      "profile",
      "facebook timeline"
    ],
    "absent_kp": [
      "animations"
    ]
  },
  {
    "text": "sendmail : save email into a file. i use sendmail to manage the emails of my website. i'm testing features which require to send emails, and i'd like to receive these emails in a local directory of my server, store them as text files that i can read with vi for example.i found a way to do this a few months earlier, the emails were stored in a specific folder with the recipient address as file name. sadly, something went wrong with my virtual machine and i had to reconfigure the whole thing. the problem is that i don't remember what i had to do in order to get my emails in my local storage, and i can't find the solution again on internet, it makes me crazy. my virtual machine is on rhel 6.thanks for your help !",
    "present_kp": [
      "rhel",
      "email",
      "sendmail"
    ],
    "absent_kp": []
  },
  {
    "text": "streaming learning ocaml. i wrote a simple online logistic regression, calibrated using gradient descent to compare the speed of an ocaml implementation vs the same python script, executed with pypy. it turned out that the ocaml implementation was slightly faster than the one run with pypy (by about 10%). now i would like to optimize my code even further.the assumption about the data is that the values of each rows are sparse (can be considered as factors), they are encoded as integers (collisions are allowed) and stored in a large array.maths.ml(** various mathematical functions*)(** given a list of indices v and a vector of weights *)let dot_product indices weights = let rec aux indices weights acc = match indices with | [] -> acc | h::tail -> aux tail weights (acc +. weights.(h)) in aux indices weights 0.(** evaluates {%latex: $s(x)= rac{1}{1+\\exp(-x)}$ %}*) let sigmoid x = 1. /. (1. +. exp(0. -. x))(** logarithmic loss, p (the first argument) is the predicted value, y (the second argument) is the actual value*)let log_loss p y = match y with 1. -> -. log(p) | _ -> -. log(1. -. p)(** evaluates {%latex: $a^b$ %} where {%latex: $a$ %} is the first argument, {%latex: $b$ %} the second argument*)let rec pow a = function | 0 -> 1 | 1 -> a | n -> let b = pow a (n / 2) in b * b * (if n mod 2 == 0 then 1 else a) read_tools.mlopen strlet csv_separator = ,let err_lists_sizes = incompatible lists size(** streams the lines of a channel.*)let line_stream_of_channel channel = stream.from (fun _ -> try some (input_line channel) with end_of_file -> none)(** streams the lines of a file.*) let read_lines file_path = line_stream_of_channel (open_in file_path)(** reads the first line of a file.*)let read_first_line file_path = stream.next (read_lines file_path)(** splits a line according the separator.*) let split_line line = str.split (str.regexp csv_separator) line(** given two lists, returns a hashtable whose keys are the elements of the first list and the values are the elements of the second list. *)let to_dict list1 list2 = let rec aux list1 list2 my_hash = match list1,list2 with | [],[] -> my_hash | a,[] -> failwith err_lists_sizes | [],a -> failwith err_lists_sizes | h1::t1,h2::t2 -> hashtbl.add my_hash h1 h2; aux t1 t2 my_hash in aux list1 list2 (hashtbl.create 15)(** given a file path to a csv file, reads it as a stream of hashtable whose keys are the header of the file *)let dict_reader file_path = let line_stream = read_lines file_path in let header = split_line (stream.next line_stream) in stream.from (fun _ -> try some (to_dict header (split_line (stream.next line_stream))) with end_of_file -> none)train.ml (** implements the usual framework for streaming learning *)(** predict the target and update the model for every line of the stream, engineered by the feature_engine *)let train dict_stream feature_engine updater predict loss_function refresh_loss target_name = let rec aux updater dict_stream t loss = match (try some(stream.next dict_stream) with _ -> none) with | some dict -> let y = float_of_string (hashtbl.find dict target_name) in hashtbl.remove dict target_name; let indices = feature_engine dict in let p = predict indices in updater indices p y; if ((t mod refresh_loss) == 0) && t > 0 then begin printf.printf [tra] execution time: %fs encountered %n loss : %f (sys.time()) t (loss /. float_of_int(t)); print_endline ; end; aux updater dict_stream (t + 1) (loss +. (loss_function p y)) | none -> () in aux updater dict_stream 0 0. ;;log_reg.mlopen mathsopen read_toolsopen train(* data *)let train_dict_stream = dict_reader train_small.csv (* parameters *) (** number of slots to store the features*)let n = pow 2 20 (** vector of weights for the features *)let weights = array.make n 0. (** print progress every refresh_loss lines *)let refresh_loss = <phone> (** parameter of the model *)let alpha = 0.01(* feature engineering *)let _get_indices dict n = hashtbl.fold (fun k v acc -> ((hashtbl.hash k) lxor (hashtbl.hash v) mod n) :: acc) dict [] let feature_engineer dict = _get_indices dict n (* logistic regression *)let rec _update indices weights step = match indices with | [] -> () | h::tail -> weights.(h) <- (weights.(h) -. step) ; _update tail weights step let predict indices = sigmoid (dot_product indices weights) let update indices p y = _update indices weights ((p -. y) *. alpha) let () = train train_dict_stream feature_engineer update predict log_loss refresh_loss click",
    "present_kp": [
      "csv",
      "stream",
      "ocaml"
    ],
    "absent_kp": [
      "performance",
      "machine learning"
    ]
  },
  {
    "text": "common mistakes with javascript arithmetic. i've ran into several oddities using javascripts floating point arithmetic, but i can never recall them off the top of my head!what are some common mistakes when using javascript to do math?",
    "present_kp": [
      "javascript",
      "math",
      "mistakes"
    ],
    "absent_kp": []
  },
  {
    "text": "speed up my delivery pipeline. i have a solution with many components with different deploy iter:webapi backend (on iis)angularjs frontend (on iis)a process manager (as windows service)a projection engine (as windows service)a command handler (as windows service)i develop all of this things. at the end of the day when something valuable is ready i need to push the updated component to the server (a local server) for testing. this usually means:build the component (remember to switch test/release environment)copy the binopen a remote desktop connectionpaste it on the server (after crossing the right path)replace the old package (for iis) or reinstall the serviceif the test succeds, redo this for a production environment. how can i speed up this process, and go in the direction of one click deployment? can a tool like vagrant be a good company?i know that this question could produce descriptive and opinion based answers but i'm stuck!",
    "present_kp": [],
    "absent_kp": [
      "builds",
      "automation"
    ]
  },
  {
    "text": "hash values that are impossible to reach. i was just curious as to if there are (or could by) any hash values that are impossible to compute due to the implementation of the algorithm. for example, sha-256 produces a value that is 256-bits long. technically, there are $2^{256}$ possible hash values that can be computed. is it possible that a specific sequence of 256-bits cannot be generated using the sha-256 algorithm?this question is not specific to sha-256 itself, but any hashing algorithm that follows a uniform distirbution pattern.",
    "present_kp": [
      "hash"
    ],
    "absent_kp": [
      "cryptography"
    ]
  },
  {
    "text": "converting from ascii to utf-8 format - iconv not working. i have a requirement to convert from ascii text format to utf-8.below is what i am performing through the iconv command:[root@main tmp]# cat file1156[root@main tmp]# file file1file1: ascii text[root@main tmp]# iconv -f ascii -t utf-8 file1 > file2[root@main tmp]# file file2file2: ascii text(still ascii not utf-8)any suggestions on how to convert it from ascii to utf-8?",
    "present_kp": [],
    "absent_kp": [
      "solaris",
      "unicode"
    ]
  },
  {
    "text": "having trouble executing a compiled c program. i am running an ubuntu v10.04 through virtualbox. to test the persistence of files i create in the virtual machine, i wrote a very basic c program. when i shutdown the virtual machine and restart it, i see that the files have been retained.what happens:i can check the directory with ls /root/ and see both program_name.c and the compiled program_namei use this command to compile: gcc program_name.c -o program_namei can run ./a.out and the program will execute properly.opening the c code with nano program_name.c shows the program, as i expect it to be.the problem is...when i try to the program via ./program_name, nothing happens!if i check the exit status (echo $?), it is zero.so what gives...?i am a beginner, clearly, and i am having difficulties understanding why i can't run the compiled c program, even though i can find it. it is most bizarre to me considering i can locate all the files and ./a.out executes it properly.edit: edited for clearer presentation.edit regarding answer...in the off chance that someone else comes to this looking for help, it should be noted that while the file program_name command did expose that the file was blank, the cause hasn't been determined. i successfully ran the executable before i restarted the virtual machine.perhaps i didn't shut down the virtual machine properly? anyways, checking the file was/is certainly helpful!",
    "present_kp": [
      "ubuntu",
      "files",
      "c"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "how to repeat a zle widget an arbitrary number of times when the completion menu is open?. i'm using the zsh shell, and i'm trying to install a few key bindings to use keys similar to the ones i would use in a vim buffer, when a completion menu is open.so, inside the menuselect keymap i've bound the keys j and k to the zle widgets down-line-or-history and up-line-or-history, by adding the following lines inside ~/.zshrc:bindkey -m menuselect 'j' down-line-or-historybindkey -m menuselect 'k' up-line-or-historydown-line-or-history and up-line-or-history are described in man zshzle as follows:down-line-or-history (^n esc-[b) (j) (esc-[b) move down a line in the buffer, or if already at the bottom line, move to the next event in the his tory list.up-line-or-history (^p esc-[a) (k) (esc-[a) move up a line in the buffer, or if already at the top line, move to the previous event in the history list.now, i would like to bind c-d and c-u to the same widgets, but repeating them an arbitrary number of times, for example 5.at first i tried this simple code:some-widget() { zle backward-char -n 5}zle -n some-widgetbindkey '^d' some-widgetit binds c-d to the zle widget backward-char, but repeats it 5 times.then, i tried to rewrite the code, moving the key binding from the default keymap to the menuselect keymap:some-widget() { zle backward-char -n 5}zle -n some-widgetbindkey -m menuselect '^d' some-widgetbut it doesn't work as i expected, because when i hit c-d while a completion menu is open, zle seems to execute the default widget bound to c-d, which is delete-char-or-list:delete-char-or-list (^d) (unbound) (unbound) delete the character under the cursor. if the cursor is at the end of the line, list possible comple tions for the current word.it exits the current completion menu, and lists possible completions for the current word, instead of moving the cursor backward 5 times.if it had worked as i expected, i would probably have ended up using this final code:fast-down-line-or-history() { zle down-line-or-history -n 5}zle -n fast-down-line-or-historybindkey -m menuselect '^d' fast-down-line-or-historyfast-up-line-or-history() { zle up-line-or-history -n 5}zle -n fast-up-line-or-historybindkey -m menuselect '^u' fast-up-line-or-historybut since it doesn't, i need to find how to repeat a zle widget when a completion menu is open.how to modify the previous code, so that down-line-or-history is repeated 5 times when hitting c-d while the completion menu is open?",
    "present_kp": [
      "zsh",
      "zle"
    ],
    "absent_kp": []
  },
  {
    "text": "angular modular file structure. my intention is to separate components on a file basis. for example, i want a specific controller to have it's own file (same goes with services, filters and directives). of course, files will be group together based on the module they will fall into.here's an overview of what i currently have:directoryuser/ user/usermodule.js user/userdirective.js user/userservice.js user/userfilter.js user/usercontroller.jsusermodules.jsusermodule = angular.module('usermodule', []);usermodule.controller('userctrl', ['$scope', 'userservice', userctrl]) .factory('userservice', function() { return new userservice(); }) .filter('userfilter', userfilter) .directive('userdirective', userdirective);usercontroller.jsuserctrl = function($scope, userservice) { // ...};userdirective.jsuserdirective = function() { return { // ... }};userservice.jsuserservice = function() { // ...};userfilter.jsuserfilter = function() { return function() { // ... }};then i'll just push the user module to the app module.app.requires.push('usermodule');my concern lies on the registration of the concepts (such as controllers, services...) to the module. i was wondering if this is the best way to go and if it's correct. also possible issues on the parameters and the external .js file. consider this part: .controller('userctrl', ['$scope', 'userservice', userctrl])the userctrl above refers to a function defined in a separate file. will i be able to pass the $scope and userservice dependency as parameters to the userctrl?userctrl = function($scope, userservice) { // pass parameters (usercontroller.js)what's the correct way of doing this in terms of services, filters and directives?finally, how can i improve the code?",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "angular.js",
      "meteor"
    ]
  },
  {
    "text": "can max-flow with mutually exclusive edges be reduced to standard max-flow problem?. i'm working with a flow network like the following:the source s has four edges, each with capacity 1, out to the nodes a, b, c, and d. all of a, b, c, and d have edges to two other nodes, x and y, also with capacity 1. x and y both have edges with capacity 4 to the sink t. typically this would have many solutions: all of the ways you could split up a, b, c, and d between x and y. in the modified version, i have to pick either x or y. if the flow on (x, t) > 0, the flow on (y, t) must be 0, and vice versa. so there are only two solutions, sending all 4 units of flow through x or through y.i'm wondering if there is a way to reduce this constraint to the standard max-flow so i can just run ford-fulkerson on a modified graph. that, or whether this is fundamentally harder and is an isomorphism of a different problem.in simpler versions like the one i've laid out above you could just reduce the decision to a problem where you have only s, t, and the nodes x and y and must send 1 unit of flow through the network, but i'm struggling with the general case where we have two edges x and y, only one of which is allowed to have nonzero flow through it in the solution.",
    "present_kp": [],
    "absent_kp": [
      "network flow",
      "max flow",
      "ford fulkerson"
    ]
  },
  {
    "text": "doubts on definition of indistinguishable encryption in the textbook. in the classic crypto textbook introduction to modern cryptography by jonathan katz and yehuda lindell, there is a definition for indistinguishable encryption in the presence of an eavesdropper as such that for every probabilistic polynomial time adversary a there is a negligible function negl(n) such that$\\pr[privk_{a,\\pi}=1] \\leq negl(n)$where privk is the indistinguishability experiment and for the purpose of this question we only need to know that the experiment outcome is 1 iff the adversary makes the correct guess.my doubts are as follows. consider a sequence of probabilistic polynomial time adversaries $\\{a_i\\}_{i>=1}$ whose advantage in the indistinguishability experiment is bounded by the following sequence of negligible functions$\\pr[privk_{a,\\pi}=1] \\leq negl_i(n) = rac{1}{(1+1/i)^n}$clearly it is necessary for the above conditions to hold for a indistinguishable encryption. but is it a correct model/condition for real-world applications? for example, in practice we typically choose a sufficiently large n and set up some encryption scheme. however, there is the always some adversary $a_i$ that wins the experiment with probability close to one. so what's wrong?",
    "present_kp": [
      "cryptography"
    ],
    "absent_kp": []
  },
  {
    "text": "why is it not possible to connect to my server using rsa from an ubuntu machine?. i tried to connect to my server usingssh <email> result was:unable to negotiate with xxx.xxx.xxx.xxx port 22: no matching host key type found. their offer: ssh-dssthen i ranssh <email> -gwith the outputuser xxxxhostname xxxxxxx.xxxport 22addressfamily anybatchmode nocanonicalizefallbacklocal yescanonicalizehostname falsechallengeresponseauthentication yescheckhostip yescompression nocontrolmaster falseenablesshkeysign noexitonforwardfailure nofingerprinthash sha256forwardagent noforwardx11 noforwardx11trusted yesgatewayports nogssapiauthentication yesgssapidelegatecredentials nohashknownhosts yeshostbasedauthentication noidentitiesonly nokbdinteractiveauthentication yesnohostauthenticationforlocalhost nopasswordauthentication yespermitlocalcommand noprotocol 2proxyusefdpass nopubkeyauthentication yesrequesttty autorhostsrsaauthentication norsaauthentication yesstreamlocalbindunlink nostricthostkeychecking asktcpkeepalive yestunnel falseuseprivilegedport noverifyhostkeydns falsevisualhostkey noupdatehostkeys falsecanonicalizemaxdots 1compressionlevel 6connectionattempts 1forwardx11timeout 1200numberofpasswordprompts 3serveralivecountmax 3serveraliveinterval 0ciphers <email>,aes128-ctr,aes192-ctr,aes256-ctr,<email>,<email>,aes128-cbc,aes192-cbc,aes256-cbc,3des-cbchostkeyalgorithms <email>,<email>,<email>,<email>,<email>,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsahostbasedkeytypes <email>,<email>,<email>,<email>,<email>,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsakexalgorithms <email>,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1loglevel infomacs <email>,<email>,<email>,<email>,<email>,<email>,<email>,hmac-sha2-256,hmac-sha2-512,hmac-sha1pubkeyacceptedkeytypes <email>,<email>,<email>,<email>,<email>,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsaxauthlocation /usr/bin/xauthidentityfile ~/.ssh/id_rsaidentityfile ~/.ssh/id_dsaidentityfile ~/.ssh/id_ecdsaidentityfile ~/.ssh/id_ed25519canonicaldomainsglobalknownhostsfile /etc/ssh/ssh_known_hosts /etc/ssh/ssh_known_hosts2userknownhostsfile ~/.ssh/known_hosts ~/.ssh/known_hosts2sendenv langsendenv lc_*connecttimeout nonetunneldevice any:anycontrolpersist noescapechar ~ipqos lowdelay throughputrekeylimit 0 0streamlocalbindmask 0177i added my public key (from ~/.ssh/id_rsa.pub) to the ~/.ssh/authorized_keys file on the server (starting with ssh-rsa) which worked quite well at least until the last ubuntu update (even today from a linux mint machine - different key, but also rsa).on the ubuntu i'm using openssh_7.2p2 ubuntu-4ubuntu1, openssl 1.0.2g-fips 1 mar 2016 (i don't know the ssh version from the mint machine; the server runs centos, i think)what am i doing wrong?just for fun i added:# <url> xxxxxxx.xxx hostkeyalgorithms +ssh-dssto the .ssh/config.the connection is successful, but then i have to type my password all the time, since the ~/.ssh/authorized_keys does not have a public dsa key.so why does ssh using rsa does not work from my ubuntu 16.04 lts machine?",
    "present_kp": [
      "ubuntu",
      "ssh",
      "openssh"
    ],
    "absent_kp": []
  },
  {
    "text": "using dd command for folder, but deleted items don't seem deleted. here is the imagei used dd command to create a new floppy.first i tried it with a folder filled with naber.bin, test.bin, blabla.bin and boot.bin.and then i deleted all except boot.bin. ls -a command shows there is no file, except boot.bin. i also deleted them in trash. then i used dd command for this folder and i am seeing, these files still exist.how is that possible?what is it? is it about deleteting files for file systems, is it possible there are still binary files on the disk under this folder (if it is now i understand deleted files recovery programs ^_^ )?",
    "present_kp": [
      "dd"
    ],
    "absent_kp": [
      "osx"
    ]
  },
  {
    "text": "missing favorites on twitter. i had over 8000 favorites at the start of the year. i've been purging them recently and now i've got 5000. however, it's only showing the most recent favorites. the last tweets i noticed were from jan 2014.is this a known issue, anything i can do?",
    "present_kp": [
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "can't access desktop manager after upgrading to kali sana. after upgrading to kali sana i am not able to get the desktop manager. all i get is a white page displaying a problem has occurred and the system can't recover. please logout and try again.though i can access terminal using ctrl+alt+f5 and run apt-get update, apt-get upgrade and apt-get dist-upgrade, but they show nothing new to install or upgrade. who -r shows run-level 2and gdm3 is on in run level 2how can i get my dm back?",
    "present_kp": [],
    "absent_kp": [
      "kali linux"
    ]
  },
  {
    "text": "selinux and chroot system call. tl; dr: this is a question about the final step, in a portable, developer-oriented rooting process, that works across all android machines. it is not based on any exploit - it is something that we are legally and morally allowed to do, as developers, to our own machines. if i get an answer and manage to chroot inside my debian, i will make a concise blog post detailing all the steps of this process for all the fellow developers that want root access to their tablets - and don't want to trust dubious-origin one-click-roots that do god-knows-what to their machines (botnet members?)... the only dependencies will be the machine's kernel sources (which the manufacturer is legally obligated to provide) and the boot partition image (boot.img), which is 99% of the times inside the manufacturer-provided over-the-air updates, or individually downloadable as a standalone flash-able image.so, a week passed where i spent all my free time on my new android tablet.and i have almost completely succeeded - in creating a portable, developer-oriented process, for achieving root in my android 5.0.2 tablet. but there's one thing missing yet - i can't do a chroot (which i need to run my debootstrap-ed debian!)what i did so farfirst, i did a minor patch in my tablet's (manufacturer-provided) kernel sources, and then compiled my own kernel - where i disabled the checks for changing selinux enforcing mode. specifically...in security/selinux/selinuxfs.c:...if (new_value != selinux_enforcing) { /* commented out by ttsiodras. length = task_has_security(current, security__setenforce); if (length) goto out; */ audit_log(current->audit_context, gfp_kernel, audit_mac_status, enforcing=%d old_enforcing=%d auid=%u ses=%u, new_value, selinux_enforcing,i then changed my initrd image's /default.prop to contain: ro.secure=0 and ro.debuggable=1since my manufacturer's initrd.img was missing it, i also compiled su.c from <url> and placed the resulting binary under /sbin, making sure it is set to suid root (chmod 04755 /sbin/su).after that, i packaged the new kernel and the new initrd, as i explained in episode 2 of my previous post - and booted from my own image:adb reboot boot-loader ; fastboot boot myboot.imgso, are you root?yes, it initially appeared to be successful:$ adb shellshell@k01e_2:/ $ iduid=2000(shell) gid=2000(shell) groups=1004(input),1007(log),1011(adb),1015(sdcard_rw),1028(sdcard_r),3001(net_bt_admin),3002(net_bt),3003(inet),3006(net_bw_stats) context=u:r:shell:s0shell@k01e_2:/ $ ls -l /sbin/su /sbin/_su-rwxr-xr-x root root <phone>-03 10:44 su-rwsr-xr-x root root 9420 2015-10-03 01:31 _su(the _su is the binary i compiled, set to suid root, and su is a script i wrote to tell su to add me to all these groups...)shell@k01e_2:/ $ cat /sbin/su#!/system/bin/shexport path=/system/bin:$pathexec /sbin/_su 0,0,1000,1028,2000,2001,1004,1007,1011,1015,\\ 1028,3001,3002,3003,3006and i have now achieved root:shell@k01e_2:/ $ suroot@k01e_2:/ # iduid=0(root) gid=0(root) groups=1000(system),1004(input),1007(log),1011(adb),1015(sdcard_rw),1028(sdcard_r),1028(sdcard_r),2000(shell),2001(cache),3001(net_bt_admin),3002(net_bt),3003(inet),3006(net_bw_stats) context=u:r:shell:s0i am 100% sure i am root - not only because id says so, but because i can also do things that normal processes definitely can't:root@k01e_2:/ # ls -l /dev/block/platform/msm_sdcc.1/by-name/bootlrwxrwxrwx root root 2015-10-03 10:47 boot -> /dev/block/mmcblk0p16root@k01e_2:/ # dd if=/dev/block/mmcblk0p16 of=/dev/null bs=1m16+0 records in16+0 records out16777216 bytes transferred in 0.569 secs (29485441 bytes/sec)lo and behold - i can finally read raw partitions out of my tablet!and selinux is indeed in down, dog mode:root@k01e_2:/ # getenforce permissivebut... there are still things i can't do:root@k01e_2:/ # mkdir /my_mntroot@k01e_2:/ # mount -t ext4 /dev/block/mmcblk1p2 /my_mntmount: operation not permittedthat is, i can't mount my ext4-fs formatted 2nd partition of my external sd card.i also can't chroot to my lovely debootstrap-ed debian:root@k01e_2:/ # chroot /data/debian/ /bin/bash chroot() failoperation not permittedis it because of selinux?i don't know - i am new (very new - one week old) to selinux. i thought that when you put it to sleep (getenforce reporting permissive) it no longer interferes...apparently, i was wrong. down the rabbit hole we go again...could it be because of my process context?remember that id returned... uid=0(root) gid=0(root)... context=u:r:shell:s0 can i change that context? being root and all, can i move away from shell? and if so, move to what?the answer to the first question is runcon:shell@k01e_2:/ $ runcon u:r:debuggerd:s0 /sbin/suroot@k01e_2:/ # iduid=0(root) gid=0(root)... context=u:r:debuggerd:s0good. but what context will allow me to mount and chroot?reading some more about selinux, back in my main machine, i parse the /sepolicy file on the root of the initrd.img:linuxbox$ $ sesearch -a sepolicy | grep chrootallow init_shell init_shell : capability { chown sys_chroot ...allow init init : capability { chown dac_read_search sys_chroot ...allow kernel kernel : capability { chown dac_override sys_chroot ... allow asus-dbug-d asus-dbug-d : capability { chown sys_chroot ......ok, a number of possibilities! especially that kernel one seems promising:shell@k01e_2:/ $ runcon u:r:kernel:s0 /sbin/suroot@k01e_2:/ # iduid=0(root) gid=0(root)... context=u:r:kernel:s0root@k01e_2:/ # chroot /data/debian/ /bin/bash chroot() failoperation not permitteddarn.who the heck is blocking me from chrooting?any advice most welcome...",
    "present_kp": [
      "root",
      "chroot",
      "selinux"
    ],
    "absent_kp": []
  },
  {
    "text": "how do you structure unit tests for multiple objects that exhibit the same behavior?. in a lot of cases i might have an existing class with some behavior:class lion{ public void eat(herbivore herbivore) { ... }}...and i have a unit test...[testmethod]public void lion_can_eat_herbivore(){ var herbivore = buildherbivoreforeating(); var test = buildlionfortest(); test.eat(herbivore); assert.iseaten(herbivore);}now, what happens is i need to create a tiger class with idential behavior to that of the lion:class tiger{ public void eat(herbivore herbivore) { ... }}...and since i want the same behavior, i need to run the same test, i do something like this:interface iherbivoreeater{ void eat(herbivore herbivore);}...and i refactor my test:[testmethod]public void lion_can_eat_herbivore(){ iherbivoreeater_can_eat_herbivore(buildlionfortest);}public void iherbivoreeater_can_eat_herbivore(func<iherbivoreeater> builder){ var herbivore = buildherbivoreforeating(); var test = builder(); test.eat(herbivore); assert.iseaten(herbivore);}...and then i add another test for my new tiger class:[testmethod]public void tiger_can_eat_herbivore(){ iherbivoreeater_can_eat_herbivore(buildtigerfortest);}...and then i refactor my lion and tiger classes (usually by inheritance, but sometimes by composition):class lion : herbivoreeater { }class tiger : herbivoreeater { }abstract class herbivoreeater : iherbivoreeater{ public void eat(herbivore herbivore) { ... }}...and all is well. however, since the functionality is now in the herbivoreeater class, it now feels like there's something wrong with having tests for each of these behaviors on each subclass. yet it's the subclasses that are actually being consumed, and it's only an implementation detail that they happen to share overlapping behaviors (lions and tigers may have totally different end-uses, for instance).it seems redundant to test the same code multiple times, but there are cases where the subclass can and does override the functionality of the base class (yes, it might violate the lsp, but lets face it, iherbivoreeater is just a convenient testing interface - it may not matter to the end-user). so these tests do have some value, i think.what do other people do in this situation? do you just move your test to the base class, or do you test all subclasses for the expected behavior?edit:based on the answer from @pdr i think we should consider this: the iherbivoreeater is just a method signature contract; it does not specify behavior. for instance:[testmethod]public void tiger_eats_herbivore_haunches_first(){ iherbivoreeater_eats_herbivore_haunches_first(buildtigerfortest);}[testmethod]public void cheetah_eats_herbivore_haunches_first(){ iherbivoreeater_eats_herbivore_haunches_first(buildcheetahfortest);}[testmethod]public void lion_eats_herbivore_head_first(){ iherbivoreeater_eats_herbivore_head_first(buildlionfortest);}",
    "present_kp": [],
    "absent_kp": [
      "unit testing"
    ]
  },
  {
    "text": "max-heap implementation with list. i am trying to create max-heap for practice.are there any bugs?are there ways that i can improve the code quality?public class maxheap <e extends comparable<? super e>>{ list<e> list; public maxheap(e[] array){ this(arrays.aslist(array)); } public maxheap(list<e> list){ if(list == null) throw new illegalargumentexception(list cannot be null); this.list = new arraylist<e>(list); buildheap(); } public void buildheap(){ for(int i=lastparent(); i >= 0; i--) maxheapify(i); } private void maxheapify(int parent){ if(isparent(parent)){ //assume left child is bigger for now int biggerchild = 2 * parent + 1; int rightchild = biggerchild+1; if(rightchild < size() && compare(rightchild, biggerchild) > 0) biggerchild = rightchild; if(compare(biggerchild, parent) > 0){ swap(biggerchild, parent); maxheapify(biggerchild); } } } private int compare(int fir, int sec){ return list.get(fir).compareto(list.get(sec)); } public boolean add(e item){ if(item == null) return false; list.add(item); int child = last(); int parent = getparent(child); while(isparent(parent)){ if(compare(parent, child) < 0){ swap(parent, child); child = parent; parent = getparent(parent); } else break; } return true; } private void swap(int left, int right){ collections.swap(list, left, right); } public int size(){ return list.size(); } public e remove(){ if(isempty()) return null; swap(0, last()); e max = list.remove(last()); maxheapify(0); return max; } public boolean isempty(){ return size() == 0; } private int last(){ return size() - 1; } private int getparent(int child){ if(index == 0) return -1; else return (child-1)/2; } private boolean isparent(int index){ return index >= 0 && index <= lastparent(); } private int lastparent(){ return size()/2 - 1; } public string tostring(){ stringbuilder builder = new stringbuilder(); int linecounter = 0; int linemax = 1; for(e item : list){ builder.append(item); builder.append( ); linecounter++; if(linecounter >= linemax){ builder.append( ); linecounter = 0; linemax++; } } return builder.tostring(); }}",
    "present_kp": [
      "heap"
    ],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "how to catch a signal in command line?. i asked this question. sigpipe signal is generated to stop the execution of the command as told in the answer.but how do i capture this signal and gracefully terminate the command? the command exits with an error saying that it is a broken pipe.[error] [errno 32] broken pipeis the error message displayed",
    "present_kp": [],
    "absent_kp": [
      "shell",
      "shell script",
      "signals"
    ]
  },
  {
    "text": "why is data stored on a flash disk irretrievable if the memory chip is cracked?. all data recovery companies, regardless of skill, unanimously say that if the memory chip of a device has just a hair line crack, data recovery is impossible. not unlikely, not expensive, but impossible. one company even stated that even the fbi can't retrieve the data. is this true?why is this? i find it hard to believe if just a tiny section of an extremely common chip has a tiny crack, all of the data is completely gone.i would have thought someone talented person somewhere would be able to patch up the area of the chip and get some of the data back...is it something to do with the charge? i know flash memory uses transistors to store its ones and zeroes in the form of an electrical charge. if the chip is cracked, do the transistors short-out, turning them all to zeroes, something like that? is the data gone rather than irretrievable?",
    "present_kp": [],
    "absent_kp": [
      "storage"
    ]
  },
  {
    "text": "working with a remote developer. my company is going to hire an external developer to write some simple php modules and some minor bugfixing in our software. we have never hired an external developer by the hour before. how can we measure external developer's productivity and coordinate with them?i thought about using a combination of <url> and <url> better ideas?",
    "present_kp": [
      "productivity"
    ],
    "absent_kp": [
      "project management",
      "outsourcing"
    ]
  },
  {
    "text": "validate the order of a list by custom strings. i have a test where i have to validate the order of items in a list based on a pre-defined hierarchy that is being given to me as part of my assignment. here it is below. cat dog horse elephant the items in the list would only ever be those four types, but the size of list is not limited. the list will be passed in as part of the method. there can be multiple of each or none at all. the below two list would be valid:cat catdog elephant this would not.elephant dog horse cat below is what i have so far, and i feel as though there is a much more elegant solution. in particular, i would like to minimize the amount of bools and if statements i am using.public bool validateanimalorder(list<string> listofanimals){ bool catexists = false; bool dogexists = false; bool horseexists = false; bool elephantexists = false; for (int x = 0; x < listofanimals.count; x++) { if (listofanimals[x] == cat) { catexists = true; if(dogexists || horseexists || elephantexists) { return false; } } if (listofanimals[x] == dog) { dogexists = true; if (horseexists || elephantexists) { return false; } } if (listofanimals[x] == horse) { horseexists = true; if (elephantexists) { return false; } } if (listofanimals[x] == elephant) { elephantexists = true; } } return true;}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "algorithm"
    ]
  },
  {
    "text": "linux commands for kids. my youngest daughter (6) is fascinated with the sl and gti commands. she even learned to combine them with ; and when the time comes to teach her about return values i'll show her how sl && gti works but gti && sl does not, as gti returns 1.what other commands might i teach her? she'll learn ls and other useful commands in time as she asks me to explain to her what i'm doing, but i'm looking for other fun commands such as sl and gti. aafire and cowsay are a bit entertaining, but if there are other exciting commands like sl and gti we'd love to know.she says thanks!",
    "present_kp": [],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "how to debug servicemain function of a service?. i have a malware which is checking for keyboard type and locale information.after that, it creates a service with binarypathname as malware's exe address. after creating a service, malware starts it and call startservicectrldispatcher and kinda stucks there. no further code is evaluated after that.i have done all this analysis in ollydbg and immdbg.i want to debug a servicemain function of the service installed by this malware.after googling a lot, i have found this article. i tried performing the 2nd method configure a service to start with the windbg debugger attached but somehow my vm got freeze.so my question (in general), how can i debug servicemain function of any service?",
    "present_kp": [
      "ollydbg",
      "windbg"
    ],
    "absent_kp": [
      "windows",
      "winapi"
    ]
  },
  {
    "text": "c++ mock social networking program. i'm currently working on my final project of my first semester of c++ (and programming in general). what my professor wants us to do is to make a mock social media program that has some basic functions such as:sign upsign infollow userwrite a postview activity (activity from friends)view profile (username, followers, people you follow, posts from you)sign outexiton the prompt it says that he:expects to see knowledge of the material, in particular object oriented design - classes.i assume that means that we should be using classes properly.that brings me to my general question about the code i have, which is whether or not i'm fulfilling that requirement of demonstrating knowledge of using classes (or objects or whatever he's probably expecting).project02.cpp#include <iostream>#include <fstream>#include <string>#include <cstdlib>#include project02.husing namespace std;ofstream fout;ifstream fin;void loginscreen(){ cout << please select from the following options by entering the corresponding number: << endl << endl; cout << 1. sign up << endl; cout << 2. log in << endl; cout << 3. user list << endl; cout << 4. exit << endl << endl; cout << please make your selection (enter 1, 2, 3, or 4): ;}void userinfo::signup(){ int offset; string line; bool istaken; string fname; string lname; string byear; string screenname; cout << enter your first name: ; cin >> fname; setfirstname(fname); cout << enter your last name: ; cin >> lname; setlastname(lname); cout << enter your birth year: ; cin >> byear; setbirthyear(byear); cout << create your screen name (no special characters or spaces): ; do { cin >> screenname; istaken = false; fin.open(registeredusers.txt); while (!fin.eof()) { getline(fin, line); if ((offset = line.find(screenname, 0)) != string::npos) { istaken = true; cout << the username << screenname << is already taken, please choose a different username: ; } } fin.close(); } while (istaken = true && istaken != false); setscreenname(screenname); cout << endl; cout << registered with the following information: << endl; cout << endl; cout << full name: << getfirstname() << << getlastname() << endl; cout << birth year: << getbirthyear() << endl; cout << screen name: << getscreenname() << endl; cout << you may now log in to your newly created account. << endl; cout << endl; string infofilename = screenname + _info.txt; string followerfilename = screenname + _follow.txt; string activityfilename = screenname + _activity.txt; registeruser(fout, screenname); fout.open(infofilename.c_str()); writeuserinfo(fout, fname, lname, byear, screenname); fout.close();}void writeuserinfo(ofstream & fout, string & first, string & last, string & year, string & screen){ fout << first + + last + + year + + screen + ;}void registeruser(ofstream & fout, string screen){ fout.open(registeredusers.txt, ios::app); fout << + screen; fout.close();}void listusers(){ ifstream fin; string screen; cout << the following users are registered: << endl << endl; fin.open(registeredusers.txt); while(!fin.eof()) { fin >> screen; cout << screen << endl; } fin.close();}void userinfo::signin(){ int offset; string line; bool exists; string screenname; cout << please enter your screen name to sign in: ; do { cin >> screenname; exists = true; fin.open(registeredusers.txt); while (!fin.eof()) { getline(fin, line); if ((offset = line.find(screenname, 0)) == string::npos) { exists = false; cout << endl; cout << user << screenname << does not exist! << endl << endl; cout << please enter an existing username to sign in: ; } } fin.close(); } while (exists = false || exists != true); cout << you are now logged in as + screenname << endl;}void userinfo::displayprofile(){}void userinfo::setfirstname(string fname){ _firstname = fname;}string userinfo::getfirstname(){ return _firstname;}void userinfo::setlastname(string lname){ _lastname = lname;}string userinfo::getlastname(){ return _lastname;}void userinfo::setbirthyear(string byear){ _birthyear = byear;}string userinfo::getbirthyear(){ return _birthyear;}void userinfo::setscreenname(string screenname){ _screenname = screenname;}string userinfo::getscreenname(){ return _screenname;}project02.h#ifndef project02_h#define project02_husing namespace std;void loginscreen();void writeuserinfo(ofstream & fout, string & first, string & last, string & year, string & screen);void registeruser(ofstream & fout, string screen);void listusers();class userinfo{ public: string getfirstname(); void setfirstname(string first); string getlastname(); void setlastname(string last); string getbirthyear(); void setbirthyear(string year); string getscreenname(); void setscreenname(string sn); void signup(); void signin(); void displayprofile(); private: string _firstname; string _lastname; string _birthyear; string _screenname;};#endif // project02_hproject02main.cpp#include <iostream>#include <fstream>#include <string>#include <cstdlib>#include project02.husing namespace std;int main(){ char input; userinfo inputinfo; cout << welcome to myface, a social media network where you can post your thoughts and see what your friends are up to. << endl << endl; do { loginscreen(); cin >> input; cout << endl; if (input == '1' && input != '2' && input != '3') { inputinfo.signup(); } else if (input == '2' && input != '3') { inputinfo.signin(); } else if(input == '3') { listusers(); cout << endl; system(pause); cout << endl; loginscreen(); } else if (input != '1' && input != '2' && input != '3' && input != '4') { cout << invalid choice! redirecting to login page... << endl << endl; } else if (input == '4') { cout << thank you for using myface. << endl; } } while (input != '4'); return 0;}as you can see, it doesn't yet include all the functionalities and signin() doesn't actually do anything yet as that's where i left off. anyway, i'm still just a beginner but please let me know if you see any potential problems or if i'm not using classes properly, or if you just have any general comments!i don't actually have a whole lot of time to finish this so if something doesn't need to be fixed then i probably won't want to fix it, especially if it involves heavy restructuring or is otherwise time consuming.",
    "present_kp": [
      "c++",
      "beginner"
    ],
    "absent_kp": []
  },
  {
    "text": "reversing a serial communication with two inputs. i'm making a device that needs me to transfer some sort of initiation code like handshaking to start further communications.there is 2 inputs and 2 outputs the first output is pretty similar to a two's compliment which only works on even numbers and copy the value into the odd numbers. but the second output is more complicated it is a combination of the first input and the second one and if the second input is 0 the second output is equal to the first output, let's see some examples:input 1 output 1 input 2 output 20- <phone> 1- <phone> ------ 8- <phone> 33- <phone> 1- <phone> 5- <phone> ------ 8- <phone> 37- <phone> 2- <phone> 5- <phone> ------ 8- <phone> 37- <phone> 3- <phone> 9- <phone> ------ 8- <phone> 57- <phone> 4- <phone> 9- <phone> ------ 8- <phone> 57- <phone> 5- <phone> 21- <phone> ------ 8- <phone> 53- <phone> 6- <phone> 21- <phone> ------ 8- <phone> 53- <phone> 7- <phone> 17- <phone> ------ 8- <phone> 49- <phone> 8- <phone> 17- <phone> ------ 8- <phone> 73- <phone> 9- <phone> 21- <phone> ------ 8- <phone> 77- <phone> this was the outputs for input 2 equal 8input 1 output 1 input 2 output 225- <phone> 85- <phone> ------ 31- <phone> 248- <phone> 26- <phone> 85- <phone> ------ 31- <phone> 245- <phone> 27- <phone> 73- <phone> ------ 31- <phone> 242- <phone> 28- <phone> 73- <phone> ------ 31- <phone> 239- <phone> 29- <phone> 69- <phone> ------ 31- <phone> 236- <phone> 30- <phone> 69- <phone> ------ 31- <phone> 233- <phone> 31- <phone> 65- <phone> ------ 31- <phone> 230- <phone> 32- <phone> 65- <phone> ------ 31- <phone> 195- <phone> 33- <phone> 69- <phone> ------ 31- <phone> 192- <phone> 34- <phone> 69- <phone> ------ 31- <phone> 61- <phone> 35- <phone> 73- <phone> ------ 31- <phone> 58- <phone> 36- <phone> 73- <phone> ------ 31- <phone> 55- <phone> here also you can find some different inputs and outputs while holding one input constant and the others change:input2=16, input 2=5,input 1=2, link: pastebin.com/k5d5j1d5any help on a way to find the protocol for the outputs or the formula between them would be highly appreciated.thanks in advance.",
    "present_kp": [
      "serial communication",
      "protocol",
      "communication"
    ],
    "absent_kp": [
      "decryption",
      "packet"
    ]
  },
  {
    "text": "saving from arecord on a raspberry pi across a network to a mac. i've currently got a usb mic plugged into a raspberry pi b+ and am using the following code to record data: arecord --buffer-time=<phone> -d plughw:1,0 -f cd -t raw | lame -r - stream.mp3i then serve the resulting stream.mp3 file on the pi using python simplehttp and listen to the recorded data using mplayer on the command line. i'd really like to skip the step of saving audio data on the pi if it can be helped. i've tried various attempts at piping the audio data using ssh and netcat to mplayer on my mac but have not figured how to do this. it's not important to me to encode the audio using lame; i'm simply doing that to save space and bandwidth.",
    "present_kp": [
      "ssh",
      "command line",
      "netcat"
    ],
    "absent_kp": [
      "pipe"
    ]
  },
  {
    "text": "x server frame buffer configuration and segmentation fault. i'm trying to configure a custom linux image. so far i am able to get display output from it, and i'm in the process of trying to make x run lxde to get a proper gui instead of just the terminal interface on my lcd.i have a proper frame buffer at /dev/fb0, and i know it works since i am able to get terminal access on it and manually write to it. when i try to start x or lxde however x segfaults at address 0x00, which from what i understand means it tries to access something that doesn't exist.i'm trying to figure out how to get more information about the segfault, and how to actually tell x which frame buffer it should render out to. how do i go about setting that up? i've been trying to get stuff to work in xorg.conf but i'm unsure on how to configure it correctly.thanks!",
    "present_kp": [
      "linux"
    ],
    "absent_kp": [
      "x11",
      "arm",
      "framebuffer"
    ]
  },
  {
    "text": "append based on line count in awk after pattern match. how can i append lines after a pattern match in awk based on how many lines they are after the pattern match.what i have looks like this:stuffpatterna b ca b ca b cendofsectionmorestuffi would like to add various things to the of end of the lines shown as a b c (without knowing what a b c are specifically i.e., they are arbitrary).desired output:stuffpatterna b c ka b c ka b c tendofsectionmorestuffi think this will require some sort of loop that counts lines after the pattern is recognised. my issue is i don't know how to link the counting of lines to variable after a pattern search. my very rough idea so far (which doesn't work):awk '/pattern/ {i=1do{print $0, ki++} while (i<=2)}",
    "present_kp": [
      "awk"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "google hangouts logged in multiple locations. if i already have a google hangout session active and i log into the same account from a different device at the same time what will happen?",
    "present_kp": [
      "google hangouts"
    ],
    "absent_kp": []
  },
  {
    "text": "dnsmasq makes ping start slowly. i just updated a lot of raspberry pis and other machines to debian stretch and while doing that (and repairing some broken stuff due to the upgrade) i noticed that my ping startup times, so the time till i see the actual first response, is really bad on some machines. i've been running the same configuration on a lot of different machines up to now, so i'm not actually sure if that is new and i just did not notice, or if this is actually related to the upgrade.to put it into shell output, here is what i see:time ping -c1 serverfault.comping serverfault.com (151.101.193.69) 56(84) bytes of data.64 bytes from 151.101.193.69 (151.101.193.69): icmp_seq=1 ttl=56 time=29.0 ms--- serverfault.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 29.085/29.085/29.085/0.000 msreal 0m5.098suser 0m0.010ssys 0m0.000sa second call will be cached, thus shows the expected behaviour:time ping -c1 serverfault.comping serverfault.com (151.101.1.69) 56(84) bytes of data.64 bytes from 151.101.1.69 (151.101.1.69): icmp_seq=1 ttl=56 time=16.8 ms--- serverfault.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 16.819/16.819/16.819/0.000 msreal 0m0.063suser 0m0.000ssys 0m0.020sthe funny thing about this is that it is actually not the upstream servers:19:49:38.040549 ip (tos 0x0, ttl 64, id 37883, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 10.179.1.1.53: [bad udp cksum 0x17ac -> 0xe329!] 54130+ a? serverfault.com. (33)19:49:38.040624 ip (tos 0x0, ttl 64, id 6297, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 208.67.220.220.53: [bad udp cksum 0xb918 -> 0x41bd!] 54130+ a? serverfault.com. (33)19:49:38.040657 ip (tos 0x0, ttl 64, id 25130, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 208.67.222.222.53: [bad udp cksum 0xbb1a -> 0x3fbb!] 54130+ a? serverfault.com. (33)19:49:38.040688 ip (tos 0x0, ttl 64, id 62720, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 83.169.184.33.53: [bad udp cksum 0x17c3 -> 0xe312!] 54130+ a? serverfault.com. (33)19:49:38.040717 ip (tos 0x0, ttl 64, id 40746, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 83.169.184.97.53: [bad udp cksum 0x1803 -> 0xe2d2!] 54130+ a? serverfault.com. (33)19:49:38.040744 ip (tos 0x0, ttl 64, id 41541, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 8.8.4.4.53: [bad udp cksum 0x1804 -> 0xe2d1!] 54130+ a? serverfault.com. (33)19:49:38.040773 ip (tos 0x0, ttl 64, id 58321, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.37868 > 8.8.8.8.53: [bad udp cksum 0x1c08 -> 0xdecd!] 54130+ a? serverfault.com. (33)19:49:38.041061 ip (tos 0x0, ttl 64, id 37884, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.35828 > 10.179.1.1.53: [bad udp cksum 0x17ac -> 0xe101!] 49810+ aaaa? serverfault.com. (33)19:49:38.041120 ip (tos 0x0, ttl 64, id 25131, offset 0, flags [df], proto udp (17), length 61) 10.179.1.11.35828 > 208.67.222.222.53: [bad udp cksum 0xbb1a -> 0x3d93!] 49810+ aaaa? serverfault.com. (33)19:49:38.049748 ip (tos 0x0, ttl 59, id 0, offset 0, flags [df], proto udp (17), length 125) 10.179.1.1.53 > 10.179.1.11.37868: [udp sum ok] 54130 q: a? serverfault.com. 4/0/0 serverfault.com. [4m46s] a 151.101.129.69, serverfault.com. [4m46s] a 151.101.65.69, serverfault.com. [4m46s] a 151.101.1.69, serverfault.com. [4m46s] a 151.101.193.69 (97)19:49:38.054841 ip (tos 0x0, ttl 57, id 43395, offset 0, flags [df], proto udp (17), length 125) 208.67.222.222.53 > 10.179.1.11.37868: [udp sum ok] 54130 q: a? serverfault.com. 4/0/0 serverfault.com. [3m7s] a 151.101.129.69, serverfault.com. [3m7s] a 151.101.193.69, serverfault.com. [3m7s] a 151.101.1.69, serverfault.com. [3m7s] a 151.101.65.69 (97)19:49:38.074955 ip (tos 0x0, ttl 57, id 53865, offset 0, flags [df], proto udp (17), length 125) 208.67.220.220.53 > 10.179.1.11.37868: [udp sum ok] 54130 q: a? serverfault.com. 4/0/0 serverfault.com. [5m] a 151.101.1.69, serverfault.com. [5m] a 151.101.65.69, serverfault.com. [5m] a 151.101.129.69, serverfault.com. [5m] a 151.101.193.69 (97)so, as you can see i get a response pretty quickly.even when i look only at the local loopback the answer when issuing a ping command is more or less instantly:19:50:48.577615 ip (tos 0x0, ttl 64, id 29962, offset 0, flags [df], proto udp (17), length 61) 127.0.0.1.45851 > 127.0.0.1.53: [bad udp cksum 0xfe3c -> 0x12d5!] 40455+ a? serverfault.com. (33)19:50:48.578344 ip (tos 0x0, ttl 64, id 29963, offset 0, flags [df], proto udp (17), length 61) 127.0.0.1.45851 > 127.0.0.1.53: [bad udp cksum 0xfe3c -> 0xab1d!] 60094+ aaaa? serverfault.com. (33)19:50:48.591133 ip (tos 0x0, ttl 64, id 29964, offset 0, flags [df], proto udp (17), length 125) 127.0.0.1.53 > 127.0.0.1.45851: [bad udp cksum 0xfe7c -> 0x3aea!] 40455 q: a? serverfault.com. 4/0/0 serverfault.com. [3m36s] a 151.101.129.69, serverfault.com. [3m36s] a 151.101.65.69, serverfault.com. [3m36s] a 151.101.1.69, serverfault.com. [3m36s] a 151.101.193.69 (97)but then ping blocks and apparently retries (i see that from the tcpdumps) and then only accepts the answer?when i dig i only see sub 100ms answers. that somehow feels as if ping (or something in the libraries) does not accept this first answer that comes from dnsmasq and needs the cached answer somehow. i can measure this with other tools too (curl, etc). that somehow defeats the purpose of having dnsmasq in the first place. i played around with basically all my dns related options in the config, but to no ends (dnssec, cache sizes, etc). i always have this five seconds delay on the first use. any other ideas where to look? am i interpreting something wrong? i'm pretty much out of ideas now. updatesome more things i tried and observations: when i disable the cache in dnsmasq completely, i still have the delays, just everytime i start the ping now.ping -4 does not show the delays, though ipv6 is disabled via sysctl.addingoptions single-requestto /etc/resolv.conf makes it go away. so apparently an issue with the parallel requests. i will go and ask the mailing list.",
    "present_kp": [
      "ping",
      "dnsmasq"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "different title formats for different terminal apps?. i use a script which either activates an already running window of a program, or starts that program if it is not running. it uses different shortcut-keys; one for each of my most used apps it checks for a unique window title format. this has worked fine, until today, when i decided to use terminator along side of gnome-terminal. these two terminal apps display the same title format, and i don't know how to change them independently (actually i don't know how to change them at all). i also use konsole (because it displays unicode better than gnome-terminal), and it has a profile-option which allows changes to the tab-title format which is mirrored in the window's title, but terminator and gnome-terminal don't have this option. is there some way to have different title formats for different terminals?",
    "present_kp": [
      "terminal",
      "window title"
    ],
    "absent_kp": [
      "terminal emulator"
    ]
  },
  {
    "text": "linux audio feedback. i am using jackd and pulseaudio with the pulseaudio-jack-module so that i can have pulseaudio and jack running at the same time. i mostly use jack applications, except for web browsing and a few other applications.i am trying to record audio but i get really bad feedback if i try to record audio. if i plug in my headphones the feedback mostly goes away but if i touch the laptop i can hear it in my recording.it sounds like linux is still recording through my built in mic. i am wondering if i can fix this or will i need to buy a usb mic or something like that? i am using kxstudio's audiohere's some debugging outputaplay -lnull discard all samples (playback) or generate zero samples (capture)pulse pulseaudio sound serverdefault playback/recording through the pulseaudio sound serversysdefault:card=loopback loopback, loopback pcm default audio devicefront:card=loopback,dev=0 loopback, loopback pcm front speakerssurround21:card=loopback,dev=0 loopback, loopback pcm 2.1 surround output to front and subwoofer speakerssurround40:card=loopback,dev=0 loopback, loopback pcm 4.0 surround output to front and rear speakerssurround41:card=loopback,dev=0 loopback, loopback pcm 4.1 surround output to front, rear and subwoofer speakerssurround50:card=loopback,dev=0 loopback, loopback pcm 5.0 surround output to front, center and rear speakerssurround51:card=loopback,dev=0 loopback, loopback pcm 5.1 surround output to front, center, rear and subwoofer speakerssurround71:card=loopback,dev=0 loopback, loopback pcm 7.1 surround output to front, center, side, rear and woofer speakersdmix:card=loopback,dev=0 loopback, loopback pcm direct sample mixing devicedmix:card=loopback,dev=1 loopback, loopback pcm direct sample mixing devicedsnoop:card=loopback,dev=0 loopback, loopback pcm direct sample snooping devicedsnoop:card=loopback,dev=1 loopback, loopback pcm direct sample snooping devicehw:card=loopback,dev=0 loopback, loopback pcm direct hardware device without any conversionshw:card=loopback,dev=1 loopback, loopback pcm direct hardware device without any conversionsplughw:card=loopback,dev=0 loopback, loopback pcm hardware device with all software conversionsplughw:card=loopback,dev=1 loopback, loopback pcm hardware device with all software conversionssysdefault:card=pch hda intel pch, cs4208 analog default audio devicefront:card=pch,dev=0 hda intel pch, cs4208 analog front speakerssurround21:card=pch,dev=0 hda intel pch, cs4208 analog 2.1 surround output to front and subwoofer speakerssurround40:card=pch,dev=0 hda intel pch, cs4208 analog 4.0 surround output to front and rear speakerssurround41:card=pch,dev=0 hda intel pch, cs4208 analog 4.1 surround output to front, rear and subwoofer speakerssurround50:card=pch,dev=0 hda intel pch, cs4208 analog 5.0 surround output to front, center and rear speakerssurround51:card=pch,dev=0 hda intel pch, cs4208 analog 5.1 surround output to front, center, rear and subwoofer speakerssurround71:card=pch,dev=0 hda intel pch, cs4208 analog 7.1 surround output to front, center, side, rear and woofer speakersiec958:card=pch,dev=0 hda intel pch, cs4208 digital iec958 (s/pdif) digital audio outputdmix:card=pch,dev=0 hda intel pch, cs4208 analog direct sample mixing devicedmix:card=pch,dev=1 hda intel pch, cs4208 digital direct sample mixing devicedsnoop:card=pch,dev=0 hda intel pch, cs4208 analog direct sample snooping devicedsnoop:card=pch,dev=1 hda intel pch, cs4208 digital direct sample snooping devicehw:card=pch,dev=0 hda intel pch, cs4208 analog direct hardware device without any conversionshw:card=pch,dev=1 hda intel pch, cs4208 digital direct hardware device without any conversionsplughw:card=pch,dev=0 hda intel pch, cs4208 analog hardware device with all software conversionsplughw:card=pch,dev=1 hda intel pch, cs4208 digital hardware device with all software conversionshdmi:card=nvidia,dev=0 hda nvidia, hdmi 0 hdmi audio outputhdmi:card=nvidia,dev=1 hda nvidia, hdmi 1 hdmi audio outputhdmi:card=nvidia,dev=2 hda nvidia, hdmi 2 hdmi audio outputdmix:card=nvidia,dev=3 hda nvidia, hdmi 0 direct sample mixing devicedmix:card=nvidia,dev=7 hda nvidia, hdmi 1 direct sample mixing devicedmix:card=nvidia,dev=8 hda nvidia, hdmi 2 direct sample mixing devicedsnoop:card=nvidia,dev=3 hda nvidia, hdmi 0 direct sample snooping devicedsnoop:card=nvidia,dev=7 hda nvidia, hdmi 1 direct sample snooping devicedsnoop:card=nvidia,dev=8 hda nvidia, hdmi 2 direct sample snooping devicehw:card=nvidia,dev=3 hda nvidia, hdmi 0 direct hardware device without any conversionshw:card=nvidia,dev=7 hda nvidia, hdmi 1 direct hardware device without any conversionshw:card=nvidia,dev=8 hda nvidia, hdmi 2 direct hardware device without any conversionsplughw:card=nvidia,dev=3 hda nvidia, hdmi 0 hardware device with all software conversionsplughw:card=nvidia,dev=7 hda nvidia, hdmi 1 hardware device with all software conversionsplughw:card=nvidia,dev=8 hda nvidia, hdmi 2 hardware device with all software conversionsaplay -l**** list of playback hardware devices ****card 0: loopback [loopback], device 0: loopback pcm [loopback pcm] subdevices: 8/8 subdevice #0: subdevice #0 subdevice #1: subdevice #1 subdevice #2: subdevice #2 subdevice #3: subdevice #3 subdevice #4: subdevice #4 subdevice #5: subdevice #5 subdevice #6: subdevice #6 subdevice #7: subdevice #7card 0: loopback [loopback], device 1: loopback pcm [loopback pcm] subdevices: 8/8 subdevice #0: subdevice #0 subdevice #1: subdevice #1 subdevice #2: subdevice #2 subdevice #3: subdevice #3 subdevice #4: subdevice #4 subdevice #5: subdevice #5 subdevice #6: subdevice #6 subdevice #7: subdevice #7card 1: pch [hda intel pch], device 0: cs4208 analog [cs4208 analog] subdevices: 0/1 subdevice #0: subdevice #0card 1: pch [hda intel pch], device 1: cs4208 digital [cs4208 digital] subdevices: 1/1 subdevice #0: subdevice #0card 2: nvidia [hda nvidia], device 3: hdmi 0 [hdmi 0] subdevices: 1/1 subdevice #0: subdevice #0card 2: nvidia [hda nvidia], device 7: hdmi 1 [hdmi 1] subdevices: 1/1 subdevice #0: subdevice #0card 2: nvidia [hda nvidia], device 8: hdmi 2 [hdmi 2] subdevices: 1/1 subdevice #0: subdevice #0i would just like to be able to record some short clips, not for music or anything, more like a voice over.i have qas mixer and it in the above screenshot i have headphones plugged in so that i don't blow out my ears.i made this sample clip, it's very short but you can literally hear my keystrokes and me moving my hands or try to type. you can listen to the 10 second clip hereso does this mean that i need a usb mic or is there something wrong with my audio setup? how could i fix this?",
    "present_kp": [
      "audio",
      "jack"
    ],
    "absent_kp": []
  },
  {
    "text": "feasibility of linear inequalities with binary variables. i have a system of linear inequalities of the form $a^t x \\leq b$, where each of the $x_i$'s is a binary variable in $\\{0, 1\\}$. are there any known fast and practical algorithms that can find a feasible solution or prove that the system has no solutions? i need this to generate an initial solution to the heterogenuous fleet vrp where the number of unknowns is ~ 10s of millions in each instance.",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "reference request",
      "decision problem",
      "integer programming"
    ]
  },
  {
    "text": "mv deleted my directory. why?. i was trying to correct the spelling on a directory, issued a mv command, and the directory is now gone. i'd like to understand--specifically--what happened.here's the command i ran:mv micheal_franti_theme/ michael_franti_theme/i understand there the slashes shouldn't be included: i was moving fast and used auto-complete.the command ran without any errors or warnings. i tried using find for both the old and new spellings, but neither returned any results. so, what happened? what did mv actually do? any chance of recovering the directory and its contents?ext4 on centos 6.5; mv version 8.4additional infonot sure why this is getting down votes.there was a directory named micheal_franti_theme. i ran the above command, then ran ls. no more directory.no directory named michael_franti_theme existed anywhere on the file system when i ran that command.as you can see from the command, the context is within the same sub-directory, so mv would have just updated the inode table (vs copying between file systems).i ran the following:sudo find / -name micheal_franti_themeno results. the directory is goneall commands posted in this question were copied directly from the command prompt.i've been using linux regularly for over a decade. i've never seen this happen before, so i'm bringing it to serverfault.actual results are long gone from the scrollback buffer, but here are the relevant lines from history:1097 ls1098 mv micheal_franti_theme/ michael_franti_theme/1099 ls1100 find / -name michael_franti_theme 2>/dev/null1101 find / -name micheal_franti_theme 2>/dev/null1102 sudo find / -name michael_franti_theme1103 sudo find / -name micheal_franti_theme",
    "present_kp": [
      "linux",
      "centos"
    ],
    "absent_kp": [
      "filesystems"
    ]
  },
  {
    "text": "what is the incoming stream in google+?. i noticed that google+ lists incoming under the streams on the left-hand side of the page. what exactly is incoming and how is it different than the standard home view?",
    "present_kp": [],
    "absent_kp": [
      "social networks",
      "google plus"
    ]
  },
  {
    "text": "how to track in google analytics registrations coming from google adwords ads?. i created a campaign in google adwords and some ads in it and gave them urls likemydomain.tld/registration/?utm_campaign=mycampaing&ad=xmydomain.tld/registration/?utm_campaign=mycampaing&ad=ymydomain.tld/registration/?utm_campaign=mycampaing&ad=zall ads lead to the registration page.a registration is a visit of the pagemydomain.tld/registration-completed/?user={id}so i can track the registrations in google analytics. i just go to behavior -> site content -> all pages and filter the pages to registration-completed.but how can i see, how many and which users have registered, after they came from an ad of a campaign, e.g. utm_campaign? and how can i also track this for a single ad of the campaign, e.g. x?",
    "present_kp": [
      "google analytics",
      "google adwords"
    ],
    "absent_kp": [
      "tracking",
      "click tracking"
    ]
  },
  {
    "text": "determining usage/context of terms/acronyms/abbreviations in python. background: i work for a major airline in the united states and have been given a pretty significant text mining and machine learning task. since there are several unique terms, acronyms, and abbreviations in aviation, i have written a program that reads through the documents. the program is using 4 groups of terms; words, stops, airports, and synonyms. words, stops, and airports are all sets where the first two were initialized from nltk and the last was initialized with a manually built list of airports that my employer services. synonyms is a nested dictionary 'trie' style structure where the branches are misspellings and the leaves are the terms that they represent. it was initialized as an empty dictionary. i have also created a command prompt ui that informs me when it finds a word that it doesn't know and allows me to correct the word or add it to one of the aforementioned groups. the documents are being tokenized by spacy and fed into scikit-learn machine learning algorithms.problem: i've started noticing that some of the words that i previously accepted in words or synonyms are showing up with alternate meanings and could have a drastic impact on how well the algorithm operates. for example the word act can be the verb act; or it can be an abbreviation for actuator or active; or it can be an acronym for auxiliary central tank or a couple other things. at present, i'm using the ui to manually correct or ignore these occurrences, which is time consuming, cumbersome, and prone to errors.desired result: what i'm looking for is a method of determining whether 'lt' means left or light depending on context (lt wing vs. warning lt) with minimal manual entry. at a minimum i would like some high level ideas/discussion on how this may be accomplished in python. optimally, i would like some example code, preferably using the same tools i already have; spacy, nltk, and sklearn but i am flexible and willing to learn.notes: i've considered a couple methods of doing this but i haven't been able to come up with any ideas strong enough to try. for example, i've considered marking the terms with the pos inside the sets by concatenating it with the word before adding it like 'rat:noun'. the issue with this is that rat:noun could be an animal or it could be an abbreviation for ram air turbine, which is also a noun.",
    "present_kp": [
      "python",
      "text mining"
    ],
    "absent_kp": [
      "nlp",
      "data cleaning"
    ]
  },
  {
    "text": "what is the difference (if any) between rem statements and comments?. i have recently come across the term rem statement and wondered, is it synonymous with comment?",
    "present_kp": [
      "comments"
    ],
    "absent_kp": []
  },
  {
    "text": "adding multiple datasets to single table. i have a table1 in db1 which is similar to the following+----+------+----------+--------+----------+----------+-------------+---------+--------+----------+----------+---------+---------+--------+----------+----------+---------------+---------+--------+----------+----------+--------+| id | name | location | rname1 | rscore11 | rscore21 | rdesc1 | enable2 | rname2 | rscore12 | rscore22 | rdesc2 | enable3 | rname3 | rscore13 | rscore23 | rdesc3 | enable4 | rname4 | rscore14 | rscore24 | rdesc4 |+----+------+----------+--------+----------+----------+-------------+---------+--------+----------+----------+---------+---------+--------+----------+----------+---------------+---------+--------+----------+----------+--------+| 1 | john | loca | dale | 5 | 4 | description | y | bob | 2 | 3 | another | y | bill | 5 | 2 | text data | y | jeff | 4 | 2 | || 2 | paul | locb | john | 4 | 2 | description | y | vinc | 4 | 5 | | y | phil | 3 | 4 | detailed data | n | | | | || 3 | vinc | loca | chou | 4 | 3 | description | y | dilan | 1 | 5 | review | n | | | | | | | | | |+----+------+----------+--------+----------+----------+-------------+---------+--------+----------+----------+---------+---------+--------+----------+----------+---------------+---------+--------+----------+----------+--------+those data is the supervisor evaluations of employees. one employee can review more than 1 supervisor with the same evaluation formif an employee is not using a secondary evaluation slot, subsequent evaluation slots will not be available to him. (one evaluation slot includes the criteria of a single supervisor)evaluation 1 is mandatory as a person who is attempting the evaluations shall evaluate at least 1 supervisorthe data is gathered and stored by a separate script. for our own review purposes, i am processing data to obtain the following results in table2 of db2;+----+--------+------+----------+-------+---------+---------+---------------+| id | app_id | name | location | rname | rscore1 | rscore2 | rdesc |+----+--------+------+----------+-------+---------+---------+---------------+| 1 | 1 | john | loca | dale | 5 | 4 | description || 2 | 1 | john | loca | bob | 2 | 3 | another || 3 | 1 | john | loca | bill | 5 | 2 | text data || 4 | 1 | john | loca | jeff | 4 | 2 | || 5 | 2 | paul | locb | john | 4 | 2 | description || 6 | 2 | paul | locb | vinc | 4 | 5 | || 7 | 2 | paul | locb | phil | 3 | 4 | detailed data || 8 | 3 | vinc | loca | chou | 4 | 3 | description || 9 | 3 | vinc | loca | dilan | 1 | 5 | review || 10 | 3 | vinc | loca | chou | 4 | 3 | description |+----+--------+------+----------+-------+---------+---------+---------------+i am currently using the following mysql query to extract data from table1 and to insert the same in table2$geteval = mysqli_query($db1,select * from table1 where location<>'');while ($y = mysqli_fetch_array($geteval)) {$addeval = mysqli_query($db2,insert into 'table2' ('app_id', 'name', 'location', 'rname', 'rscore1', 'rscore2', 'rdesc')values ('{$y[id]}', '{$y[name]}', '{$y[location]}', '{$y[rname1]}', '{$y[rscore11]}', '{$y[rscore21]}', '{$y[rdesc1]}'));if ($y[enable2] == y) {$addeval = mysqli_query($db2,insert into 'table2' ('app_id', 'name', 'location', 'rname', 'rscore1', 'rscore2', 'rdesc')values ('{$y[id]}', '{$y[name]}', '{$y[location]}', '{$y[rname2]}', '{$y[rscore12]}', '{$y[rscore22]}', '{$y[rdesc2]}'));}if ($y[enable3] == y) {$addeval = mysqli_query($db2,insert into 'table2' ('app_id', 'name', 'location', 'rname', 'rscore1', 'rscore2', 'rdesc')values ('{$y[id]}', '{$y[name]}', '{$y[location]}', '{$y[rname3]}', '{$y[rscore13]}', '{$y[rscore23]}', '{$y[rdesc3]}'));}}this continues for all evaluation slots. the above code executes fine and update the databases without errors. but i have a concern that i maybe wasting server resources with the said code. is there anyway i could improve the efficiency of the insertion process?",
    "present_kp": [
      "mysql"
    ],
    "absent_kp": [
      "performance",
      "php",
      "security"
    ]
  },
  {
    "text": "would ollydbg help recognizing the passed parameters between the caller and the calle?. the calling convention used in assembly differs depending to the compiler, so i need to know how ollydbg2.01 would help me to recognize the parameters passed from caller to the callee and the values returned back from the callee to the caller for a call instruction.the assembly which i am working on is compiled by microsoft visual c++.",
    "present_kp": [
      "ollydbg"
    ],
    "absent_kp": []
  },
  {
    "text": "how often does google re-calculate the page rank of webpage?. am updating my website backlinks and content from last 2 month but page rank is not changing,how often does google re-calculate the page rank?",
    "present_kp": [],
    "absent_kp": [
      "seo",
      "pagerank"
    ]
  },
  {
    "text": "questions about reversing object oriented code(initializing vtables in ctors). i was reversing some c++ code and encountered following function.sub_106c0a0 proc nearvar_10= dword ptr -10hvar_c= dword ptr -0chvar_4= dword ptr -4push 0ffffffffhpush offset seh_106c0a0mov eax, large fs:0push eaxmov large fs:0, esppush ecxpush esimov esi, ecxpush edilea edi, [esi+4]push 30hmov ecx, edimov [esp+1ch+var_10], esimov dword ptr [esi], offset off_12c0680call struc_13_ctormov dword ptr [edi], offset off_12c057c ; another vtable init ?this function passes this pointer of some object (struc_13), which is esi+4, to the struc_13_ctor. inside the struc_13_ctor function, it initializes the vtable pointer and other member variables. ; int __thiscall struc_13_ctor(struc_13 *this, __int16 a2)struc_13_ctor proc neararg_0= word ptr 4mov dx, [esp+arg_0]mov eax, ecxxor ecx, ecxmov dword ptr [eax], offset struc_13_vtablemov [eax+4], ecxmov [eax+8], ecxmov [eax+0ch], dxmov [eax+0eh], cxmov [eax+14h], ecxmov [eax+10h], ecxretn 4struc_13_ctor endphowever after returning from struc_13_ctor, it overwrites the vtable pointer with the new value, which is off_12c057c in this case. call struc_13_ctormov dword ptr [edi], offset off_12c057c ; another vtable init ?i have seen this kind of behaviors a lot while looking at ctor functions, but never understood why this happens.",
    "present_kp": [
      "c++"
    ],
    "absent_kp": []
  },
  {
    "text": "entity-relationship model diagrams in visio. i would love to create some database diagrams like this one with visio but i can't find any templates at all for that kind of notation. the example i linked to was apparently made in photoshop, which sounds like a terrible way to make erds. are there any good visio templates for this sort of thing?(i have visio 2010 pro, by the way.)",
    "present_kp": [
      "visio"
    ],
    "absent_kp": [
      "database design"
    ]
  },
  {
    "text": "automatic background processes. i'm running my raspberry pi off an ssh server, and want to be able to access it out of home. sure, all i need is an ip. but with my terrible internet, it's constantly dropping out. my ip is constantly changing.to counteract this, i setup a script to test if my ip is the same as it was 30 minutes ago, every 30 minutes. i also have a script set to kill this, so it doesn't go on forever or until reboot.how can i make my process run itself in the background, without user interaction via. regex like nohup? can nohup be self-automated? i want this functionality so i don't need an extra computer open while away. (again, i'm accessing my pi from ssh)",
    "present_kp": [
      "ssh",
      "raspberry pi",
      "background process",
      "nohup"
    ],
    "absent_kp": [
      "shell"
    ]
  },
  {
    "text": "transferring imgur images to outlook.com. how do i transfer an image from my imgur account to my outlook.com account?i want to use it as a signature. i copied the url and pasted it into my email but it didn't work.",
    "present_kp": [
      "outlook.com",
      "imgur"
    ],
    "absent_kp": []
  },
  {
    "text": "why do people say they hate drama?. on social sites sometimes people will state, i hate drama!, as if to say if you cause drama, please go away.my theory is the people who say this, in fact, actually like drama... as evidenced by the apparent hatred for it. has there been any research into this?people could also say, i hate being kicked in the rear!, which i'm sure most people would hate, and if it happened commonly enough, people may start posting such on their profiles. this line of thinking leads me to believe that the statement of hatred for drama is the admission that drama is a commonly occurring problem.also, it seems to be as reasonable to state this on a profile as it is to hang a sign on a door reading, i hate thieves! or a sign on a backside saying, i hate muggers! since people don't commonly hang these types of signs, why do they hang the drama sign on their profiles?",
    "present_kp": [],
    "absent_kp": [
      "social psychology"
    ]
  },
  {
    "text": "how do you reverse engineer an exe compiled with pyinstaller. having recently watched/read a presentation given by dave kennedy at def con 20 [pdf], i'd like to know how to decompile a python script compiled with pyinstaller.in his presentation, he is creating a basic reverse shell script in python, and converts it to an exe with pyinstaller.my question is how do you take a pyinstaller created exe and either completely, or generally, retrieve the logic/source code from the original python script(s)?",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "pe"
    ]
  },
  {
    "text": "what's the next level of abstraction?. since programming languages initially only used lines of code executed sequentially, and it evolved into including functions which were one of the first levels of abstraction, and then classes and objects were created to abstract it even further; what is the next level of abstraction?what's even more abstract than classes or is there any yet?",
    "present_kp": [
      "programming languages",
      "abstraction"
    ],
    "absent_kp": [
      "object oriented",
      "language agnostic"
    ]
  },
  {
    "text": "scope_exit macro. this is actually not something new, but i think many people wanted something useful and not incredibly complicated. so, here it is:#pragma once#include <utility>#define concat_impl(x, y) x##y#define concat(x, y) concat_impl(x, y)#ifdef __counter__#define anonymous_variable(name) concat(name, __counter__)#else#define anonymous_variable(name) concat(name, __line__)#endifnamespace detail{ template <typename func> class scopeguardonexit { func f; public: scopeguardonexit(func&& f) : f(std::forward<func>(f)) {} ~scopeguardonexit() { f(); } }; struct dummy {}; template <typename func> scopeguardonexit<func> operator+(dummy, func&& f) { return std::forward<func>(f); }}#define scope_exit \\ auto anonymous_variable(scope_exit_whatever) = ::detail::dummy() + [&]()usage:#include scope_exit.hpp#include <iostream>int f(){ scope_exit {std::cout << exiting f() ;}; return 0;}int main(){ f(); scope_exit {std::cout << it's working! ;};}do note that the lambda takes (pulls into abyss) everything by reference. on top of that, it is possible to register multiple function to execute at exit. is it possible to make it more user friendly? the best would be to try to write it using templates.by being more user friendly i mean eliminating that scope_exit_whatevern variable from the variable list for the current scope, because people will get surprised when they will see it in an ide. also, forgetting semicolon ; will lead to pretty confusing error messages.",
    "present_kp": [
      "scope"
    ],
    "absent_kp": [
      "c++",
      "c++14",
      "macros"
    ]
  },
  {
    "text": "do operation on lines in a stream and retain context. imagine the following problem: i have a standard apache log. i want to filter out request urls with a certain keyword. simple, we use,$ grep keyword somedomain-access.logthis works well, but isn't robust, i.e., it doesn't work as required in 100% of the cases. imagine our keyword being get, (depending on the website) almost all lines would be matched by the grep command.we do some preprocessing by doing:$ cut -d -f['i'th field containing the url] somedomain-access.log | grep keywordthis works a bit better, but now i lose all context information, i.e., the other fields which i threw away with the cut command.now this issue in general is biting me more and more. of course you can use awk in this specific case, but often in the general case an awk command doesn't suffice.in non-shell languages you'd simply check for a object's member and do your operation. so using our apache log example again, take this in scala,> // preprocessed list of apache log into 'records'> val records = list(accesslogrecord(...), accesslogrecord(...), ...)> val recordswithkeyword = records.filter(_ => _.request == keyword)the result is still a list where every item, in this case accesslogrecord, still has all context information like date, http code, etc.how can we achieve the same on the command line using pipes, redirection, etc; without relying on specific applications like awk?",
    "present_kp": [
      "command line",
      "pipe"
    ],
    "absent_kp": [
      "stdout"
    ]
  },
  {
    "text": "php password encryption algorithm. i've written a password encryption algorithm in php, which (i think) is not very vulnerable to rainbowtable attacks. it's just that i don't have a lot of experience with encryptions, nor php. but from the knowledge i have i think this is a hashing algorithm which automatically adds salt, but i actually have no idea if this is true or not, so please tell me.this is the code i use to create a password hash:<?php $pass = $argv[1]; $pass_len = strlen($pass) - 1; $pass_chars = str_split($pass, 1); // convert password characters to their ascii values foreach ($pass_chars as $key => $val) { $pass_chars[$key] = ord($val); } // generate an array of random characters the size of $pass_chars for ($i = 0; $i < $pass_len + 1; $i++) { $rand_chars[$i] = mt_rand(33, 126); } // create list of added $pass_vals values foreach ($pass_chars as $key => $val) { $pass_vals[$key] = $val + $pass_chars[$key + 1]; } $pass_vals[$pass_len] = $pass_chars[$pass_len] + $pass_chars[0]; // create list of added $rand_vals values foreach ($rand_chars as $key => $val) { $rand_vals[$key] = $val + $rand_chars[$key + 1]; } $rand_vals[$pass_len] = $rand_chars[$pass_len] + $rand_chars[0]; // add $rand_vals to $pass_chars foreach ($pass_chars as $key => $val) { $pass_chars[$key] += $rand_vals[$key]; } // add $pass_vals to $rand_chars foreach ($rand_chars as $key => $val) { $rand_chars[$key] += $pass_vals[$key]; } // create combined array $i = 1; foreach ($pass_chars as $key => $val) { $combined[$key * 2] = str_pad($pass_chars[$key], 3, 0, str_pad_left); $combined[$i] = str_pad($rand_chars[$key], 3, 0, str_pad_left); $i += 2; } // print $combined as string echo implode($combined) . ;?>and this code to reverse it:<?php $pass_i = $argv[1]; $hash = $argv[2]; $pass_len_i = strlen($pass_i) - 1; $pass_chars_i = str_split($pass_i, 1); $hash_chars = str_split($hash, 3); $hash_len = sizeof($hash_chars); // convert input password characters to their ascii values foreach ($pass_chars_i as $key => $val) { $pass_chars_i[$key] = ord($val); } // create list of added $pass_vals_i values foreach ($pass_chars_i as $key => $val) { $pass_vals_i[$key] = $val + $pass_chars_i[$key + 1]; } $pass_vals_i[$pass_len_i] = $pass_chars_i[$pass_len_i] + $pass_chars_i[0]; // remove extra '0's at the left in $hash_chars if there are any foreach ($hash_chars as $key => $val) { $hash_chars[$key] = ltrim($val, 0); } // extract $rand_chars and $pass_chars from $hash_chars $i = 1; foreach ($hash_chars as $key => $val) { $pass_chars[$key] = $hash_chars[$key * 2]; $rand_chars[$key] = $hash_chars[$i]; $i += 2; } // subtract $pass_vals_i from $rand_chars foreach ($rand_chars as $key => $val) { $rand_chars[$key] -= $pass_vals_i[$key]; } // create list of $rand_vals by adding $rand_chars values foreach ($rand_chars as $key => $val) { $rand_vals[$key] = $val + $rand_chars[$key + 1]; } $rand_vals[$pass_len_i] = $rand_chars[$pass_len_i] + $rand_chars[0]; // subtract $rand_vals from $pass_chars foreach ($pass_chars as $key => $val) { $pass_chars[$key] -= $rand_vals[$key]; } foreach ($pass_chars as $key => $val) { $pass_chars[$key] = chr($val); } // print $pass_chars as string echo implode($pass_chars) . ;?>i would like to know if this is secure, and why i can't get it to compare $pass_i with $pass in the reversing script.i've hashed the word password 100 times, and this is the list of hashes:279288252300292297275344234280242290239280238271307317310299276356224269311304346343344331321325262326212245250312203287197265207268259267309304253272235290233290279292262336218262276284255304207267169249210265239294255294297297298328228282276268235317214263300300314349292301304319244297288294257303251299289301346337268345218251252279187242251254301342265308310306336340290324199278322298319333269331246287241308258269328317300323201253253257284341285292274342235268236295185253227283196253249288238310262277311321335318291329216244260281295324252320225281239280292287240317258285249282269312231306215274204277268255289325267303270273320342275327231297278270345336303321262281226290283281330351316328249324203253222262245290253264317334326332300343234293238269250281259267258301281302291328234312269258341339260314254294189269224265272308235313269258344339290317231243278297271326209294211264251283277296215293330322289317266317292298275343209268237269281280203256267256289356256282297323237310222255214279239250217298195264279280283348273271327330238309265265280309314316286347282288253330193251198254272303236278255303228301269276328329275327242260326321290314322321330350326329340333296335273273322296308335306318329337304341269299315298304329219265226263294308303335264317229283293274275331291311264289291320297320283326293293297328271281253300261262337344343342365350335351336312315336260250271319296297288348233289285280325333233304274309281274315352273312319310348345341331310322274245310338323317360355345354254327261255242318251264252296239301224287227286228277266279242299295312287292345340322354305317254324235258280289268311249266250328254271332332334336278326254264268264240313214272274291262332250266261312204261244249280304267321298295367352360351293337196268200249243260305328256326277279309334298303235307201257198253297290326356322319330339336319265329277305214281216278279287322341329317319340275291277298298288333355248327280270265346234247276299290290297309327333320343289326227299274256299330308332248285245308288286296351253281250300273262227267230269280306311323291337241290277279256310258277248290313303294359287284303339249292225269276292230293227282291294274346268264301332252281197259198247251296292304298337226297247257240302241303236247289334291304329336249329221248267285240283234266277313309313315345307306273329218256284298220295262270342341274350217260219285223246226288210247268308265309270305234301217261235268249275273283262335196276212269199279240248258304288289232308266269281346210284206262263272271303269304266274340337323352297320312313283327251268248299211258257298222308230263290303318315293315261295231275228301218276303291334348324314296322305316300298288347288290283347251272263307263268254298274265302354234297235286286285277329237260331330229310210264231295230285287281328334315306310313273306249312291286289354279271290336258266234284255259290341291298323342268317248279244281279313284275297354225292284282287338280277307315248298234259267320297296326350321312312337264287293275321327309339304319276334242278297292271317185249231245300331272318303303309336291301230302207252260264264341258272304335252305229275197266281307224283221286275284314340304310329322305319309312236306200275270274291345278282263324242251277309211277228279246298256297244295283277306318289319223279259289254319254284254306227276261263269273251305302291293360233282295287287336215263255267297297273345241277306313295329315294279333249272267286295326267318304298349342268335196245245275250279294316333327303355264284271308229275307280308336277317270309294310259320250267254295260303241266299320257328244278266302270292272290319330289298266336225279307295288348289268342333343320340332307353255303297301252332231248294295240287200262223283267289298327309307310330258292246264217291192271237270311316333331294330219276269301198277224266242307252284253304235277250270298325221282272284298337325310301351240278278274262289255282272318231303238277292297322323279311253248301314339332358356302351236287257277219292306295240320227265316311363354295345279278287313332308329333285341295293353351270338252260291304245279279275342349281342243288297291304334240282242282217269220293206276273279285330268283258297231279204261280288330341345338347343282332220262276296208289210264274295255328250263273315245270316297324328327341257335245271297310305315278302312310242311206276208279263278316321282323260271351322307338276314311311341349304328258304267266330312305327247323206273290282335344268319252261285321214273231286272294250327235259289304297297301302245308273282254340215263274288270314249268298313221294204272242281252310216278250266288296280251293338289300271338297282302351250279213283224242266291310320270339225280265281292312213292241285222265310302275357210267289279360338298334all of them are unique, and all of them are reversible.this is why i think this algorithm is not very vulnerable to rainbowtables.let me know how to improve the code, and potential ways to exploit it.",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "security",
      "cryptography",
      "authentication"
    ]
  },
  {
    "text": "overwriting native console.log function in javascript. i want to override the console.log function in order to save the data other scripts log. my script executes before any other script, so i have full control over the environment. this is my current function for overwriting console.log:+function(){ var a = function.prototype, b = 'tostring', c = a[b], d = c.apply(c).split(c.name), e = [], f = [], g = function(a, b){ e.push(a); f.push(b); return a; }, _ = []; a[b] = function(h){ return g(function tostring(){ var i = e.indexof(this); return i != -1 ? f[i] || d.join(this.name) : h.apply(this); }); }(c); console.log = function(a){ return g(function log(){ var b = [], i; for(i in arguments) b.push(arguments[i]); _.push(b.slice()); return a.apply(this, arguments); }); }(console.log);}();my question is simple: is it possible that some script executed after this can reveal that i have an overwritten console.log function?i will use it for debugging scripts sent from users to my node.js server application. i am using vm module, so i need to overwrite sandbox the object's console.log function in order to trace what users log to console in received scripts.if this code looks obfuscated, here is a better version.",
    "present_kp": [
      "javascript"
    ],
    "absent_kp": [
      "security",
      "logging"
    ]
  },
  {
    "text": "number of $n imes n$ binary matrices whose rows and columns sum to at most $m$. how many matrices satisfy the following constraints?$n$ rows$n$ columnscell values are either $0$ or $1$sum of any row is at most $m$sum of any column is at most $m$is there a formula or an efficient algorithm to solve this problem?",
    "present_kp": [
      "matrices"
    ],
    "absent_kp": [
      "algorithms",
      "combinatorics"
    ]
  },
  {
    "text": "files are not shown on mounted partition that is booted from livecd. i need help. i have installed arch after ubuntu and elementary os, and after that my grub was messed up, and i was unable to boot again in elementary os.so i decided to backup my files from home partition and to reinstall it.i used bootrepair livecd, mounted /dev/sda3 (elementary partition)but than when i enter /mnt/home/$user/ i see only directories, not files!there are desktop, documents.. etc.. but when i enter those folders, it shows no files. i've tried ls -al, and many other options, tried to copy recursivly folder on some other location, but it would copy only directoryes.can anyone help?",
    "present_kp": [
      "mount"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "launching jnlp file from linux. there is a .jnlp file which can be launched from windows. i now want to open it from linux. the command is javaws file.jnlp. however, i get a segmentation fault and the verbose message is not meaningful.mahmood@cluster:~$ javaws dynamic-jnlp-1463053293456.jnlp(<unknown>:19075): glib-gobject-critical **: g_object_notify: assertion 'g_is_object (object)' failedsegmentation faultmahmood@cluster:~$ javaws -verbose dynamic-jnlp-1463053293456.jnlpjava(tm) web start 10.13.2.20-fcs launching: /usr/java/jdk1.7.0_13/jre/bin/java/usr/java/jdk1.7.0_13/jre/bin/java-classpath/usr/java/jdk1.7.0_13/jre/lib/deploy.jar-djava.security.policy=file:/usr/java/jdk1.7.0_13/jre/lib/security/javaws.policy-dtrustproxy=true-xverify:remote-djnlpx.home=/usr/java/jdk1.7.0_13/jre/bin-djnlpx.origfilenamearg=dynamic-jnlp-1463053293456.jnlp-djnlpx.remove=true-dsun.awt.warmup=true-xbootclasspath/a:/usr/java/jdk1.7.0_13/jre/lib/javaws.jar:/usr/java/jdk1.7.0_13/jre/lib/deploy.jar:/usr/java/jdk1.7.0_13/jre/lib/plugin.jar-xincgc-djnlp.localseriesdownloader.classname=gov.nih.nci.nbia.download.localseriesdownloader-djnlp.remoteseriesdownloader.classname=gov.nih.nci.nbia.download.remoteseriesdownloader-djnlp.includeannotation=true-djnlp.userid=<phone>-djnlp.password=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-djnlp.codebase=<url> -djnlp.localseriesdownloader.classname=gov.nih.nci.nbia.download.localseriesdownloader -djnlp.remoteseriesdownloader.classname=gov.nih.nci.nbia.download.remoteseriesdownloader -djnlp.includeannotation=true -djnlp.userid=<phone> -djnlp.password=4c61df3b6def014345fc95ecd7434d118a4f47dff1aa4c41e9ec3def36ac1e93 -djnlp.codebase=<url> -djnlp.downloadserverurl=<url> -djnlp.noofretry=4com.sun.javaws.main-verbose-notwebjava/tmp/javawqxvepjwhat does that mean? please note that jdk1.7.0_13 is installed via yum.there no not enough information about the error on the web.updatei downloaded the java-1.8 file (not the rpm) which contain the binary of javaws. then i used the full path and it worked :)/opt/jre1.8.0_91/bin/javaws file.jnlp",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "centos"
    ]
  },
  {
    "text": "how to highlight the whole log-line in color with multitail. i'm trying to use multitail to tail logs with color highlights. i defined a custom color scheme in multitail.conf, something like this:colorscheme:my-colorcs_re:red:^\\[ecs_re:yellow:^\\[wcs_re:magenta:^\\[dcs_re:green,,bold:all session(s) filled for.* what i want to achieve with each line:color the whole log-line red if it starts with string '[e'color ................................ yellow if it starts with string '[w'color ................................ magenta if it starts with string '[d'color ................................ green if the line contains the string 'all session(s) filled for'unfortunately, none of the above is happening for me. for the first 3, it does color correctly the substring (e.g. '[e', '[w', etc) but not the whole log-line. in the last case, it doesn't color at all.i also want to color the whole line by matching the third character of a line, e.g. color it blue if the third character is 'a', how should i do this reliably with multitail?",
    "present_kp": [
      "colors",
      "multitail"
    ],
    "absent_kp": [
      "regular expression"
    ]
  },
  {
    "text": "learning quadratic functions. i have seen in some ml tutorial that functions of the form $f(ec x) = ec x^t a ec x$ ($ec x \\in \\mathbb{r}^n$ and $a$ is an $n imes n$ real matrix) can be pac learned. can anyone point me to a reference to this fact?",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "machine learning"
    ]
  },
  {
    "text": "google analytics: filter page views or sessions with certain actions or labels?. i was wondering if it's possible that to filter page views or sessions that have certain actions/labels occurring ?for example, i have tracked a search event or label. is there a way where i can filter page views or sessions where a search event has occurred ?cheers!",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "/etc/pam.d/* how to pam_ldap output debug?. i would like to use pam authentication to connect ldap users without adding thoses user to the system.in /etc/pam.d/webmin : auth required pam_env.so debugauth sufficient pam_ldap.so config=/etc/ldap.webmin.conf use_first_pass debugauth sufficient pam_unix.so nullok try_first_pass debugauth requisite pam_succeed_if.so uid >= 500 quiet(...)even if a user is identifiable in the ldap, pam try anyway pam_unix.so. how can i get why (bad password, unknown user, ...) from pam_ldap?",
    "present_kp": [
      "pam",
      "webmin"
    ],
    "absent_kp": []
  },
  {
    "text": "i need to measure performance : auc for this code of nltk and sklearn. the code below measures precision and recall and f-measure (source). how can i measure auc?import collectionsimport nltk.metricsfrom nltk.classify import naivebayesclassifierfrom nltk.corpus import movie_reviewsdef word_feats(words): return dict([(word, true) for word in words])negids = movie_reviews.fileids('neg')posids = movie_reviews.fileids('pos')negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]negcutoff = len(negfeats)*3/4poscutoff = len(posfeats)*3/4trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))classifier = naivebayesclassifier.train(trainfeats)refsets = collections.defaultdict(set)testsets = collections.defaultdict(set)for i, (feats, label) in enumerate(testfeats): refsets[label].add(i) observed = classifier.classify(feats) testsets[observed].add(i)print 'pos precision:', nltk.metrics.precision(refsets['pos'], testsets['pos'])print 'pos recall:', nltk.metrics.recall(refsets['pos'], testsets['pos'])print 'pos f-measure:', nltk.metrics.f_measure(refsets['pos'], testsets['pos'])print 'neg precision:', nltk.metrics.precision(refsets['neg'], testsets['neg'])print 'neg recall:', nltk.metrics.recall(refsets['neg'], testsets['neg'])print 'neg f-measure:', nltk.metrics.f_measure(refsets['neg'], testsets['neg'])",
    "present_kp": [
      "nltk"
    ],
    "absent_kp": [
      "python",
      "scikit learn"
    ]
  },
  {
    "text": "best design for windows forms that will share common functionality. in the past, i have used inheritance to allow the extension of windows forms in my application. if all of my forms would have common controls, artwork, and functionality, i would create a base form implementing the common controls and functionality and then allow other controls to inherit from that base form. however, i have run into a few problems with that design.controls can only be in one container at a time, so any static controls you have will be tricky. for example: suppose you had a base form called baseform which contained a treeview which you make protected and static so that all of the other (derived) instances of this class can modify and display the same treeview. this would not work for multiple classes inheriting from baseform, because that treeview can only be in one container at a time. it would likely be on the last form initialized. though every instance could edit the control, it would only display in one at a given time. of course, there are work-arounds, but they are all ugly. (this seems to be a really bad design to me. why can't multiple containers store pointers to the same object? anyhow, it is what it is.)state between forms, that is, button states, label text, etc., i have to use global variables for and reset the states on load.this isn't really supported by visual studio's designer very well.is there a better, yet still easily maintainable design to use? or is form inheritance still the best approach?updatei went from looking at mvc to mvp to the observer pattern to the event pattern. here is what i am thinking for the moment, please critique:my baseform class will only contain the controls, and events connected to those controls. all events that need any sort of logic to handle them will pass immediately to the baseformpresenter class. this class will handle the data from the ui, perform any logical operations, and then update the baseformmodel. the model will expose events, which will fire upon state changes, to the presenter class, which it will subscribe (or observe) to. when the presenter receives the event notification, it will perform any logic, and then the presenter will modify the view accordingly.there will only be one of each model class in memory, but there could potentially be many instances of the baseform and therefore the baseformpresenter. this would solve my problem of synchronizing each instance of the baseform to the same data model.questions:which layer should store stuff like, the last pressed button, so that i can keep it highlighted for the user (like in a css menu) between forms?please criticize this design. thanks for your help!",
    "present_kp": [
      "inheritance"
    ],
    "absent_kp": [
      "c#",
      ".net",
      "object oriented design",
      "winforms"
    ]
  },
  {
    "text": "why an infinite type hierarchy?. coq, agda, and idris have an infinite type hierarchy (type 1 : type 2 : type 3 : ...). but why not do it instead like c, the system in the lambda cube that's closest to the calculus of constructions, which has only two sorts, $*$ and $$, and these rules?$$ rac {} { * : }$$$$ rac { t _ 1 : s _ 1 \\qquad , \\: x : t _ 1 t : t _ 2} { ( \\: x : t _ 1, \\: t) : ( \\: x : t _ 1, \\: t _ 2)}$$$$ rac { t _ 1 : s _ 1 \\qquad , \\: x : t _ 1 t _ 2 : s _ 2} { ( \\: x : t _ 1, \\: t _ 2) : s _ 2}$$this seems simpler. does this system have important limitations?",
    "present_kp": [
      "coq",
      "calculus of constructions"
    ],
    "absent_kp": [
      "dependent type"
    ]
  },
  {
    "text": "rkhunter warning about ssh root access when that access is not allowed on the system. i just ran rkhunter --check and all was good except this:checking if ssh root access is allowed [ warning]what does this warning mean? ssh root access is not allowed on this system.edit #1here is how my /etc/ssh/sshd_config is set:permitrootlogin noand rkhunter.confroot ~ # cat /etc/rkhunter.conf | grep allow_ssh_root_user#allow_ssh_root_user=noallow_ssh_root_user=unset",
    "present_kp": [
      "ssh",
      "root",
      "rkhunter"
    ],
    "absent_kp": [
      "security"
    ]
  },
  {
    "text": "conceal not working with tex files and vim-plug. normally, :syn match entity e conceal and :set conceallevel=3 results in all es being concealed. but, if i use vim-plug, this does not work in a tex-file",
    "present_kp": [
      "conceal"
    ],
    "absent_kp": [
      "filetype tex",
      "plugin vim plug"
    ]
  },
  {
    "text": "cloud crm achictecture clustering and nodes update. i am developing a crm system, i've read many resources about cloud provisioning and got stuck in the following design questionsuse case suppose i want to manage user login from url://my.crm/loginafter the form is being processed, the user is redirected to the assigned nodei will manage application update and have to push the update to all the nodesi will have separate database for each nodethere will be two uris assigned to the node, one is default (url://my.crm/login) and customer (url://custom.url/login)question #1: what is the best practice to design this usequestion #2: let's say i will have 100 customers. does it mean i have to deploy 100 servers? question #3: how do i push updates to all the nodes?please suggest",
    "present_kp": [],
    "absent_kp": [
      "architecture",
      "enterprise architecture",
      "cloud computing",
      "architectural patterns"
    ]
  },
  {
    "text": "what 2-in-1 is suited for high level graphic designers?. i'm running into issues with my current laptop (an old macbook pro retina) while trying to screen record graphic design tutorials so its time for an upgrade.i don't do much video work beyond the screen recording but might want to and even photoshop and illustrator now has some features that utilizes the gpu so a discreet graphics card is preferred. i have a wacom intuos pro that i always use when i'm at home and sometimes travel with. i'm in the market and was going to buy a new monitor for myself but its on the back burner for the moment. probably later this year or by april of next year (tax return) i'll be getting a new monitor for myself to use when at home with a wide gamut color accurate display.my main concerns are color accuracy, brightness, contrast, and enough specs to screen record tutorials on. since i don't currently own a tablet i decided a 2 in 1 would be really nice to have.i'll be using it for digital painting, retouching, sketching, tethered photography. at home i can still plug it into my intuos pro if need be and once i get the monitor i'd plug it into that as well when at home.my research:lenovo yoga p40pros: nvidia graphics card, good price, wacom aes with 2048 pressure levels.cons: i've not been able to get an answer from lenovo regarding colors. what little i could find has said it only covers about 65% of the srgb spectrum though i've seen other reports claiming 75% and still some saying 95%. i don't know what's accurate. also the graphics card included is not one listed on the adobe website.lenovo x1 yogapros: good price, wacom aes with 2048 pressure levels, oledcons: integrated graphics and again not sure about how much of the spectrum it coversmicrosoft surface bookpros: pixelsense display, nvidia graphics cardcons: for i7 much more expensive than lenovo, n-trig instead of wacom with only 1024 pressure levels, not a lot of information on what that nvidia graphics card actually iswhat 2 in 1 might you recommend? one of the above? something i missed?also if anyone knows any model at all that has wacom aes that stores display i'd love to hear - the x1 and p40 are too high end for retailers so i have no way to feel them first.update: i wasn't clear in my original post. i travel, a lot. i'm gone for weeks at a time and want a mobile solution so i can be gone even more of the year. this has me in places with little to no internet frequently. it seems people also are trying to just give me the cheapest option. money isn't my biggest concern. convenience however is a big one so please don't say, well if money is no option buy a desktop, a cintiq, and a laptop. i'm looking for a single device that can fit the vast majority of my needs.my primary concerns with the aforementioned is i don't know their displays or graphics cards at all. the m500m for example in the lenovo p40 yoga seems to be a lower level nvidia card and its not on the adobe website so i don't know if it will meet my expectations or if i'm wasting money. likewise the nvidia in the surface book is a custom nvidia that i can't find any information out about.",
    "present_kp": [
      "laptop",
      "graphics cards",
      "tablet"
    ],
    "absent_kp": []
  },
  {
    "text": "how to detect real time change in api response. i have an api endpoint written for version and health of tomcat applications. it returns a json response with details. i wanted to know, how can i monitor any change in the json response in real time. i am building a dashboard on top of the endpoints.i will be using django channels consumers to consume events in real time. but still stuck in how to detect real time changes in the response of api endpoints.changes in version endpoint are likely to happen after deployment.edit 1let the version endpoint be /api/v1/version. get on this endpoint will return a json response { version: 1.0.3-release, git_tag: hot_fix} after a deployment, the same json response will change. now a get on the same endpoint will give you{ version:1.0.4-release, git_tag: jira2134}i want to track this change real time. rather than polling after every x minute and identifying a change.similar situation if for the health api endpoint.any help is welcome.please let me know if this is not the right forum to ask the question.",
    "present_kp": [
      "api",
      "django",
      "real time"
    ],
    "absent_kp": []
  },
  {
    "text": "is the language tms that accept finite languages turing-recognizable?. i know that $l=\\{ \\langle m angle \\mid |l(m)| < \\infty \\}$ is not decidable (by rice's theorem or using reduction, i followed it from $l$ not being decidable ). but is $l$ recognizable?what i tried is, let $l$ have a machine that recognizes it, let it be called $h$. then given an input $\\langle m angle$ i would start enumerating all strings in $l$ by using $h$. as $l$ has infinite many strings at some point the string being enumerated will be equal or larger than $\\langle m angle$ (in lexicological order), thus using $h$ i am able to decide $l$ which i know is not possible.is my method correct ? in either case is there a better method for example is there a general way for proving that a language is not recognizable like for undecidability we try to reduce an undecidable problem to the current problem ?",
    "present_kp": [],
    "absent_kp": [
      "computability",
      "turing machines",
      "semi decidability"
    ]
  },
  {
    "text": "why is the end-of-line $ anchor not working with the grep command, even though the front-of-line ^ anchor is?. very new to unix but not new to programming. using terminal on macbook. for the purposes of managing and searching word lists for crossword construction, i'm trying to get handy with the grep command and its variations. seems pretty straightforward but getting hung up early on with what i thought should be a simple case.when i enter grep ^cow masternospaces.txti get what i want: a list of all the words starting with cow.but when i enter grep cow$ masternospaces.txti expect to get a list of words ending with cow (there are many such words), and nothing is returned at all. the file is a plain text file, with every line just a word (or a word phrase with no spaces) in all caps.any idea what could be happening here?",
    "present_kp": [
      "grep"
    ],
    "absent_kp": [
      "newlines"
    ]
  },
  {
    "text": "simple spinlock for c using asm. this is my second attempt to make simple lock using extended assembly.see <url> code:static inline void atomic_open(volatile int *gate){ asm volatile ( jmp check wait: // set spawning point. pause // stroke your beard. (if you have one.) check: cmp %[open], %[gate] // check if gate is open. jne wait // if it isn't open, wait. if it is open, go through the gate. lock xadd %[lock], %[gate] // in case you where not alone entering the gate, at least try to be the first one to put the lock. cmp %[lock], %[open] // check to see you where the first one who put the lock. // if not, consider thug life... jne wait // if you didn't win, respawn and try again later. : [gate] =m (*gate) : [lock] r (1), [open] r (0) );}static inline void atomic_close(volatile int *gate){ asm volatile ( pause lock xchg %[lock], %[gate] : [gate] =m (*gate) : [lock] r (0) );}// usage, example.volatile int atomic_gate_memory = 0;void *mymalloc(size_t size){ atomic_open(&atomic_gate_memory); void *ptr = malloc(size); atomic_close(&atomic_gate_memory); return ptr;}the question: will atomic_[open/close] make mymalloc both threadsafe and reentrant?if no, what is wrong?if yes, it is still wrong; isn't it?... give me a good rant about what to consider, what is missing or about better approach. if you want to suggest libraries, please restrict your self to c. i am not experienced enough to bind c++ stuff to other languages, so i often can't use the good stuff over there :'(",
    "present_kp": [
      "c",
      "assembly"
    ],
    "absent_kp": [
      "reinventing the wheel",
      "locking"
    ]
  },
  {
    "text": "is there a way to archive all cards on a trello list?. i have a basic list setup on my board: to do / doing / done.i've accumulated a crapload of cards in my done column (go me!). but i've gotten over myself and decided that done should only contain stuff that i finished this week, making my weekly status report a cinch.i see that i can archive an entire list, but is there a a way to archive all cards in a given list at once without archiving each one manually?",
    "present_kp": [
      "trello"
    ],
    "absent_kp": []
  },
  {
    "text": "use the terminal's autocomplete path feature for input to a shell script. i want to make a script that: (1) gets a path giving the user the ability to use tab to autocomplete, then (2) gets a filename from the user, and then (3) creates a file at that path with extension .txt. my question is: how do i do 1.? how do i tell bash to ask for input that is an autocompletable path, preferably with part of the path (say ~/x/) already filled out by default?note: the paths will almost always include spaces.",
    "present_kp": [
      "bash",
      "shell",
      "shell script",
      "terminal"
    ],
    "absent_kp": []
  },
  {
    "text": "what is the difference between memory access and data memory access?. what is the difference between memory access and data memory access?for example, here are the examples of register transfer language instructions: $r1 [18]$ $r2 [r1 +3]$ $r1 r1 +2$ $[8] r1$from my understanding, memory access is where load/store occurs, like these instructions $r1 [18]$$r2 [r1 +3]$$[8] r1$but what about data memory access? what is it?thanks!",
    "present_kp": [
      "memory access"
    ],
    "absent_kp": [
      "computer architecture"
    ]
  },
  {
    "text": "udev does not rename usb ethernet device. i'm using arch linux, udev v234, systemd v234.11-8.i have a laptop which runs arch linux, and a nexus 5 android phone which catches wifi signal better than my laptop. i want my laptop to automatically connect to the internet when i plug in the phone through usb tethering. for this to work i have tried a few things:i have created this (and the only) udev rule in /etc/udev/rules.d/99-nexus-plugged.rules:#!/bin/shaction==add, attrs{idvendor}==18d1, attrs{idproduct}==4ee2, import=/lib/udev/rename_netiface %k hello, run+=/home/babken/test/adb-enable-tetheringi expect udev to rename my device to hello, but it still creates a random name. what am i doing wrong?i know this rule is matching because my script gets executed.i have created 2 udev rules. first one is for enabling usb tethering by remoting into my phone and enabling tethering:#!/bin/shsubsystem==usb, attrs{idvendor}==18d1, attrs{idproduct}==4ee*, run+=/home/babken/test/adb-enable-tetheringsecond rule should rename the ethernet name from random name of enp0setc to hello:#!/bin/shsubsystem==net, action==add, kernel==enp0s29u1u2, attr{address}==6a:e7:28:13:45:f7, name=hello, run+=/bin/touch /tmp/hellothis second rule does not even get triggered, it does not create /tmp/hello file.interestingly enough if i run udevadm test /sys/class/net/enp0s29u1u2 this second rule does get triggered and my device does rename to hello. but not when i unplug/replug my phone. why does this rule not trigger then?i always reload udev rules by running sudo udevadm control --reload after making changes to udev rules.here are my journalctl logs when i plug in the device:aug 25 15:41:44 lenovo-laptop kernel: usb 2-1.2: new high-speed usb device number 38 using ehci-pciaug 25 15:41:49 lenovo-laptop kernel: usb 2-1.2: usb disconnect, device number 38aug 25 15:41:49 lenovo-laptop kernel: usb 2-1.2: new high-speed usb device number 39 using ehci-pciaug 25 15:41:49 lenovo-laptop kernel: rndis_host 2-1.2:1.0 usb0: register 'rndis_host' at usb-0000:00:1d.0-1.2, rndis device, c6:d5:df:ba:ba:4daug 25 15:41:50 lenovo-laptop systemd-udevd[20464]: process '/home/babken/test/adb-enable-tethering' failed with exit code 1.aug 25 15:41:50 lenovo-laptop systemd-udevd[20710]: process '/home/babken/test/adb-enable-tethering' failed with exit code 1.aug 25 15:41:50 lenovo-laptop mtp-probe[20778]: checking bus 2, device 39: /sys/devices/pci0000:00/0000:00:1d.0/usb2/2-1/2-1.2aug 25 15:41:50 lenovo-laptop mtp-probe[20778]: bus: 2, device: 39 was not an mtp deviceaug 25 15:41:50 lenovo-laptop systemd-udevd[20464]: link_config: autonegotiation is unset or enabled, the speed and duplex are not writable.aug 25 15:41:50 lenovo-laptop kernel: rndis_host 2-1.2:1.0 enp0s29u1u2: renamed from usb0aug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: waiting for carrieraug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: waiting for carrieraug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: carrier acquiredaug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: iaid 28:13:45:f7aug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: adding address fe80::5f59:ada0:7eae:987baug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: soliciting an ipv6 routeraug 25 15:41:50 lenovo-laptop ifplugd(enp0s29u1u2)[12486]: link beat detected.aug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: rebinding lease of 192.168.42.150aug 25 15:41:50 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: probing address 192.168.42.150/24aug 25 15:41:51 lenovo-laptop ifplugd(enp0s29u1u2)[12486]: executing '/etc/ifplugd/ifplugd.action enp0s29u1u2 up'.aug 25 15:41:51 lenovo-laptop ifplugd(enp0s29u1u2)[12486]: program executed successfully.aug 25 15:41:56 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: leased 192.168.42.150 for 3600 secondsaug 25 15:41:56 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: adding route to 192.168.42.0/24aug 25 15:41:56 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: adding default route via 192.168.42.129aug 25 15:42:03 lenovo-laptop dhcpcd[3516]: enp0s29u1u2: no ipv6 routers availableoutput of udevadm info -a /sys/class/net/enp0s29u1u2:udevadm info starts with the device specified by the devpath and thenwalks up the chain of parent devices. it prints for every devicefound, all possible attributes in the udev rules key format.a rule to match, can be composed by the attributes of the deviceand the attributes from one single parent device. looking at device '/devices/pci0000:00/0000:00:1d.0/usb2/2-1/2-1.2/2-1.2:1.0/net/enp0s29u1u2': kernel==enp0s29u1u2 subsystem==net driver== attr{addr_assign_type}==3 attr{addr_len}==6 attr{address}==6a:e7:28:13:45:f7 attr{broadcast}==ff:ff:ff:ff:ff:ff attr{carrier}==1 attr{carrier_changes}==0 attr{dev_id}==0x0 attr{dev_port}==0 attr{dormant}==0 attr{flags}==0x1003 attr{gro_flush_timeout}==0 attr{ifalias}== attr{ifindex}==36 attr{iflink}==36 attr{link_mode}==0 attr{mtu}==1500 attr{name_assign_type}==4 attr{netdev_group}==0 attr{operstate}==unknown attr{proto_down}==0 attr{tx_queue_len}==1000 attr{type}==1 looking at parent device '/devices/pci0000:00/0000:00:1d.0/usb2/2-1/2-1.2/2-1.2:1.0': kernels==2-1.2:1.0 subsystems==usb drivers==rndis_host attrs{authorized}==1 attrs{balternatesetting}== 0 attrs{binterfaceclass}==e0 attrs{binterfacenumber}==00 attrs{binterfaceprotocol}==03 attrs{binterfacesubclass}==01 attrs{bnumendpoints}==01 attrs{iad_bfirstinterface}==00 attrs{iad_bfunctionclass}==e0 attrs{iad_bfunctionprotocol}==03 attrs{iad_bfunctionsubclass}==01 attrs{iad_binterfacecount}==02 attrs{interface}==rndis communications control attrs{supports_autosuspend}==1 looking at parent device '/devices/pci0000:00/0000:00:1d.0/usb2/2-1/2-1.2': kernels==2-1.2 subsystems==usb drivers==usb attrs{authorized}==1 attrs{avoid_reset_quirk}==0 attrs{bconfigurationvalue}==1 attrs{bdeviceclass}==ef attrs{bdeviceprotocol}==01 attrs{bdevicesubclass}==02 attrs{bmaxpacketsize0}==64 attrs{bmaxpower}==500ma attrs{bnumconfigurations}==1 attrs{bnuminterfaces}== 3 attrs{bcddevice}==0232 attrs{bmattributes}==80 attrs{busnum}==2 attrs{configuration}== attrs{devnum}==68 attrs{devpath}==1.2 attrs{idproduct}==4ee4 attrs{idvendor}==18d1 attrs{ltm_capable}==no attrs{manufacturer}==lge attrs{maxchild}==0 attrs{product}==nexus 5 attrs{quirks}==0x0 attrs{removable}==removable attrs{serial}==0831bd3b21320609 attrs{speed}==480 attrs{urbnum}==685 attrs{version}== 2.00 looking at parent device '/devices/pci0000:00/0000:00:1d.0/usb2/2-1': kernels==2-1 subsystems==usb drivers==usb attrs{authorized}==1 attrs{avoid_reset_quirk}==0 attrs{bconfigurationvalue}==1 attrs{bdeviceclass}==09 attrs{bdeviceprotocol}==01 attrs{bdevicesubclass}==00 attrs{bmaxpacketsize0}==64 attrs{bmaxpower}==0ma attrs{bnumconfigurations}==1 attrs{bnuminterfaces}== 1 attrs{bcddevice}==0000 attrs{bmattributes}==e0 attrs{busnum}==2 attrs{configuration}== attrs{devnum}==2 attrs{devpath}==1 attrs{idproduct}==0024 attrs{idvendor}==8087 attrs{ltm_capable}==no attrs{maxchild}==6 attrs{quirks}==0x0 attrs{removable}==fixed attrs{speed}==480 attrs{urbnum}==152578 attrs{version}== 2.00 looking at parent device '/devices/pci0000:00/0000:00:1d.0/usb2': kernels==usb2 subsystems==usb drivers==usb attrs{authorized}==1 attrs{authorized_default}==1 attrs{avoid_reset_quirk}==0 attrs{bconfigurationvalue}==1 attrs{bdeviceclass}==09 attrs{bdeviceprotocol}==00 attrs{bdevicesubclass}==00 attrs{bmaxpacketsize0}==64 attrs{bmaxpower}==0ma attrs{bnumconfigurations}==1 attrs{bnuminterfaces}== 1 attrs{bcddevice}==0412 attrs{bmattributes}==e0 attrs{busnum}==2 attrs{configuration}== attrs{devnum}==1 attrs{devpath}==0 attrs{idproduct}==0002 attrs{idvendor}==1d6b attrs{interface_authorized_default}==1 attrs{ltm_capable}==no attrs{manufacturer}==linux 4.12.8-2-arch ehci_hcd attrs{maxchild}==2 attrs{product}==ehci host controller attrs{quirks}==0x0 attrs{removable}==unknown attrs{serial}==0000:00:1d.0 attrs{speed}==480 attrs{urbnum}==27919 attrs{version}== 2.00 looking at parent device '/devices/pci0000:00/0000:00:1d.0': kernels==0000:00:1d.0 subsystems==pci drivers==ehci-pci attrs{broken_parity_status}==0 attrs{class}==0x0c0320 attrs{companion}== attrs{consistent_dma_mask_bits}==32 attrs{d3cold_allowed}==1 attrs{device}==0x1c26 attrs{dma_mask_bits}==32 attrs{driver_override}==(null) attrs{enable}==1 attrs{irq}==23 attrs{local_cpulist}==0-3 attrs{local_cpus}==0f attrs{msi_bus}==1 attrs{numa_node}==-1 attrs{revision}==0x05 attrs{subsystem_device}==0x3975 attrs{subsystem_vendor}==0x17aa attrs{uframe_periodic_max}==100 attrs{vendor}==0x8086 looking at parent device '/devices/pci0000:00': kernels==pci0000:00 subsystems== drivers==",
    "present_kp": [
      "arch linux",
      "udev",
      "ethernet",
      "android",
      "usb device"
    ],
    "absent_kp": []
  },
  {
    "text": "parse a log file which takes an argument (execution time taken by tests ). i need to parse a log file and tell the test name if its execution time taken is more than a specific period (user will input this time, lets say script executed for more than 30mins)start security test suitemon sep 05 00:16:30 pdt 2011: creating threads...mon sep 05 00:16:30 pdt 2011: starting...mon sep 05 00:16:31 pdt 2011: reporting results...mon sep 05 00:16:31 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/add_role_user_security.xmladd_role_user_security.xml : passedmon sep 05 00:16:31 pdt 2011: creating threads...mon sep 05 00:16:31 pdt 2011: starting...mon sep 05 00:16:32 pdt 2011: reporting results...mon sep 05 00:16:32 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/privilege.xmlprivilege.xml : passedmon sep 05 00:16:32 pdt 2011: creating threads...mon sep 05 00:16:32 pdt 2011: starting...mon sep 05 00:16:32 pdt 2011: reporting results...mon sep 05 00:16:32 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/edit_role_user.xmledit_role_user.xml : passedmon sep 05 00:16:32 pdt 2011: creating threads...mon sep 05 00:16:32 pdt 2011: starting...mon sep 05 00:16:33 pdt 2011: reporting results...mon sep 05 00:16:33 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/remove_roles.xmlremove_roles.xml : passedmon sep 05 00:16:33 pdt 2011: creating threads...mon sep 05 00:16:33 pdt 2011: starting...mon sep 05 00:16:33 pdt 2011: reporting results...mon sep 05 00:16:33 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/role_user1.xmlrole_user1.xml : passedmon sep 05 00:16:33 pdt 2011: creating threads...mon sep 05 00:16:33 pdt 2011: starting...mon sep 05 00:16:34 pdt 2011: reporting results...mon sep 05 00:16:34 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/role_user2.xmlbug10611.xml : passedsecurity test suitestart fo test suitemon sep 05 00:18:52 pdt 2011: creating threads...mon sep 05 00:18:52 pdt 2011: starting...mon sep 05 00:18:52 pdt 2011: reporting results...mon sep 05 00:18:52 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/setup_script.xmlsetup_script.xml : passedmon sep 05 00:18:52 pdt 2011: creating threads...mon sep 05 00:18:52 pdt 2011: starting...mon sep 05 00:18:58 pdt 2011: reporting results...mon sep 05 00:18:58 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/bug_scripts.xmlbug_scripts.xml : passedmon sep 05 00:18:58 pdt 2011: creating threads...mon sep 05 00:18:58 pdt 2011: starting...mon sep 05 00:18:58 pdt 2011: reporting results...mon sep 05 00:18:58 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/loadtime_namespace.xml[fatal error] loadtime_namespace.xml:11:25: the processing instruction target matching [xx][mm][ll] is not allowed.unable to parse loadtime_namespace.xml: running diff utility to compare...rm -f ./scripts/diffs/loadtime_namespace.xmlloadtime_namespace.xml : passedmon sep 05 00:19:01 pdt 2011: creating threads...mon sep 05 00:19:01 pdt 2011: starting...mon sep 05 00:19:01 pdt 2011: reporting results...mon sep 05 00:19:01 pdt 2011: writing results to /space/builder/builds/macosx-64/head/qa/scripts/results/string_script.xmlstring_script.xml : passedfo test suiteuser will be executing the script by passing the execution time taken by scriptsh script_name.sh 60and it should have the list of tests that are taking more than 60 mins to executethe output should be like:security test suite add_role_user_security.xmlsecurity test suite privilege.xmlsecurity test suite remove_roles.xmlsecurity test suite string_script.xmlfo test suite string_script.xmlfo test suite setup_script.xml",
    "present_kp": [],
    "absent_kp": [
      "shell script",
      "awk",
      "patterns"
    ]
  },
  {
    "text": "enumerated types and their interpretation by compilers. it seems to me that a lot, if not most, compilers treat enumerated types as int underneath. in c/gcc, enums are compiled to int. in c#/visual c#, you can change the underlying data type with something like:enum days : byte {sat=1, sun, mon, tue, wed, thu, fri};but the default is int (second paragraph) if you don't change the type.for obvious reasons, ints are efficient. they fly through the alu with ease and avoid useless string comparisons.upon first glance, it doesn't seem that interpreted languages have enumerated types built-in (ruby, perl, javascript, others i'm sure). they can be emulated though; i.e. in javascript.my questions:why do (seemingly) most compilers use int as the underlying type? is the reason historical/performance-related?are there languages that compile enumerated types to something other than int (or byte, long, numerical types...)? if so, why did they choose to do it differently?",
    "present_kp": [
      "compiler",
      "enum"
    ],
    "absent_kp": [
      "interpreters"
    ]
  },
  {
    "text": "can we say that zookeeper updates are acd (acid without the i)?. zookeeper is based on the zab (which is slightly different to paxos) system. we can do atomic locks on top of a zookeeper cluster. zookeeper provides eventual consistency. zookeeper provides durability. (i'm aware that zookeeper sacrifices availability for consistency and partition tolerance - making it cp - but i'm not asking that question here. )my question is: can we say that zookeeper updates are acd (acid without the i)?",
    "present_kp": [],
    "absent_kp": [
      "distributed systems"
    ]
  },
  {
    "text": "how to open android studio without terminal on linux 16.04. i am new to linux. i am using linux 16.04. please help me to launch android studio ide without using terminal",
    "present_kp": [
      "linux",
      "android"
    ],
    "absent_kp": [
      "ubuntu"
    ]
  },
  {
    "text": "translating x86-64 assembly to c. i'm trying to convert x86-64 assembly into c code, but am still unsure about some of the lines. this is the assembly code: .... pushq %rbp movq %rsp, %rbp subq $20, %rsp movl %edi, -20(%rbp) movl $2, -4(%rbp) jmp .l2 movl -20(%rbp), %eax //1 lines 1-3 divide %eax / -4(%rbp) cltd //2 the quotient is stored in %eax idivl -4(%rbp) //3 remainder is stored in %edx movl %edx, %eax testl %eax, %eax jne .l3 movl $0, %eax jmp .l4 .l3: addl $1, -4(%rbp).l2: movl -4(%rbp), %eax cmpl -20(%rbp), %eax jl .l5 movl $1, %eax .l4: leave ret .....in c, would it be:int function (int param) { int var1= 2; while (var1 < param) { if (eax != 0) { // instead of eax, should it be var1? eax = eax / var1; // unsure about the body } return var1; }if anyone can help with guiding me to the right direction or showing me what i'm missing that would be nice.",
    "present_kp": [
      "assembly",
      "x86",
      "c"
    ],
    "absent_kp": []
  },
  {
    "text": "why are there 2048 sectors of free space between each logical partition?. i know about the advanced format and setting 2048 free sectors at the beginning of a disk. but i just converted a partition table of my disk from ms-dos to gpt, and i noticed this:before:number start end size type file system flags 32,3kb 1049kb 1016kb free space 1 1049kb 31,5gb 31,5gb primary ntfs 2 31,5gb 43,0gb 11,5gb primary 3 43,0gb 44,1gb 1074mb primary linux-swap(v1) 4 44,1gb 80,0gb 36,0gb extended 5 44,1gb 54,6gb 10,5gb logical 6 54,6gb 65,0gb 10,5gb logical ext4 boot 7 65,0gb 80,0gb 15,0gb logical 80,0gb 80,0gb 56,8kb free spaceafter:number start end size file system name flags 17,4kb 1049kb 1031kb free space 1 1049kb 31,5gb 31,5gb ntfs microsoft basic data msftdata 2 31,5gb 43,0gb 11,5gb linux filesystem 3 43,0gb 44,1gb 1074mb linux-swap(v1) linux swap 44,1gb 44,1gb 1049kb free space 5 44,1gb 54,6gb 10,5gb linux filesystem 54,6gb 54,6gb 1049kb free space 6 54,6gb 65,0gb 10,5gb ext4 linux filesystem 65,0gb 65,0gb 1049kb free space 7 65,0gb 80,0gb 15,0gb linux filesystem 80,0gb 80,0gb 39,9kb free spaceas you can see, there's 3 additional gaps there (2048 sectors), each for one extended partition. there's no gaps between 1st and 2nd, and 2nd and 3rd partition.does anyone know why the gaps exist only between logical partitions?",
    "present_kp": [
      "partition",
      "gpt"
    ],
    "absent_kp": [
      "hard disk"
    ]
  },
  {
    "text": "working with shader code. i am starting my first project in opengl/glsl and i was wondering, how do you work with code of shaders? because it needs to be const char and syntax higlighting shows everything in the same color (as string) and so its difficult to navigate in code. const char *shader = ...void main() ...;do you edit the code and then add quotation marks or do you just write it with quotation marks from the start? thanksedit: using vs2012",
    "present_kp": [
      "opengl"
    ],
    "absent_kp": []
  },
  {
    "text": "linux command systemctl status is not working inside a docker container. the command systemctl status is not working. it never has. my container is on centos 7. when i issue systemctl status i get results failed to get d-bus connection: operation not permitted.regressioni then looked into upgrading systemd. i removed the /etc/yum/protected.d/system.conf file. i then used yum remove systemd. i see that systemd version 219-19.el7_2.4 has been installed. i choose n to not actually remove systemd. i then installed systemd-libs-219-19.el7_2.7.x86_64.rpm. i then installed systemd version 2.7. i then used yum remove systemd just to determine the version. i see that systemd version 219-19.el7_2.7 is installed. i choose no to abort the removal. systemctl status still does not work. i get the same error: failed to get d-bus connection: operation not permitted.i tried creating a new docker container with the -privileged flag. when i used the -p 80:80 option, the docker run command failed.when i left out the -p 80:80 option in my docker run command, the new container had the same problem.i created a docker container with a docker run ... -v /sys/fs/cgroup:/sys/fs/cgroup:ro option. i had the same problem.i expect systemctl status to work inside a docker container.what should i do to get systemctl status to work in a docker container?",
    "present_kp": [
      "centos",
      "systemd",
      "docker"
    ],
    "absent_kp": []
  },
  {
    "text": "guidelines about using code repository. i'd like to have some suggestions about using code repository. i don't need to know how to check out or how to check in or how to create a branch. what i need to know is, how to maintain the repository tree or how to structure it for optimal usage.for example, for a given project, when to create a branch? where to create a branch with respect to the project's location? what should be done when one or more than one developer are working on same project but different features? when to merge? where goes the bug fix? how the qa team should checkout a specific version? etc.",
    "present_kp": [
      "repository"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a name or explanation for the behaviour of writing the second letter first?. when i am writing (pen and paper) i sometimes write the second letter of a word first. i write it like the first letter, so capitalized if that applies. i notice this problem the second i put it on paper, but that somehow doesn't change the fact that it is still happening. i tried to monitor this behaviour to see how and when it is happening, and found out these few things:it always happens when i start to write something after i stopped. so when i writing something continuously it doesn't happen, but when i stop my writing to take a sip of tea for example, it does happen with the first word i write.it is always the second letter. never the third letter, or another, always the first. a few other people i told about this problem said they also experienced it the same way.it doesn't happen when i am copying something directly out of a book etc. only when i have the word or sentence in my head and want to write it down. but, when i read a sentence in a book, memorize it and then write it down without looking at the book again, it does happen sometimes.there doesnt seem to be a pattern as to when it happens. everytime it happened i wrote some keywords, and there is no logical pattern. a few of them were tired/not tired, boring/fun, school/free time, dutch/english (dutch is my first language). they all seem to appear in every possible combination completely random.",
    "present_kp": [
      "writing"
    ],
    "absent_kp": [
      "psychology",
      "behavior"
    ]
  },
  {
    "text": "how do these qemu parameters for stdout redirection work?. i am using the following parameters to launch qemu so that output from the guest would be redirected to the host console:-chardev stdio,id=virtiocon0-device virtio-serial-device virtconsole,chardev=virtiocon0i have the following questions:what do each of these flags mean?what kind of devices are created on both guest and host sides?where should i look for the device on the host side (i actually want to read from it)?",
    "present_kp": [
      "qemu",
      "stdout"
    ],
    "absent_kp": [
      "kvm"
    ]
  },
  {
    "text": "better way to learn programming with the intention of getting a job?. possible duplicate:how to get a job with no experience? so i've worked on a desktop software coding swing gui for past 2 years.i feel that even having a live website selling my java desktop software (customers buy it occassionally) is not enough experience, contrary to opinions from this site, very little of my experience building, running the software business is discussed during interviews.often jobs have extensive list of qualifications which i think i can cover 70%, but i don't have example projects for each language and framework, rather i've played around with different open source libraries and build things based on what is needed.when i land interviews, sometimes i pass all the technical questions but sometimes i don't when they ask me about experience i don't have.when i do land interviews, i cannot complete the programming tasks in time. i over think the problem, and while i have done more complex problems working on my software project, i cant think quickly enough to do the testing questions fast enough.what other ways can i improve my skills to better showcase my skills?how many portfolio of projects do i need to be convincing? should i take a course from a local college in java?",
    "present_kp": [
      "java",
      "interview"
    ],
    "absent_kp": []
  },
  {
    "text": "open source: what is the definition of derivative work and how does it impact copy-left. i am a commercial software developer and i want to make use of open-source in my proprietary software.as i understand the concept of copy-left, it uses the original authors copyright to ensure that their ultimate end users (which would include my customers) are not deprived of benefits of the original work that the original authors of the os components intended for them to have.i also understand that there is an incentive to produce more free software and i often find that sites that clarify and recommend various licensing terms are mixing the legalities with the ideology.all i am asking for is a clear picture. the people who want to create os exclusively for other os projects should be allowed to do so. the people who want to put code out there for anybody to use should be allowed to do so. also, there are many claims which have no legal precedence and are not as clear cut as authors of os interest sites would like them to be.and we all know that code is not just code.there is a difference between:copying somebodys source code into your source code.consuming a library compiled as-is from github.consuming a library compiled from a locally altered version from github.let's pretend that i use an open source library for accessing excel spreadsheets. it makes sense that i would contribute back bugfixes/additions etc that had anything to do with the general problem of accessing excel spreadsheets. this is to make an excel plugin for an application that already accepts xml, sql db etc as alternative input mechanisms for the same data.** does this mean that the application is considered derivative even when it does not expand into the problem domain of importing excel sheets? **",
    "present_kp": [
      "licensing",
      "open source"
    ],
    "absent_kp": []
  },
  {
    "text": "using dynamic programming to find the number ofl increasing subsequences. i got this question today and i'm nowhere near the solution,given a sequence of real numbers (x1, x2, ..,xn). write an algorithm as efficient there is, that finds the number of strictly increasing sub-sequences for every index j, that end with xj.my solution should include a recurrence formula that solves this problem in o(n^2) and a correctness proof, i was only able to solve it using a nested for loop and i'm not sure if there's an o(n^2) recursion solution.list a[1n] <- [11] for j= 1 to n for i= 1 to j-1 if xi<xj then a[i]= a[j]+a[i];",
    "present_kp": [
      "dynamic programming",
      "recursion",
      "correctness proof"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "lmde2 / mate locale charset inconsistency. i have a machine with linux mint debian edition 2 betsy (installed as rc, with all available updates applied) and mate desktop environment. my problem is that in some applications special characters used in my mother tongue (polish) and, as i have some folders and files containing are not handled correctly.to be more specific: in mate-terminal, pluma (mate text editor) and caja (file manager) and probably a few others i just didn't happen to check, any polish special characters normally typed by alt+letter are either ignored (no character printed -- in pluma and caja) or replaced with a question mark (in mate-terminal). even vim, when run in mate-terminal, behaves this way, i.e. replaces special characters with question marks.i don't think this is a system-wide problem. why? because when i switch to another tty and try to input those special characters in the terminal i encounter no problems. the same folder which by mate-terminal is displayed as zdj?cia in another tty is correctly labeled zdjcia. it looks as though the problem is mate-specific, since vim, when run in terminator, doesn't cause any problems.furthermore, i've tried debugging this in the following manner: in mate-terminal i listed my home directory (containing files and directories with polish special characters) and redirected ls output to a test file. then i switched to another tty and cat the test file -- the characters were printed correctly.i've already tried dpkg-reconfigure locales. language packs have been installed (and reinstalled in the process) via mate control centre.what do i try next?edit:in mate-terminal in graphical environment:$ localelocale: cannot set lc_all to default locale: no such file or directorylang=en_gb.utf-8language=lc_ctype=en_gb.utf-8lc_numeric=\\pl_pl.utf-8\\lc_time=en_gb.utf-8lc_collate=en_gb.utf-8lc_monetary=\\pl_pl.utf-8\\lc_messages=en_gb.utf-8lc_paper=\\pl_pl.utf-8\\lc_name=\\pl_pl.utf-8\\lc_address=\\pl_pl.utf-8\\lc_telephone=\\pl_pl.utf-8\\lc_measurement=\\pl_pl.utf-8\\lc_identification=\\pl_pl.utf-8\\lc_all=in tty1 (where character encoding works fine):$ localelang=en_gb.utf-8language=en_gb:enlc_ctype=en_gb.utf-8lc_numeric=pl_pl.utf-8lc_time=en_gb.utf-8lc_collate=en_gb.utf-8lc_monetary=pl_pl.utf-8lc_messages=en_gb.utf-8lc_paper=pl_pl.utf-8lc_name=pl_pl.utf-8lc_address=pl_pl.utf-8lc_telephone=pl_pl.utf-8lc_measurement=pl_pl.utf-8lc_identification=pl_pl.utf-8lc_all=edit:grep -rs pl_pl /etc ~/.?* yields, after removing binary file x matches pattern and piping through sort | uniq:/etc/default/locale/etc/locale.alias/etc/locale.gen/etc/mdm/locale.conf/home/marta/../marta/.bash_history/home/marta/../marta/.config/user-dirs.locale/home/marta/../marta/.linuxmint/mintmenu/apt.cache/home/marta/../marta/.pam_environment/home/marta/../marta/.xsession-errors/home/marta/.bash_history/home/marta/.config/user-dirs.locale/home/marta/.linuxmint/mintmenu/apt.cache/home/marta/.pam_environment/home/marta/.xsession-errorsyes, the computer's not actually mine, but never mind :)yet another edit:the contents of files containing locale settings:$ cat /etc/default/localelang=en_gb.utf-8language=en_gb:enlc_numeric=pl_pl.utf-8lc_time=en_gb.utf-8lc_monetary=pl_pl.utf-8lc_paper=pl_pl.utf-8lc_identification=pl_pl.utf-8lc_name=pl_pl.utf-8lc_address=pl_pl.utf-8lc_telephone=pl_pl.utf-8lc_measurement=pl_pl.utf-8$ cat /home/marta/.pam_environmentlc_numeric=pl_pl.utf-8lc_time=en_gb.utf-8lc_monetary=pl_pl.utf-8lc_paper=pl_pl.utf-8lc_identification=pl_pl.utf-8lc_name=pl_pl.utf-8lc_address=pl_pl.utf-8lc_telephone=pl_pl.utf-8lc_measurement=pl_pl.utf-8$ cat /home/marta/.config/user-dirs.localepl_pl",
    "present_kp": [
      "locale",
      "character encoding",
      "mate",
      "lmde"
    ],
    "absent_kp": []
  },
  {
    "text": "fenics subdomains - restriction/ prolongation operators. i am trying to implement my own multigrid method in fenics. is there any smart/ fenics way how to assemble subdomains and obtain restriction/ prolongation operators ? thanks!",
    "present_kp": [
      "fenics",
      "multigrid"
    ],
    "absent_kp": [
      "finite element"
    ]
  },
  {
    "text": "how do i check if my site is banned in saudi arabia?. i have a website which allows sexuality explicit materials for some reason. recently, going through google analytics i realized that i stopped receiving traffic from saudi arabia. i'm very curious to know if saudi arabia blocked my domain name.how do i know or check if my site is banned in saudi arabia? i'd love find to some quick solution online where i can just insert my domain name into an input and check.",
    "present_kp": [],
    "absent_kp": [
      "domains"
    ]
  },
  {
    "text": "for an autocmd in a ftplugin, should i use pattern matching or ?. i have an autocmd for tex and markdown files to save the file automatically. nothing unusual:autocmd cursorhold *.tex,*.md whowever, as custom settings for these files increased, i split them off into ftplugin/tex.vim and ftplugin/markdown.vim: ftplugin/tex.vimautocmd cursorhold *.tex w ftplugin/markdown.vimautocmd cursorhold *.md wnow, these files are sourced only for the appropriate files, so the pattern matching is redundant. apparently, autocmds can be buffer-local. from :h autocmd-buffer-local:buffer-local autocommands are attached to a specific buffer. they are usefulif the buffer does not have a name and when the name does not match a specificpattern. but it also means they must be explicitly added to each buffer.instead of a pattern buffer-local autocommands use one of these forms: <buffer> current buffer <buffer=99> buffer number 99 <buffer=abuf> using <abuf> (only when executing autocommands) <abuf>that seems to be meant for such usage. now, both ftplugin/tex.vim and ftplugin/markdown.vim can have:autocmd cursorhold <buffer> wi'm not really concerned about the actual extension as long as the filetype is correct, so this saves me from having to worry about *.md and *.markdown and whatever other extensions are valid for markdown.is this usage of <buffer> correct? are there any pitfalls i should be aware of? will things get messy if i wipe a buffer and open another (hopefully the numbers won't collide, but )?",
    "present_kp": [
      "autocmd",
      "filetype"
    ],
    "absent_kp": []
  },
  {
    "text": "setfacl remove all write access. i want to remove all write access to files & directories for any user or group while preserving other permissions. is this possible?",
    "present_kp": [
      "files",
      "acl"
    ],
    "absent_kp": [
      "linux",
      "filesystems"
    ]
  },
  {
    "text": "concatenate three 16-bit integers in one 64-bit integer with c++. i am looking for an elegant alternative of the following code where wordxx contains always 16 bits:uint64_t wordhi = 0xaa; // i would like u_int16_t over u_int64_t hereuint64_t wordmi = 0xbb; // because it represents the real data betteruint64_t wordlo = 0xcc;uint64_t largeword = (wordhi << 32) + (wordmi << 16) + (wordlo << 0);to me this (very simplified) code looks a bit dirty, because reader gets confused about the real size of the wordxx data. i could store wordhi to largeword and then shift largeword and add wordmi and so on, but this would make the code worse and probably needs more cpu cycles. edit: changed u_int64_t to uint64_t in the example as suggested in the comments.",
    "present_kp": [
      "c++",
      "integer"
    ],
    "absent_kp": [
      "performance",
      "bitwise"
    ]
  },
  {
    "text": "why do haskell and scheme use singly-linked lists?. a doubly linked list has minimal overhead (just another pointer per cell), and allows you to append to both ends and go back and forth and generally have a lot of fun.",
    "present_kp": [],
    "absent_kp": [
      "data structures",
      "functional programming"
    ]
  },
  {
    "text": "need common platform: wiki, article, forum, quiz, news & a global dashboard. i am looking for a application to install in my server having the following features:'a global dashboardwikiarticleforumquiznewsleter (optional)q/a (optional)i already found a application: twiki, but looking for a better alternative.",
    "present_kp": [],
    "absent_kp": [
      "web applications",
      "looking for a script"
    ]
  },
  {
    "text": "what is an implementation plan?. i was recently given the task of creating an implementation plan document. when i asked for an example of one that i could look at, i was told to look at the project plan that had already been created an use that as a base. i'm still a bit confused on what i should be creating.can anyone point me to a good example out there or to something that explains what this is and more importantly the details about what it should contain.",
    "present_kp": [],
    "absent_kp": [
      "project management",
      "documentation"
    ]
  },
  {
    "text": "nfs shared folders - is it transitive?. if i have computer-a, and share a folder to be accessed by computer-b, can i take that same shared folder and share it with computer-c? computer-b has two itnerface cards, eth0, and eth1. eth0 is connected on the same network as computer-a, and eth1 is connected on an alternate network that computer c.computer-b is on both networks. computer-a <--> computer b <--> computer cplatform: ubuntu 10.04 thanks-manny",
    "present_kp": [
      "ubuntu",
      "nfs"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "how to package and add to tool to kali-rolling repositories?. i have created a framework that helps in penetration testing a while ago and it's pretty spreading.how could i package that framework and add/send it to kali repositories?i have searched and asked a lot till a security researcher i know told me that it could be done the same way in debian! i don't know how is that is done so any one could help?by the way, the framework is in this page <url> i don't know if that matters or not.thanks",
    "present_kp": [],
    "absent_kp": [
      "apt",
      "kali linux",
      "repository"
    ]
  },
  {
    "text": "why is each successive tree in gbm fit on the negative gradient of the loss function?. page 359 of elements of statistical learning 2nd edition says the below.can someone explain the intuition & simplify it in layman terms?questionswhat is the reason/intuition & math behind fitting each successive tree in gbm on the negative gradient of the loss function?is it done to make gbm more generalization on unseen test dataset? if so how does fitting on negative gradient achieve this generalization on test data?",
    "present_kp": [
      "gbm",
      "loss function"
    ],
    "absent_kp": [
      "machine learning",
      "optimization",
      "gradient descent"
    ]
  },
  {
    "text": "is my bst time zone an hour behind?. my system (gnome 3 on debian testing) is confused about the current time. when i run date the time is showing correctly but some applications are an hour behind the times. for instance, when i add an event to gnome calendar the event time shown in the calendar appointments will be the time i entered minus one hour.i've found out what the issue is but don't know how to solve it:$ date ; tz=gmt date ; tz=bst datesun 30 apr 11:25:37 bst 2017sun 30 apr 10:25:37 gmt 2017sun 30 apr 10:25:37 bst 2017the first two lines of the output are correct, the third is an hour behind. what i can't understand is why the bst time zone appears to be an hour behind while at the same time the current time is correct - and using bst.this may also be relevant:$ timedatectl status local time: sun 2017-04-30 11:33:07 bst universal time: sun 2017-04-30 10:33:07 utc rtc time: sun 2017-04-30 10:33:07 time zone: europe/london (bst, +0100) network time on: yesntp synchronized: yes rtc in local tz: noeditoutput of zdump /etc/localtime:$ zdump /etc/localtime/etc/localtime sun apr 30 12:22:53 2017 bst$ date ; tz=gmt date ; tz=bst datesun 30 apr 12:22:53 bst 2017sun 30 apr 11:22:53 gmt 2017sun 30 apr 11:22:53 bst 2017",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "systemd",
      "timezone"
    ]
  },
  {
    "text": "poly time superset of np complete language with infinitely many strings excluded from it. for any arbitrary np complete language is there always a polytime superset the complement of which is also infinite?a trivial version which does not stipulate the superset to have infinite complement has been asked at <url> purposes of this question, you can assume that $p e np$. as vor explained, if $p = np$ then the answer is no. (if $p = np$, then $x = \\{x \\mid x \\in \\mathbb{n^+} \\land x > 1\\}$ is np-complete. clearly there is no superset of $x$ which is infinite and has an infinite complement, as the complement of $x$ has only a single element.) thus we can focus on the case $p e np$.",
    "present_kp": [
      "np complete"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "structural complexity"
    ]
  },
  {
    "text": "removed label from message in gmail, and message disappeared!. i had one label on a message, and then i clicked remove label when that message was selected. now i can't find that message - it's not in the inbox, and of course not in the label that i removed from itcan someone explain to me what i did wrong and where my message is?",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "gmail labels"
    ]
  },
  {
    "text": "how to make highest rated the default on yelp.com. whenever i start a new search on yelp, it sets the sort order to best match. is there a way to have the default be highest rated instead?if i can't figure anything else out, i'll set up a keyword search in my browser with &sortby=rating included in the url, but some way to make this universal for my logged-in yelp account would be friendlier.",
    "present_kp": [
      "yelp.com"
    ],
    "absent_kp": [
      "sorting"
    ]
  },
  {
    "text": "question simplifying boolean expression. this is what i have so far, so i just want to know if i am doing everything right or wrong. i am novice in the topic.i have been given:$(a \\oplus b) \\land eg a \\lor a$xor = $\\oplus$by order of operations regroup:$(a \\oplus b ) \\land ( eg a \\lor a)$ // xor (~a b + a ~b) * ~a + a // distributive law(~a ~a b + ~a a ~b) + a // idempotent law~a b + a ~a ~b + a // inverse law~a b + 0 ~b + a ~a b + ais this statement right?",
    "present_kp": [],
    "absent_kp": [
      "boolean algebra"
    ]
  },
  {
    "text": "does printing a pdf to pdf degrade its quality?. say i have a pdf of a website which is very long. after reading some of it, i decide there are extraneous pages in it; but rather than finding the website every time i decide to eliminate a page, i want to print it to pdf and just not select that page to print (using cups-pdf). will this degrade the quality of the pdf, particularly if i were to do it multiple times? is there a better way to achieve what i am looking for? i have tried pdfedit, with mixed results, and would like something more reliable. of course, i can always just go back to the site and save a new version, using the same technique of neglected those pages that i don't want.",
    "present_kp": [
      "pdf",
      "cups"
    ],
    "absent_kp": []
  },
  {
    "text": "how does command < filename.txt look when passing filename into a command. i've got a scenario where i have command < filename.txt so i can pass the contents of filename.txt and use it in command. but say i want to take the contents out of the file and just use them in one command line action. how would it look?say the contents of filename.txt are as follows:to: <email> some messagei've tried stuff like command to: <email> message: some message with no luck. how do the contents of a text file look when they get parsed into a command in that way?",
    "present_kp": [
      "command line"
    ],
    "absent_kp": [
      "arguments"
    ]
  },
  {
    "text": "how would i create this function to choose a random variable from an array?. here is my attempt:rand_var() {printf %s ${${!1}[random % ${#${!1}[@]}]}}and i run it like thisarray=(something somethingelse test)rand_var arrayhowever, it tells me bad substitution. i think it may have something to do with the variables and quoting but i can't figure it out, i use ${!1} so that it acctually uses the contents of the variable and not just array. this line has worked before when i specify the variable name instead of ${!1}.",
    "present_kp": [
      "array"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "searching file based on data range. i previously posted requesting help with counting occurrences of a string. i'm now hoping to search for the occurrence of a string within a range of values and print out a similarly formatted file (the ranges below are sorted by the initial number in the range). 500506 genome 71445 71461 <phone> genome 308369 308384 <phone> genome 335450 335533 <phone> genome 425268 425293 <phone> genome 623326 623715 <phone> genome 308370 308384 <phone> genome 335462 335689 <phone> genome 425268 425290 0and i want to get a list showing the range, the number of times i see that range in my file, and which of the line identifiers has that range71445-71461 1 500506308369-308369 1 500506308370-308384 2 500506,5<phone>-335461 1 500506335462-335533 2 500506,502289335534-335689 2 500506,502289425268-425290 2 500506,502289425291-425293 1 500506in the example above, 502289 could be either exactly matching the same range as 500506, or may fall somewhere within that range, or vice versa. will this be do-able with a simple script? or should i be using something like a perl script instead?",
    "present_kp": [
      "search"
    ],
    "absent_kp": [
      "shell script",
      "awk"
    ]
  },
  {
    "text": "basic web calculator. i've built a calculator. i would not use angular or bootstrap because i am becoming addicted to them. i also wanted to check for double '.' use, and to limit the screens max text length but did not make it in time.i am new to javascript, css and html and would like to know how i am doing. <html> <body style=font-size: 40px; ><div style= max-width: 350px; class=bordered><div class=cont bordered> <label style=max-width:340px; id=screen>welcome!</label> </div> <div class=cont> <button class=bt onclick=code(7)>7</button> <button class=bt onclick=code(8)>8</button> <button class=bt onclick=code(9)>9</button> <button class=bt style=margin-left: 50px; onclick=code('+')>+</button> <button class=bt onclick=code('-')>-</button><button class=bt onclick=clr()>c</button> </div><div class=cont> <button class=bt onclick=code(4)>4</button> <button class=bt onclick=code(5)>5</button> <button class=bt onclick=code(6)>6</button> <button class=bt style=margin-left: 50px; onclick=code('*')>*</button> <button class=bt onclick=code('/')>/</button> </div><div class=cont> <button class=bt onclick=code(1)>1</button> <button class=bt onclick=code(2)>2</button> <button class=bt onclick=code(3)>3</button> <button class=bt style=margin-left: 50px; onclick=code('%')>%</button> <button class=bt onclick=code('(')>(</button> <button class=bt onclick=code(')')>)</button> </div><div class=cont> <button class=bt onclick=code(0) style= padding-right: 25px; padding-left: 25px;> 0 </button> <button class=bt style=; margin-left:2px; padding:0 10px 0 10px; onclick=code('.')>,</button> <button class=bt onclick=compiler() style= padding-right: 30px; padding-left: 30px; margin-left: 50px;> = </button></div></div></body><script > //regular expression for input controll and users value holder.var rg = new regexp(/\\d/);var codestr = ;//event listener for button presses and input controllvar code = function(str){ var tested = rg.test(codestr.substring(codestr.length-1)); var sstring = (codestr.substring(codestr.length-1)); (str==. && !tested ? codestr = codestr+0+str : ((rg.test(str) || str==( || str==)) ? codestr = codestr+str : (tested || sstring==( || sstring==)) ? codestr= codestr+str: restring(str) )) ; document.getelementbyid('screen').innerhtml = codestr;};function restring(str){ codestr = (codestr.substring(0,codestr.length -1))+str };//user input interpreter ( calculator logic )var compiler = function(){ var rezplz = new function('return '+codestr)(); codestr = +rezplz; document.getelementbyid('screen').innerhtml = codestr;};//clear buttonfunction clr(){codestr=; document.getelementbyid('screen').innerhtml = 0;}</script></html><style rel=stylesheet type=text/css>button{ font-size:40px; background-color: #fafafa;}.cont{ margin: 5px; padding-top:6px }.bt{ display: inline; padding: 0 5px 0 5px; margin-top: 0px; border: solid; border-width: 1px; border-color: blue; }.bt:hover{ background-color: darkblue; color:#f0f0f0; }.bordered{ border:solid; border-width: 2px; border-color : blue; outline:solid; outline-width:1px; outline-color:aqua; }</style>i know it's not mobile friendly, but that's what i get for doing a no-bootstrap project in short time.",
    "present_kp": [
      "javascript",
      "html",
      "css",
      "calculator"
    ],
    "absent_kp": []
  },
  {
    "text": "how does gmail store the new look flag?. we use google apps for domains, including gmail. some of our users have gotten the new look forced upon them already, but others still have a choice. i have one person who was given the choice, tried the new look, and then used the revert temporarily link to go back to the old interface. he now wants to use the new look, but he is not getting the link to switch. i'm assuming, since the url doesn't change when you change from old to new, that there's a cookie stored somewhere that lets gmail know which interface to display. what is that cookie?",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": []
  },
  {
    "text": "good dns hosting. we look after about 50 websites for clients on shared hosting. we'll soon be moving them to a dedicated server so i am looking for a good place to manage my dns records (the shared server is currently used as the nameserver too). i want something more reliable.i found dyndns and was looking at their small to medium business offering, does anyone have experience of using them? also i presume '100 records' means 100 a records, cnames etc, not 100 different domains (my dns knowledge is very limited).can anyone suggest a good provider for a design/web agency that manages the hosting for it's clients?thanksric",
    "present_kp": [
      "dns",
      "nameserver"
    ],
    "absent_kp": [
      "web hosting"
    ]
  },
  {
    "text": "data science conferences?. this is a similar question like the statistics conferences question at crossvalidatedwhat are the most significant annual data science conferences?rules:include a link to the conferenceplease include links for the talks (be it youtube, the conference site or some other video streaming site)",
    "present_kp": [],
    "absent_kp": [
      "community"
    ]
  },
  {
    "text": "would ordering multiple ip addresses increase my adsense income?. currently i manage a server housing multiple domains on one ip address.only one domain with relatively rich content has adsense. the remaining domains do not use adsense, and one domain consists of one page with no textual content (just an image).because one can find out domain names attached to an ip address, i was thinking of ordering extra ip addresses and putting the domain with adsense on its own ip and everything else on another so that google will think that the domains on the other ip address aren't part of the one with adsense on it, and therefore google will evaluate fewer pages thereby providing me with a higher income. am i being correct with what i mentioned or would ordering extra ip addresses and splitting the domains amongst them make no difference at all with adsense earnings?",
    "present_kp": [
      "domains",
      "ip address"
    ],
    "absent_kp": [
      "google adsense",
      "website design",
      "webserver"
    ]
  },
  {
    "text": "what is the difference between information and data?. from demystifying java..for many of us, the terms information and data are synonymous. however, information and data are distinctly different in programming. data is the smallest amount of meaningful information. can someone please give me an example that could help me out, and perhaps relate to a 14 year old? i sort of understand, but when i try to separate the two in my head, i'm having problems for some reason (probably thinking of them as the same for my whole life is the reason for this).",
    "present_kp": [
      "java",
      "data",
      "information"
    ],
    "absent_kp": []
  },
  {
    "text": "php review of object oriented geoip class. i wrote a little php wrapper class for geoip which looks like:<?phpclass geoip { private $ip; private $geo_ip_details; function __construct($ip) { $this->ip = $ip; $this->fetch(); } private function fetch() { if(filter_var($this->ip, filter_validate_ip)) { $curl = new curl(); $json = $curl->get_request(<url> . $this->ip, true); $result = json_decode($json); if($result !== null) { $this->geo_ip_details = $result; } } } public function __get($property) { if(property_exists($this, $property)) { return $this->$property; } } public function __tostring() { if(isset($this->geo_ip_details) && !empty($this->geo_ip_details)) { if(isset($this->geo_ip_details->city) && !empty($this->geo_ip_details->city) && isset($this->geo_ip_details->region_name) && !empty($this->geo_ip_details->region_name) && isset($this->geo_ip_details->country_name) && !empty($this->geo_ip_details->country_name)) { return $this->geo_ip_details->city . , . $this->geo_ip_details->region_name . . $this->geo_ip_details->country_name; } else if(isset($this->geo_ip_details->region_name) && !empty($this->geo_ip_details->region_name) && isset($this->geo_ip_details->country_name) && !empty($this->geo_ip_details->country_name)) { return $this->geo_ip_details->region_name . . $this->geo_ip_details->country_name; } else if(isset($this->geo_ip_details->country_name) && !empty($this->geo_ip_details->country_name)) { return $this->geo_ip_details->country_name; } } }}?>usage is like://constructor, and autocalls fetch()$geoip = new geoip('64.87.28.98');//getter of ip property print_r($geoip->ip);//getter of geo_ip_details propertyprint_r($geoip->geo_ip_details);//tostring of the class echo $geoip;basically, i am going back and forth on implementation details. should i expose fetch() publicly, and not automatically call it in the constructor? i.e.$geoip = new geoip('64.87.28.98');$result = $geoip->fetch();is using a getter a good idea? should i have a class method called stringify() instead of overriding the __tostring?also, right now, once you instantiate geoip with an ip address, there is no way to pass a new ip address into the existing object. you must instantiate a new geoip object. does making a method:public function set($ip) { $this->ip = $ip; $this->fetch();}make sense, or simply just do something like: $geoip = new geoip('new-ip-address');what is the best practice for object oriented design for this pattern?",
    "present_kp": [
      "php",
      "object oriented"
    ],
    "absent_kp": []
  },
  {
    "text": "prompt user to enter for his/her user password to execute non sudo terminal command. as the question asks i want to learn how to prompt users' password for nonsudo commandsedit: i think that i could not tell it clearly according to comments, so i will elaborate my request with example, for example i open terminal and type ls -l command, after pressing enter it should ask me user password i want this for every non-sudo commands.",
    "present_kp": [
      "terminal",
      "password"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "what would a pda be with a queue instead of a stack?. a while ago it occurred to me that the stack data model in a push-down automaton could be exchanged for a queue or deque model. i've explored this a bit as a pet project and it looks like an automaton with a deque model is tm equivalent. intuitively because analogous to moving a head over a fixed tape, the deque model allows for moving the tape under a fixed head. formally i think this could be proved nicely via equivalence with a dual stack pda.the queue model continues to puzzle me however, since it seems to define a class of languages quite different from the context-free languages (stack vs. queue seems to be analogous to nested vs. cross-serial character dependencies). i haven't been able to prove or disprove whether the queue model also accepts context-free languages though, so it might just as well turn out to be tm equivalent too. on the other hand i also couldn't construct the equivalents of the tm transition relations using the queue model, it seems to fall just short of 'full tm power'.at this point i've started going in circles, so i'm left with the question whether the queue model would really define a separate (not necessarily useful) class of languages or not. it seems a simple question but i haven't been able to find any conclusive literature on this, so i was hoping someone could point me to an answer to this question.",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "automata theory",
      "turing machines"
    ]
  },
  {
    "text": "how does one leverage vtx to disable screen capture?. i came across this cool feature while playing around with kaspersky '15. basically, when you launch a smart money protected browser (this browser is just a modified, clean install of chrome), if your computer hardware supports vtx, you are unable to take screenshots while the protected browser is running.i tried doing some research myself (furious googling, browsing re websites like kernelmode.info, etc...) but i couldn't figure out how they did it. for more details, check out their troubleshooting section about the technology: <url> anyone have any idea on how this is done? when i try to grab the screen, i just get an entirely black screenshot. i don't know how one can leverage vtx to accomplish such a task. are they just using vtx to hook all the screen capture syscalls?! or is there a more interesting way?i'll probably try to poke around with the kav drivers, but they definitely don't make it easy to re them.",
    "present_kp": [],
    "absent_kp": [
      "virtual machines"
    ]
  },
  {
    "text": "how can i enter visual mode *after* (or: to the right of) the cursor. let's say i am typing something, then realize that what i just typed will be repeated a couple of times.now, what i would like to do is to select backwards, yank (thereby returning to the position i started from), and immediately paste. however, when my last typed character is also the end of the line, i cannot move the cursor one space over, and going into visual mode starts the selection to the left of the cursor, which means that the last character i typed (usually a brace), will not get copied along with it.in spite of a long and fruitless search, i cannot come up with any way to start selecting after the cursor instead of in front of it.in vim, after all, you have i to start inserting before, and a to start inserting after the cursor. so if v is the equivalent of i, where is the equivalent of a to start selecting after the current character? no cheat sheets or tutorials i looked at had an answer.",
    "present_kp": [
      "vim"
    ],
    "absent_kp": []
  },
  {
    "text": "double screen: desktops moving with the mouse. i am running linux mint 17.1 rebecca, with cinnamon 2.4.5.i have a double screen: my laptop's screen, and another (dell) screen, both with resolution <phone>. i have a strange bug (maybe is it a feature, that i do not know how to deactivate!), and i have difficulties to explain it, so please tell me if you cannot make sense of my explanations. let me precise that my external screen is the primary screen, and the laptop screen the secondary screen. also, the laptop screen is on the right of the external screen. the bug occurs with mouse moves:when i log in, everything is displayed well. the mouse is on the primary screen.i move the mouse to the right on the external screen, up to the frontier between both screens, everything works well.then, if i continue to the right (going now to the laptop screen), the laptop screen displays what it should, but the external screens begins to display what is on the laptop screen also. what is displayed on the external screen begins to slide to the left (the left part is not visible anymore) and on its right, i see the same thing as the left part of the laptop screen.if i go all the way long to the right of the laptop screen, i end up with two identical screens, both displaying what the laptop is supposed to display.now if i make the inverse path, going to the left, nothing is going on as long as the mouse is on the laptop screen, and when it attains the external screen, the external screen begins to slide again, to the right this time, to display what it should. when the mouses attains the left edge of the external screen, i am back with the correct display.i wanted to put here a screenshot, but screenshots are (also...) working strangely, it is probably related.do you have any clues? dell precision m4700",
    "present_kp": [
      "linux mint",
      "cinnamon"
    ],
    "absent_kp": [
      "dual monitor"
    ]
  },
  {
    "text": "yellow appears as brown in konsole. for some reason, the yellow color color (ansi esc. code 33), appears for normal fonts as orange/brownish in my terminal (yakuake, konsole).for example, the command echo -e \\\\033[33mhello world\\\\033[0m returns an orange/brownish text hello world. bold yellow, however, appears as expected. in the following, small, sccreenshot, the hostname is on top of a yellow background, which is the escape code \\e[43m.another example, is the output of the command terminal-colors -o. it gives the output as seen in the larger screenshot below.i work with funtoo-linux and kde. though i have set some transparency (23%) i don't think this is a misleading of the eye issue. how can i troubleshoot this?relevant detailsin funtoo, the default bashrc, under /etc/bash/, contains:38:# set colorful ps1 only on colorful terminals.63: ps1='\\[\\033[01;31m\\]\\h\\[\\033[01;34m\\] \\w \\$\\[\\033[00m\\]'65: ps1='\\[\\033[01;32m\\]\\u@\\h\\[\\033[01;34m\\] \\w \\$\\[\\033[00m\\] 'echo $term returns xterm-256colorecho $ps1 is set to\\[\\e[0;30m\\e[45m\\] \\u \\[\\e[0;35m\\e[43m\\] \\[\\e[0;30m\\e[43m\\]@\\h \\[\\e[0;33m\\]\\[\\e[0;32m\\] \\w\\a\\[\\e[0;32m\\] \\[\\e[0m\\]the font used is irrelevant, as i have tried various onesif useful, dircolors returns:ls_colors='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.pdf=00;32:*.ps=00;32:*.txt=00;32:*.patch=00;32:*.diff=00;32:*.log=00;32:*.tex=00;32:*.doc=00;32:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:';export ls_colorsstrangely, there is a table in the post bash shell: change the color of my shell prompt under linux or unix, which describes the color code 0;33 as brown!updateperhaps more useful for 256 colors, is the output of terminal-colors -cn (or other parameters). in the screenshot below, the yellow background has been correctly set:",
    "present_kp": [
      "terminal",
      "colors",
      "konsole"
    ],
    "absent_kp": []
  },
  {
    "text": "looking for books on creating and understanding theorems targeted at computer science. in studying logic to understand verifying programs i have found that there are books on logic targeted at computer science e.g.logic in computer science: modelling and reasoning about systems mathematical logic for computer science computability and logic handbook of practical logic and automated reasoning with regards to books on understating theorems targeted at computer science i find only one that may fit. as i don't have the book i can't say for sure.handbook of logic and proof techniques for computer science are there any books for understating theorems targeted at computer science? in other words are there books for understating syntax, semantics and construction of theorems that don't rely on a heavy math background and that give examples more from the world of computer science and explain in a style more natural to a person in computer science.editafter seeking more on this topic i have come upon the phrases informal mathematics and mathematical discourse which are starting to turn up useful info from google. in particular the following: understanding informal mathematical discourse found at understanding informal mathematical proofs",
    "present_kp": [
      "logic",
      "proof techniques",
      "books"
    ],
    "absent_kp": []
  },
  {
    "text": "backup a sqlite database. i want to backup a single sqlite database daily up to 30 days back, but i also want to keep at least 2 backups at all times (i.e. if there have been no backups in the last 30 days because the database didn't change, i don't want to delete old backups).i came up with this simple script that is supposed to run as a daily cronjob:#!/bin/bashbackup_file=/path/to/db.sqlite3backup_dir=$home/backupstoday='date +%y-%m-%d'# less than 31 days old, i.e. 30 days or youngerif find $backup_file -type f -mtime -31 | grep -q .then find $backup_dir -type f -mtime +30 -exec rm {} \\;filast_backup=$(ls -t $backup_dir | head -1)if [ -n $last_backup ] && diff $backup_file $backup_dir/$(ls -t $backup_dir | head -1) >/dev/nullthen :else cp $backup_file $backup_dir/$today.sqlite3fii'm not sure if using a nop in the second then clause makes sense, but it seemed cleaner to me than wrapping the condition in a test and checking $?.the database is used by <20 people and not changed very often, but i'm not sure if i should lock the database anyways - and i'm also not sure how to lock it from a shell script.since this is the first bash script i've ever written for serious use, i'd appreciate any feedback on how it could be improved.",
    "present_kp": [
      "bash",
      "shell",
      "sqlite"
    ],
    "absent_kp": []
  },
  {
    "text": "why does my 9 months old site with more than 400 pages has pr0?. i have a paid applicants' testing site with average traffic of 40 visitors per day.the site is very legitimate and allows people to take technical tests based on a unique content our private community creates.the site runs in production for 9 months now, and i get some traffic from google.the thing that i fail to understand is that my pagerank is 0 (all this time).all the site's pages have special urls generated according to their content and we gave special seo attention to the pages using seomoz.what am i doing wrong? how can i tell what is the problem?the site name is codelect.net.",
    "present_kp": [
      "google",
      "pagerank"
    ],
    "absent_kp": [
      "search engines"
    ]
  },
  {
    "text": "when to use a singleton and when to use a static class. i've searched about this here and on stackoverflow and found some differences between the two.but i'm still not sure in what cases one would prefer a singleton, and in what cases one would choose to use a static class.(in languages which don't support 'static classes', like java, i'm obviously referring to classes containing only static methods and fields).please give me concrete examples of cases where you would pick each one, and explain why.",
    "present_kp": [
      "singleton",
      "static"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "possible solutions for sharing working copy of project between multiple computers?. so there are 3 computers that i use to work on this project with, my home pc, work pc, and work mac (for building to devices). the project has an svn repository that two other programmers use so i can't commit broken code to it. the lead doesn't know how to use version control so the trunk contains art assets and everything else in addition to the project itself, making branching impractical (and i wouldn't want to use svn for branching anyway). i would use git if i could but it is not an option. my question is, how can i go to work, update my working copy, work on it a bit, send it to my mac for building, then go home and work on it some more later- keeping in mind that i may go 1-2 days without being able to commit working code to the repository?",
    "present_kp": [
      "svn"
    ],
    "absent_kp": [
      "workflows"
    ]
  },
  {
    "text": "'ls -l' of a file and all the directories leading to it?. before i start writing a (probably easy) script, is there a command that does the equivalent of the following one:[:~/software/scripts] % ls -ld / /usr /usr/bin /usr/bin/tee drwxr-xr-x 21 root root 4096 mar 31 08:48 /drwxr-xr-x 11 root root 4096 jan 30 09:48 /usrdrwxr-xr-x 2 root root 73728 apr 14 07:54 /usr/bin-rwxr-xr-x 1 root root 26308 jan 16 2013 /usr/bin/teewithout having to manually type all the partial paths? the idea would be to be able to say ls --this-new-flag /usr/bin/tee or command -l /usr/bin/tee and having the output above --- showing the detailed listing of all partial path leading to the final one. a shell expansion trick that can output / /usr /usr/bin /usr/bin/tee given /usr/bin/tee will do, too.",
    "present_kp": [
      "shell"
    ],
    "absent_kp": [
      "bash",
      "zsh"
    ]
  },
  {
    "text": "chunk size when parallelizing disk access. when multiple threads/processes access read from the same hard drive concurrently, the hard drive needs to seek back and forth between the multiple files being read, which slows down the processes.is there a way to globally increase the size of chunks that are read at a time, so that the processes may run less parallel, but the slowdown from seeking is reduced?on ubuntu linux",
    "present_kp": [
      "linux",
      "disk"
    ],
    "absent_kp": [
      "hard disk",
      "scheduling"
    ]
  },
  {
    "text": "are writes to eventfd counted as io?. i am trying to reduce hard-disk activity on my system. running iotop shows that eclipse (the ide, latest version (luna)) is writing kilobytes of data every few seconds.so i ran strace on the eclipse process and the only writes that i can see are to a file-descriptor that points to eventfd.i am not familiar with eventfd, but it seems like an event bus of some sort. does write to it get accounted as a disk write?",
    "present_kp": [
      "io",
      "eclipse"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "logging in json effect on performance. i see more and more articles about logging in json. you can also find one on nodejs blog. why does everyone like it so much? i can only see more operations getting involved:a couple new objects being created.stringifying objects, which either involves calculating string length or multiple string allocations.gcing all the crap that was created.is there any test on performance when using json logging and regular string logging? do people use json (for logging) in enterprise projects?",
    "present_kp": [
      "logging",
      "json"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i port msvc++ code with non-dependent names in templates to linux?. i can deal with porting platform dependent functions. i have a problem that the compilers i tried on linux (clang and g++) do not accept the following code, while the msvc++ compiler does:template <class t>class base {protected: t value;};template <class t>class derived : public base<t> {public: void setvalue(const t& invalue){ value = invalue; }};int main(int argc, char const *argv[]){ derived<int> tmp; tmp.setvalue(0); return 0;}g++ error:main.cpp: in member function void derived<t>::setvalue(const t&):main.cpp:11:3: error: value was not declared in this scopei believe this due to the use of a non-dependent name (value) in the second class. more information.the problem is that i have a very large code base, in which this type of code is used very often. i understand that it is wrong when looking at the standard. however it is very convenient not having to write this-> or base<t>:: in front of every use of value. even writing using base<t>::value; at the start of the derived class is problematic when you use ~20 members of the base class.so my question is: are there compilers for linux that allow this kind of code (with or without extra compiler switches)? or are there small modifications that will allow this code to compile on linux?",
    "present_kp": [
      "c++",
      "templates"
    ],
    "absent_kp": []
  },
  {
    "text": "can mental exhaustion be measured?. i asked this question a long while ago, but i never got an answer to whether mental exhaustion can be measured. if mental exhaustion could be measured, it would mean that i would have a way of knowing the performance i can get out of my brain in a day. i would be able to know what is best for refilling my brain with energy (maybe tv is your best option after all...;) ) as far as i understand, different parts of the brain gets used for different purposes, so they should get exhausted at different times, so the measuring would have to be on specific regions of the brain or performance of the brain in various fields.",
    "present_kp": [
      "mental exhaustion"
    ],
    "absent_kp": []
  },
  {
    "text": "bring up shutdown menu of cinnamon via command line. how can i bring up the shutdown menu of cinnamon via command line?note: i don't want the user menu. this menu for switching or logging out a user is brought up via ctrl+alt+del.",
    "present_kp": [
      "command line",
      "shutdown",
      "cinnamon"
    ],
    "absent_kp": []
  },
  {
    "text": "two frameworks one repo. so i am going to use reactjs for the front-end for a web applicationthe application is mostly crud stuff but with some ajax ui etc.for the back-end i am using laravelright now i have both the front-end code and the back-end code in the same repository which works for me so far, but i get the feeling that i have two separate projects in the repo. both can/have a lot of dependencies etc.the structure looks like thisproject/ client/ front-end code... node_modules/ server/ vendor/ laravel... package.json webpack.config.js webpack.config.production.js etc.what would you do?",
    "present_kp": [],
    "absent_kp": [
      "architecture"
    ]
  },
  {
    "text": "retrieving value from html table. currently all this does is retrieve data from specific columns, the final result will be that i will check the data to make sure that it passes the test cases, but i want to look at this foreach right now and see if i can't make it a little simpler. a lot of what i have coded i have come back and turned into linq statements and made things a lot simpler (shorter), and i would really like to do the same with this foreach statement, but not real sure how to do it.i hate to admit that i am very new to using linq, i can read it for the most part but still have a little difficulty when writing more complex statements/queries.is there something that i can do to make this a lot more simple before i code any more on this scenario, i would like to simplify so that i don't write extraneous code that will be refactored out when i make this more clear.i have also been trying to find something that imports the html table into a nice neat object that i can query, but everything i have found so far has been similar to what i am doing or more complex than what i am doing here.[then(@see the '(.*)' of '(.*)')]public void thenseethe(string columnheader, string entryname){ var htmltable = ie.findelementbyclassname(table); var tableheaders = htmltable.findelements(by.tagname(th)); var rows = new list<list<string>>(); var htmlrows = htmltable.findelements(by.tagname(tr)); foreach (var htmlrow in htmlrows) { //first row holds the table headers if (htmlrow.findelements(by.tagname(th)).count > 0) { var thlist = tableheaders.select(th => th.text.tostring()).tolist(); rows.add(thlist); continue; } var cellsinrow = htmlrow.findelements(by.tagname(td)); var cells = cellsinrow.select(cell => cell.text.tostring()).tolist(); rows.add(cells); } var columnindex = rows.first().indexof(columnheader); var field = rows.where(x => x[0] == entryname).select(x => x[columnindex]).first(); if (columnheader == create utc date) { _createutc = convert.todatetime(field); } else if (columnheader == modify utc date) { _modifyutc = convert.todatetime(field); }}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "selenium",
      "specflow"
    ]
  },
  {
    "text": "shifting from no-www to www and browsers' password storage. i created a website having user-registration system and invited my friend to join it. i gave him the link of no-www version: <url> but now after reading this and this, i want to shift to <url> there's a problem. i saw that my browser is storing separate passwords for mydomain.com and <url>. so in my friend's browser his password must have been stored for no-www. that means after i shift to www and next time he opens the login page, his browser wouldn't auto-fill the username and password fields and there will also be an extra entry (of no-www) in his browser's database of stored passwords.can this be avoided? can i do something that will convey to browsers that <url> and mydomain.com are the same website? i already have a cname record for www pointing to mydomain.com but it seems that search engines consider cname as alias but browsers consider them as different websites, i don't know why.",
    "present_kp": [
      "browsers"
    ],
    "absent_kp": [
      "dns",
      "no www"
    ]
  },
  {
    "text": "rm command returns a message [1] 12345 what does this mean?. i'm trying to remove a file and i keep getting a message similar to:[1] 12345and nothing happens, i run a directory search (dir) and the file remains and i get a stopped message",
    "present_kp": [
      "rm"
    ],
    "absent_kp": [
      "command line",
      "filenames"
    ]
  },
  {
    "text": "accessing windows7_os partition from linux on a dual-boot. are there any limitations on accessing the windows7_os partition while i am booted on my linux os? occasionally i like to browse files that are on my windows partition or copy files to my linux drive without having to reboot. this appears safe, but is there any risk with doing such operations? sometimes i get ubuntu internal errors, and i don't know if this may contribute to the cause.i am running ubuntu 13.10 (saucy salamander) on a w520 thinkpad 7200 rpm 500 gb hdd. i have a typical partition pattern: system_drv | windows7_os | ubuntu_13.10 | swap space (7-8 gb) | lenovo recovery",
    "present_kp": [
      "partition",
      "windows"
    ],
    "absent_kp": [
      "dual boot",
      "ntfs"
    ]
  },
  {
    "text": "what strings should i look for in /var/log/auth.log?. i wrote a bash command to scan /var/log/auth.log for messages occurring on the current day indicating unauthorised access. currently it just fetches messages matching break-in and unauthorized.what other strings should i search for in /var/log/auth.log to keep tabs on unauthorized access?here's the script for reference:cat /var/log/auth.log|grep $(date|awk '{print $2 $3}')|grep -e '(break-in|invalid user|failed|refused|su|illegal)'edithere's the amended command based on justins suggestions and what i found through googlegrep $(date|awk '{print $2 $3}') /var/log/auth.log|grep -e '(break-in|invalid user|failed|refused|su|illegal)'",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "command line",
      "ssh",
      "authentication"
    ]
  },
  {
    "text": "is the clique problem np-complete also on bipartite or planar graphs?. we know that the clique problem is np-complete. is the restriction of the problem to bipartite graphs or planar graphs still np-complete?",
    "present_kp": [
      "graphs"
    ],
    "absent_kp": [
      "complexity theory",
      "graph theory",
      "np complete"
    ]
  },
  {
    "text": "append the matched text to the line. lets say i have a file called sample.txt which contains abbcacgrep -e ^b|c$ sample.txt gives me output asbcacnow i want the filter string to be added to the output.i want the output asbc,bac,chow can i achieve this ?",
    "present_kp": [
      "grep"
    ],
    "absent_kp": []
  },
  {
    "text": "masterviewcontroller. i plan on including this work in a portfolio. will this code get me hired or laughed at?more specifically:how would you rate the general complexity of the code?how bad does the code smell?is the vc too fat?glaring best practices mistakes?follow-up questions:can you expand on what you said about magic numbers? (totally missed the bool/bool usually i'm better than that. the names w/2 are just temp renames for so)i have a lot of .h files because i tried to refactor somethings, like animation and url methods, into helpers, presumably to increase readability. did i go overboard?in theory, the way the program is setup, the mastervc should never be deallocated. vc's are just pushed on top, not more than one layer at a time. is it still necessary to unsubscribe from notifications?lastly, on a scale of 1-10 what is your impression of the code overall? (from what you've seen and discounting the name and bool problem) details:ios: 6 (updating to 7 currently) xcode: 4.6tested: iphone 4 devicearc enabledmasterviewcontroller.h#import <uikit/uikit.h>#import srapi.h#import srchoicebox.h#import srposttopic.h#import srdetailviewcontroller.h#import srcollapsiblecell.h#import sranimationhelper.h#import sropentokvideohandler.h#import srobserveviewcontroller.h@interface srmasterviewcontroller2 : uiviewcontroller <uitableviewdelegate, uitableviewdatasource, srchoiceboxdelegate, srposttopicdelegate>@property (weak, nonatomic) iboutlet uitableview *topicstableview;@property (weak, nonatomic) iboutlet uiview *posttopiccontainer;@property (weak, nonatomic) iboutlet uilabel *statuslabel;@property (strong, nonatomic) nsindexpath *opencellindex;@property (strong, nonatomic) rkpaginator *paginator;@property (strong, nonatomic) sropentokvideohandler *opentokhandler;@endmasterviewcontroller.m#import srmasterviewcontroller2.h#import uiscrollview+svpulltorefresh.h#import uiscrollview+svinfinitescrolling.h#import srurlhelper.h#import srnavbarhelper.h@interface srmasterviewcontroller2 ()@property nsinteger offset;@property nsinteger totalpages;@property nsmutablearray *topicsarray;@property bool ispaginatorloading;@end@implementation srmasterviewcontroller2- (void)viewdidload { [super viewdidload]; [self configuretableview]; [self configurenavbar]; [self configureposttopiccontainer]; [srapi sharedinstance]; [self paginate]; self.opentokhandler = [sropentokvideohandler new]; [self configurenotifications];}- (void)configurenotifications { [[nsnotificationcenter defaultcenter] addobserver:self selector:@selector(receivenotifications:) name:kfetchnewtopicsandreloadtabledata object:nil]; [[nsnotificationcenter defaultcenter] addobserver:self selector:@selector(receivenotifications:) name:kfetchroomfromurl object:nil];}- (void)receivenotifications:(nsnotification *)notificaiton { if ([notificaiton.name isequaltostring:kfetchroomfromurl]) { nsurl *url = notificaiton.userinfo[@url]; [self fetchroomwithurl:url]; } else if ([notificaiton.name isequaltostring:kfetchnewtopicsandreloadtabledata]) { self.offset = 1; [self.topicstableview.infinitescrollingview startanimating]; [self paginate]; }}- (void)fetchroomwithurl:(nsurl *)url { nsdictionary *dict = [srurlhelper parsequerystring:[url query]]; srroom *room = [[srroom alloc] init]; room.position = (nsstring *)[url pathcomponents][3]; room.topicid = [url pathcomponents][2]; room.sessionid = dict[@sessionid]; [self performseguewithidentifier:@showdetail2 sender:room];}- (void)configurenavbar { //button displays container for posting topics uibarbuttonitem *rightposttopicbutton = [srnavbarhelper buttonfornavbarwithimage:[uiimage imagenamed:@logo] highlightedimage:nil selector:@selector(showposttopiccontainer) target:self]; self.navigationitem.rightbarbuttonitem = rightposttopicbutton; //suffle button - joins random room uibarbuttonitem *leftshufflebutton = [srnavbarhelper buttonfornavbarwithimage:[uiimage imagenamed:@shuffle.png] highlightedimage:[uiimage imagenamed:@shufflepressed.png] selector:@selector(joinrandomroom) target:self]; self.navigationitem.leftbarbuttonitem = leftshufflebutton;}- (void)joinrandomroom { nsmutablearray *activetopics = [nsmutablearray new]; srtopic *randomtopic = [srtopic new]; srroom *randomroom = [srroom new]; //find topics with people in them for (srtopic *topic in self.topicsarray) { if ([topic.agreedebaters integervalue] > 0 || [topic.disagreedebaters integervalue] > 0) { [activetopics addobject:topic]; } } int numberofactivetopics = activetopics.count; if (numberofactivetopics > 0) { //put user into a random active room int random = arc4random() % numberofactivetopics; randomtopic = (srtopic *)activetopics[random]; if (randomtopic.agreedebaters.intvalue > randomtopic.disagreedebaters.intvalue) { randomroom.position = @disagree; } else if (randomtopic.agreedebaters.intvalue < randomtopic.disagreedebaters.intvalue) { randomroom.position = @agree; } else { randomroom.position = [self randomlychooseagreedisagree]; } } else { //no active rooms, put user in a random room int random = arc4random() % self.topicsarray.count; randomtopic = (srtopic *)self.topicsarray[random]; randomroom.position = [self randomlychooseagreedisagree]; } randomroom.topicid = randomtopic.topicid; [self performseguewithidentifier:@showdetail2 sender:randomroom];}- (nsstring *)randomlychooseagreedisagree { int r = arc4random() % 2; return (r == 0) ? @agree : @disagree;}- (void)configuretableview { //set offset for loading tabledata self.offset = 1; //add pull to refresh controls uirefreshcontrol *refreshcontrol = [[uirefreshcontrol alloc] init]; [refreshcontrol addtarget:self action:@selector(refresh:) forcontrolevents:uicontroleventvaluechanged]; [self.topicstableview addsubview:refreshcontrol]; //add infinite scrolling [self addinfinitescrolling:self.topicstableview]; //close all cells self.opencellindex = nil; //smooth scrolling self.topicstableview.layer.shouldrasterize = yes; self.topicstableview.layer.rasterizationscale = [[uiscreen mainscreen] scale];}- (void)configureposttopiccontainer { //configure container for posting topics srposttopic *posttopic = [[srposttopic alloc]initwithframe:cgrectmake(0, 0, 320, 133)]; [self.posttopiccontainer addsubview:posttopic]; posttopic.delegate = self;}- (void)addinfinitescrolling:(uitableview *)tableview { [tableview addinfinitescrollingwithactionhandler: ^(void) { self.offset += 1; dispatch_async(dispatch_get_global_queue(dispatch_queue_priority_default, 0), ^{ [self paginate]; double delayinseconds = 0.8; dispatch_time_t poptime = dispatch_time(dispatch_time_now, delayinseconds * nsec_per_sec); dispatch_after(poptime, dispatch_get_main_queue(), ^(void) { [self.topicstableview.infinitescrollingview stopanimating]; }); }); }]; //configure infinite scrolling style self.topicstableview.infinitescrollingview.activityindicatorviewstyle = uiactivityindicatorviewstylewhitelarge;}- (void)refresh:(uirefreshcontrol *)refreshcontrol { self.offset = 1; self.opencellindex = nil; //stop refresh after successful ajax call for topics dispatch_async(dispatch_get_global_queue(dispatch_queue_priority_default, 0), ^{ [self paginate]; double delayinseconds = 1; dispatch_time_t poptime = dispatch_time(dispatch_time_now, delayinseconds * nsec_per_sec); dispatch_after(poptime, dispatch_get_main_queue(), ^(void) { [refreshcontrol endrefreshing]; }); });}- (void)paginate { // create weak reference to self to use within the paginators completion block __weak typeof(self) weakself = self; // setup paginator if (!self.paginator) { self.paginator.perpage = 20; nsstring *requeststring = [nsstring stringwithformat:@?page=:currentpage&per_page=:perpage]; self.paginator = [[rkobjectmanager sharedmanager] paginatorwithpathpattern:requeststring]; [self.paginator setcompletionblockwithsuccess: ^(rkpaginator *paginator, nsarray *objects, nsuinteger page) { nsmutablearray *topicsarraytemp = [objects mutablecopy]; weakself.ispaginatorloading = no; if (weakself.offset == 1) { [weakself replacerowsintableview:topicsarraytemp]; } else { [weakself insertrowsintableview:topicsarraytemp]; } [weakself.topicstableview.infinitescrollingview stopanimating]; } failure: ^(rkpaginator *paginator, nserror *error) { weakself.ispaginatorloading = no; [weakself.topicstableview.infinitescrollingview stopanimating]; [weakself.self noresults]; }]; } if (!weakself.ispaginatorloading) { weakself.ispaginatorloading = yes; [self.paginator loadpage:self.offset]; }}- (void)noresults { double delayinseconds = 0.6; dispatch_time_t poptime = dispatch_time(dispatch_time_now, delayinseconds * nsec_per_sec); dispatch_after(poptime, dispatch_get_main_queue(), ^(void) { [self performseguewithidentifier:@noresults sender:nil]; });}#pragma mark - posting a new topic//open/close container for posting topics- (void)showposttopiccontainer { [self.view endediting:yes]; cgrect newtableviewframe = self.topicstableview.frame; cgrect newposttopicframe = self.posttopiccontainer.frame; float duration, alpha; if ([self isposttopiccontaineropen]) { newtableviewframe.origin.y -= 133; newposttopicframe.origin.y -= 133; duration = .3; alpha = 0; } else { newtableviewframe.origin.y += 133; newposttopicframe.origin.y += 133; duration = .4; alpha = 1; } [uiview animatewithduration:duration delay:0 options:uiviewanimationoptioncurveeaseinout animations: ^{ self.posttopiccontainer.alpha = alpha; self.topicstableview.frame = newtableviewframe; self.posttopiccontainer.frame = newposttopicframe; } completion:nil];}- (bool)isposttopiccontaineropen { return (self.posttopiccontainer.frame.origin.y < 0) ? no : yes;}//update fading status uilabel at the bottom of the screen- (void)statusupdate:(nsstring *)message { self.statuslabel.text = message; [self.statuslabel.layer addanimation:[sranimationhelper fadeofsrmasterviewstatuslabel] forkey:nil];}//post a new topic to the server- (void)posttopicbuttonpressed:(nsstring *)contents { //set up params nsdictionary *newtopic = @{ @topic:contents }; //send new topic posting [[rkobjectmanager sharedmanager] postobject:nil path:@topics/new parameters:newtopic success: ^(rkobjectrequestoperation *operation, rkmappingresult *mappingresult) { if ([self isposttopiccontaineropen]) { //close post box if it's open [self showposttopiccontainer]; } [self statusupdate:@topic posted!]; } failure: ^(rkobjectrequestoperation *operation, nserror *error) { uialertview *alert = [[uialertview alloc] initwithtitle:@oops message:@we weren't able to post your shout. try again soon! delegate:nil cancelbuttontitle:@sure otherbuttontitles:nil, nil]; [alert show]; }];}//delegate for srchoicebox - user chooses agree/disagree/observe- (void)positionwaschoosen:(nsstring *)choice topicid:(nsnumber *)topicid { srroom *room = [[srroom alloc] init]; room.position = choice; room.topicid = topicid; if ([choice isequaltostring:@observe]) { [self performseguewithidentifier:@showobserve sender:room]; } else { [self performseguewithidentifier:@showdetail2 sender:room]; }}- (void)seguetoroomwithtopicid:(nsnumber *)topicid andposition:(nsstring *)choice { srroom *room = [[srroom alloc] init]; room.position = choice; room.topicid = topicid; if ([choice isequaltostring:@observe]) { [self performseguewithidentifier:@showobserve sender:room]; } else { [self performseguewithidentifier:@delete sender:nil]; }}- (void)prepareforsegue:(uistoryboardsegue *)segue sender:(id)sender { //close post topic container if ([self isposttopiccontaineropen]) { [self showposttopiccontainer]; } if ([[segue identifier] isequaltostring:@showdetail2] || [[segue identifier] isequaltostring:@showobserve]) { if (self.opentokhandler) { [self.opentokhandler safetlyclosesession]; } [[segue destinationviewcontroller] setopentokhandler:self.opentokhandler]; [[segue destinationviewcontroller] setroom:sender]; } sender = nil;}#pragma mark - uitableview- (nsinteger)numberofsectionsintableview:(uitableview *)tableview { return 1;}- (nsinteger)tableview:(uitableview *)tableview numberofrowsinsection:(nsinteger)section { return [self.topicsarray count];}- (void)insertrowsintableview:(nsmutablearray *)topics { if (topics.count < 1) { [self nonewresults]; return; } nsmutablearray *temp = [nsmutablearray new]; int lastrownumber = [self.topicstableview numberofrowsinsection:0] - 1; for (srtopic *topic in topics) { if (![self.topicsarray containsobject:topic]) { [self.topicsarray addobject:topic]; nsindexpath *ip = [nsindexpath indexpathforrow:lastrownumber insection:0]; [temp addobject:ip]; ++lastrownumber; } } [self.topicstableview beginupdates]; [self.topicstableview insertrowsatindexpaths:temp withrowanimation:uitableviewrowanimationtop]; [self.topicstableview endupdates]; if (temp.count == 0) { [self nonewresults]; }}- (void)nonewresults { int lastrownumber = [self.topicstableview numberofrowsinsection:0] - 1; [self statusupdate:@no new topics. check back soon!]; [self.topicstableview scrolltorowatindexpath:[nsindexpath indexpathforrow:lastrownumber - 6 insection:0] atscrollposition:uitableviewscrollpositiontop animated:yes]; self.offset--;}- (void)replacerowsintableview:(nsmutablearray *)topics { self.topicsarray = topics; [uiview animatewithduration:.3 delay:.5 options:uiviewanimationoptioncurveeaseinout animations: ^{ self.topicstableview.layer.opacity = 0; } completion: ^(bool finished) { self.topicstableview.layer.opacity = 1; [[self.topicstableview layer] addanimation:[sranimationhelper tableviewreloaddataanimation] forkey:@uitableviewreloaddataanimationkey]; [self.topicstableview reloaddata]; }];}- (uitableviewcell *)tableview:(uitableview *)tableview cellforrowatindexpath:(nsindexpath *)indexpath { nsstring *cellidentifier2 = @srcollapsiblecellclosed; srcollapsiblecell *cell = [tableview dequeuereusablecellwithidentifier:cellidentifier2]; if (cell == nil) { cell = [[srcollapsiblecell alloc] initwithstyle:uitableviewcellstyledefault reuseidentifier:cellidentifier2]; } srtopic *topic = [self.topicsarray objectatindex:indexpath.row]; [cell updatewithtopic:topic]; if ([self iscellopen:indexpath]) { cgaffinetransform transformation = cgaffinetransformmakerotation(m_pi / 2); cell.arrow.transform = transformation; if (![self haschoicebox:cell]) { [self insertchoicebox:cell atindex:indexpath]; } } else { cgaffinetransform transformation = cgaffinetransformmakerotation(0); cell.arrow.transform = transformation; } return cell;}- (void)tableview:(uitableview *)tableview didselectrowatindexpath:(nsindexpath *)indexpath { if ([self iscellopen:indexpath]) { [self closecellatindexpath:indexpath]; } else { nsindexpath *opencell = self.opencellindex; nsindexpath *newopencell = indexpath; [self closecellatindexpath:opencell]; [self opencellatindexpath:newopencell]; } [tableview beginupdates]; [tableview endupdates]; [tableview deselectrowatindexpath:indexpath animated:no];}- (cgfloat)tableview:(uitableview *)tableview heightforrowatindexpath:(nsindexpath *)indexpath { if ([indexpath isequal:self.opencellindex]) { return 217.0; } else { return 63.0; }}- (void)rotatecellarrowatindexpath:(nsindexpath *)indexpath willopen:(bool)willopen animated:(bool)animated { // change arrow orientation srcollapsiblecell *cell = (srcollapsiblecell *)[self.topicstableview cellforrowatindexpath:indexpath]; cgaffinetransform transformation; if (willopen) { transformation = cgaffinetransformmakerotation(m_pi / 2); } else { transformation = cgaffinetransformmakerotation(0); } if (animated) { [uiview animatewithduration:.2 delay:0 options:uiviewanimationoptioncurvelinear animations: ^{ cell.arrow.transform = transformation; } completion:nil]; } else { cell.arrow.transform = transformation; }}- (bool)iscellopen:(nsindexpath *)indexpath { return [indexpath isequal:self.opencellindex];}- (void)closecellatindexpath:(nsindexpath *)indexpath { [self rotatecellarrowatindexpath:indexpath willopen:no animated:yes]; [self removesrchoiceboxfromcellatindexpath:indexpath]; self.opencellindex = nil;}- (void)opencellatindexpath:(nsindexpath *)indexpath { [self rotatecellarrowatindexpath:indexpath willopen:yes animated:yes]; srcollapsiblecell *cell = (srcollapsiblecell *)[self.topicstableview cellforrowatindexpath:indexpath]; [self insertchoicebox:cell atindex:indexpath]; self.opencellindex = indexpath;}- (void)removesrchoiceboxfromcellatindexpath:(nsindexpath *)indexpath { srcollapsiblecell *cell = (srcollapsiblecell *)[self.topicstableview cellforrowatindexpath:indexpath]; for (id subview in cell.srcollapsiblecellcontent.subviews) { if ([subview iskindofclass:[srchoicebox class]]) { [subview removefromsuperview]; } }}- (void)insertchoicebox:(srcollapsiblecell *)cell atindex:(nsindexpath *)indexpath { srchoicebox *newbox = [[srchoicebox alloc] initwithframe:cgrectmake(0, 0, 310, 141)]; srtopic *topic = [self.topicsarray objectatindex:indexpath.row]; [newbox updatewithsrtopic:topic]; newbox.delegate = self; [cell.srcollapsiblecellcontent addsubview:newbox];}- (bool)haschoicebox:(srcollapsiblecell *)cell { for (uiview *subview in cell.srcollapsiblecellcontent.subviews) { if ([subview iskindofclass:[srchoicebox class]]) { return true; } } return false;}@end",
    "present_kp": [
      "ios"
    ],
    "absent_kp": [
      "objective c",
      "interview questions"
    ]
  },
  {
    "text": "change rss name for yahoo pipe. i use yahoo pipes to filter my tech news rss feeds. i run the pipe serveral times with different feed urls via the user input module.here is the pipe: <url> when i subscribe to the pipe output via feedly, it always shows the pipe title instead of the rss feed name. see here:i already renamed the feed in google reader and/or feedly but it doesn't affect the title display when i select the feed.my question is: how do i change the title of the output rss feed?",
    "present_kp": [
      "rss",
      "yahoo pipes"
    ],
    "absent_kp": []
  },
  {
    "text": "avoid starvation using flock with 2 process with write and read lock. i have two scripts let's call them script1 and script2.the script1 is scheduled every 2 minutes and it takes 4 minutes to execute the script2 is scheduled every 30 minutes and it takes 4 minutes to execute. at the moment i'm using flock within the scripts to assure that script1 and script2 never run concurrently. however the exclusiveness of the write lock cause the script1 to never be executed concurrently as well. in my case i would like to allow parallelism of script1 and non concurrency with script2. if i use read lock between the instances of script1 the problem is that i will cause a starvation for script2 that it will never be executed.is there a clever way to do that?that is once a write lock is asked the following read lock are not granted? because this is the problem while script2 wait for a write lock there are other instances of script1 that are able to get the read lock and the script2 instance wait for ever",
    "present_kp": [
      "lock"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "how to search in visual mapping?. i am trying to create a text object for consecutive lower-case letters.here is how i am setting up the inner text object:xnoremap in :<c-u>normal! ?[^a-z]?e+1<cr>v/[^a-z]/s-1<cr>onoremap in :normal vin<cr>the following shows what happens when i type vin:[text] some important text[cursor] |[expected selection] ^^^^^^^^^[actual selection] ^^^^i then tried the following with the same text and cursor position\u270c\ufe0f<c-u>normal! ?ithe cursor didn't move. i expected it to.searching forward doesn't work either\u270c\ufe0f<c-u>normal! /thowever all these work\u270c\ufe0f<c-u>normal! bv:<c-u>normal! ev:<c-u>normal! fiv:<c-u>normal! fthow can i solve this?",
    "present_kp": [],
    "absent_kp": [
      "cursor motions",
      "visual mode"
    ]
  },
  {
    "text": "do jax ws implementation classes come as part of the java 5/6 package or only as part of an application server libraries?. do jax ws implementation classes come as part of the java5 package, as part of the java6 package or only as part of an application server libraries like was?i read that it comes as part of java ee? what does that mean? java 5?",
    "present_kp": [
      "java",
      "java ee"
    ],
    "absent_kp": [
      "web services"
    ]
  },
  {
    "text": "how title structure and separators affect seo. when viewing a topic on my blog it has a title like:<title>topic : cakephp &bull; blog &bull; driz - cameron drysdale</title>which produces:topic : cakephp blog driz - cameron drysdalei use a bullet point to separate the sections of the site, so the topic, notebook, and the sitename, and then a colon to separate the topic itself from the topic prefix. you'll also notice that the sitename is split in two using a dash, as the sitename itself is driz, but it's a personal site so i have also included my name into the title.now the question is... how will my use of seperators affect seo? i've followed the advice of making sure the most relevant part of the title is first e.g. the topic section (although perhaps the topic itself cakephp should be first?) but wondered if search engines like google or bing had preferences when it comes to dashes vs colons vs bullets...any advice? suggestions?some examples of other titles in the site:a blog post called animate location hash:animate location hash blog driz - cameron drysdalethe about me page:about cameron drysdale driz - cameron drysdaleor does the separators not affect things at all?",
    "present_kp": [
      "seo",
      "title"
    ],
    "absent_kp": []
  },
  {
    "text": "persistent object using localstorage. the goal is tomake an object that persists upon page reloads,have an interface as close as possible to the object class.function persistentobject(key,initial_value)//use for(..in data.keys()) instead of for(..in data){ var ret; if(localstorage[key]) ret=json.parse(localstorage[key]); if(!ret) ret = initial_value; if(!ret) ret = {}; //json.stringify ignores put and keys functions ret.put=function() { localstorage[key]=json.stringify(this) }; ret.keys=function() { var res = {}; for(var prop in this) if(this[prop] !== this.put && this[prop] !== this.keys) res[prop]=true; return res; }; return ret;}the code is used as follows:var mypersistentobject = new persistentobject('mypersistentobject');var mypersistentarray = new persistentobject('mypersistentarray',[]);unfortunately there is afaik no way to get the name of the variable and therefore the name of the variable needs to be passed as first argument.also unfortunate is that the function keys needs to be called in order to iterate over the object. i'm aware of the defineproperty function that allow to add a propoerty that is not enumerable but afaik cross browser compability is an issue with defineproperty.",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "browser storage"
    ]
  },
  {
    "text": "determine the color of last bean in a tin. i have write a program to determine the color of last bean from a tin (char[] beans). beans in a tin are only green or blue.the rule is: if two beans taken out are both greens or blues, put 1 blue bean back, else put the green one back. repeat until there are only 1 bean left. i don't know whether my code is right or not.public class coffeetingame { /** constant value for the green bean*/ private static final char green = 'g'; /** constant value for the blue bean*/ private static final char blue = 'b'; /** constant for removed beans */ private static final char removed = '-'; public static void main(string[] args) { char[] beans = { green, blue, blue, green, green }; // count number of greens int greens = 0; for (char b : beans) { if (b == green) greens++; } // the expected last bean final char last = (greens % 2 == 1) ? green : blue; // print the content of tin before the game textio.putf(tin before: %s %n, arrays.tostring(beans)); // perform the game char lastbean = tingame(beans); // print the content of tin and last bean textio.putf(tin after: %s %n, arrays.tostring(beans)); // check if last bean as expected and print if (lastbean == last) { textio.putf(last bean: %c , lastbean); } else { textio.putf(oops, wrong last bean: %c (expected: %c)%n,lastbean,last); } } private static int taketwo(char[] tin) { do { int bi1= (int)(math.random()*tin.length); } while (tin[bi1] != removed); return b1; do { int bi2= (int)(math.random()*tinlength); } while (tin[bi2]!=removed || bi2!=bi1); return bi2; } private static char tingame(char[] tin) { int count = tin.length; while (count >= 2) { // remove b1, b2 from tin int bi1, bi2= taketwo(beans); b1 = tin[bi1]; b2 = tin[bi2]; tin[bi1] = removed; tin[bi2] = removed; if (b1 == blue && b2 == blue|| b1 == green && b2 == green) { // put b in bin tin[bi2] = blue; } else { // bg, gb // put g in bin tin[bi2] = green; } count = count-1; } return tin; }}",
    "present_kp": [],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "correctness of the greedy algorithm. i am trying to solve the following problem:given a matrix which consists of only 0's and 1's. considering the matrix as a metal sheet, we need to cut-out square blocks of sizes 2x2 consisting of only 0's from it. a 1 in the sheet (represented by the matrix) indicates that we cannot cut the region out from the sheet. given such a matrix, find the maximum number of blocks which can be extracted.for instance, if the given matrix is:there can be 2 blocks which can be extracted out of this.my solution:i am using a greedy algorithm to solve the problem. i traverse from all the corners of the matrix (top-left, top-right, bottom-left, bottom-right) - one by one, extracting out the blocks on a first encountered first extracted basis. finally i return the maximum of the 4 values that i get. from each corner, i traverse an entire row first (horizontally), only then i move up or down in the matrix.the algorithm is as follows:1) starting from the top-left corner of the matrix (0,0), i iterate along all the columnsin this row from left to right. 2) if a zero is encountered at a position (i,j), i check if this is a possible contender to be the top-left corner of a 2x2 block consisting of all zeros -which would be the case when values at (i, j+1), (i+1, j) and (i+1, j+1) are all zeros.3) if it is, i fill the 2x2 block {(i,j), {i,j+1), (i+1,j), (i+1,j+1)} with 1's, and acounter is incremented.4) steps 2 through 3 are repeated for all rows from the top to bottom.5) i restore the original matrix in the problem, and start again from the top-right corner of the matrix (0, n) - n being the number of columns in the matrix, and iterate along all the columns in this row, from right to left.6) if a zero is encountered at a position (i,j), i check if this is a possible contender to be the top-right corner of a 2x2 block consisting of all zeros - which would be the case when values at (i, j-1), (i+1, j) and (i+1, j-1) are all zeros.7) if it is, i fill the 2x2 block {(i,j), {i,j-1), (i+1,j), (i+1,j-1)} with 1's, and adifferent counter is incremented.8) steps 6 through 7 are repeated for all rows from the top to bottom.9) likewise, the matrix is traversed two more times from bottom-left and bottom-rightcorners, checking for a '0', which can be a possible bottom-right or bottom-left cornerfor a 2x2 block consisting of all zeros. each of these matrix traversals are performed onthe original matrix given in the problem - i.e. changes made in top-left traversal are discarded while traversing the matrix from top-right and so on.10) the 4 traversals of the matrix give us 4 different counters, and the maximum ofthese 4 values is returned as the result.so far i have not been able to come with a test case which shows that the algorithm is incorrect. as i am not very good with proving correctness of algorithms, i need some help to figure out if this algorithm is correct.thanks!",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "correctness proof",
      "greedy algorithms"
    ]
  },
  {
    "text": "making thousands of dom elements draggable with javascript. this is a very simple implementation of dragging elements in html/js. i'm working on a web application that could have thousands of draggable elements on screen at any given time.currently, this code works perfectly as shown below (with only one draggable element), however if i copy and paste that element (<span class=draggable>this is draggable</span>) a few thousand times (i've been using around 4000 for testing) page load is significantly slower, and the framerate slows considerably. i can understand the page load slowing due to the number of elements, but is there anything that can be done to ensure the frame rate remains smooth while dragging an element given large numbers of draggable elements in the dom?note - the implementation here deliberately ignores various issues like scrolling and so on that i will be implementing later, and i believe will have a largely negligible effect on performance. if that's an incorrect assumption please let me know.dragdrop.html<!doctype html><html> <head> <title>drag + drop</title> <link rel=stylesheet type=text/css href=dragdrop.css /> </head> <body> <div id=draggableitemcontainer class=noselect> <span class=draggable>this is draggable</span> </div> <script src=<url> <script type=text/javascript src=dragdrop.js></script> </body></html>dragdrop.cssspan { position:absolute; background: #ff8888; cursor: pointer;}.noselect { -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}dragdrop.jsvar dragdrop = (function() { var elementbeingdragged; var clickpointoffsetx; var clickpointoffsety; function _dragging(e) { elementbeingdragged.style.left = (e.clientx - clickpointoffsetx) + px; elementbeingdragged.style.top = (e.clienty - clickpointoffsety) + px; } function _stopdrag(e) { document.removeeventlistener('mousemove', _dragging); document.removeeventlistener('mouseup', _stopdrag); } function startdrag(e) { elementbeingdragged = this; document.addeventlistener('mouseup', _stopdrag); document.addeventlistener('mousemove', _dragging); var rect = elementbeingdragged.getboundingclientrect(); clickpointoffsetx = e.clientx - rect.left; clickpointoffsety = e.clienty - rect.top; } var publicapi = { startdrag: startdrag }; return publicapi;})();$(function() { $('#draggableitemcontainer').on('mousedown', '.draggable', dragdrop.startdrag);});",
    "present_kp": [
      "javascript",
      "performance",
      "html",
      "dom"
    ],
    "absent_kp": [
      "jquery"
    ]
  },
  {
    "text": "shortest path with exactly $k$ edges. from skiena's book the algorithm design manual, chapter 6, problem 22:let $g = (v,e,w)$ be a directed weighted graph such that all the weights are positive. let $v$ and $u$ be two vertices in $g$ and $k \\leq |v|$ be an integer. design an algorithm to find the shortest path from $v$ to $u$ that contains exactly $k$ edges. note that the path need not be simple, and is permitted to visit vertices and edges multiple times.this is not homework, its me preparing for an interview. i have no clue how to approach this.",
    "present_kp": [
      "shortest path"
    ],
    "absent_kp": [
      "algorithms",
      "graph theory"
    ]
  },
  {
    "text": "concatenate all commentary about source files in a directory tree. i am working on a multitude of projects involving codes in fortran. they are in a directory tree involving 10 to 20 folders, each of the codes is in a 'src' folder.what i am looking for is a simple command that i could run at the root of the arborescence to go fetch all relevant information about the programs. this information is commented in the head of the .f or .f90 files, but of course it can run on a different number of lines in each file.a difficulty is that it is not always at the very head of the file, since there are sometimes modules first. but the information always recalls the name of the file, or at least contains the word 'main'.more precisely, let's say the arborescence is as follows :/|-folder1/ |-program1.f|-folder2/ |-program2.f90in program1.f i need the following block :cc program1 does the followingc blah blahc(this might be a capital c)and in program2.f90 i need the following :!! program2 does the following! blah blah!perhaps, there is a regular expression which could be used to fetch the full notice block?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "programming"
    ]
  },
  {
    "text": "ssh key required for every connection. i installed an ssh key on my machine to connect to a server, why does it ask me to insert the password for that key even if i am trying to connect to a different server?",
    "present_kp": [
      "ssh"
    ],
    "absent_kp": [
      "sshd",
      "ssh keygen"
    ]
  },
  {
    "text": "prove or disprove that every $l$ in this class is a cfl iff $l$ is equivalent to a substitution. let $l$ be a language with every string of the form $(w_i\\#)^*$ with $w_i\\in\\{0,1\\}^*$. set $w'\\sim w$ if there is a permutation $\\pi_1$ such that $w_i=w'_{\\pi_1(i)}$ for all $i$. if additionally $\\mid w_i\\mid=n$ for all $i$, then set $w'pprox w$ if also $\\mid w'_i\\mid=n$ for all $i$ and there are permutations $\\pi_1,\\pi_2$ such that $w_i[j]=w'_{\\pi_1(i)}[\\pi_2(j)]$. $l$ is closed under $\\sim$ and $pprox$.for example, if $100\\#0000\\#$ is in $l$, so is $0000\\#100\\#$. if $100\\#110\\#$ is in $l$, so are $110\\#100\\#$, $010\\#011\\#$, $011\\#010\\#$, etc. additionally, set $w'owtie w$ if $w'\\sim w$ and $\\mid w_i\\mid_1=\\mid w'_{\\pi_1(i)}\\mid_1$ for all $i$ ($\\mid \\cdot\\mid_1$ means ''number of 1's). $l$ is not closed under $owtie$. my question is: are there context-free languages $l$ with these properties such that $l$ can not be written as a substitution $s(l_1)$ where $s(a)=l_a\\#$ for some $l_1$ and $l_a$? is it true that such an $l$ is context-free if and only if it is a substitution? i think this in fact equivalent to the conjecture that if $l$ is closed under $\\sim$ and $pprox$ and context-free, then it is in fact closed under $owtie$. (the intuition being: how else could the permutation invariance be enforced context-freely unless a side effect of $owtie$-closure?).i have been trying to think about this in terms of matching relations ([1]). the idea is that a language is context-free if and only if for every string there is a matching (non-crossing pairing relation) and a first-order sentence that they together satisfy (so this sentence basically says that the arcs of the matching correspond to productions). if $l$ can be written as a substitution, every string will have matching where $\\#$'s are paired and the symbols of every $w_i$ are paired up with symbols in the same $w_i$. i'm trying to show that if there are arcs that cross over a $\\#$, (which means there are productions that generate symbols in distinct subwords), then there is a contradiction with the invariance properties.[1] lautemann, clemens, thomas schwentick, and denis thrien. logics for context-free languages. computer science logic. springer berlin heidelberg, 1995.",
    "present_kp": [],
    "absent_kp": [
      "formal languages",
      "context free",
      "formal grammars"
    ]
  },
  {
    "text": "how to reference one object with two interfaces?. suppose i have two interfaces i and j that is implemented by test class. now i need one object of class test that is referenced by i and j both interfaces. i can do it by singleton design pattern. but the problem is sometime i won't need a single object in the program. so there is also another approach that i have known. i i = new test();i.dosomething();j j = (j) i;j.print();my question, is there any better way to do this ? ...update...public interface i {void dosomething();}public interface j {void print();}public class test implements i, j{private int a;@overridepublic void dosomething() { a += 10;}@overridepublic void print() { system.out.println(this.a);}}...update...public class main { public static void main(string[] args) { i i = new test(); foo(i); j j = (j) i; ffoo(j);}/*** this method has business with only the dosomething method that * implement the test class. this method has not nothing with the print* method that is in the test class. so it would be well that only pass * the i interface to the foo method. */public static void foo(i i) { i.dosomething();}public static void ffoo(j j) { j.print();}}",
    "present_kp": [],
    "absent_kp": [
      "object oriented design",
      "coding standards"
    ]
  },
  {
    "text": "dhcp server with static ip not resolving hostnames (clients do). network setupi have a server which i am trying to set up lxcs oni am using lxd which forces me to use dhcpdhcp is working fine alreadydue to my setup i need to be able to access the containers using their hostnamesthis works now using the .local tldproblemthe problem now is that i need to access the containers using their hostnames from the host too which does not receive it's configuration from the dhcp server. currently this does not work.editthis does work when i set the dns server of the host interface to it's own ip. i still cannot ping the host from anywhere.workaroundi could just put the host with it's ip in the host's /etc/hosts file, but i am not sure if this is the right way to do it.host setupthe host is running gentoo gnu/linux 4.1.5 (openrc)./etc/conf.d/net looks as follows:dns_servers=8.8.8.8 8.8.4.4config_eth0=<static ip>routes_eth0=default via <static gateway>fallback_eth0=dhcprc_net_lxcbr0_provide=!netconfig_lxcbr0=10.2.0.1/24brctl_lxcbr0=setfd 0sethello 10stp offbridge_lxcbr0=dns_domain_lxcbr0=localdns_servers_lxcbr0=10.2.0.1 8.8.8.8 8.8.4.4dnsmasq is configured like this (comments removed):local=/local/interface=lxcbr0listen-address=10.2.0.1expand-hostsdomain=local,10.2.0.0/24dhcp-range=10.2.0.2,10.2.0.128,255.255.255.0,12hdhcp-range=<static ip range>, 12henable-racontainer setupthe containers just run their dhcp client.hostnameslet's just assume those:hostcont1cont2pingsthe upper row shows who is pinged.the left column shows who is pinging.pings are run in the form ping <machine>.local e.g.: ping host.local.+-------+-------+-------+-------+| | host | cont1 | cont2 |+-------+-------+-------+-------+| host | no | yes | yes |+-------+-------+-------+-------+| cont1 | no | yes | yes |+-------+-------+-------+-------+| cont2 | no | yes | yes |+-------+-------+-------+-------+",
    "present_kp": [
      "linux",
      "dns",
      "gentoo",
      "dhcp"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "how to transform a text file into a picture. if i have a plain text file, how can i convert it to an image file through the command line? (and preserve the layout of the ascii art in it)",
    "present_kp": [
      "command line"
    ],
    "absent_kp": []
  },
  {
    "text": "inverting an image. the problem is that i am trying to modify the code to invert the image in c and optimize it to make it run faster than the original by any method i could think of. after tried to use blocking and loop unrolling, it still does not seem to speed up. maybe i did it in a wrong way as i'm not really fully understanding these methods.void invert(int width, int height, char *code){ int x, y, z; int i, n; char rgb[4]=rgb; for (z=0; z<3; z++) for (y=0; y<width; y++) for (x=0; x<height; x++) { b[x][y][z] = a[x][y][z]; n = strlen(code); for(i=0; i<n; i++) { if (code[i]==rgb[z]) { b[x][y][z] = 255 - a[x][y][z]; } } } return;}void invert_optimized(int width, int height, char *code){ int x, y, z , xx , yy; int i, n; char rgb[4]=rgb; for (z=0; z<3; z++) for (xx=0; xx<height; xx+=4) for (yy=0; yy<width; yy+=4) for (x=xx; x<4+xx; x++) for (y=yy; y<4+yy; y++) { c[x][y][0] = a[x][y][0]; c[x][y][1] = a[x][y][1]; c[x][y][2] = a[x][y][2]; n = strlen(code); for(i=0; i<n; i++) { if (code[i]==rgb[z]) { c[x][y][z] = 255 - a[x][y][z]; } } } return;}i also was thinking about inline, but the problem is that i don't know how to implement it for this code and i don't think it will work for this either.",
    "present_kp": [
      "c",
      "image"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "ntp minpoll and maxpoll only communication but not really synchronize,isn't it?. my question,minpoll and maxpoll only communication but not really synchronizehello my friends,i have a problem want to know,why ntp syncorized from uppper stratum ntp server so slowly??minpoll ,maxpoll at my view is not really synchronize and do adjust system's time to correct ,but only communication with upper ntp server and after almost 10-20mins really do synchronize and adjust system's time by upper ntp servermy question is can i adjust my client server's parameter to make my client to synchronize from upper ntp server frequently?issuebellow is just a test ,so only one ntp server was configured,just want to know ntp's synchronization behaviornow:#datemon oct 24 10:54:55 cst 2016reset an incorrect system time:#date -s 2016-10-24 10:52after about 10min:#ntpq -np remote refid st t when poll reach delay offset jitter==============================================================================10.101.242.8 10.233.7.230 3 u 4 64 377 0.102 175930. 0.070after about 10min:#ntpq -np remote refid st t when poll reach delay offset jitter==============================================================================*10.101.242.8 10.233.7.230 3 u 4 64 377 0.102 175930. 0.070after about 10min:time was adjusted by ntp",
    "present_kp": [
      "ntp"
    ],
    "absent_kp": []
  },
  {
    "text": "want some advice on structuring my text-editing program. i want to make a small command-line-run program that looks for a word or phrase in a target .txt. or .docx file, prints out a corresponding blurb about that phrase, and then replaces it with a different word/phrase. there are about 200 of these tuples. what is the best way to structure this? i'm thinking of putting this info into a text file and writing code to read it in. or should i simply write it all into the program?i'm also thinking of making a class for each tuple w/ three fields that stores this information.is this a good approach, or are there better ways?ps: i'm thinking of using java for this unless someone can suggest python for a particular reason.",
    "present_kp": [
      "java"
    ],
    "absent_kp": [
      "design",
      "design patterns",
      "object oriented",
      "object oriented design"
    ]
  },
  {
    "text": "how can i get in the know?. my company posted a job listing to get me a helper. a recruiter called me today and all he kept saying was mvc this entity framework that... - he sounded shocked when i said the project uses datasets and linq2sql over winforms and asp.net webforms.then i was looking at options for automated website testing and i come upon this here: and i began to get agitated.most folks in the know are using presentation layers to make asp.net so thin that a tool like nunitasp isn't helpful.this person is in the know, and his friends are apparently in the know. i want to be in the know too, because being out of the know makes me feel insecure and a little sad.in my efforts this past year to get with the times, i realized great benefits from linq2sql and the unity container. they both were nothing but good for me - filling gaps that have been apparent to me for ages.then i moved on to model-view-preseneter for winforms guis and was again very happy with it for the same reason - i had been asking myself for a long time how to separate things out so that i could have a thick client and a web client share their common logic in a common code base.yet, i am stuggling with the following. and i know a zillion people can't be wrong and i'm not smarter than the masses, but i need help to see:mvc as the evolution of webformswpf as the evolution of winformsentity framework as the evolution of linq2sql (and, for that matterthe deprecation of datasets)(i suspect it all stems from my, to date, lack of obtaining test fahrvergngen)thus, i have been asking myself, and not hearing an answer to:what do i gain using mvc in a web application? i know i gainadditional source code artifacts and a new dsl to learn. what else?what would happen if i used wpf objects without the mvvm pattern? would i be hurting my chances to get a job somewhere else?for that matter, is winforms really broken? is it me or does visual studio have noticable visual lag on my dual core 2.8 ghz machine with 8 gigs of ram? i like snappy. i want end users to experience snappy all the time without fail.why are datasets the old way? they seem quick efficient and succinct for many small to medium sized problems i have to solve (yet they are not even in silverlight).i feel like big pile of complexity is on the plate and spreading it around won't make it go away. the intrinsic amount of complexity needs to be confronted head on, and maybe software engineering should become more like electrical engineering or mechanical engineering, or brain surgery.",
    "present_kp": [
      "mvc",
      "mvvm"
    ],
    "absent_kp": [
      "design patterns",
      "architectural patterns"
    ]
  },
  {
    "text": "finding difference in dates which is in format %y%m%d%h%m%s. i have a two dates in date +%y%m%d%h%m%s format. how to find the difference and how to check whether the difference is more than 4 hours?this is how i have triedecho $(( ( $(date +%y%m%d%h%m%s) - $(date +%y%m%d%h%m%s -d 1970-01-01 + $(stat -c '%z' filename ) secs))))date command returns thissun sep 6 10:35:19 cdt 2015",
    "present_kp": [
      "date"
    ],
    "absent_kp": [
      "linux",
      "shell script"
    ]
  },
  {
    "text": "why does my fedora 14 system with an intel mobile gme965/gle960 integrated graphics controller come up with the wrong aspect ratio?. i have a:compaq 610 vc275ea 15,6 wxga i celeron t1500and i installed fedora 14 on it. everything is great, except one: the aspect ratio of the screen is not very good :\\<url> vga compatible controller: intel corporation mobile gme965/gle960 integrated graphics controller (rev 0c)00:02.1 display controller: intel corporation mobile gme965/gle960 integrated graphics controller (rev 0c)can someone please say, that it cannot be fixed, or say: yes, it could be fixed, do xy, read xy, etc. :\\ this is an issue for me for months now.. :\\ please help",
    "present_kp": [
      "fedora"
    ],
    "absent_kp": [
      "linux",
      "xorg",
      "intel gma"
    ]
  },
  {
    "text": "an algorithm for finding subset matching criteria?. i recently came up with a problem which i would like to share some thoughts about with someone on this forum. this relates to finding a subset. in reality it is more complicated, but i tried to present it here using some simpler concepts.to make things easier, i created this conceptual db model:let's assume this is a db for storing recipes. recipe can have many instructions steps and many ingredients. ingredients are stored in a cupboard and we know how much of each ingredient we have.now, when we create a recipe, we have to define how much of each ingredient we need. when we want to use a recipe, we would just check if required amount is less than available amount for each product and then decide if we can cook a dinner - if amount required for at least one ingredient is less than available amount - recipe cannot be cooked. simple sql query to get the result.this is straightforward, but i'm wondering, how should i work when the problem is stated the other way round, i.e. how to find recipies which can be cooked only from ingredients that are available?i hope my explanation is clear, but if you need any more clarification, please ask.",
    "present_kp": [
      "sql"
    ],
    "absent_kp": [
      "algorithms",
      "database"
    ]
  },
  {
    "text": "transform in linear grammar. i have the following regular grammar :$$s ightarrow as | cs | bq_1$$$$q_1 ightarrow bq_2$$$$q_2 ightarrow aq_3 | cq_3 | bq_1$$$$q_3 ightarrow aq_4 | cq_4$$ $$q_4 ightarrow arepsilon$$the question is to transform that into a linear grammar with less nonterminals than the regular grammar and my idea was:$$s ightarrow asa | csc | asc | csa | bq_1a | bq_1c$$$$q_1 ightarrow b$$and the rest i don't know. could you help me to solve this problem?",
    "present_kp": [],
    "absent_kp": [
      "formal grammars"
    ]
  },
  {
    "text": "is there a web site offering to browse a cloud of semantically related words?. is there a web site offering to browse a cloud of semantically related words?for example to enter coffee and get drink, aroma, stimulation, brown, latte, cappuccino, arabica, starbucks milk, cup, liquid, morning, cafeteria, caffeine, etc...",
    "present_kp": [],
    "absent_kp": [
      "dictionary"
    ]
  },
  {
    "text": "using two wordlists to search a list of texts. i have a function that takes two separate wordlists and searches a third list, which is a text formatted as a list of wordlists. the function finds the proximity between words in word_list1 and word_list2 by taking the difference between their indexes; (it takes one over the difference, so that larger numbers will indicate closer proximity).i ultimately will write the output to a .csv file and create a network of the word proximities in gephi. this function works for me, but it is very slow when used on a large number of texts. do you have any suggestions for making it more efficient? (if this is unclear at all, let me know, and i will try to clarify.)text = [ 'this, reader, is the entertainment of those who let loose their own thoughts, and follow them in writing, which thou oughtest not to envy them, since they afford thee an opportunity of the like diversion if thou wilt make use of thy own thoughts in reading.', 'for the understanding, like the eye, judging of objects only by its own sight, cannot but be pleased with what it discovers, having less regret for what has escaped it, because it is unknown.']word_list1 = ['entertainment', 'follow', 'joke', 'understanding']word_list2 = ['envy', 'use', 'nada']text_split = []for line in text: text_split.append(line.split(' '))def word_relations(list_a, list_b, text): relations = [] for line in text: for i, item in enumerate(line): for w in list_a: if w in item: first_int = i first_word = w for t, item in enumerate(line): for x in list_b: if x in item: second_int = t second_word = x if first_int: if second_int != first_int: dist = 1.0 / abs(second_int-first_int) if dist in relations: continue else: relations.append((first_word, second_word, dist)) return(relations)print(word_relations(word_list1, word_list2, text_split))here is the output: [('entertainment', 'envy', 0.05263157894736842), ('entertainment', 'use', 0.02857142857142857), ('follow', 'envy', 0.1111111111111111), ('follow', 'use', 0.04), ('understanding', 'use', 0.03571428571428571)]",
    "present_kp": [],
    "absent_kp": [
      "python",
      "performance"
    ]
  },
  {
    "text": "will you use an online technical skills test to hire a senior developer?. there are online services such as ikm that offer skills tests in many areas, including programming.would you use these kind of tests when hiring for a senior developer position?what about just for objectively benchmarking candidates before calling them for an interview? would you use it as a step after short-listing candidates after interviews?is this approach more suitable in some situations compared to others? have you personally used this kind of service or know someone who has?",
    "present_kp": [
      "hiring",
      "interview"
    ],
    "absent_kp": []
  },
  {
    "text": "how to factor in responsive design when providing an estimate for web applications?. in the past usually i have only had to estimate web applications based on browser support. but for more recent projects device and platform support are also very important as well (screen resolution).i am having a hard time providing an estimate to account for responsive design. how much additional time (estimate only) is needed to account for this over the entire implementation of a web based project?",
    "present_kp": [
      "web",
      "responsive design"
    ],
    "absent_kp": [
      "estimation"
    ]
  },
  {
    "text": "python reading from stdin while doing other tasks. i am trying to write a system log parser. it will receive messages from the freebsd syslog daemon through stdin.it will use those messages to determine if an ip should be banned or not.the problem i have is that after x seconds the ban should be removed, but if i won't get any input from stdin, my program will just block waiting for it. so in the mean time i can't do anything.i fixed it using threads, but isn't there a better way to do it?for example something like this:while true: while <data in stdin>: handledata dosomestuff()so as long nothing comes in from stdin i want to execute dosomestuff, and if there is data handle it.",
    "present_kp": [
      "python"
    ],
    "absent_kp": [
      "io"
    ]
  },
  {
    "text": "rename multiple files and add date before the files. i have a folder contains one or more tar.gz files. i want to add current date before each files when the script run. for example:two file name(those files will be created each day, but the name will remain the same):file1.tar.gz file2.tar.gzin first day(2011-10-07), those two files will be renamed to:2011-10-07_file1.tar.gz2011-10-07_file2.tar.gzin next day(2011-10-08), they are changed to:2011-10-08_file1.tar.gz2011-10-08_file2.tar.gzfinally, the folder contains the following files:2011-10-07_file1.tar.gz2011-10-07_file2.tar.gz2011-10-08_file1.tar.gz2011-10-08_file2.tar.gzhow to achieve this using one line? i tried to use rename command, but i can only add the date after the file, not before. my codecdate='date +%y-%m-%d'; rename .gz .gz.$cdate *.gz",
    "present_kp": [
      "rename"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "how to stop getting notifications on likes?. when people comment on my post/photo/link/whatever, it's nice to get a notification, because they say something and it might be interesting to read or perhaps reply to it. but when people like my post, there is really no extra information there, except an increase in number of likes. the notification is just noise in my opinion. can i stop notifications for all likes?",
    "present_kp": [],
    "absent_kp": [
      "facebook",
      "facebook notifications"
    ]
  },
  {
    "text": "how to force user to use subdomain?. possible duplicate:how do i prevent access to an add-on domain's root directory from main hosting domain name i am hosting a webshop with opencart and its current url is e.g. <url> have created two subdomains ( <url> and <url> ) and both subdomains are already working as they should. however, can i restrict direct access to mydomain.com/shop/ while leaving all the files (index.php, etc.) there?since both subdomains are pointing to <url> i thought this would restrict all access.so in the end, i would like my two shops to be accessable through <url> and <url> but not <url> while leaving all the files in <url>",
    "present_kp": [
      "subdomain"
    ],
    "absent_kp": []
  },
  {
    "text": "problems for which algorithms based on partition refinement run faster than in loglinear time. partition refinement is a technique in which you start with a finite set of objects and progressively split the set. some problems, like dfa minimization, can be solved using partition refinement quite efficiently. i don't know of any other problems that are usually solved using partition refinement other than the ones listed on the wikipedia page. out of all these problems, the wikipedia page mentions two for which algorithms based on partition refinement run in linear time. there's the lexicographically ordered topological sort [1] and an algorithm for lexicographic breadth-first search [2].are there any other examples or references to problems that can be solved using partition refinement very efficiently, meaning something better than loglinear in terms of time?[1] sethi, ravi, scheduling graphs on two processors, siam journal on computing 5 (1): 7382, 1976.[2] rose, d. j., tarjan, r. e., lueker, g. s., algorithmic aspects of vertex elimination on graphs, siam journal on computing 5 (2): 266283, 1976.",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "reference request",
      "data structures",
      "partitions",
      "sets"
    ]
  },
  {
    "text": "fft-based image rotation algorithms more accurate than chirp-z?. we're currently using a chirp-z based implementation (tong and cox, 1999) for rotation of astronomical images. i was wondering if there were any algorithms/implementations out there that could also be used to rotate images using ffts, and were more accurate than the one we're using now. perhaps any progress made in the past few years in the area?",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "image processing",
      "cuda",
      "fftw"
    ]
  },
  {
    "text": "rsync optimized for speed. context: copying large volumes of small and large files over a gigabit switch. rsync is preferred over other commands because it provides excellent feedback and sync capability.in the past i have used rsync but it was limited to 12mb/sec. i suspect that the encryption is the bottleneck. date > tictoc_bloggie.txtrsync -avxu --progress --delete-after --exclude recycler/ \\ --exclude system volume information/ \\ /source/public/video/bloggie\\ sony\\ dad/ /destination/media/bloggie\\ sony\\dad/ \\ | tee ~/rsync_log_bloggie.txt;date >> tictoc_bloggie.txtthe source is typically another network device that mounted via cifs.what is the syntax that needs to be add to the statement above to disable encryption? examples are appreciated.",
    "present_kp": [
      "rsync"
    ],
    "absent_kp": []
  },
  {
    "text": "to check whether a given number has been computed previously or not. given a 64 bit positive integer. how to determine in the most efficient way whether the given integer has ever been seen or not? implementation in c++11 (please do include this fact, while suggesting your opinions)intent: i am generating numbers randomly, by flipping one bit at a time. i need to check every time on generation of a number whether it has been previously generated or not? ex: 1,4,8,16,3,5,9,11,12, .... . current solution:1.i can create an unordered_map. however, i would be wasting memory for storing the value part which is boolean in this case. and also hashing isnt the cheapest operation and also their is a penalty of rehasing.can create a list and keep it sorted. too expensive operations --sorting and lookup.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "data structures"
    ]
  },
  {
    "text": "the gpg keys listed for the atomicrocketturtle.com repository are already installed but they are not correct for this package.. when running this on centos 6:yum updatei accept the transaction summary that it presents and am then immediately presented with this:downloading packages\u26a0\ufe0f rpmts_hdrfromfdno: header v3 rsa/sha1 signature, key id 4520afa9: nokeyretrieving key from file:///etc/pki/rpm-gpg/rpm-gpg-key.art.txtthe gpg keys listed for the centos / red hat enterprise linux 6 - atomicrocketturtle.com repository are already installed but they are not correct for this package.check that the correct key urls are configured for this repository.how can i fix this issue?when i run this:rpm -q --queryformat %{summary} gpg-pubkeyi get this response:gpg(centos-6 key (centos 6 official signing key) <<email>)gpg(epel (6) <<email>)gpg(atomic rocket turtle <<email>)gpg(new relic <<email>)",
    "present_kp": [
      "centos",
      "yum",
      "rpm"
    ],
    "absent_kp": []
  },
  {
    "text": "where to find and how to install ubuntu gui themes?. i tried ubuntu several times, but i didn't stay with it for very long. one reason was i felt the interface was boring.today i saw some nice themes here: the #6 in <url> or #2 in <url> i don't know where to find these resource and install these themes? is this available to install just as we install some official packages from terminal or package manager? or do i have to contact the author personally?",
    "present_kp": [
      "gui",
      "theme"
    ],
    "absent_kp": [
      "linux",
      "desktop"
    ]
  },
  {
    "text": "hotmail has stopped sending emails to groups. this just started. am getting the error message that error: the message can't be sent right now. please try again later. not sure how to fix this.",
    "present_kp": [],
    "absent_kp": [
      "outlook.com"
    ]
  },
  {
    "text": "session in restful web services, how it works?. in a web services, how does the server know which request belongs to which session?i know that for a web application, the web server inspects the cookie (or the sessonid query parameter in case cookies are disabled) so it knows which session the request is associated with. but for a request that comes from a rest client, how do the server know?",
    "present_kp": [
      "web services",
      "rest",
      "session"
    ],
    "absent_kp": []
  },
  {
    "text": "random password generator based on user input. this is my second program written in python. it basically creates a password made up of numbers, capital and lower case letters with the option to include special characters and dashes. i created a simpler project and i decided to build upon it to create version 2. since i am still new, i would like to receive advice and any thoughts on how to improve my code as well as a programmer. such as how random this password is, any syntax errors, or any ways to simplify my code. i commented as best as i could. any thoughts would be appreciated.#version 2 introduces option to include special characters and the option for the password to be separated into#sections by a dash as well as a more secure and better created password which has no certain pattern to it#as the previous version did#loop goes through steps until user decides to quit# 1. ask for user input if special characters can be added and set to var response# 2. come up with random number between 1 and 3, set = to var typevalue if special is no# come up with random number between 1 and 4, set = to var typevalue if special is yes# 3. assign randint between 0 and 25 to lowercase and uppercase var, assign randint between 0-9 to number var,# assign randint between 0-9 to character var# 4. if type=0 number value is added to objects list# if type=1 upper[uppercase] is added to objects list# if type=2 lower[lowercase] is added to objects list# if response is yes and only yes, characters[character] is added to objects listfrom random import randintupper = [a,b,c,d,e,f,g,h,i,j,k,l,m, n,o,p,q,r,s,t,u,v,w,x,y,z]lower = [a,b,c,d,e,f,g,h,i,j,k,l,m, n,o,p,q,r,s,t,u,v,w,x,y,z]characters = [!,@,#,$,%,^,&,*,_,+]objects = []def runfun(a,b): typevalue = randint(a, b) lowercase = randint(0, 25) uppercase = randint(0, 25) number = randint(0, 9) character = randint(0, 9) if typevalue == 1: objects.append(upper[uppercase]) elif typevalue == 2: objects.append(number) elif typevalue == 3: objects.append(lower[lowercase]) elif typevalue == 4: objects.append(characters[character])def runtype2(c,d): first = c second = d for i in range(16): runfun(first, second) function1()def function1(): dashes = raw_input(would you like it to be seperated into four sections of four characters divided by a dash? y for yes n for no: ) if dashes == y or dashes == y: #print dashes %s % (objects) print %s%s%s%s-%s%s%s%s-%s%s%s%s-%s%s%s%s % ( objects[0], objects[1], objects[2], objects[3], objects[4], objects[5], objects[6], objects[7], objects[8], objects[9], objects[10], objects[11], objects[12], objects[13], objects[14], objects[15]) else: #print no dashes %s % (objects) print %s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s % ( objects[0], objects[1], objects[2], objects[3], objects[4], objects[5], objects[6], objects[7], objects[8], objects[9], objects[10], objects[11], objects[12], objects[13], objects[14], objects[15])#-------------foundation-----------while true: #requests user input which determines if special characters #are included answer = raw_input(can it have special characters? y for yes n for no. x to exit: ) if answer == y or answer == y: runtype2(1,4) #hands over value 1 and 4 to include #characters in the creation elif answer == n or answer == n: runtype2(1,3) #hands over values 1 and 3, opts out 4 #which is special characters elif answer == x or answer == x: exit() else: print invalid input. del objects[:]",
    "present_kp": [
      "python",
      "random"
    ],
    "absent_kp": [
      "python 2.7"
    ]
  },
  {
    "text": "how can i get rid of all script blocks in html files?. how can i remove all script blocks (including multi-line ones) from html files such as:<script type=text/javascript>var googletag = googletag || {};googletag.cmd = googletag.cmd || [];(function() {var gads = document.createelement('script');gads.async = true;gads.type = 'text/javascript';var usessl = 'https:' == document.location.protocol;gads.src = (usessl ? 'https:' : 'http:') +'//www.googletagservices.com/tag/js/gpt.js';var node = document.getelementsbytagname('script')[0];node.parentnode.insertbefore(gads, node);})();</script>i tried things like this with no success:sed -i -e 's/<script.* .*<\\/script>//g' 'path/to/file.html'",
    "present_kp": [
      "sed"
    ],
    "absent_kp": [
      "shell script"
    ]
  },
  {
    "text": "lazily load permissions from database in multithreading environment. i would like to get the feedback about this code:import java.util.hashset;import java.util.queue;import java.util.set;public class utils { private final set<string> permissionsset = new hashset<string>(50); private platformmodulemodellocator modellocator = lookup.getdefault().lookup(platformmodulemodellocator.class); public boolean hasuserpermission(string permission) { synchronized (permissionsset) { if (permissionsset.isempty() && modellocator.getusersession() != null) { queue<string> userpermissions = modellocator.getusersession().getuserpermissionsfromdb(); for (string userpermission : userpermissions) { permissionsset.add(userpermission); } } } return permissionsset.contains(permission); }}i've tried to fill set only after first call in multi-threading environment. can i do it without synchronized block? please suggest some variants.ps: it's not from utils actually, i've just copied this method from application class. platformmodulemodellocator returns user permissions like queue strings. it can have duplicates and i have to iterate over this queue when i need to check permissions. so i decided optimize this block and put this lines to set.but it not so matter i look for effective method for lazy initialization collections. how can i initialize my set after first call?",
    "present_kp": [
      "java",
      "multithreading",
      "database",
      "lazy"
    ],
    "absent_kp": [
      "authorization"
    ]
  },
  {
    "text": "which paper to cite when referring to reservoir sampling *with replacement*?. as far as i can tell, the term reservoir sampling is commonly used to refer to sampling without replacement and references [1], [2], and [3] are cited while mentioning it. when referring to reservoir sampling with replacement, which papers should be cited? a recent reference that i found is titled reservoir-based random sampling with replacement from data stream available at <url> [1] donald e. knuth: the art of computer programming, volume ii: seminumerical algorithms, 2nd edition. addison-wesley 1981, isbn 0-201-03822-6 [2] mcleod, a.i., bellhouse, d.r.: a convenient algorithm for drawing a simple random sample. appl, stat., pp. 182-184 (1983). [3] jeffrey scott vitter: random sampling with a reservoir. acm trans. math. softw. 11(1): 37-57 (1985)",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "data streams",
      "citations",
      "streaming algorithms"
    ]
  },
  {
    "text": "statistics - train and test data split. how much data should we use during training, and how much in testing? can anyone explain why does it always seem to be 70:30 or 80:20 ratios?",
    "present_kp": [
      "statistics"
    ],
    "absent_kp": []
  },
  {
    "text": "print files in reverse order from an associative array in bash. for key in ${!current_file[@]} do echo $key donei declare current_file like below in bash:declare -a current_fileinsert key as a file and size as value in current_file. output of the for loop prints:file2file1i want to print like:file1 file2how can i print like this?",
    "present_kp": [
      "bash",
      "files",
      "array"
    ],
    "absent_kp": [
      "directory",
      "sort"
    ]
  },
  {
    "text": "how to find current chroot jail path on linux <2.6.26. while running kernel 2.6.26 or newer it's possible to get the path of the current chroot jail by comparing the mountinfo of the current process and the init process. is there a way to get the same information with kernel <2.6.26?",
    "present_kp": [
      "linux",
      "process",
      "chroot"
    ],
    "absent_kp": []
  },
  {
    "text": "craigslist search-across-regions script. i'm a javascript developer. i'm pretty sure that will be immediately apparent in the below code if for no other reason than the level/depth of chaining that i'm comfortable with. however, i'm learning ruby, and so i'd love to write beautiful ruby code too. my simple first project is a craigslist search-across-regions script.the full code is on github, but broken down into snippets with questions below.def get_us_regions() # accumulator for building up the returned object. results = {} # important urls sitelist = uri('<url>) geospatial = uri('<url>) # get a collection of nodes for the us regions out of craigslist's site list. usregions = nokogiri::html(net::http.get(sitelist)).search(a[name=us]).first().parent().next_element().search('a') # parse out the information to build a usable representation. usregions.each { |usregion| hostname = usregion.attr('href').gsub('http://','').gsub('.craigslist.org','') results[hostname] = { name: usregion.content, state: usregion.parent().parent().previous_element().content } } # merge that information with craigslist's geographic information. areas = json.parse(net::http.get(geospatial)) areas.each { |area| if results[area[hostname]] results[area[hostname]][:stateabbrev] = area[region] results[area[hostname]][:latitude] = area[lat] results[area[hostname]][:longitude] = area[lon] end } # this is a complete list of the us regions, keyed off of their hostname. return resultsendbootstrappinghow should i get procedural information i need to get started?does this change if i were doing this on bootstrap for a long-running application and wanted to refresh, say, monthly?should i shove bootstrapping this into some really abstract class?this isn't jshow should i chain calls to class methods?why hashes with string keys versus the weird named key thing?object-ionsshould i be creating an object for each region and feeding the pieces i parse out of the document into the constructor function?if i did that, should that constructor function just take a dom node and be clever with figuring out what i passed it?and for reopening an object since i have to collate across two sources what's the right approach?# perform a search in a particular region.def search_region(regionhostname, query) # in case there are multiple pages of results from a search pages = [] pagecount = false # an accumulator for storing what we need to return. result = [] # make requests for every page. while (pages.length != pagecount) # end up with a start of 0 on the first time, 100 is craigslist's page length. page = pages.length * 100 # here is the url we'll be making the request of. url = uri(http://#{regionhostname}.craigslist.org/search/cto?query=#{query}&srchtype=t&s=#{page}) # get the response and parse it. pages << nokogiri::html(net::http.get(url)) # if this is the first time through if (pagecount == false) #check to make sure there are results. if pages.last().search('.resulttotal').length() != 0 # there are results, and we need to see if additional requests are necessary. pagecount = (pages.last().search('.resulttotal').first().content().gsub(/[^0-9]/,'').to_i / 100.0).ceil else # there are no results, we're done here. return [] end end end # go through each of the pages of results and process the listings pages.each { |page| # go through all of the listings on each page page.search('.row').each { |listing| # skip listings from other regions in case there are any (few local results found). if listing.search('a[href^=http]').length() != 0 next end # parse information out of the listing. car = {} car[id] = listing[data-pid] car[date] = listing.search(.date).length() == 1 ? date.parse(listing.search(.date).first().content) : nil # when craigslist wraps at the end of the year it doesn't add a year field. # fortunately craigslist has an approximately one month time limit that makes it easy to know which year is being referred to. # overshooting by incrementing the month to make sure that timezone differences between this and cl servers don't result in weirdness if car[date].month > date.today.month + 1 car[date] = car[date].prev_year end car[link] = http://#{regionhostname}.craigslist.org/cto/#{car['id']}.html car[description] = listing.search(.pl > a).length() == 1 ? listing.search(.pl > a).first().content : nil car[price] = listing.search(span.price).length() == 1 ? listing.search(span.price).first().content : nil car[location] = listing.search(.l2 small).length() == 1 ? listing.search(.l2 small).first().content.gsub(/[\\(\\)]/,'').strip : nil car[longitude] = listing[data-longitude] car[latitude] = listing[data-latitude] # pull car model year from description # can be wrong, but likely to be accurate. if /(?:19[0-9]{2}|20[0-9]{2}|[0-9]{2})/.match(car[description]) { |result| # two digit year if result[0].length == 2 # not an arbitrary wrapping point like it is in mysql, etc. # cars have known manufacture dates and can't be too far in the future. if result[0].to_i <= date.today.strftime(%y).to_i + 1 car[year] = 20#{result[0]} else car[year] = 19#{result[0]} end # four digit year is easy. elsif result[0].length == 4 car[year] = result[0] end } else car[year] = nil end # store the region lookup key. car[regionhostname] = regionhostname result << car } } return resultendcar vs. listingnow i have two possible competing objects if i were to throw this into a class. the listing is describing a car, but i care about capturing information from both. should i store both and link them? a listing has-one car?results pagesshould each page be an object? the first little bit i go through is to figure out how many pages i need to request.how should i prevent this from running in serial? should i bubble these functions back out by returning functions? is that really possible to do cleanly in ruby?if the code has to look like this...the if statements where i'm checking to see if something is there (and calling the method twice) are terrible. but it throws ugly errors if i try to access things that aren't present.ternary was the best i found, are there other tricks?misc.is next in good favor?are there idioms for pulling information out of match objects?what about building up strings? am i doing that right?def search(query) results = [] # get a copy of the regions we're going to search. regions = get_us_regions() # divide the requests to each region across the right number of threads. iterations = 5 count = (regions.length/iterations.to_f).ceil # spin up the threads! (0..(iterations-1)).each { |iteration| threads = [] # protect against source exhaustion if iteration * count > regions.length() next end # split the requests by region. regions.keys.slice(iteration*count,count).each { |regionhostname| threads << thread.new(regionhostname) { |activeregionhostname| # new block for proper scoping of regionhostname results << search_region(activeregionhostname, query) } } # wait until all threads are complete before kicking off the next set. threads.each { |thread| thread.join } } # from search_region we return an array, which means we need to flatten(1) to pull everything up to the top level. results = results.flatten(1) # sort the search results by date, descending. results.sort! { |a,b| if a[date] == b[date] b[id].to_i <=> a[id].to_i else b[date] <=> a[date] end } return resultsendputs search(tdi).to_jsonpublic static void mainthreading! asynchronous code makes sense to me, but my (ruby) threads blow up if i create too many at once. is there an idiom for queuing activity for a set number of worker threads?for statements? or (0..5).each { |index| }?globals for collections of objects? only in main?are there naming conventions i'm doing incredibly wrong?is there anything else i should have asked?conclusionthe code works, and you can use it to get results from every region for a car search on craigslist. this is nice for rare/hard-to-find vehicles. i'd love for the threading to be better and include the multiple requests from pagination on different threads, but i'd need some sort of pool to handle that. eventually i'm thinking of integrating rack into this for a simplistic vehicle search api. or maybe it gets smarter and stores the results in a db to track pricing over time and create more educated sellers and consumers or to flag good deals.",
    "present_kp": [
      "ruby",
      "http"
    ],
    "absent_kp": [
      "object oriented",
      "multithreading",
      "web scraping"
    ]
  },
  {
    "text": "black desktop background [linux mint 18.1 mate]. for some reason my desktop is black and i cannot change it. i can create folders and they are visible, but trying to make icons visible (e.g. computer, drives) is not possible. when i restart the issue is resolved briefly but it always ends up coming back.",
    "present_kp": [
      "linux mint",
      "desktop",
      "mate"
    ],
    "absent_kp": []
  },
  {
    "text": "why does xterm/bash word-wrap even tho window is large to fit command. so this happens some times, not always.i'll write a really long command and i'll be satisfied with it wrapping around at the edge like so:what i don't like to happen however is, after increasing the size of the window, if i write a new long command or go back in my command-history to my previously long command it will word-wrap in a way that destroys readablity, like so:<url> linux kernel: 3.17.6-1xterm version: 314-1bash version: 4.3.030-1",
    "present_kp": [
      "bash",
      "xterm"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i best study a problem to determine whether recursion can/should be used?. in some cases, i fail to see that a problem could be solved by the divide and conquer method. to give a specific example, when studying the find max sub-array problem, my first approach is to brute force it by using a double loop to find the max subarray. when i saw the solution using the divide and conquer approach which is recursion-based, i understood it but ok. from my side, though, when i first read the problem statement, i did not think that recursion is applicable. when studying a problem, is there any technique or trick to see that a recursion based (i.e. divide and conquer) approach can be used or not?",
    "present_kp": [
      "recursion"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "take the subset of the file related to the time stamp. i have some json file in dictionary format. the lines looks like here:{a:1, b:2, c:3, time:1334572551435}{a:1, b:2, c:4, time:1334575352456}{a:2, b:2, c:7, time:1334575335345}...time is in a utc format. the whole file has about 300 milliones unique lines (anyway the same time could come twice). how i can choose a lines for some particular time, for example between 1334575352456 and 1334575353456?i personally have the next idea from some tutorial:awk $time == 1334575352456, $time == 1334575353456 inputfile.jsonanyway, i suppose this solution is for column time, not for dictionary with the key time (actually $time should be $4)",
    "present_kp": [
      "awk",
      "json"
    ],
    "absent_kp": [
      "text processing"
    ]
  },
  {
    "text": "showing color in log output using tail command when using cygwin?. i have a debian install that runs an application server.i ssh into this debian install from a windows computer using cygwin and with the application server running i use tail -f to monitor the log files.errors from the application are printed in red, warning in yellow, and all other output is the console text color.however, when i run a nearly identical application server in windows, and use cygwin to print the log from the filesystem, the log is not colored the way it is when ssh'd into debian.is this a difference in the tail command installed in debian and in cygwin? how can i emulate this behavior in cygwin?",
    "present_kp": [
      "debian",
      "cygwin",
      "tail"
    ],
    "absent_kp": [
      "bashrc"
    ]
  },
  {
    "text": "splitting an address into fields in sql. i have the following code to split an address string in t-sql. excepting the unit number, which is already in its own field, it would affect too much of the application to split the address into different database fields. it's a bit of a long story, but it's also not possible to make it a parameterized query, or to write the equivalent application code in c#. still, i'm curious if anyone can think of any edge case that would put things into the wrong fields.the only case i've come across is east end ave, but even the us postal service suggests incorrectly parsing 'east' as a directional (for consistency) (reference: very long pdf, search for 'directional', or go to page 233).i'm only worried about canadian and american addresses, but in canada, french-style street types before the street name are fair game (e.g. 'rue montreal'). for a tie-breaker, i default to the english style (e.g. 'rue street' is parsed with the name 'rue' and type 'street').streettype and streetdirection are tables which contain street types and street directions, as typename/typeabbr and directionname/directiontype pairs respectively - i can post the values i've been using there if anyone's curious, but the streettype is quite long. streetdirection also includes french directions ('ouest', 'nord', 'sud', 'est', etc.), as well as their equivalents of 'northeast', 'northwest', etc.declare @civicnum as nvarchar(10) = ''declare @predir as nvarchar(10) = ''declare @name as nvarchar(100) = ''declare @type as nvarchar(15) = ''declare @frenchtype as nvarchar(15) = ''declare @postdir as nvarchar(10) = ''set @name = '123 e fake st. s'set @civicnum = substring(@name, 1, 1)if isnumeric(@civicnum) = 1 begin -- will assume an initial integer is a civic number declare @lastspace as integer declare @nextspace as integer declare @temp as varchar(15) -- get the first token, and push it into @civicnum set @lastspace = 1 set @nextspace = charindex(' ', @name) set @civicnum = substring(@name, 1, @nextspace) -- get the next token, to check for a fractional @civicnum set @lastspace = @nextspace + 1 set @nextspace = charindex(' ', @name, @lastspace) set @temp = substring(@name, @lastspace, @nextspace - @lastspace) -- assumption: if the token contains a slash, it is a fraction -- for @civicnum if charindex('\\', @temp) > 0 or charindex ('/', @temp) > 0 set @civicnum = @civicnum + ' ' + @temp else set @nextspace = @lastspace -- reverse the string to extract type, direction from right set @name = reverse(substring(@name, @nextspace, len(@name))) -- get the final token, check if it is a post directional (n, s, e, w) set @lastspace = 1 set @nextspace = charindex(' ', @name) set @temp = rtrim(ltrim(reverse(substring(@name, 1, @nextspace)))) -- strip period, if one exists if substring(@temp, len(@temp), 1) = '.' set @temp = substring(@temp, 1, len(@temp) - 1) -- check if it exists in the streetdirection table select @postdir=directionabbr from streetdirection where upper(directionname) like upper(@temp) if not (@postdir like @temp) -- try abbreviation select @postdir=directionabbr from streetdirection where upper(directionabbr) like upper(@temp) -- if @postdir was found, get the next token if not (@postdir like '') begin set @lastspace = @nextspace + 1 set @nextspace = charindex(' ', @name, @lastspace + 1) set @temp = rtrim(ltrim(reverse(substring(@name, @lastspace, @nextspace - @lastspace)))) if substring(@temp, len(@temp), 1) = '.' -- strip period set @temp = substring(@temp, 1, len(@temp) - 1) end -- check if the current token is a streettype select @type=typename from streettype where upper(typename) like upper(@temp) if not (@type like @temp) -- try abbreviation select @type=typename from streettype where upper(typeabbr) like upper(@temp) -- reverse address again to check for pre-directional and french street type if not (@type like '') set @lastspace = @nextspace + 1 set @name = rtrim(ltrim(reverse(substring(@name, @lastspace, len(@name))))) -- get the next token, and check for a pre-directional set @lastspace = 1 set @nextspace = charindex(' ', @name) set @temp = rtrim(ltrim(substring(@name, 1, @nextspace))) if substring(@temp, len(@temp), 1) = '.' -- strip period set @temp = substring(@temp, 1, len(@temp) - 1) select @predir=directionabbr from streetdirection where upper(directionname) like upper(@temp) if not (@predir like @temp) -- try abbreviation select @predir=directionabbr from streetdirection where upper(directionabbr) like upper(@temp) -- if a pre-directional was found, get the next token if not (@predir like '') begin set @lastspace = @nextspace + 1 set @nextspace = charindex(' ', @name, @lastspace + 1) set @temp = rtrim(ltrim(substring(@name, @lastspace, len(@name)))) if substring(@temp, len(@temp), 1) = '.' -- strip period set @temp = substring(@temp, 1, len(@temp) - 1) end -- check for french street type before address, if an -- english street type has not already been found if (@type like '') -- only if not already found (prefer english type) begin select @frenchtype=typename from streettype where upper(typename) like upper(@temp) if not (@frenchtype like @temp) -- try abbreviation select @frenchtype=typename from streettype where upper(typeabbr) like upper(@temp) end -- if @frenchtype was found, get the final remaining token if not (@frenchtype like '') begin set @lastspace = @nextspace set @type = @frenchtype end -- assume it is the street name set @name = substring(@name, @lastspace, len(@name)) select @civicnum as civicnum, @name as address, @type as streettype, @postdir + @predir as direction endelse select @civicnum as civicnum, @name as address, @type as streettype, @postdir + @predir as directionif nothing else, i hope this is a snippet of code someone finds handy! although they don't particularly apply in my case, here is a handy list of address edge cases from @200_success.",
    "present_kp": [
      "sql",
      "parsing"
    ],
    "absent_kp": [
      "sql server",
      "t sql"
    ]
  },
  {
    "text": "what is the ios equivalent of michael hartl's rails 3 tutorial?. i'm a newbie programmer and i've been reading michael hartl's ruby on rails 3 tutorial. i'm enjoying the book very much. it's easy to follow and doesn't assume i know much. i'd also like to learn to code ios apps (both iphone and ipad) and would appreciate any recommendations on books or courses that could help me to do so.thanks in advance for the assistance!eddie",
    "present_kp": [
      "ruby on rails",
      "ios"
    ],
    "absent_kp": []
  },
  {
    "text": "how often do you refactor or restructure your code in long term projects?. as developers we are always eager to learn new things and better ourselves at what we do.you've all had moments when you look at your old code and get that feeling:wth, i can't believe i used to write code like thiswell, when it comes to long term projects that you're working on, what do you do when you look at your old code? you probably have learnt new techniques that you didn't use when you started the project. so you probably are very eager to refactor or restructure, or swap out modules in your project.but when is the right time to do this, and how often do you do this?also, there are risks involved if you do some major refactoring. there's also budget constraints so you may have the urge to make changes but your project manager won't give you the time to do so.how do people approach such situations?",
    "present_kp": [
      "refactoring"
    ],
    "absent_kp": [
      "design",
      "architecture"
    ]
  },
  {
    "text": "standard deviation of hourly temperatures of 2 days. it seems that when i program in lisp my brain goes on auto pilot and i end up solving the problem somehow. i don't even think i just do and it works out.that said, this is some horrible lisp code that was hacked together in about 20 mins, just to see if i could do it.the c++ program that this is based off was about 150 lines long, so doing it in about 59 lines of terrible code is neat.the date is 50 lines and is structured like 2 dates and 48 doubles 1 for each hour:3/14/20153/15/<phone>.2334.12..56.12(defun read-nth-line (file n &aux (line-number 0)) read the nth line from a text file. the first line has the number 1 (assert (> n 0) (n)) (with-open-file (stream file) (loop for line = (read-line stream nil nil) if (and (null line) (< line-number n)) do (error file ~a is too short, just ~a, not ~a lines long file line-number n) do (incf line-number) if (and line (= line-number n)) do (return line))))(defun arithmetic-average (samples) (/ (reduce #'+ samples) (length samples)))(defun get-file (filename) (with-open-file (stream filename) (loop for line = (read-line stream nil) while line collect line))) ;; compute sdev(defun standard-dev (colc) (let ((mean (arithmetic-average colc))) (sqrt (* (/ 1.0d0 (length colc)) (reduce #'+ colc :key (lambda (x) (expt (- x mean) 2)))))))(defun split-in-half (sequence) (let ((mid (ceiling (length sequence) 2))) (list (subseq sequence 0 mid) (subseq sequence mid nil))))(defun parse-string-to-float (line) (with-input-from-string (s line) (loop :for num := (read s nil nil) :while num :collect num)))(defun extract-float (line) doc (first (parse-string-to-float line)))(defun process-file () print mean and standard deviation to terminal (let* ((l1 (get-file ~/clionprojects/project5withtemplates/twoday.txt)) (date1 (first l1)) (date2 (second l1)) (day1temps (mapcar #'extract-float (first (split-in-half (rest (rest l1)))))) (day2temps (mapcar #'extract-float (second (split-in-half (rest (rest l1)))))) (s-dev-day-1 (standard-dev day1temps)) (s-dev-day-2 (standard-dev day2temps))) (print date:)(print date1) (print standard deviation:) (print s-dev-day-1) (print date:)(print date2) (print standard deviation:) (print s-dev-day-2)) nil)",
    "present_kp": [
      "lisp"
    ],
    "absent_kp": [
      "statistics",
      "common lisp"
    ]
  },
  {
    "text": "how to recover yahoo! mail account. i still remember my yahoo! id and password but the problem is when i login, i'm asked to provide the security question which i already forgot the answer. i don't have any other recovery ways like alternate email or phone number.i tried also the answers from this forgot my yahoo! mail password but seems to be not applicable to me or not working.is there any email we can send for support? since hotline numbers are for uk & canada only i think.",
    "present_kp": [],
    "absent_kp": [
      "yahoo mail",
      "yahoo account"
    ]
  },
  {
    "text": "self registration in factory class. i currently want the base class also be the factory with static create function.to make base class does not need to know the imp concrete classes, i try to forward the two core jobs of factory to the concrete class. one is what are the all concretes. another is how to dispatch it.i try let the concretes to be added by itself. registered in a global vector with global instance this of each concrete class. factory method will iterate all the method* from vector.the job about what concrete class should be dispatched based on the argument is decided by a virtual boolean function, overridden by concreted class itself and check it can accept or not. struct method { virtual void call() = 0; virtual bool accept(const arg& arg) = 0; virtual ~method(){} static std::vector<method*> concretes; static method* create(const arg& arg) { for(auto m: method::concretes) { // let imp concrete decide accept argument or not if(m->accept(arg)) { return m;} } return nullptr; }protected: // avoid explicitly called by client method(){ method::concretes.push_back(this); }};// methoda.cppstruct methoda : method { virtual void call() { ... }; virtual bool accept(const arg& arg) { ... };} methoda_ins; // self registered in base ctor into method::concretes// methodb.cppstruct methodb : method { virtual void call() { ... }; virtual bool accept(const arg& arg) { ... };} methodb_ins;is this technique common? or is there any flaw or drawback i should be careful?thanks.",
    "present_kp": [],
    "absent_kp": [
      "c++",
      "object oriented",
      "design patterns"
    ]
  },
  {
    "text": "how can i remove referral spam using a .htaccess file?. i have three websites on various topics, but i can't decrease the bounce rate for them. some spam referrers have been increasing my site's bounce rate day-by-day. how can i remove this type of referral spam via a .htaccess? can you provide an example for one such referrer?",
    "present_kp": [
      "htaccess",
      "referrer"
    ],
    "absent_kp": [
      "google analytics"
    ]
  },
  {
    "text": "can you perform system calls from osx terminal?. so i get system calls in the context of a c program, but my textbook doesn't really address making system calls in terminal (on mac osx). can you do these on the command line like with commands, or is it a totally different concept? sorry, i'm sure this is very elementary, just can't find an answer.",
    "present_kp": [
      "command line",
      "osx",
      "system calls"
    ],
    "absent_kp": []
  },
  {
    "text": "is there a factory pattern to prevent multiple instances for same object (instance that is equal) good design?. i have a number of objects storing state. there are essentially two types of fields. the ones that uniquely define what the object is (what node, what edge etc), and the others that store state describing how these things are connected (this node is connected to these edges, this edge is part of these paths) etc. my model is updating the state variables using package methods, so all these objects act as immutable to anyone not in model scope. all objects extend one base type.i've toyed with the idea of a factory approach which accepts a builder object and constructs the applicable object. however, if an instance of the object already exists (ie would return true if i created the object defined by the builder and passed it to the equal method for the existing instance) the factory returns the current object instead of creating a new instance. because the equal method would only compare what uniquely defines the type of object (this is node a to node b) but won't check the dynamic state stuff (node a is currently connected to nodes c and e) this would be a way of ensuring anyone that wants my node a automatically knows its state connections. more importantly it would prevent aliasing nightmares of someone trying to pass an instance of node a with different state then the node a in my model has.i've never heard of this pattern before, and it's a bit odd. i would have to do some overriding of serialization methods to make it work (ensure that when i read in a serilized object i add it to my facotry list of known instances, and/or return an existing factory in its place), as well as using a weakhashmap as if it was a weakhashset to know whether an instance exists without worrying about a quasi-memory leak occuring. i don't know if this is too confusing or prone to its own obscure bugs.one thing i know is that plugins interface with lowest level hardware. the plugins have to be able to return state that is different than my memory; to tell my memory when its own state is inconsistent. i believe this is possible despite their fetching objects that exist in my memory; we allow building of objects without checking their consistency with the model until the addtomodel is called anyways; and the existing plugins design was written before all this extra state existed and worked fine without ever being aware of it.should i just be using some other design to avoid this crazyness? (i have another question to that affect that i'm posting).",
    "present_kp": [
      "design"
    ],
    "absent_kp": [
      "mvc",
      "factory method"
    ]
  },
  {
    "text": "turing machine that computes maximum steps of halting machines. suppose that $tm_{halting}$ is the set of machines that halt.given a number of states $m$ and a length $n$ of the input, let $f(m,n)$ be the maximum number of steps a machine with $m$ states in $tm_{halting}$ can take on an input of length $n$.is the function $f(m,n)$ computable?",
    "present_kp": [],
    "absent_kp": [
      "turing machines",
      "halting problem"
    ]
  },
  {
    "text": "c++ equivalent of python's deque with maxlen - sliding window. in python it is really easy to get sliding window functionality using a deque with maxlen:from collections import dequedeck = deque(maxlen=4)deck.append(0x01)deck.append(0x02)deck.append(0x03)deck.append(0x04)deck.append(0x05)for item in deck: print(item) # outputs 2, 3, 4, 5this does two things - it grows until maxsize and then once maxsize has been reached items drop off the deque.i wanted something similar in c++ and wrote the following (note, i know c++ has a deque, but i couldn't see how to reserve the size):template <typename t>auto rotate_push(std::vector<t> &container, const t& val) -> void{ if (container.size() < container.capacity()) { container.resize(deck.size() + 1); } else { std::rotate(container.begin(), container.begin() + 1, container.end()); } container[container.size() - 1] = val;}auto deck = std::vector<int>();deck.reserve(4);rotate_push(deck, 1);rotate_push(deck, 2);rotate_push(deck, 3);rotate_push(deck, 4);rotate_push(deck, 5);for (auto const &item : deck) { printf(%d , item); // outputs 2, 3, 4, 5}my questions are:are the implementations basically equivalent (if not then why)is there a better custom implementationis there a easier/pre-existing implementation using stlis there a easier/pre-existing implementation using otheris there a more performant implementationanswers:no, they have different push complexity [by johnbot]use a free function or wrap std::deque [by johnbot](un-answered)boost circular buffer [by ratchet freak]circular buffer [by ratchet freak]",
    "present_kp": [
      "python",
      "c++",
      "collections"
    ],
    "absent_kp": []
  },
  {
    "text": "flop counting for library functions. when evaluating the number of flops in a simple function, one can often just go down the expression tallying basic arithmetic operators. however, in the case of mathematical statements involving even division, one cannot do this and expect to be able to compare with flop counts from functions with only additions and multiplications. the situation is even worse when the operation is implemented in a library. therefore, it is imperative to have some reasonable notion of the performance of the special functions.by special functions, we mean things like: exp() sqrt() sin/cos/tan()which are usually provided by system libraries.determining the complexity of these is confounded even further by the fact that many of them are adaptive and have input-dependent complexity. for example, numerically stable implementations of exp() often adaptively rescale and use look-ups. my initial impression here is that the best one may do in this case is ascertain the average behavior of the functions.this entire discussion is, of course, highly dependent on the architecture. for this discussion we can restrict ourselves to traditional general purpose architectures and exclude those with special function units (gpus, etc.)one can find fairly simple attempts to standardize these for particular architectures for the sake of system vs. system comparison, but this is not acceptable if one cares about method vs. method performance. which methodologies for determining the flop complexity of these functions are considered to be acceptable? are there any major pitfalls?",
    "present_kp": [
      "performance",
      "complexity"
    ],
    "absent_kp": [
      "floating point"
    ]
  },
  {
    "text": "how to fix inconsistent (variable spelling) categorical data and fill in missing data. i am a newbie data science engr. my first challenge is to (1) normalize inconsistent values in categorical features and (2) fill any missing information. to describe inconsistency lets say we have a country field and there can be multiple entries for usa. e.g. usa, united states of america, us, us-50, united states, america, etc.how do i normalize all these entries and just say usa for all entries. i can think of some set of full text search rules to match against using lucene or something. is there any specific technical term for this problem?",
    "present_kp": [
      "categorical data",
      "missing data"
    ],
    "absent_kp": [
      "data cleaning",
      "normalization"
    ]
  },
  {
    "text": "mint 13: is it possible to skip standard login password dialog in presence of a pendrive with the key. to meet my security needs i set up quite long user password on my notebook. but when i am at home or other secure location, typing it down is cumbersome. it would be nice to let the gdm (or: mdm, since i am using mint 13 with mate) search for a specific file (on a pendrive), and when it is present, treat is as a security token and log in me automaticaly with it. i use encrypted home folders.",
    "present_kp": [
      "gdm"
    ],
    "absent_kp": [
      "linux mint",
      "login manager",
      "autologin"
    ]
  },
  {
    "text": "how to change the default file manager in gnome 3 (fedora 23) with lxde installed?. i did a fresh install of fedora 23 workstation (gnome spin), then later installed lxde on top of it using dnf for running the more memory-extensive applications.the problem is, since i installed lxde, while using gnome 3, when i press super + e (which is assigned to launch the home folder), pcman file manager (which came with lxde) opens up instead of gnome's default nautilus.note that simply changing the shortcut to open nautilus instead is not a solution, since other applications may still launch pcman file manager.my question is: how do i change the default file manager in gnome to nautilus, and yet keep pcman file manager as the default in lxde?what i've tried:went to settings -> details -> default applications, no option to change the default file manager there.this solution doesn't work for me either. $ locate defaults.list yields nothing.",
    "present_kp": [
      "fedora",
      "gnome",
      "lxde"
    ],
    "absent_kp": [
      "gnome3"
    ]
  },
  {
    "text": "would using ajax extensively improve server performance?. clearly ajax improves the user interface but does this also decrease server load? you would think it does because the entire page will not have to be served up each time, but maybe there are other variables i'm not considering.",
    "present_kp": [
      "performance",
      "ajax"
    ],
    "absent_kp": []
  },
  {
    "text": "saving a model with joblib, load it and keep training it. i know how to fit a linear regression model, save it using joblib.dump and then load it again with joblib_load.however, after i reload the model, i would like to be able to keep training it, but it looks like if i doalg = joblib.load(mymodel)alg.fit(x, y)the fit will fit it from scratch, dropping the previously saved model loaded with joblib.how can i train a model, save it, load it, and then do some more training on it?",
    "present_kp": [
      "training"
    ],
    "absent_kp": [
      "python",
      "scikit learn"
    ]
  },
  {
    "text": "how to specify a daemon shutdown command with upstart?. in an upstart configuration how do i define what command should be used to shutdown a server. lets say i have daemon that has two seperate processes. startup.sh - to start the server shutdown.sh - to shut down the serversuppose i have an upstart file that looks like this. description some example serviceauthor mestart on runlevel [2345]stop on runlevel [016]respawnexec satrtup.sh how do i tell upstart that it should called shutdown.sh when shutting down the server? how does upstart normally expect to shut down a daemon?",
    "present_kp": [
      "daemon",
      "upstart"
    ],
    "absent_kp": [
      "ubuntu",
      "administration"
    ]
  },
  {
    "text": "does source control have any provisions for preventing old code from overwriting new code?. i'm sure that there is a similar question like this already in existence, but i didn't see one that matched closely enough, so here goes...we use a third party company to host our site and do most of the code updates and the code is maintained in a git repository. however, we haven't been too happy with the job they've done, so we've outsourced more and more projects to other companies. these other companies maintain their own staging servers and i send them updated versions of the source code and the database as frequently as possible, but in most cases they don't always start each project with the absolute latest version of either.due to a backlog, we recently had an issue where a project that was submitted by that company didn't make it to our staging server until about a month after it had been submitted. so when these files were copied to the staging server, the file that is used by the rest of the application was about a month old and there had been quite a few updates to it in the interim. so when this file went to the staging server, a lot of the recent updates were not present and functionality that had gone live on production was missing from staging. some of the missing functionality wasn't immediately obvious because you had to be in a certain mode to notice it was missing, so it wasn't detected right away.i should also mention that even before we had outside companies start working on projects, this was still a problem. old code would frequently replace more recent updates and then we would have to pay this company to correct the problem and redo work that was already completed. obviously, sites that are worked on by multiple developers must face this problem on a continual basis. is this a case where the company that controls the process employs a questionable methodology or is there really no good way to prevent this from happening? i feel like i'm stuck in a twilight zone version of the springsteen song one step forward, two steps back. thanks in advance for any replies. much appreciated!",
    "present_kp": [
      "git"
    ],
    "absent_kp": [
      "version control"
    ]
  },
  {
    "text": "code contracts/asserts: what with duplicate checks?. i'm a huge fan of writing asserts, contracts or whatever type of checks available in the language i'm using. one thing that bothers me a bit is that i'm not sure what the common practice is for dealing with duplicate checks.example situation: i first write the following functionvoid dosomething( object obj ){ contract.requires<argumentnullexception>( obj != null ); //code using obj}then a few hours later i write another function that calls the first one. as everything is still fresh in memory, i decide not to duplicate the contract, since i know that dosomething wil check for a null object already:void dosomethingelse( object obj ){ //no requires here: dosomething will do that already dosomething( obj ); //code using obj}the obvious problem: dosomethingelse now depends on dosomething for verifying that obj is not null. so should dosomething ever decide not to check anymore, or if i decide to use another function obj might not be checked anymore. which leads me to writing this implementation after all:void dosomethingelse( object obj ){ contract.requires<argumentnullexception>( obj != null ); dosomething( obj ); //code using obj}always safe, no worries, except that if the situation grows the same object might be checked a number of times and it's a form of duplication and we all know that's not so good.what is the most common practice for situation like these?",
    "present_kp": [
      "code contracts"
    ],
    "absent_kp": [
      "assertions"
    ]
  },
  {
    "text": "invalid description for google search. when i go to google and type princetonstaffingsolutions.com i get for my search description: fatal error: uncaught exception 'zend_controller_router_exception' with message 'route default is not defined' in ...i have the following set in my html : <meta name=robots content=index,follow >how do i get google to update my website description in google?",
    "present_kp": [
      "google",
      "google search"
    ],
    "absent_kp": []
  },
  {
    "text": "splitting single class into multiple classes. i am writing automated test scripts with selenium webdriver (python) and i try to follow the correct programming practices, specifically the object oriented methodologies, where possible.at the moment, i represent every test scenario as a single class. that class is basically has the following structure:imports (selenium modules as well as python stuff)logging configurationclass definition that includes the below:driver instance initializationspecific test scenario variablesgeneric methods (some wrappers i created that are used in multiple testing scenarios)specific application methodsso that's something like that:importsloggingclass appname(object): def __init__(self): self.driver = webdriver.chrome() self.localappvar = ... ... def genericfunction(self): #this is a generic function that is going to be used in many other test scenarios as well as in this one def specificappfunction(self): #this is a specific application function. this function is only relevant withing this test. this function will use genericfunction internally.app = appname() #initialize an appname objectapp.specificappfunction()...what i would like to do is to separate the above class into 2 new classes and a launcher file:generic functions class. this one will define the driver object as well as all generic functions that are going to be used by multiple tests.specific functions class. this one will contain the application specific function that are irrelevant for other applications.launcher file that will initialize\\instantiate the above mentioned classes and will control the scenario on a higher level. (kind of main in c if you like).the above idea makes sense to me but i am a bit confused about the practical approach. how should that be implemented properly? i was thinking about following options:creating a generic class instance withing a specific application class.make the generic class a base class and then inherit it by specific application class.i am not sure about pros and cons of both approaches and currently a bit stuck with the implementation. it will be great if someone could give me some insight on how such task should be implemented.hopefully my question is clear enough. if it's not, please comment and i will elaborate or/and edit.",
    "present_kp": [
      "python",
      "class",
      "object oriented",
      "selenium"
    ],
    "absent_kp": []
  },
  {
    "text": "how to install ubuntu touch on an iphone 4?. is it possible to install ubuntu touch on an iphone 4? in my research, some claimed it wasn't, but i'm not convinced. i found some tutorials for the nexus phone, and a forum thread, but it wasn't very clear.how can it be done? does it require an ubuntu desktop? the iphone i'm installing on isn't important, so i'm willing to try unsafe installations.",
    "present_kp": [
      "ubuntu",
      "iphone"
    ],
    "absent_kp": []
  },
  {
    "text": "how does the agpl apply to javascript libraries?. i have a web app that i sell.it is a java rest service with an angularjs front end.i want to use a javascript library that is licensed under the agpl but i don't understand the implications or if it is ok for me to use it. specifically, i don't understand the modifying/linking/usage parts and how it applies and what it applies to.i'm not modifying the library.i am distributing the library inside my webapp rather than via a full url (external web access is not always available in this case)my javascript code that calls the library is minifiedso the questions:does the agpl mean i have to distribute my source code that is using this library?do i have to include the source code of the java part or just the javascript part?since the user can see my javascript in the browser does that count as distributing my source code?does it still count if it is minified since it doesn't match the source code in my repo?is there a matrix anywhere giving a short summary about what the common licences mean in different situations?",
    "present_kp": [],
    "absent_kp": [
      "licensing",
      "agpl 3.0",
      "website"
    ]
  },
  {
    "text": "will this delete my entire google account or just google plus?. i don't know why can't they be more clear on this.",
    "present_kp": [
      "google plus",
      "google account"
    ],
    "absent_kp": []
  },
  {
    "text": "is gmail priority inbox only for google apps accounts?. i don't see gmail priority inbox feature in normal gmail account, but the option to activate is there on my google apps gmail. so, wondering is this priority thing has been launched only for apps??",
    "present_kp": [
      "gmail",
      "google apps"
    ],
    "absent_kp": []
  },
  {
    "text": "to find a subsequence having largest sum among n positive integers by not choosing 3 consecutive elements. this problem is from codechef.can anyone please help me out with this one as i am unable to find out the subproblem.thanks in advance!problem -: in ipl 2025, the amount that each player is paid varies from match to match. the match fee depends on the quality of opposition, the venue etc.the match fees for each match in the new season have been announced in advance. each team has to enforce a mandatory rotation policy so that no player ever plays three matches in a row during the season.nikhil is the captain and chooses the team for each match. he wants to allocate a playing schedule for himself to maximize his earnings through match fees during the season.input formatline 1: a single integer n, the number of games in the ipl season.line 2: n non-negative integers, where the integer in position i represents the fee for match i.output formatthe output consists of a single non-negative integer, the maximum amount of money that nikhil can earn during this ipl season.sample input 15 10 3 5 7 3 sample output 123(explanation: 10+3+7+3)sample input 283 2 3 2 3 5 1 3sample output 217(explanation: 3+3+3+5+3)",
    "present_kp": [],
    "absent_kp": [
      "dynamic programming"
    ]
  },
  {
    "text": "optimizing code for project-euler problem #23. i'm working on project euler's problem #23, which isfind the sum of all the positive integers which cannot be written as the sum of two abundant numbersi came up with this algorithm. find all abundant numbers under 28123 (defined numeric#abundant?), this is slow and could be faster if skipped primes, but is fairly fast (less than 4 secs):abundant_numbers = (12..28123).select(&:abundant?)find all numbers that can be expressed as the sum of 2 perfect numbers:inverse_set = abundant_numbers.each.with_index.inject([]) do |a,(n,index)| a.concat( abundant_numbers[index..abundant_numbers.size-1] .take_while { |i| (n+i) <= 28123 }.map { |i| n+i } )end.to_setthe rest them from all the integers under 28123 and sum them all:solution_set = (1..28123).set - inverse_setsolution_set.reduce(:+)benchmarked: time ruby 0023.rb real 0m20.036suser 0m19.593s sys 0m0.352s rvm use 2.0.0 time ruby 0023.rb solution: 4*****1real 0m7.478suser 0m7.348s sys 0m0.108sit works, but it's a little bit slow, takes about 20secs to solve, and i hear people around saying it can be solved within miliseconds. i'm sure many of you will have a quick insight on what have i missed.",
    "present_kp": [
      "ruby",
      "primes"
    ],
    "absent_kp": [
      "programming challenge"
    ]
  },
  {
    "text": "how do i fix the status bar symbols in the airline plugin?. i installed the airline plugin in order to have a custom status bar, as seen in the figure below:however, my status bar is presenting the symbols <, >> and <. how do i fix this problem?",
    "present_kp": [],
    "absent_kp": [
      "plugin vim airline"
    ]
  },
  {
    "text": "using a spinner like a html select to display string but return int value. i'm still learning android, i need to have a spinner and for it to display a list of string values. however, when i submit that data later on i need a corresponding integer value.similarly to how a html select uses <option value=2>blahblah</option>.from searching i've come up with a method which works, just wondering if anyone had any suggestions for improving the code?i've got the two variables setup:private string[] arrmuppetnames = {kermit,gonzo,fuzzy,animal};hashmap<string, integer> hashmuppets = new hashmap<string, integer>();hashmuppets is built up with a simple set of kermit:1,gonzo:2 etc.then to stop the code running on load i've added a --please select-- to index 0.//add please select to spinnerarrnewarray[0] = this.getstring(r.string.muppet_select);for(int i=0; i < arrmuppets.length; i++){ arrnewarray[i+1] = arrmuppets[i];}obviously i add this array arrnewarray to the spinner using arrayadapter. then use the onitemselectedlistener.private spinner.onitemselectedlistener spinnerlistener = new spinner.onitemselectedlistener(){ @override public void onitemselected(adapterview<?> arg0, view arg1,int arg2, long arg3) { spinner spinner = (spinner) findviewbyid(r.id.muppet_spinner); //arg 3 is selected index. lets ensure we didn't select our please select if(arg3 != 0){ //get selected item and convert to corresponding value using hashmap string strselectedmuppet = spinner.getselecteditem().tostring(); int intcatid = hashmuppets.get(strselectedmuppet); //show toast of value toast.maketext(getapplicationcontext(), string.valueof(intcatid), toast.length_short).show(); } } @override public void onnothingselected(adapterview<?> arg0) { //do nothing }};if anyone has any suggestions or pointers i'd very much appreciate it. i'm happy to post the full code if you'd like, but i'm hoping the above short example is pretty self explanatory.thanks",
    "present_kp": [
      "android"
    ],
    "absent_kp": [
      "java"
    ]
  },
  {
    "text": "can integration tests be run asynchronously with maven?. because i work at a company with lots and lots of computers, i find it to be a little ironic that it takes half an hour to cut a release of the latest version of our software. the bottleneck seems to be integration tests run by maven, and the cause of the bottleneck is because those integration tests seem to want to be run sequentially. there isn't any real reason for them to be run in order, other than the fact that they're lots of cucumber tests run against a single database that has to be set up and torn down for every feature. so, my question is, how do we fail faster with maven?",
    "present_kp": [
      "integration tests",
      "maven",
      "cucumber"
    ],
    "absent_kp": []
  },
  {
    "text": "have network always wait for a network connection?. just as the title says, is there a way to tell ubuntu server to constantly wait for an ethernet connection after it gets disconnected? use case: ethernet cable gets unplugged (intentionally) for a long period of time, cable gets plugged back in, computer must be forcefully restarted to get on the network again",
    "present_kp": [
      "ubuntu"
    ],
    "absent_kp": []
  },
  {
    "text": "reading input from the console in f#. in the process of learning f#, i wrote this code that reads lines of input from the console and stores them in a list.as far as i can tell the code works correctly, but since i'm new to functional programming, i'm not sure if it is written as well as it could have been.should i have read characters iteratively instead of recursively?is there a better alternative to using a stringbuilder object?does my code follow proper functional style?open system/// appends a character to the string builder and returns the new builder./// characters 10 and 13 (newline and carriage return) are ignored./// returns the updated stringbuilder.let appendchar char (builder : text.stringbuilder) = match char with | 10 | 13 -> builder | n -> let c = convert.tochar(n) builder.append(c)/// finishes building a string by clearing the stringbuilder/// and appending the string to the end of the list of strings./// empty strings are ignored./// returns a tuple containing the lines and the new stringbuilder.let finishstring lines (builder : text.stringbuilder) = let s = builder.tostring() let l = builder.length let newbuilder = builder.clear() match l with | 0 -> (lines, newbuilder) | _ -> (lines @ [s], newbuilder)/// handles a character by appending it to the builder and taking an appropriate action./// if char is a newline, finish the string./// returns a tuple containing lines and the new builder.let handlechar char lines builder = let newbuilder = appendchar char builder match char with | 10 -> finishstring lines newbuilder | c -> (lines, newbuilder)/// gets all the lines from standard input until end of input (ctrl-z)./// empty lines are ignored./// returns a list of strings read.let rec getlines lines builder = match console.read() with | -1 -> lines | c -> let tuple = handlechar c lines builder let newlines = fst tuple let newbuilder = snd tuple getlines newlines newbuilder[<entrypoint>]let main argv = text.stringbuilder() |> getlines [] |> ... and so on",
    "present_kp": [
      "functional programming",
      "f#"
    ],
    "absent_kp": []
  },
  {
    "text": "friends of a friend can see my post when my friend comments or likes, even if i am not my friend's friends. if i post something on facebook and a friend comments on it or likes it, how is it that other people who are friends of the comment writers or likers, but not friends of mine, can see it?surely this is against the point of me having a private profile, isnt it?",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": [
      "privacy"
    ]
  },
  {
    "text": "how can i search within someone's twitter followers?. i'm trying to find all users that describe themselves as a professor within their twitter profiles, but only if they follow certain accounts. i've looked at tweet reports but i believe this tool only allows you to search within your own followers. you can see another account's followers and do ctrl + f, but if they have thousands of followers you don't get everyone.is there a better way to do this?",
    "present_kp": [
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "switch to drupal. currently i manage a website written entirely in html5, php, javascript and css3 with a mysql database. the site resides on a dedicated server with centos and plesk is used for management. i thought i'd switch to a cms like drupal and continue to use the current mysql database in order to speed up the expansion of the project. the site is a portal that will sustain a traffic of about 5000 registered users monthly and any visitors (the latter, however, can not perform operations if the consultation pages). is this an optimal solution?any advice is welcome. thanks",
    "present_kp": [
      "cms",
      "mysql",
      "drupal"
    ],
    "absent_kp": [
      "web development"
    ]
  },
  {
    "text": "controller card(s) for handling eight usb 2.0 devices at full speed. connecting two usb2 devices to an external usb2/3 hub, connected to one usb2/3 port would normally limit the average read-speed to 240 mb/s, and continuing adding devices would limit the average speed to 480mb/s divided by number of devices. the same would be if i use a usb controller card on the mainboard of most computers, as they are normally implemented using only one usb channels.i guess the solution for handling eight devices in full speed is to get usb controller(s) that is implemented using eight dedicated channels to handle the speed of all of the devices.it does exist an usb controller card that are able to handle full speed of four usb 3.0 devices (pexusb3s44v). four two of these the total would cost about $255 here in norway. as i do not need the speed of usb 2.0 this price is a bit to much.are there any other alternatives that would handle 8 or 2*4 usb 2.0 drives at full speed to a cheaper price than $255?",
    "present_kp": [
      "usb"
    ],
    "absent_kp": []
  },
  {
    "text": "fixed point number to string. i recently learned about using fixed point arithmetic on embedded systems without floating point hardware, so i decided to code it. i tried to write in good style, but emphasized speed over style.one hard problem i encountered was to convert the number to a string. i coded up the following in my internal class; the macros aren't leaked to the user. the intent of using macros is so that i could easily make a new function for a data-type of uint32_t, uint16_t, and so on, but also have different length of the fractional bits.unfortunately, my algorithm requires a larger data-type to actually compute the fractional representation, so it's not trivial to make a fractional type for say uint64_t, as there are no larger types. also, it fails on signed integers. how is the snprint function?#define fixmath_internal_digit_to_char(x)\\ (x) == 0 ? (char) '0'\\: (x) == 1 ? (char) '1'\\: (x) == 2 ? (char) '2'\\: (x) == 3 ? (char) '3'\\: (x) == 4 ? (char) '4'\\: (x) == 5 ? (char) '5'\\: (x) == 6 ? (char) '6'\\: (x) == 7 ? (char) '7'\\: (x) == 8 ? (char) '8'\\:/*(x)==9*/ (char) '9'// we convert the fixed point number type to a string via the following algorithm:// let fixed = w.f// output the integer 'w' to the string, then append '.'// now we need to convert 'f' to a string. 'f' is a binary decimal, so note the following:// 2**-1 = 0.5// 2**-2 = 0.25// 2**-3 = 0.125// 2**-4 = 0.0625// basically, we get increasing powers of 5 on the right. this is true because we operate// in base 10. so to convert 'f' to a string://// powerof5 = 1; acc = 0;// for (bit b : f) { // starting from the left// powerof5 *= 5; // advance power of 5 so we start at 0.5// acc *= 10; // notice that the decimal place needs to shift as we multiply by powers of 5// if (b) acc += powerof5;// }//// now 'acc' contains an integer representation of the string we want. add this to our// output string. however *remember leading 0s.*#define fixmath_internal_def_snprint(/* the type of fixed-point we are dealing with */ fix_t,\\ /* a printf specifier that handles the data type */ prtype,\\ /* the storage type for fix_t. prtype matches this */ storage_t,\\ /* a bigger storage type that holds >= 5**bitlen(f) */super_storage_t,\\ /* the width of storage_t. w + f, where we have w.f */ n,\\ /* the width of the fractional part of the number */ f)oid cutils_fixmath_internal_ ## fix_t ## _snprint(const fix_t *self, const size_t n, char *writeto) {\\ storage_t wholeparts = self->data >> f; /* 'w' where the fix_t is of the form w.f */\\ storage_t fracparts = self->data & ((1 << f) - 1); /* 'f' where the fix_t is of the form w.f */\\ char wholestring[n - f + 1]; /* stores the whole part of the number w.f */ \\ size_t numwholechars = sprintf(wholestring, % prtype ., wholeparts);\\ super_storage_t powerof5 = 1;\\ super_storage_t acc = 0;\\ for (size_t i = 0; i < f; i++) {\\ powerof5 *= 5;\\ acc *= 10;\\ if (fracparts & (1 << (f - i - 1))) {\\ acc += powerof5;\\ }\\ }\\ /* at this point, note that 'acc' stores an integer representation of the fractional string. */\\ char fracstring[f + 1]; /* always output at least m decimal places, +1 for the '' */\\ memset(fracstring, '0', f); /* account for leading 0s! */\\ fracstring[f] = '';\\ size_t fracstringindex = f - 1; /* where do we store the next digit? */\\ while (acc > 0) { /* iterate from the rightmost digit to the leftmost; more efficient */\\ fracstring[fracstringindex] = fixmath_internal_digit_to_char(acc % 10);\\ acc /= 10;\\ fracstringindex--;\\ }\\ strncpy(writeto, wholestring, n); /* copy our 'w.' string to the output */\\ strncpy(writeto + numwholechars, fracstring, n - numwholechars); /* append the 'f' string to the output */\\}here is an example class:typedef struct ufix8_f4_t{ uint8_t data; struct ufix8_f4_t(*add)(const struct ufix8_f4_t *self, const struct ufix8_f4_t *other); void (*addeq)(struct ufix8_f4_t *self, const struct ufix8_f4_t *other); struct ufix8_f4_t(*sub)(const struct ufix8_f4_t *self, const struct ufix8_f4_t *other); void (*subeq)(struct ufix8_f4_t *self, const struct ufix8_f4_t *other); struct ufix8_f4_t(*mul)(const struct ufix8_f4_t *self, const struct ufix8_f4_t *other); void (*muleq)(struct ufix8_f4_t *self, const struct ufix8_f4_t *other); struct ufix8_f4_t(*div)(const struct ufix8_f4_t *self, const struct ufix8_f4_t *other); void (*diveq)(struct ufix8_f4_t *self, const struct ufix8_f4_t *other); void (*snprint)(const struct ufix8_f4_t *self, const size_t n, char *writeto);} ufix8_f4_t;i can define the snprint function for this via:fixmath_internal_def_snprint(ufix8_f4_t, priu8, uint8_t, uint16_t, 8, 4);(naturally, i'd need to have to include string.h, inttypes.h, and stdio.h).this snprint would expand to:void cutils_fixmath_internal_ufix8_f4_t_snprint(const ufix8_f4_t *self, const size_t n, char *writeto) { uint8_t wholeparts = self->data >> 4; uint8_t fracparts = self->data & ((1 << 4) - 1); char wholestring[8 - 4 + 1]; size_t numwholechars = sprintf(wholestring, % u ., wholeparts); uint16_t powerof5 = 1; uint16_t acc = 0; for (size_t i = 0; i < 4; i++) { powerof5 *= 5; acc *= 10; if (fracparts & (1 << (4 - i - 1))) { acc += powerof5; } } char fracstring[4 + 1]; memset(fracstring, '0', 4); fracstring[4] = ''; size_t fracstringindex = 4 - 1; while (acc > 0) { fracstring[fracstringindex] = (acc % 10) == 0 ? (char) '0' : (acc % 10) == 1 ? (char) '1' : (acc % 10) == 2 ? (char) '2' : (acc % 10) == 3 ? (char) '3' : (acc % 10) == 4 ? (char) '4' : (acc % 10) == 5 ? (char) '5' : (acc % 10) == 6 ? (char) '6' : (acc % 10) == 7 ? (char) '7' : (acc % 10) == 8 ? (char) '8' : (char) '9'; acc /= 10; fracstringindex--; } strncpy(writeto, wholestring, n); strncpy(writeto + numwholechars, fracstring, n - numwholechars);};",
    "present_kp": [
      "c",
      "fixed point"
    ],
    "absent_kp": [
      "performance",
      "generics"
    ]
  },
  {
    "text": "traverse a matrix using a linear index to get an evenly distributed values sample. i'm looking for an algorithm idea on how to traverse a matrix using a linear index while avoiding row/column based traversals to get a more diverse distribution of values.to understand this better, think of an image that's split in blocks, with n rows & m columns. i need to process each image block sequentially (from 1 to nxm) but i don't know in advance what the processing time will be for each block ( blocks that are close together tend to have a similar processing time, with small variations). during processing, i need to be able to estimate as best as possible the remaining processing time based on the number of blocks that have already been processed & their associated processing time. for this reason, traversing the blocks by columns or by rows will not give an accurate estimation so i need to find another way of traversing the matrix that would pick values from different zones of the image.it's also important to be able to determine the blocks processing order based on a linear index (from 1 to nxm), without calculating them in advance. the algorithm that returns the row & column corresponding to the linear index should be as fast as possible.shorter version of the questionfor a liner index named idx, i need to get a corresponding row & column pair from a matrix with n rows & m columns while avoiding a row/column based traversal. for each idx between 1 and nxm, the algorithm would return a [row, column] pair so that all the rows & columns combinations are returned exactly once.example(the values in the matrix represent the linear index's value that's associated with that row&column position) 1 17 13 9 5 6 2 18 14 1011 7 3 19 1516 12 8 4 20the above example is for a diagonal traversal that would produce a better distribution of values that a row/column based traversal.another possible solution would be to split the matrix into smaller blocks & traverse those blocks in rows/columns. for example a 4x5 matrix could be virtually split into 2x2 blocks and those smaller blocks could be traversed by rows or columns (e.g. idx(1) = block1[1, 1], idx(2) = block2[1, 1], etc.). the traversal would look something like this: 1 13 | 3 15 | 5 7 17 | 9 18 | 11------+-------+--- 2 14 | 4 16 | 6 8 19 | 10 20 | 12any other traversal ideas are welcomed. ideally, this algorithm would translate to a math formula to calculate the row & column based on the linear index, possibly with a few conditions (if statements) to compensate for missing values, etc.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "language agnostic"
    ]
  },
  {
    "text": "reorder attachments in trello. by default, trello adds the newest attachment to the top of a stack. short of deleting all attachments on a card and re-adding them in the order i require, is there any other way to sort them?",
    "present_kp": [
      "trello"
    ],
    "absent_kp": []
  },
  {
    "text": "how to evaluate a web developer?. i want to hire someone to set up a website. what do i ask to determine competence and integrity of the individual? is there a chart of reasonable charges/costs? how do i know if i am being over-charged?",
    "present_kp": [],
    "absent_kp": [
      "web development",
      "website design",
      "ecommerce"
    ]
  },
  {
    "text": "interrupt process in samba share mounted folder breaks mount. i can successfully mount a samba share on a local folder in opensuse 12.1:sudo mount -t cifs -o username=<username>,password=<password> //<win-box>/<share> <mountpoint>the problem comes if i interrupt (^c) for example a long cp process in <mountpoint>: i get> cp -r big_folder/ /tmp^c> lsls: reading directory .: permission deniedthe only solution i found is to sudo umount <mountpoint> then mount again.any advice is welcome!",
    "present_kp": [
      "mount",
      "samba"
    ],
    "absent_kp": []
  },
  {
    "text": "do open source projects have better or worse female participation than proprietary projects?. sometimes the claim is heard open source projects are especially unfriendly to women. sometimes the claim is heard, that open-source projects are especially inclusive. it probably is impossible to answer which is more true, but we could get a hint by looking at real participation from females.are there studies comparing similar projects in open source and in proprietary projects that analyze the numbers and perhaps roles of male and female contributors?",
    "present_kp": [],
    "absent_kp": [
      "community"
    ]
  },
  {
    "text": "how can i clean up strings built at runtime?. how can i clean up/simplify strings that are built at runtime?i've seen this a couple of times and figured that there has to be something easier. i've been manually converting the characters to try and interpret what strings are being formed..text:0040166e c6 45 f0 5c mov [ebp+pszsubkey+2ch], ''.text:<phone> c6 45 f1 57 mov [ebp+pszsubkey+2dh], 'w'.text:<phone> c6 45 f2 69 mov [ebp+pszsubkey+2eh], 'i'.text:0040167a c6 45 f3 6e mov [ebp+pszsubkey+2fh], 'n'.text:0040167e c6 45 f4 6c mov [ebp+pszsubkey+30h], 'l'.text:<phone> c6 45 f5 6f mov [ebp+pszsubkey+31h], 6fh.text:<phone> c6 45 f6 67 mov [ebp+pszsubkey+32h], 67h.text:0040168a c6 45 f7 6f mov [ebp+pszsubkey+33h], 6fh.text:0040168e c6 45 f8 6e mov [ebp+pszsubkey+34h], 6eh.text:<phone> c6 45 f9 5c mov [ebp+pszsubkey+35h], 5ch",
    "present_kp": [],
    "absent_kp": [
      "ida",
      "idapython"
    ]
  },
  {
    "text": "is there any linux command to get number of context switches for a process?. is there any linux command to get various information like context switches of a process? any solution other than ps will be appreciated.",
    "present_kp": [
      "linux",
      "process"
    ],
    "absent_kp": []
  },
  {
    "text": "binding an i2c device driver. i am attempting to use a tca8418 keypad (which operates over i2c) and i have the driver loaded into the kernel, but the device was not recognized so i am instantiating it myself and am unable to bind the driver. i get the following error:# echo -n 1-0034 > /sys/bus/i2c/drivers/tca8418_keypad/bind-bash: echo: write error: no such devicethis is after having tried the following (as root):# echo -n tca8418_keypad 0x34 > /sys/bus/i2c/devices/i2c-1/new_devicei have the following device and driver trees, respectively:/sys/bus/i2c/devices/1-0034|-- modalias|-- name|-- power| |-- autosuspend_delay_ms| |-- control| |-- runtime_active_time| |-- runtime_status| '-- runtime_suspended_time|-- subsystem -> ../../../../../bus/i2c'-- uevent/sys/bus/i2c/drivers/tca8418_keypad|-- bind|-- module -> ../../../../module/tca8418_keypad|-- uevent'-- unbindi have used the following for reference thus far, but neither seems to work completely:<url> have run out of ideas and could use some suggestions. am i even approaching this the right way?i'm running debian on an arm single board computer if that matters.edit:i have since discovered that i am receiving the following error when i instantiate the new device:tca8418_keypad: probe of 1-0034 failed with error -22",
    "present_kp": [
      "drivers",
      "devices",
      "arm"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "what's shell script's advantage over interpreted programming languages?. (i'm not sure if it's a appropriate question here)shell scripts, like those written in bash, can do many things. they can call unix programs, pipe their output, redirect i/o from/to files, control flow, check whether a file exists, etc.but a modern programming language, e.g, python and ruby, can also do these things. and, they are (i think) more readable and maintainable.bash enjoys wide spread adoption. but many distributions have installed python interpreter, too.so what's the advantage of shell a script? if i could write python, ruby or perl, is it worth to learn bash?",
    "present_kp": [
      "programming languages",
      "shell"
    ],
    "absent_kp": []
  },
  {
    "text": "are there any oo-principles that are practically applicable for javascript?. javascript is a prototype-based object oriented language but can become class-based in a variety of ways, either by:writing the functions to be used as classes by yourselfuse a nifty class system in a framework (such as mootools class.class)generate it from coffeescriptin the beginning i tended do write class based code in javascript and heavily relied on it. recently however i've been using javascript frameworks, and nodejs, that go away from this notion of classes and rely more on the dynamic nature of the code such as:async programming, using and writing writing code that uses callbacks/eventsloading modules with requirejs (so that they don't leak to the global namespace)functional programming concepts such as list comprehensions (map, filter, etc.)among other thingswhat i gathered so far is that most oo principles and patterns i've read (such as solid and gof patterns) were written for class-based oo languages in mind like smalltalk and c++. but are there any of them applicable for a prototype-based language such as javascript?are there any principles or patterns that are just specific to javascript? principles to avoid callback hell, evil eval, or any other anti-patterns etc.",
    "present_kp": [
      "javascript",
      "object oriented"
    ],
    "absent_kp": [
      "design patterns",
      "patterns and practices",
      "design principles"
    ]
  },
  {
    "text": "vba performance with early bind vs. late bind on called sub-procedure. i was using early bind to reference the dictionary and realised that some users might not be willing to manually add the reference to use it and just consider the macro to be 'broken'.i looked at programmatically enabling the reference but that would still require the user to go through several steps to change their macro security level, which again would seem 'broken' to an end user.so my solution is to offer early bind and late bind options to the user, early bind for those comfortable with the vbe, late bind if not.my question is, would the potential efficiency/performance gain in early binding still be present in going with this method, or is it wiped out simply by having to call to another sub?if the gain is lost, i can simply use late bind within the main sub-procedure.option explicitpublic sub matcharraysearlybind() dim arraymatchdictionary as dictionary set arraymatchdictionary = new dictionary call continuematcharray(arraymatchdictionary)end subpublic sub matcharrayslatebind() dim arraymatchdictionary as object set arraymatchdictionary = createobject(scripting.dictionary) call continuematcharray(arraymatchdictionary)end sub",
    "present_kp": [
      "vba",
      "dictionary"
    ],
    "absent_kp": [
      "excel"
    ]
  },
  {
    "text": "how to import msn live blog to wordpress.com blog?. i have my blog at <url> and i want to move all of the posts (and comments) to my wordpress blog at <url>. i don't know how to do this. please help if you know how to!",
    "present_kp": [
      "wordpress",
      "blog",
      "import"
    ],
    "absent_kp": []
  },
  {
    "text": "operation with same asymptotic cost on hash tables and lists. let $x \\in \\{ \\log n, n, \\dots , n!\\}$ some (cost) function.are there interesting operations with runtime in $o(x)$ on lists which also have runtime in $o(x)$ on hash tables?",
    "present_kp": [
      "hash tables",
      "lists"
    ],
    "absent_kp": [
      "data structures"
    ]
  },
  {
    "text": "how may i distinguish encryption algorithm of htpasswd?. i have an apache web server running on debian linux and i secure a certain directory with htaccess. i have no history or knowledge how the .htpasswd file was created. apache documentations says that crypt() encryption was used to encrypt passwords until version 2.2.17 and md5 encryption is used since 2.2.18. how may i distinguish which encryption my .htpasswd file uses?",
    "present_kp": [
      "password",
      "htaccess"
    ],
    "absent_kp": [
      "apache httpd"
    ]
  },
  {
    "text": "using keystrokes in linux terminal. how i can simulate keyboard input, something like ctrl+a+d, in linux terminal? is there any command for this?reason i'm asking this is that i need some other way to detach from my screen session than to use ctrl+a+d",
    "present_kp": [],
    "absent_kp": [
      "gnu screen"
    ]
  },
  {
    "text": "size of address spaces (logical and physical). suppose a system in which addresses (physical and logical) occupy 32 bits, page size is 1024 bytes(210), and physical memory is of size 32mb. how many frames are in physical memory? is the logicaladdress space larger than physical memory? explain.the solution given is: 232 byte logical address space (assuming byte-addressable machine)225 byte physical memory210 byte pagesat one page per frame, there are 225/210 = 215 pages in physical memory. the logical memory addressspace is larger than physical memory.can someone explain how to arrive at this solution?",
    "present_kp": [],
    "absent_kp": [
      "operating systems",
      "memory management"
    ]
  },
  {
    "text": "barebone linux bluetooth pairing. i have a small embedded arm box, without any kvm, just a serial console, net and a bluetooth usb dongle.system is autocompiled using buildroot framework and reasonably working.i can access the box either via serial line or via ssh.i have the bluetooth stack running and i can see hci0:hci0: type: br/edr bus: usb bd address: 00:15:83:3d:0a:57 acl mtu: 310:10 sco mtu: 64:8 up running pscan iscan auth rx bytes:7576 acl:27 sco:0 events:267 errors:0 tx bytes:1396 acl:27 sco:0 commands:130 errors:0i can scan and also be visible from outside.i need to pair with my android phone and i found out its address, but i didn't find any way to process authentication.# hcitool scanscanning ... a0:f8:95:54:c8:00 wiko mcondarelli# rfcomm connect hci0 a0:f8:95:54:c8:00 1can't connect rfcomm socket: operation now in progressresults in the following trace:< hci command: inquiry (0x01|0x0001) plen 5 lap 0x9e8b33 len 8 num 0> hci event: command status (0x0f) plen 4 inquiry (0x01|0x0001) status 0x00 ncmd 1> hci event: inquiry result with rssi (0x22) plen 15 bdaddr a0:f8:95:54:c8:00 mode 1 clkoffset 0x6d1c class 0x5a020c rssi -77> hci event: inquiry result with rssi (0x22) plen 15 bdaddr a0:f8:95:54:c8:00 mode 1 clkoffset 0x6d1c class 0x5a020c rssi -77> hci event: inquiry result with rssi (0x22) plen 15 bdaddr a0:f8:95:54:c8:00 mode 1 clkoffset 0x6d1c class 0x5a020c rssi -76> hci event: inquiry complete (0x01) plen 1 status 0x00< hci command: remote name request (0x01|0x0019) plen 10 bdaddr a0:f8:95:54:c8:00 mode 1 clkoffset 0x6d1c (valid)> hci event: command status (0x0f) plen 4 remote name request (0x01|0x0019) status 0x00 ncmd 1> hci event: remote name req complete (0x07) plen 255 status 0x00 bdaddr a0:f8:95:54:c8:00 name 'wiko mcondarelli '< hci command: create connection (0x01|0x0005) plen 13 bdaddr a0:f8:95:54:c8:00 ptype 0xcc18 rswitch 0x01 clkoffset 0x6d1c (valid) packet type: dm1 dm3 dm5 dh1 dh3 dh5> hci event: command status (0x0f) plen 4 create connection (0x01|0x0005) status 0x00 ncmd 1> hci event: link key request (0x17) plen 6 bdaddr a0:f8:95:54:c8:00> hci event: connect complete (0x03) plen 11 status 0x10 handle 42 bdaddr a0:f8:95:54:c8:00 type acl encrypt 0x00 error: connection accept timeout exceededi am bound to legacy pairing because:# hciconfig hci0 sspmode 1can't set simple pairing mode on hci0: input/output error (5)the trace for the above command is:< hci command: write simple pairing mode (0x03|0x0056) plen 1 mode 0x01> hci event: command status (0x0f) plen 4 write simple pairing mode (0x03|0x0056) status 0x01 ncmd 1 error: unknown hci commandwhich i understand means secure simple pairing is not supported by my hardware.on my system i have bluez v3.57, but i do not have hcid, bluetooth-agent, passkey-agent or bluez-simple-agent. how can i pair using just the basic tools?if that is not possible: what is the bare minimum i need to install to my box?",
    "present_kp": [
      "bluetooth",
      "bluez"
    ],
    "absent_kp": [
      "command line"
    ]
  },
  {
    "text": "good practice to pass this information through url parameter. basically, let's suppose an application that manage some user's meetings.i have a filtering zone on a page that aims to specify the category of items i need to specifically return. supposing two kind of filters: retrieving my actual meetings (meetings currently occurring or planned in the near future) retrieving my past meetings (meetings that are already past) i think of passing a kind of url parameter like this: <url> indeed, i can't have both actual and past in the same call since it would not be appropriate for the listing. so in my server side, i would handle through a simple conditional the passed value to filter the query.is it right enough to pass a string like this (past or actual) or is there a better practice to handle this case?note that by default, meaning without filtering, all meetings are returned.",
    "present_kp": [
      "url"
    ],
    "absent_kp": [
      "architecture",
      "web applications",
      "parameters"
    ]
  },
  {
    "text": "testing new c++11 features with hangman. i wrote a hangman game to try out some of the new features in c++11. i'm pretty new to c++, and i would like some good advice on how i can improve this code (in terms of conventions, bad/good practices, ...):#include <iostream>#include <fstream>#include <vector>#include <string>#include <stdexcept>#include <random>#include <algorithm>const unsigned initial_number_of_lives = 5;// returns a random word from the given words file.std::string pick_word(const std::string& words_filename) { std::vector<std::string> words; std::ifstream words_file(words_filename.c_str()); if (!words_file) { throw std::runtime_error(couldn't open file.); } std::string word; do { std::getline(words_file, word); words.push_back(word); } while (!words_file.eof()); std::uniform_int_distribution<uintmax_t> random_distribution(0, words.size() - 1); std::mt19937 random_engine(static_cast<std::mt19937::result_type>(std::time(nullptr))); uintmax_t word_index = random_distribution(random_engine); return words[word_index];}int main(int argc, const char *argv[]) { if (argc != 2) { std::cerr << usage: << argv[0] << <words-file> ; return 1; } std::string word; try { word = pick_word(argv[1]); } catch(...) { std::cerr << argv[0] << : couldn't open words file: << argv[1] << ' '; return 1; }#if debug std::cout << (debug) word: << word << ;#endif std::cout << welcome to hangman!; // newline in main loop below. unsigned lives = initial_number_of_lives; std::vector<char> guessed_letters; for (;;) { bool won = true; for (char &letter : word) { if (std::find(guessed_letters.begin(), guessed_letters.end(), letter) == guessed_letters.end()) { won = false; } } if (won) { std::cout << you won the game!!1 ; return 0; } std::cout << lives left: << lives; std::cout << already guessed: ; for (char &letter : guessed_letters) { std::cout << letter << ' '; } std::cout << ' '; for (char &letter : word) { if (std::find(guessed_letters.begin(), guessed_letters.end(), letter) != guessed_letters.end()) { std::cout << letter; } else { std::cout << '_'; } } char guess; std::cout << enter a letter: ; std::cin >> guess; guess = std::tolower(guess); // don't allow player to enter the same letter twice. if (std::find(guessed_letters.begin(), guessed_letters.end(), guess) != guessed_letters.end()) { std::cout << you have already guessed that letter! ; continue; } // don't allow player to enter anything but letters. if (!std::isalpha(guess)) { std::cout << that is not a letter! ; continue; } guessed_letters.push_back(guess); bool word_contains_letter = false; for (char &letter : word) { if (letter == guess) { word_contains_letter = true; break; } } if (word_contains_letter) continue; --lives; if (lives == 0) { std::cout << game over! the right word was: << word << ' '; break; } } return 0;}",
    "present_kp": [
      "c++",
      "c++11",
      "hangman"
    ],
    "absent_kp": [
      "beginner"
    ]
  },
  {
    "text": "on an e-commerce site, how do you attribute a sale to ppc if a visitor comes from ppc but then returns to buy through another medium?. can we use cookies and if so how do we install this? what software could track this kind of conversion scenario?",
    "present_kp": [
      "ppc"
    ],
    "absent_kp": [
      "google",
      "ecommerce",
      "google adwords",
      "conversions"
    ]
  },
  {
    "text": "algorithm for shell language interpreter to find if a char is between quotes. assume we have a string s (a c char *) that is a program in a language l. i want to parse l and know the following from the specificationthe following characters must be quoted if they are to represent themselves:| & ; < > ( ) $ ' \\ ' so let's say i scan and parse the string checking char by char and dynamically building up a structure in-memory for the whole program. the program can be as short as echo foobar but the important is to parse the different meanings of | in a string such as echo foo|cat and echo 'foo|cat' where the first is a pipeline and the second is printing a literal. now i have a new token char c that is the current char of s. now i want to have a function boolean isbetweenquotes(int position, string s) that returns true iff the character at position position is quoted in the string s - do you agree this is a good way of solving the problem? what should the function isbetweenquotes look like? the return values should be for exampleisbetweenquotes(6, echo foobar); /* returns false */isbetweenquotes(6, echo foobar|less); /* returns false */isbetweenquotes(6, echo 'foobar'|less); /* returns true */isbetweenquotes(20, echo foo bar|awk '{print $1}''); /* returns true */i was recommended that a could use a finite state machine and/or an abstract syntax tree and do the code either with flex/bison or a custom scanner/tokenizer. i can currently execute trivial pipelines and i'm trying to make the shell code more readable than other current shells. i've studied the source for the following shells: ash, dash, sash, posh and custom shells and the most readable code has been sash, while i understand that posh and dash are more posix compliant. my goal is to make a shell that can perform infinite pipeline by recursion with fork and exec and solve some signal handling problem that other shells might have if they allocate memory with malloc.",
    "present_kp": [
      "c",
      "shell",
      "posix"
    ],
    "absent_kp": []
  },
  {
    "text": "how would deepmind's new differentiable neural computer scale?. deepmind just published a paper about a differentiable neural computer, which basically combines a neural network with a memory. the idea is to teach the neural network to create and recall useful explicit memories for a certain task. this complements the abilities of a neural network well, because nns only store knowledge implicitly in the weights and the information used to work on a single task is only stored in the activation of the network and degrades quickly the more information you add. (lstms are one try to slow down this degradation of short term memories, but it still happens.)now, instead of keeping the necessary information in the activation, they presumably keep the addresses of memory slots for specific information in the activation, so these should also be subject to degradation. my question is why this approach should scale. shouldn't a somewhat higher number of task specific information once again overwhelm the networks capability of keeping the addresses of all the appropriate memory slots in its activation?",
    "present_kp": [],
    "absent_kp": [
      "deep learning",
      "ai design"
    ]
  },
  {
    "text": "command-line completion from command history. so, i've looked at history and at ctrl+r, but they are not what i thought i knew.is there a way that i can type in the beginning of a command, and cycle through the matches in my history with some bash shortcut?# mysq(some shortcut key)gives me:# mysqldump --add-drop-table -e -q -n -c -u (some shortcut key)# mysql -u ben.dauphinee -p",
    "present_kp": [
      "bash",
      "command history"
    ],
    "absent_kp": [
      "autocomplete"
    ]
  },
  {
    "text": "sshd error: no more sessions. i see many lines in /var/log/auth.log about sshd sessions, like belowmar 25 11:04:47 hosting-prd sshd[7882]: error: no more sessionsmar 25 11:04:47 hosting-prd sshd[7882]: error: no more sessionsmar 25 11:04:47 hosting-prd sshd[7882]: error: no more sessionsi tried to increase more messages with loglevel verbose in /etc/ssh/sshd_config, but still no more hints.",
    "present_kp": [
      "sshd",
      "session"
    ],
    "absent_kp": []
  },
  {
    "text": "iptrace for linux: how can i trace full packet contents?. i normally use iptrace on our aix servers to get packet traces but have recently found out that this doesn't work for other 'nix systems - namely centos. does anyone know what the analog would be? i've tried the following, but none seem to work as i expect:697 sudo /usr/sbin/tcpdump -w test.pcap -i eth01010 sudo /usr/sbin/tcpdump port 801012 sudo /usr/sbin/tcpdump port 80 -i eth01015 sudo /usr/sbin/tcpdump -a port 80 -i eth01017 sudo /usr/sbin/tcpdump -w ~/capture.pcap port 80 -i eth0i can see the header data in wireshark, but i can't seem to see the actual packet data.",
    "present_kp": [
      "ip",
      "tcpdump"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "excluding a directory when zipping files. i've got a bash script that does something like this:zip -0 ../backup/backup.zip \\-r ./* \\-x \\*cvs\\* \\-x *thumbs.db* \\the directory it's backing up is a svn archive (it used to be cvs back in the day). i've been unable to get it to exclude .svn and it's contents. what's the cleanest way to exclude .svn (recursively through the entire tree)?",
    "present_kp": [
      "bash",
      "zip"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "there are 4 ssds but df only listed one. why?. i just replaced ssdsthere are 4 hard diskdisk /dev/sda: 240.1 gb, 240057409536 bytes255 heads, 63 sectors/track, 29185 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0xc4521435 device boot start end blocks id system/dev/sda1 1 29185 234428481 83 linuxdisk /dev/sdb: 240.1 gb, 240057409536 bytes255 heads, 63 sectors/track, 29185 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0xc8c906e0 device boot start end blocks id system/dev/sdb1 1 29185 234428481 83 linuxdisk /dev/sdd: 120.0 gb, <phone> bytes255 heads, 63 sectors/track, 14593 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0x00061c96 device boot start end blocks id system/dev/sdd1 * 1 14 103424 83 linuxpartition 1 does not end on cylinder boundary./dev/sdd2 14 536 <phone> 82 linux swap / solarispartition 2 does not end on cylinder boundary./dev/sdd3 536 14594 112921600 83 linuxdisk /dev/sdc: 250.1 gb, 250059350016 bytes255 heads, 63 sectors/track, 30401 cylindersunits = cylinders of 16065 * 512 = <phone> bytessector size (logical/physical): 512 bytes / 512 bytesi/o size (minimum/optimal): 512 bytes / 512 bytesdisk identifier: 0x4fa82c2a device boot start end blocks id system/dev/sdc1 1 30401 244196001 83 linuxroot@host [/home]#but if i type df, only one shows up. this could be problematic. should i open a new ticket for this?root@host [/home]# dffilesystem 1k-blocks used available use% mounted on/dev/sdd3 111148848 28170020 77332748 27% //usr/tmpdsk <phone> 18208 937516 2% /tmptmpfs <phone> 0 <phone> 0% /dev/shm",
    "present_kp": [
      "ssd"
    ],
    "absent_kp": []
  },
  {
    "text": "traveling salesman's tour approx algorithm: is this really a hamiltonian path?. i'm given this problem:consider the following closest-point heuristic for building an approximate traveling-salesman tour. begin with a trivial cycle consisting of a single arbitrarily chosen vertex. at each step, identify the vertex u that is not on the cycle but whose distance to any vertex on the cycle is minimum. suppose that the vertex on the cycle that is nearest u is vertex v. extend the cycle to include u by inserting u just after v. repeat until all vertices are on the cycle. prove that this heuristic returns a tour whose total cost is not more than twice the cost of an optimal tour. this is the same as prim's algorithm. unless i'm missing something, this is not an approximate traveling salesman tour since the traveling salesman requires a hamiltonian path where we don't revisit any nodes, but on many graphs this algorithm seems to require revisiting nodes to get back to the source node. am i wrong or is this problem unclearly worded?",
    "present_kp": [
      "traveling salesman"
    ],
    "absent_kp": [
      "spanning trees",
      "approximation algorithms"
    ]
  },
  {
    "text": "not able to control power options settings in xfce4 with kali linux?. i'm using kali linux for my pentest environment. to my needs, i found that xfce is a better alternative as an interface for the distro & i particularly like it as it is. however, lately i noticed .. i'm not able to tune the settings for the lockscreen which presently turns on after 2 minutes of idle time. i wanted to change this into turn off.i did my research:there is no way my system settings show me an option to tune this.i used the cli for xscreensaver-demo as posted in xfce forum to no avail.here's my lock application:root@foxtrot:~# ps -ef | grep lockroot 27 2 0 qun14 ? 00:00:00 [kblockd]root 705 1 0 qun14 ? 00:00:00 /usr/sbin/vmware-vmblock-fuse -o subtype=vmware-vmblock,default_permissions,allow_other /var/run/vmblock-fuseroot 855 839 0 03:13 pts/7 00:00:00 grep lockroot 1210 1178 0 qun14 ? 00:00:01 light-lockerroot 1316 1202 0 qun14 ? 00:00:00 /usr/lib/i386-linux-gnu/xfce4/panel/wrapper-1.0 /usr/lib/i386-linux-gnu/xfce4/panel/plugins/libactions.so 16 <phone> actions action buttons log out, lock or other system actionsi need to know how do i find the power manager options in order to get this disabled?",
    "present_kp": [
      "xfce"
    ],
    "absent_kp": [
      "xfce4 terminal"
    ]
  },
  {
    "text": "automaton accepting $\\{a^{2i}bc^{2k} \\mid i, k \\in\\mathbb{n}\\}$. how can i produce an automaton accepting $\\{a^{2i}bc^{2k} \\mid i, k \\in\\mathbb{n}\\}$? i am essentially confused about exactly what the $2i$ and $2k$ mean. does that mean that the automaton only accepts strings where the number of $a$'s and $b$'s are multiples of $2$ and there is one occurrence of $b$ between $a$ and $c$? any help is greatly appreciated, thanks.",
    "present_kp": [],
    "absent_kp": [
      "regular languages",
      "finite automata"
    ]
  },
  {
    "text": "can a frequent page in/out on the same mmaped file increase virt space of a process?. i program in c++ and run it on linux centos 7.i strictly control the dynamic memory allocation. i pre-allocate as many memory as needed and re-use the pre-allocated buffer chunks where required.however, i have a data structure, an big array, that i delegate the memory management to os by exploiting memory mapped file. note that the remaining physical memory size except for the pre-allocated buffer chunks is smaller than the size of the big array. so the pages of its mmaped region can be paging in/out.during the long running of the program, the big array is often scanned from its beginning to end. whenever the linear scan on the array occurs, i see the virtual address space size shown on top command increases. what does it mean? i think unless i un-map the memory-mapped file and re-mapping it, its virtual address space must remain the same.does any one have any thought on it? did i make any mistake otherwise?",
    "present_kp": [
      "linux",
      "memory"
    ],
    "absent_kp": [
      "virtual memory"
    ]
  },
  {
    "text": "how to rename multiple files in single command or script in unix?. i have the below list of filesaro_tty-mif-45875564pmo_optaro_tty-mif-45875664pmo_optaro_tty-mif-45875964pmo_optaro_tty-mif-45875514pmo_optaro_tty-mif-45875524pmo_optthat i need to rename toaro_tty-mimpfra-45875564pmo_optaro_tty-mimpfra-45875664pmo_optaro_tty-mimpfra-45875964pmo_optaro_tty-mimpfra-45875514pmo_optaro_tty-mimpfra-45875524pmo_optplease help me out.",
    "present_kp": [
      "rename"
    ],
    "absent_kp": [
      "linux",
      "shell script"
    ]
  },
  {
    "text": "count combinations differing by fixed number of elements. i'll try to formulate my problem through an example.lets suppose we have a collection of items of type a,b,c,d,e,f.a1, a5, a7b2, b3c5, c6, c7, c8d4, d5e1, e2, e3f3, f7, f8if we take one element from each type there are 3*2*4*2*3*3 abcdef lines (combinations).we have another random line a1b5c7d1e5f7.i want to count how many from the combinations lines differ by the current line in exactly 3 elements. i.e these lines differ only in one (the first) elementa5b5c7d1e5f7a8b5c7d1e5f7i want to do that if it's possible without generating and comparing each combination.",
    "present_kp": [],
    "absent_kp": [
      "algorithms",
      "combinatorics"
    ]
  },
  {
    "text": "finding duplicate invoices. i have a invoicelist which is a list<map<string:string>> and am trying to find out if all the invoices have same sender_country and client_country or not. if not, it will add the message to a json array.[ [invoice_date:20150617, invoice_number:617151,sender_country:usa, client_country:usa] [invoice_date:20150617, invoice_number:617152,sender_country:cad, client_country:mex] [invoice_date:20150617, invoice_number:617153,sender_country:cad, client_country:mex]]jsonarray jsonarray = new jsonarray();def sendercountry = invoicelist[0]['sender_country']def clientcountry = invoicelist[0]['client_country']invoicelist.each{ it ->if(it['sender_country'] != sendercountry) jsonarray.add((new jsonobject()).put(sender_country,multiple sender countries associated)); if(it['client_country'] != clientcountry) jsonarray.add((new jsonobject()).put(client_country,multiple client countries associated));}i feel this code can be refactored/optimized to a better version in groovy. can someone please help me with it?",
    "present_kp": [
      "groovy"
    ],
    "absent_kp": [
      "performance"
    ]
  },
  {
    "text": "how can a devops-team correctly prioritise fixing incoming issues versus building new code?. enterprises are increasingly adopting devops methodologies for development of software. a couple of common outcomes of this are that:application teams are more cross functional in nature, with operations and support staff working in self-contained teams alongside developers.developers have an increasing support role... the you wrote it, you fix it culture. increasingly they're on-call. i'm seeing this creating a challenge. development teams are structured this way primarily because it delivers more rapid software innovation, and hence value to the company and to the customer (new features, new products, etc). they're working to an evolving backlog of feature desires. but at the same time, support issues are arriving. facing a queue of two tickets, or ten tickets, or one hundred tickets, the application team has to decide what to do first. if you're working in a structure like this, how do you establish what to prioritise, what to defer?",
    "present_kp": [
      "devops"
    ],
    "absent_kp": [
      "technical support"
    ]
  },
  {
    "text": "why use bootstrapping?. the wiki page for bootstrapping says that you use it in the case where the underlying distribution is unknown. why is bootstrapping, or sampling with replacement, better than just calculating the variance and other properties from the data directly?",
    "present_kp": [],
    "absent_kp": [
      "statistics"
    ]
  },
  {
    "text": "isn't weakly universal hashing even a stronger than truly random?. so as far as i know the weakly universal hashing is defined as:for any $x, y \\subset u, pr(h(x) = h(y)) \\le rac{1}{m}$ where m is a smaller number than the cardinality of $u$, and h are chosen randomly from a set of all possible hash function $h$.i am just wondering if we choose the hash of an item randomly from the set $z_m$, then the probability of having a hash collision is $ rac{1}{m}$ for x and y. so the weakly universal hashing is a quite strong requirement on how to choose hash function isn't it? why?",
    "present_kp": [
      "hash function"
    ],
    "absent_kp": [
      "ds.algorithms",
      "ds.data structures"
    ]
  },
  {
    "text": "copying a file onto several other files with different names. i have one file (lets call it file1.xyz) that i want to use as a template to work on. i need to copy the contents of file1.xyz so that they replace the contents of the other files - file2.xyz, file3.xyz, file4.xyz, file5.xyz.....file70.xyz whilst keeping the original file name. i have tried using: cp file1.xyz *.xyzthe files are all in the same directory and i don't want to append them to each other.this has not worked, how can i solve this problem?",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "bash",
      "shell script"
    ]
  },
  {
    "text": "evaluating logistic regression model in tensorflow. following this tutorial, i have a doubt about the evaluation part in:# test the modeln_batches = int(mnist.test.num_examples/batch_size)total_correct_preds = 0for i in range(n_batches): x_batch, y_batch = mnist.test.next_batch(batch_size) _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={x: x_batch, y:y_batch}) preds = tf.nn.softmax(logits_batch) correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(y_batch, 1)) accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :( total_correct_preds += sess.run(accuracy) print 'accuracy {0}'.format(total_correct_preds/mnist.test.num_examples)note that this is done on the test set, so the goal is purely to obtain the accuracy using a previously trained model. however isn't calling the line:_, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={x: x_batch, y:y_batch}) equivalent to re-optimizing the model using the test data (and labels)?shouldn't we avoid re-running optimizer and loss and just compute the predictions?",
    "present_kp": [
      "tensorflow",
      "logistic regression",
      "evaluation"
    ],
    "absent_kp": [
      "machine learning",
      "training"
    ]
  },
  {
    "text": "difference between '[[ $a -lt 2 ]]' and '(( $a < 2 ))'. is there any significant difference between using [[ $a -lt 2 ]] and (( $a < 2 ))? for example, is one of them faster or more posix compliant than the other?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "test"
    ]
  },
  {
    "text": "how to integrate numerically over a radial domain. i want to integrate a function over a radial domain $d=\\{r<r( heta)\\}$. the change to polar coordinates yields:$$ \\int_d f = \\int_0^{2\\pi} \\int_0^{r( heta)}f(r, heta)rdr d heta $$so i tried calculating each integral using trapezoidal quadrature:$$\\int_a^b f(x)dx pprox rac{b-a}{m} (f(x_1)+...+f(x_m)) ext{ for } x_i=a+(i-1) rac{b-a}{m-1}$$but i guess this is not the right way to do it, since the density of evaluation points is too great at the origin, and i get a pretty large error for $100 imes 100$ discretization grid (approx 0.1) for $f(r, heta)=r$.what other way can i use which converges faster?",
    "present_kp": [
      "quadrature"
    ],
    "absent_kp": []
  },
  {
    "text": "google docs: how to find and display matching value on new sheet based on two criteria. i have created a demo spreadsheet to help explain.(this is a small set of example data, the real set has more values [and the data may or may not be there from week to week])i will have a static list of dimension values (in the example it is source/medium values) in the report sheet. i want to compare the performance of a metric from week to week (pageviews per visit in the example)wanting to automate the getting of the appropriate values from sheet1 and populate the report sheet's corresponding empty cells with themfor example, cell b2 of the report sheet would contain the value 6.05, and so on",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets"
    ]
  },
  {
    "text": "companies that provide seo solutions?. possible duplicate:what are the best ways to increase a site's position in google? i've seen a lot of those companies around, saying that they could improve my website's ranking in search engine results,the thing is, that they say you'll be on the first / second page, guaranteed.i tried to contact a few of them, and they are charging a nice amount of money for it,the cheapest i found was about 5,000$,now i didn't believe that they could make a huge change, but i did see that a few of their customers did get to the first pages fast, while leaving bigger and more experienced companies behind,i'm quite sure that i could hear about their way of doing that, and maybe even do it myself.so do you have any idea what those companies do to improve the ranking?",
    "present_kp": [
      "seo"
    ],
    "absent_kp": []
  },
  {
    "text": "survivable networks, directed case. i have been working on a project that turns out to be a special case of the directed version of the survivable network problem.iterative rounding gives a 2-approximation of the undirected case. i'm wondering if the directed case has been studied at all and if so, what approximations can be guaranteed.",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "network modeling"
    ]
  },
  {
    "text": "how can i verify both www and non-www version of a website in wordpress using webmaster tools. how can i verify both www and non-www version of a website in wordpress if i'm using yoast seo and there is only one verification file upload? i do not have access to the site's ga.",
    "present_kp": [
      "wordpress"
    ],
    "absent_kp": [
      "google search console",
      "no www"
    ]
  },
  {
    "text": "environment path for all users. i'm trying to add an environment path /usr/pgsql-9.5/bin for all users on my centos 7 system.i created a new file under /etc/profile.d/it looks like this:export path=/usr/pgsql-95/bin:$pathi then restart the system and login using root.i type in echo $path, it lists/usr/pgsql-9.5/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/binso everything is correct for root user.i then type sudo su postgres echo $pathit lists:/sbin:/bin:/usr/sbin:/usr/bin/usr/pgsql-9.5/bin is missing?why is the path not added for user postgres? if i create a new user the path is correctly added $path.",
    "present_kp": [
      "centos",
      "path"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "how to find partition set of a partition problem using its decision problem. i understand partition problem is np-complete.given we have a magic black box that can answer yes or no for the partition problem. i was wondering how to come up with a polynomial time algorithm to find the actual set using this black box. thank you.",
    "present_kp": [
      "partition problem"
    ],
    "absent_kp": [
      "complexity theory",
      "np complete"
    ]
  },
  {
    "text": "selecting non-existent files with wildcard/regex. i'm trying to convert hundreds of *.jpg files to *.webp files with libwebp on macos. particularly, i want to use the command line tool cwebp to perform the conversion. it works like this:cwebp <input_file>.jpg -o <output_file>.webpmy *.jpg files, whose names are img_20160227_110640.jpg or so, are stored under a directory called root. the problem is that *.webp files does not exist when the conversion is performed, so i don't know how to pass their names to cwebp. for example, if i only have one picture to convert, i would simple execute cwebp img_20160227_110640.jpg -o img_20160227_110640.webphowever, there are hundreds of them, and i don't want to type hundreds lines of command. how to use a regular expression / write a script to automate the conversion?",
    "present_kp": [
      "regular expression"
    ],
    "absent_kp": [
      "bash",
      "shell script",
      "shell",
      "arguments"
    ]
  },
  {
    "text": "naive password checker. i'm looking for advice on how i could improve this. i'm using vs2015 to compile so whatever language features are supported in there is fair game!problem: create a program that reads a username and a password from the user and grants access if that username and password exists in code. bonus points for storing the possible usernames in a file like so: user1,passuser2,pass ...encryption is not really a concern; i'm just getting the hang of things. points i'd like to improve:i'm using a placeholder vector for the user input, initialized with empty strings. it feels like there would be a more elegant way to get user input without using a holding variable?i imagine there's a more elegant way to go through each line of the file too, again, lots of placeholder variables for data i could process in place i think.#include <iostream>#include <fstream>#include <vector>#include <string>using namespace std;// extract the contents of a user file for processing.vector<string> get_user_list(ifstream& userfile){ string line; vector<string> userlist; if (userfile.is_open()) { while (getline(userfile, line)) userlist.push_back(line); userfile.close(); } else cout << couldn't read from file.; return userlist;}// go through each line of the user list and extract a comma// seperated username and pass; match against the supplied// username and pass.bool check_pass(vector<string> tomatch, vector<string> userlist){ string fuser, fpass; bool match = false; for (string uline : userlist) { for (size_t i = 0; i < uline.size(); i++) { if (uline[i] == ',') { fuser = uline.substr(0, i); fpass = uline.substr(i + 1, string::npos); break; } } if (tomatch[0] == fuser && tomatch[1] == fpass) { match = true; break; } } return match;}int main(){ ifstream userfile(data/users.txt); vector<string> userlist = get_user_list(userfile); vector<string> input = { , }; cout << enter your username followed by your pass: ; cin >> input[0] >> input[1]; if (check_pass(input, userlist)) cout << access granted << endl; else cout << access denied << endl; return 0;}",
    "present_kp": [],
    "absent_kp": [
      "c++"
    ]
  },
  {
    "text": "where does cinnamon store its desktop art settings?. running linux mint 16 right now, cinnamon 64-bit. i'm trying to find out where cinnamon stores my desktop settings. precisely looking for where the desktop image settings are stored and want to figure out how to manipulate it via the command line for a bash script i've written.tl;dr: can i change cinnamon's desktop image from the command line?any clues or tips?",
    "present_kp": [
      "command line",
      "linux mint",
      "cinnamon"
    ],
    "absent_kp": []
  },
  {
    "text": "mount: no medium found on /dev/sr0. according this instruction i tried to mount dvd disk into fedora 24what i did.[root@mic3ael mic3ael]# wodim --devices wodim: overview of accessible drives (1 found) :------------------------------------------------------------------------- 0 dev='/dev/sr0' rwrw-- : 'hl-dt-st' 'dvdram guc0n'-------------------------------------------------------------------------according to output, i understood that /dev/sr0 should be mounted [root@mic3ael mic3ael]# mount -t iso9660 /dev/sr0 /media/cdrommount: /dev/sr0 is write-protected, mounting read-onlymount: no medium found on /dev/sr0but the dvd didn't mount.the question is what does it mean mount: no medium found on /dev/sr0and how to mount dvd disk into fedora 24.thanks, michael.",
    "present_kp": [
      "fedora"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "object key diff. i've been tasked with finding property differences in massive json structures and return them in a particular fashion ([key_1.key_2, key_1, etc]).here's my code, which is focused on readability so some redundant decorators are used (they will be removed). i am looking for any performance/logical problems with this approach.it also has to be in javascript, node stack (isomorphic)./** * --decorator for prettiness-- * checks array if key exists * @param needle * @param haystack * @returns {boolean} */export function inarray (needle, haystack) { return haystack.indexof(needle) > -1}/** * --decorator for prettiness-- * merge two arrays together * @param array_1 {array} * @param array_2 {array} * @returns {array} */export function arraymerge(array_1, array_2) { return array_1.concat(array_2)}/** * returns all differences of keys * note: nested keys are returned like this [key_1.key_2, key_1.key_2.key_3] * @param object_compare * @param object_against * @param ignorekeys * @param depth * @returns {array} */export function diffkeysrecursive(object_compare, object_against, ignorekeys = [], depth = '') { function _isobject(mixed) { return typeof mixed === 'object' } function _propexists(prop, object) { return typeof object === 'object' && typeof object[prop] !== 'undefined' } function _depthpath(prop, depth = '') { return depth = depth ? '${depth}.${prop}' : prop } if (_isobject(object_against)) { var diffs = [] // iterate through the against object to see differences in the compare $.each(object_against, (prop, value_against) => { // checks if prop should be ignored if(!inarray(prop, ignorekeys)) { if (!_propexists(prop, object_compare)) { diffs.push(_depthpath(prop, depth)) } // recurse if value_against is an object if (_isobject(value_against)) { var object_compare_safe = _propexists(prop, object_compare) ? object_compare[prop] : null diffs = arraymerge(diffs, diffkeysrecursive(object_compare_safe, value_against, _depthpath(prop, depth))) } } }) return diffs } else { throw 'invalid type supplied' }}",
    "present_kp": [
      "javascript",
      "performance"
    ],
    "absent_kp": [
      "search"
    ]
  },
  {
    "text": "nvidia proprietary driver on debian jessie problems. i have dabbled in running a debian server before, but this is my first time using its graphical interface for my main pc. i have been trying to install the nvidia proprietary drivers. i have sli gtx 460s 1gb. i am running debian jessie (if it turns out my issues are due to me running the testing build, please let me know).so far, i have tried following the exact directions on the debian wiki.upon reboot, my primary monitor remains completely blank once the desktop environment launches (i never even see the login screen), though it is still receiving some sort of video signal because the monitor doesn't complain about no signal. this contrasts my secondary monitor which is given no signal whatsoever. oddly, when i hook up my monitor via hdmi to my motherboard's integrated graphics, i see a black screen with a cursor blinking at the top left corner. i am able to alt+ctrl+f1 to login to the terminal, purge my system of nvidia packages, delete the xorg config file, and reboot; this returns my system to a usable state using nouveau, dual monitors and everything.i have tried slightly different methods such as installing the 'nvidia-driver' metapackage. still, i get the same result. digging through the xorg log, i found this segment:[ 7.605] (ii) loadmodule: glx[ 7.605] (ii) loading /usr/lib/xorg/modules/linux/libglx.so[ 7.642] (ii) module glx: vendor=nvidia corporation[ 7.642] compiled for 4.0.2, module version = 1.0.0[ 7.642] module class: x.org server extension[ 7.642] (ii) nvidia glx module 331.67 fri apr 4 11:43:47 pdt 2014[ 7.642] loading extension glx[ 7.642] (ii) loadmodule: nvidia[ 7.642] (ii) loading /usr/lib/xorg/modules/drivers/nvidia_drv.so[ 7.649] (ii) module nvidia: vendor=nvidia corporation[ 7.649] compiled for 4.0.2, module version = 1.0.0[ 7.649] module class: x.org video driver[ 7.650] (ii) nvidia dlloader x driver 331.67 fri apr 4 11:24:40 pdt 2014[ 7.650] (ii) nvidia unified driver for all supported nvidia gpus[ 7.650] (++) using vt number 7any help would be greatly appreciated. i'll gladly provide any more information that's required. thanks.",
    "present_kp": [
      "debian",
      "xorg",
      "drivers",
      "nvidia"
    ],
    "absent_kp": []
  },
  {
    "text": "real time backup if file changed?. are there any linux/unix console applications similar to yadis that would allow me to:be set up from the console backup multiple directoriesbackup / sync in real time after the files (text files) are changedupdate 1:i write shell scripts, ruby scripts, aliases etc etc to make my work easier. i want to have backup of these files. the solution i am looking for will copy these files after any change was made to them to a subdirectory of my dropbox directory and that's it. backup is done and available from anywhere. always fresh and ready and i don't have to think about it.i know i can run cron few times a day but i thought there must be a solution for what i am looking for available on linux. i am not so linux experienced so i asked here.",
    "present_kp": [
      "linux",
      "backup",
      "real time"
    ],
    "absent_kp": [
      "suse"
    ]
  },
  {
    "text": "excellent wordpress unix hosts with ssh access?. possible duplicate:how to find web hosting that meets my requirements? my boss is sick of dreamhost's excuses. we have a popular wp site on a unix vps with dreamhost. we'd like to find a new, more reliable host, who can handle a high-ish traffic of perhaps 2000 uniques a day wp site and offers ssh access.anyone have a recommendation?",
    "present_kp": [
      "wordpress",
      "web hosting"
    ],
    "absent_kp": [
      "looking for hosting"
    ]
  },
  {
    "text": "is there a simpler way of copying and pasting one inputs value into other input with the same name. i am trying to write something that will copy the current <input>s value and enter it into any <input> that start with the same name.<input> names will follow this pattern: price-0, price-1, price-2, upc-0, upc-1, upc-2.so if a user enters a value in <input name=price-0> and hits copy the value should be transferred over to all input whos name start with pricethis is the code i've written:$(document).on('click', '.--copy', function () { var input_name = $(this).closest('div').find('input').attr('name').split('-')[0]; $('input[name^=' + input_name + ']').val($(this).closest('div').find('input').val());});a fiddle to make everyones life easier: <url> feel like there are too many selectors being called upon and the code is somewhat difficult to read.",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "jquery"
    ]
  },
  {
    "text": "robust smoothers for geometric multigrid. i'm searching for robust smoothers for geometric multigrids.by robust i mean:effective for high order approximations (say spectral element, spectral discontinuous galerkin),parallel (suitable for co-processors),effective for heterogeneity and anisotropy problems.from what i can gather, schwarz type smoothers may be promising (fischer et al); and block/line/ plane, and ilu smoothers are also recommended (trottenberg et al).are there any other state-of-the-art smoothers i should consider?",
    "present_kp": [
      "multigrid"
    ],
    "absent_kp": [
      "linear algebra",
      "linear solver",
      "iterative method"
    ]
  },
  {
    "text": "how to choose parameter for golomb coding?. i am trying to implement golomb coding, but i don't understand how it's tuned to obtain optimal code.it is said that golomb coding uses a tunable parameter m to divide an input value into two parts: q, the result of a division by m, and r, the remainder. the quotient is sent in unary coding, followed by the remainder in truncated binary encoding.i don't understand how should i choose the parameter m - i can't see how the explanation in wikipedia relates to actual data. i believe it should be related to statistical moments, is that true?for example, if i have this example set:{3,4,4,4,3,1,2,2,3,1,2,1,4,1,2,2,2,2,1,1,2,2,1}i believe m should be very small for this kind of data. i bet it's either 1 or 2. it's mean is ~2.2 and standard deviation is ~1.1. my intuition would tell me to choose 2.another dataset here:{2,7,11,19,6,2,6,13,11,1,5,2,19,7,6,9,6,7,2,4,5,12,3}this time the mean is ~7.2 and standard deviation is ~5.0.is 7 the right value in this case? and should i prefer rice code (use 8 as it is a power of 2) if i get a value like 7?i understand that division will be easier if i use rice coding, but are there any benefits in not using it? i mean - 3 bits will be used for remainder in either case, how could pure golomb code be more optimal then?one more nuance - golomb code is for nonnegative integers. if i have positive integers instead, should i save x-1 instead? it would change a lot for the first of the mentioned datasets.",
    "present_kp": [],
    "absent_kp": [
      "compression"
    ]
  },
  {
    "text": "groups/colors/removes cells. based on the value of what is in column b (column a is hidden) it groups/colors/removes the corresponding node(s). r - values are nodes that need to be grouped. the rows are 6 cells apart before a new node starts. it also adds a formula below the value.i wrote this code and it of course looks messy. i just want to know if there is a way to make it a little easier to understand. it's not the best when it comes to recursion and i need to explain this to a few peers so they will be able to keep the model running as well.example:code for review: 'set values to 5; first row to begin grouping start_row = 5 last_row = 5 application.wait now + timevalue(00:00:02) application.statusbar = grouping and formating workgroups...while worksheetfunction.counta(rows(start_row)) <> 0 'color code certain ranges based on ending values of functions/nodes if (right(range(b & start_row).value, 10) = - overhead or right(range(b & start_row).value, 14) = - non overhead or right(range(b & start_row).value, 4) = - wg) then finish_row = start_row - 1 last_row = start_row + 6 end if with activesheet lastrow_das_delete = .cells(.rows.count, a).end(xlup).row end with 'delete actual and support nodes, loop twice to remove r value rollups for double_actuals_support = 0 to lastrow_das_delete range(b & (start_row + 1)).formula = =concatenate(~ & index('complete database pull'!b:b,match(b & start_row & ,'complete database pull'!c:c,0))) if right(range(b & start_row).value, 19) = - actuals & support then for adjust_delete = 0 to 5 rows(start_row).entirerow.delete next adjust_delete end if next double_actuals_support 'group r- nodes together if left(range(b & start_row).value, 2) = r- and start_row <> 5 and last_row <> start_row then finish_row = start_row - 1 rows(finish_row & : & last_row).group last_row = start_row + 6 'if r- is in the first row, don't group up elseif left(range(b & start_row).value, 2) = r- and start_row = 5 then last_row = start_row + 6 end if 'color wg rows/columns if (right(range(b & start_row).value, 10) = - overhead or right(range(b & start_row).value, 14) = - non overhead) then range(b & start_row & :y & (start_row + 3)).interior.color = <phone> range(b & start_row & :b & (start_row + 5)).interior.color = <phone> end if if right(range(b & start_row).value, 4) = - wg then range(b & start_row & :y & (start_row + 3)).interior.color = <phone> range(b & start_row & :b & (start_row + 5)).interior.color = <phone> last_row = start_row + 6 end if 'adjust start_row 6 rows start_row = start_row + 6wend",
    "present_kp": [
      "recursion"
    ],
    "absent_kp": [
      "vba",
      "excel"
    ]
  },
  {
    "text": "should the sender of an event always be a generic object?. when programming events in c#, it is advised to create a delegate in form of:delegate xeventhandler(object sender, xeventargs e);my question is on the first argument of the delegate, object sender. does it always have to be a generic object? having a sender of type object always results in code similar to this.val = ((concretetype)sender).property;or, even more verbose,concretetype obj = sender as concretetypeif (obj != null) { ... }one argument against strongly typed senders is that other objects can forward the event without worrying about the type. while this might make sense in gui environments, i am not sure if it could benefit outside a gui.what if the class of the sender is always known (at least as an abstract class)? for example, if i am implementing a listchanged event in an abstract list class, and if other classes are going to inherit it (e.g. linkedlist, arraylist), is it all right to define my delegate with a sender of type list?delegate listchangedeventhander(list sender, listchangedeventargs e);or, would there be a downside of changing the conventional object sender to a more specific type?",
    "present_kp": [
      "c#",
      "event"
    ],
    "absent_kp": []
  },
  {
    "text": "can an io device have some memory space or can it only have registers?. i am learning about io devices, and so far i have only seen examples of io devices that have registers and no memory space. for example, this is a printer that have three registers and no memory space:if you want to print a character, you would put the ascii code of the character in the data register.but what if you want to print an entire page and not just one character, shouldn't the printer have some memory space that can hold an entire page? or is the printing of an entire page possible by sending the page to the printer device controller one character at a time?does all io devices only have registers, or do some io devices also have some memory space?",
    "present_kp": [
      "io"
    ],
    "absent_kp": [
      "hardware",
      "computer architecture"
    ]
  },
  {
    "text": "acl: givin - - - permissions for the owner fo the file. at the beginning, i have these permissions for a file:# file: jar# owner: my_user# group: my_useruser::rw-group::rw-other::r--after running this:setfacl -m u:my_user:--- jarand get this permissins: # file: foobar# owner: my_user# group: my_useruser::rw-user:my_user:---group::rw-mask::rw-other::r--i expected my_user not to have permissin to read (for example) this file, but it has..",
    "present_kp": [
      "permissions",
      "acl"
    ],
    "absent_kp": [
      "files"
    ]
  },
  {
    "text": "monotone-2sat and vertex cover. the following decision problem is called k-true-monotone-2sat:given a 2-cnf boolean formula $f$ that does not contain any negated variables and given a positive integer $k$, can $f$ be satisfied by setting $k$ or fewer variables to true?it is np-complete: it's easy to see a straightforward reduction from vertex cover to it (i.e. can we cover all the edges with $k$ or fewer nodes?).the following decision problem is called monotone-2sat:given a 2-cnf boolean formula $f$ that does not contain any negated variables, is it satisfiable?as a decision problem, monotone-2sat is trivial. the answer is always yes: just set every variable to true.but consider its counting version, called #monotone-2sat:given a 2-cnf boolean formula $f$ that does not contain any negated variables, how many satisfying assignments $f$ has?surprisingly, #monotone-2sat is #p-complete.now here is the question. suppose we have an oracle for #monotone-2sat, which returns the exact solution count of a monotone-2sat formula: how such solution count can be used to solve k-true-monotone-2sat?i'm asking this because i do not immediately see how the solution count may give information on how many solutions have k or less literals set to true and how many don't.",
    "present_kp": [
      "sat"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "ds.algorithms"
    ]
  },
  {
    "text": "integration tests across a 3-tier .net solution. i have a 3-tiered .net solution.database (sql server 2008)web service (soap service - *.asmx)wpf clienti am comfortably writing unit tests within (3) the client.i am currently working on writing tests between (1)database & (2)service.my question is, what are some useful ways to run integration tests across all 3 tiers. i would like this to run locally in my test runner, as well as part of the integration test.primarily, i am stuck on how to have a transient (setup-teardown-able) (2) web service & (1) database that can be tested with (3) client code as part of a full integration test.",
    "present_kp": [
      ".net",
      "integration tests"
    ],
    "absent_kp": [
      "unit testing",
      "web services",
      "continuous integration"
    ]
  },
  {
    "text": "basic php cloud script. i would like to add basic cloud system to my website project. i have my php login system already included. every person must be logged in to view this site.there are several session variables like $_session[id].i've got my files.php file - main file with list of uploaded files on server, form to upload new and delete. file data to remove/add is sent to php script by post + hidden inputs keeping user id.i've found some basic php functions that are successfully connected to my website and working.uploadscript.php (w3schools)<?php$target_dir = files/ . $_post[id] . /;$target_file = $target_dir . basename($_files[filetoupload][name]);$uploadok = 1;$imagefiletype = pathinfo($target_file,pathinfo_extension);// check if image file is a actual image or fake imageif(isset($_post[submit])) { $check = getimagesize($_files[filetoupload][tmp_name]); if($check !== false) { echo file is an image - . $check[mime] . .; $uploadok = 1; } else { $uploadok = 0; }}// check if file already existsif (file_exists($target_file)) { header('location: files.php?alert=4;'); $uploadok = 0;}// check file sizeif ($_files[filetoupload][size] > 500000) { header('location: files.php?alert=5;'); $uploadok = 0;}// allow certain file formatsif($imagefiletype != jpg && $imagefiletype != png && $imagefiletype != jpeg&& $imagefiletype != gif ) { header('location: files.php?alert=3;'); $uploadok = 0;}// check if $uploadok is set to 0 by an errorif ($uploadok == 0) { echo sorry, your file was not uploaded.;// if everything is ok, try to upload file} else { if (move_uploaded_file($_files[filetoupload][tmp_name], $target_file)) { header('location: files.php?alert=1;'); } else { header('location: files.php?alert=2;'); }}?>downloadscript.php (php.net/manual/en/function.readfile.php)<?php$file = files/ . $_post[id] . / . $_post[file];if (file_exists($file)) { header('content-description: file transfer'); header('content-type: application/octet-stream'); header('content-disposition: attachment; filename='.basename($file).''); header('expires: 0'); header('cache-control: must-revalidate'); header('pragma: public'); header('content-length: ' . filesize($file)); readfile($file); exit;}?>deletescript.php (php.net/manual/en/function.unlink.php)<?php$file = files/ . $_post[id] . / . $_post[file];if (file_exists($file)) { unlink($file); header('location: files.php?alert=6;'); exit;}?>are these scripts secure? do you suggest any modifications to it to prevent some unexpected and unwanted actions by users?",
    "present_kp": [
      "php"
    ],
    "absent_kp": [
      "security",
      "network file transfer"
    ]
  },
  {
    "text": "what is the state of the art in computerised coding of thematic apperception tests (tats)?. thematic apperception tests (tats) involve showing test takers pictures and getting them to write stories based on the pictures. coding such stories for themes and traits can be complex, time-consuming, and potentially suffer from issues of unreliability. thus, it would be interesting to see whether automated computerised coding could make the process of scoring tats more efficient, reliable, and valid.what is the current state of computerised coding of tats?how does the reliability and validity of computerised coding compare to human coding?",
    "present_kp": [
      "test"
    ],
    "absent_kp": [
      "measurement",
      "experimental psychology",
      "software"
    ]
  },
  {
    "text": "name for the stronger submodularity property in cut function. let $f:2^v ightarrow \\mathbb{r}$ be a set function over $v$ that satisfies the following:$f(a \\cap b) + f(a \\cup b) \\le f(a) + f(b)$$f(a ackslash b) + f(b ackslash a) \\le f(a) + f(b)$.here are the questions:cut function $c(\\delta(\\cdot))$ is known to satisfy both 1) and 2). is there any other natural example of function satisfying both ?if $f$ satisfies 1), then we say $f$ is submodular. but is there a name for the property of function satisfying both 1) and 2) ? or only 2) ?",
    "present_kp": [
      "submodularity"
    ],
    "absent_kp": [
      "co.combinatorics"
    ]
  },
  {
    "text": "find with -execdir. when i run find with -execdir i don't get the results i was expecting.for example:mkdir -p a/b/cfind . -type d -execdir touch foo \\;$ tree aa b c foo foodirectory c does not contain a foo file.how do i get find to visit and do something locally in each directory?",
    "present_kp": [
      "find",
      "directory"
    ],
    "absent_kp": [
      "shell",
      "files",
      "directory structure"
    ]
  },
  {
    "text": "command substitution with pkg-config in fish. fish's command substitution is supposed to be the equivalent of bash's $() yet this simple example fails:g++ -std=c++14 -wall -wextra -pedantic -g (pkg-config --cflags sdl2) \\ test.cpp (pkg-config --libs sdl2)/usr/bin/ld: cannot find -lsdl2if i run it in bash, it works perfectly fine. also typing -lsdl2 instead of using pkg-config works as well.to clarify, there's nothing wrong with pkg-config:echo (pkg-config --libs sdl2)-lsdl2why does this not work for fish?",
    "present_kp": [
      "command substitution",
      "fish"
    ],
    "absent_kp": [
      "shell",
      "pkg config"
    ]
  },
  {
    "text": "twitter to facebook connection is not working. i'm trying to connect a twitter account to a facebook one.i have connected the facebook account from app settings in twitter and authorized twitter application.however, tweets are not being posted to the facebook account, and every time i visit the app settings page in twitter, i find that the facebook account is disconnected.i tried to disconnect both facebook and twitter, clear cache, restart browser and try reconnecting again (as mentioned in twitter help center), but it is still not working.your help is highly appreciated!",
    "present_kp": [
      "facebook",
      "twitter"
    ],
    "absent_kp": []
  },
  {
    "text": "simple program to split arguments up. i am writing this small tester program to be used as part of a larger project, and i am quite unsure about the strtok function, which i (think) i need to use to split some character arrays up on a certain character (in my case this is a colon). for each character array (which is passed in as an argument), it should split the array into two. apologies if it's hard to follow, i'm bad at explaining things.#include <stdio.h>#include <string.h>int main(int argc, char **argv){ char *pt; for (int i = 1; i < argc; i++) { pt = strtok(argv[i], :); int j = 0; while (pt != null || j < 2) { j++; if (j == 1) { printf(item: ); } else if (j == 2) { printf(quantity: ); } printf(%s , pt); pt = strtok(null, :); } j = 0; } return 0;}yes, i know the program will crash if not enough arguments are supplied, but i just quickly threw this together to try and learn more about strtok. now although this code works, i feel it is not the most efficient. i have not been programming c for very long, so any help for how i could improve this loop would be greatly appreciated.",
    "present_kp": [
      "c"
    ],
    "absent_kp": [
      "strings"
    ]
  },
  {
    "text": "run -i vs run -it?. i am using boot2docker on windows. i tried the following commands docker run -i centos /bin/bash docker run -it centos /bin/bashboth provides same kind of execution. i read -i is interactive mode. -t is terminal mode. but i can able to execute commands like pwd and ls in both -i and -it. only resulting ui is different.then whats the use of these two flags? am i missing something?",
    "present_kp": [
      "bash",
      "docker"
    ],
    "absent_kp": []
  },
  {
    "text": "fastest way to put a point on the circumference of a circle. my goal is to take a point that is inside of a circle with a given radius and put it on the circumference.recently i have been normalizing the vector between the point and the center of the circle then multiplying that by the radius. however i need (if possible) a less computationally expensive method because the distance formula is expensive.another thought i had was to use atan2 to get the angle between the two points and then use sine and cosine multiplied by the radius to get the point on the circumference.which method do you think would be faster for the computer to process? can you think of a faster method.details about the simulationthis is an ios application written in swift.basically there are a bunch of particles moving around randomly. and the user is putting down fingers. each finger is a circle with a radius that grows as time goes on. the part that is inneficent is that if the dot is ever inside of any of the circles (attached to touchscreen touches) that it goes on the circumference of the circle.",
    "present_kp": [],
    "absent_kp": [
      "maths",
      "mathematics"
    ]
  },
  {
    "text": "are representations of unattended objects bound?. in our phenomenal experience, different features of an object, like shape and color, seem to be bound together into a single percept, even though those features are represented in different parts of the brain. explaining this phenomenon is known as the binding problem. if i look at a red apple, the internal representations of its red-ness and its apple shape are bound together. but what if i am not looking at the red apple -- what if my visual attention is not on the red apple? in that case, are the object's redness and appleness still bound together? or does binding require attentional focus? does it require consciousness?",
    "present_kp": [
      "attention"
    ],
    "absent_kp": [
      "vision"
    ]
  },
  {
    "text": "mgetty stopped working as dialin after opensuse upgrade. background: opensuse 11.4 worked well for a couple of years. mgetty was configured to listen to /dev/ttys0 and work as dialin link.updated system to opensuse 12.1 > 12.2. > 12.3 > 13.1 and lost mgetty funcionality.i'm pretty knoledgeless regarding mgetty, so please let me know which logs/configs should i post.i have added mgetty to systemctl (previously opensuse used inittab), to no avail.server:~ # cat /etc/systemd/system/mgetty.service [unit]description=mgetty allows a dialin modem connectionafter=network.target[service]type=simpleuser=rootgroup=rootexecstart=/usr/sbin/mgetty -s 38400 -x 7 /dev/ttys0restart=alwaysrestartsec=0killsignal=sighupkillmode=process[install]wantedby=multi-user.targetserver:~ # systemctl status mgettymgetty.service - mgetty allows a dialin modem connection loaded: loaded (/etc/systemd/system/mgetty.service; enabled) active: active (running) since fri 2014-11-07 18:36:11 cet; 1 day 7h ago main pid: 656 (mgetty) cgroup: /system.slice/mgetty.service 656 /usr/sbin/mgetty -s 38400 -x 7 /dev/ttys0nov 07 18:36:11 server systemd[1]: starting mgetty allows a dialin modem connection...nov 07 18:36:11 server systemd[1]: started mgetty allows a dialin modem connection., this is the /var/log/mgetty.ttys011/07 16:49:20 ys0 mgetty: interim release 1.1.36-jun1511/07 16:49:20 ys0 user id: 0, pid: 2980, parent pid: 111/07 16:49:20 ys0 reading configuration data for port 'ttys0'11/07 16:49:20 ys0 reading /etc/mgetty+sendfax/mgetty.config...11/07 16:49:20 ys0 conf lib: read: 'debug 4'11/07 16:49:20 ys0 conf lib: read: 'fax-id 49 115 xxxxxxxx'11/07 16:49:20 ys0 conf lib: read: 'speed 38400'11/07 16:49:20 ys0 conf lib: read: 'init-chat at ok at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60 ok'11/07 16:49:20 ys0 conf lib: read: 'issue-file /etc/mgetty+sendfax/mgissue'11/07 16:49:20 ys0 conf lib: read: 'login-prompt \\c '11/07 16:49:20 ys0 conf lib: read: 'speed 57600'11/07 16:49:20 ys0 conf lib: read: 'toggle-dtr no'11/07 16:49:20 ys0 key: 'speed', type=0, flags=2, data=<phone>/07 16:49:20 ys0 key: 'switchbd', type=0, flags=1, data=011/07 16:49:20 ys0 key: 'direct', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'blocking', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'port-owner', type=1, flags=1, data=uucp11/07 16:49:20 ys0 key: 'port-group', type=1, flags=1, data=uucp11/07 16:49:20 ys0 key: 'port-mode', type=0, flags=1, data=43211/07 16:49:20 ys0 key: 'toggle-dtr', type=3, flags=3, data=false11/07 16:49:20 ys0 key: 'toggle-dtr-waittime', type=0, flags=1, data=50011/07 16:49:20 ys0 key: 'need-dsr', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'data-only', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'fax-only', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'modem-type', type=1, flags=1, data=auto11/07 16:49:20 ys0 key: 'modem-quirks', type=0, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'init-chat', type=2, flags=3, data= at ok at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60 ok\\datq0v1h0 ok ys0 key: 'force-init-chat', type=2, flags=1, data= \\d\\d\\d\\d+++\\d\\d\\d11/07 16:49:20 ys0 key: 'post-init-chat', type=2, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'data-flow', type=4, flags=1, data=111/07 16:49:20 ys0 key: 'fax-send-flow', type=4, flags=1, data=711/07 16:49:20 ys0 key: 'fax-rec-flow', type=4, flags=1, data=711/07 16:49:20 ys0 key: 'modem-check-time', type=0, flags=1, data=360011/07 16:49:20 ys0 key: 'rings', type=0, flags=1, data=111/07 16:49:20 ys0 key: 'msn-list', type=2, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'get-cnd-chat', type=2, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'cnd-program', type=1, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'answer-chat', type=2, flags=1, data= ata connect \\c11/07 16:49:20 ys0 key: 'answer-chat-timeout', type=0, flags=1, data=8011/07 16:49:20 ys0 key: 'autobauding', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'ringback', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'ringback-time', type=0, flags=1, data=3011/07 16:49:20 ys0 key: 'ignore-carrier', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'issue-file', type=1, flags=3, data=/etc/mgetty+sendfax/mgissue11/07 16:49:20 ys0 key: 'prompt-waittime', type=0, flags=1, data=50011/07 16:49:20 ys0 key: 'login-prompt', type=1, flags=3, data=\\c 11/07 16:49:20 ys0 key: 'login-time', type=0, flags=1, data=24011/07 16:49:20 ys0 key: 'fido-send-emsi', type=3, flags=1, data=true11/07 16:49:20 ys0 key: 'login-env-ttyprompt-hack', type=3, flags=1, data=false11/07 16:49:20 ys0 key: 'login-conf-file', type=1, flags=1, data=login.config11/07 16:49:20 ys0 key: 'fax-id', type=1, flags=3, data=49 115 xxxxxxxx11/07 16:49:20 ys0 key: 'fax-min-speed', type=0, flags=1, data=011/07 16:49:20 ys0 key: 'fax-max-speed', type=0, flags=1, data=<phone>/07 16:49:20 ys0 key: 'fax-server-file', type=1, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'diskspace', type=0, flags=1, data=102411/07 16:49:20 ys0 key: 'notify', type=1, flags=1, data=faxadm11/07 16:49:20 ys0 key: 'fax-owner', type=1, flags=1, data=root11/07 16:49:20 ys0 key: 'fax-group', type=1, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'fax-mode', type=0, flags=1, data=43211/07 16:49:20 ys0 key: 'fax-spool-in', type=1, flags=1, data=/var/spool/fax/incoming:/tmp11/07 16:49:20 ys0 key: 'debug', type=0, flags=2, data=711/07 16:49:20 ys0 key: 'statistics-chat', type=2, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'statistics-file', type=1, flags=0, data=(empty)11/07 16:49:20 ys0 key: 'gettydefs', type=1, flags=1, data=n11/07 16:49:20 ys0 key: 'term', type=1, flags=0, data=(empty)11/07 16:49:20 ys0 check for lockfiles11/07 16:49:20 ys0 checklock: stat failed, no file11/07 16:49:20 ys0 locking the line11/07 16:49:20 ys0 makelock(ttys0) called11/07 16:49:20 ys0 do_makelock: lock='/var/lock/lck..ttys0'11/07 16:49:20 ys0 lock made11/07 16:49:20 ys0 tio_get_rs232_lines: status: rts cts dsr dtr11/07 16:49:20 ys0 tss: set speed to 38400 (017)11/07 16:49:20 ys0 tio_set_flow_control( hard )11/07 16:49:20 ys0 waiting for line to clear (vtime=1), read:11/07 16:49:21 ys0 send: at[0d]11/07 16:49:21 ys0 waiting for ''ok''11/07 16:49:21 ys0 got: at[0d]11/07 16:49:21 ys0 cnd: at[0d][0a]ok ** found **11/07 16:49:21 ys0 send: at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60[0d]11/07 16:49:21 ys0 waiting for ''ok''11/07 16:49:21 ys0 got: [0d]11/07 16:49:21 ys0 cnd: ok[0a]at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60[0d]11/07 16:49:21 ys0 cnd: at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60[0d][0a]ok ** found **11/07 16:49:21 ys0 mdm_send: 'ati'11/07 16:49:21 ys0 got:[0d][0a]ati[0d]11/07 16:49:21 ys0 got:[0d][0a]1444[0d]11/07 16:49:21 ys0 mdm_gis: string 1: '1444'11/07 16:49:21 ys0 got:[0a][0d][0a]ok[0d]11/07 16:49:21 ys0 mdm_identify: string '1444'11/07 16:49:21 ys0 usr courier/sportster v32bis detected (assuming non-fax capable)11/07 16:49:21 ys0 no class 2/2.0 faxmodem, no faxing available11/07 16:49:21 ys0 waiting for line to clear (vtime=3), read:11/07 16:49:22 ys0 removing lock file11/07 16:49:22 ys0 waiting...here i made the attempted connection:11/07 16:50:02 ys0 select returned 111/07 16:50:02 ys0 checking lockfiles, locking the line11/07 16:50:02 ys0 makelock(ttys0) called11/07 16:50:02 ys0 do_makelock: lock='/var/lock/lck..ttys0'11/07 16:50:02 ys0 lock made11/07 16:50:02 ys0 wfr: waiting for ''ring''11/07 16:50:02 ys0 got: [0a][0d][0a]ring[0d]11/07 16:50:02 ys0 cnd: ring11/07 16:50:02 ys0 wfr: rc=0, drn=011/07 16:50:02 ys0 send: ata[0d]11/07 16:50:02 ys0 waiting for ''connect''11/07 16:50:02 ys0 got: [0d]11/07 16:50:13 ys0 cnd: ok[0a]connect ** found **11/07 16:50:13 ys0 send:11/07 16:50:13 ys0 waiting for ''_''11/07 16:50:13 ys0 got: 14400/arq/v32/lapm/v42bis[0d]11/07 16:50:13 ys0 cnd: connect 14400/arq/v32/lapm/v42bis11/07 16:50:13 ys0 cnd: found: 14400/arq/v32/lapm/v42bis[0a] ** found **11/07 16:50:13 ys0 waiting for line to clear (vtime=3), read: ~[ff]}#[c0]!}!} } }7}}&} } } } }%}&#[a6].*}'}}(}}-}#}&[89]5~11/07 16:50:13 ys0 looking for utmp entry... (my pid: 2980)11/07 16:50:14 ys0 tio_set_flow_control( hard )11/07 16:50:14 ys0 print welcome banner (/etc/mgetty+sendfax/mgissue)11/07 16:50:14 ys0 getlogname (no opts), read:~[ff]}#[c0]!}!}!} }7}}&} } } } }%}&#[a6].*}'}}(}}-}#}&[d4][9c]--11/07 16:50:15 ys0 mgetty: interim release 1.1.36-jun1511/07 16:50:15 ys0 user id: 0, pid: 2986, parent pid: 111/07 16:50:15 ys0 reading configuration data for port 'ttys0'11/07 16:50:15 ys0 reading /etc/mgetty+sendfax/mgetty.config...11/07 16:50:15 ys0 conf lib: read: 'debug 4'11/07 16:50:15 ys0 conf lib: read: 'fax-id 49 115 xxxxxxxx'11/07 16:50:15 ys0 conf lib: read: 'speed 38400'11/07 16:50:15 ys0 conf lib: read: 'init-chat at ok at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60 ok'11/07 16:50:15 ys0 conf lib: read: 'issue-file /etc/mgetty+sendfax/mgissue'11/07 16:50:15 ys0 conf lib: read: 'login-prompt \\c '11/07 16:50:15 ys0 conf lib: read: 'speed 57600'11/07 16:50:15 ys0 conf lib: read: 'toggle-dtr no'and it seems to .. crash... and restart...again, another phone call:11/07 17:07:27 ys0 select returned 111/07 17:07:27 ys0 checking lockfiles, locking the line11/07 17:07:27 ys0 makelock(ttys0) called11/07 17:07:27 ys0 do_makelock: lock='/var/lock/lck..ttys0'11/07 17:07:27 ys0 lock made11/07 17:07:27 ys0 wfr: waiting for ''ring''11/07 17:07:27 ys0 got: [0a][0d][0a]ring[0d]11/07 17:07:27 ys0 cnd: ring11/07 17:07:27 ys0 wfr: rc=0, drn=011/07 17:07:27 ys0 send: ata[0d]11/07 17:07:27 ys0 waiting for ''connect''11/07 17:07:27 ys0 got: [0d]11/07 17:07:38 ys0 cnd: ok[0a]connect ** found **11/07 17:07:38 ys0 send:11/07 17:07:38 ys0 waiting for ''_''11/07 17:07:38 ys0 got: 14400/arq/v32/lapm/v42bis[0d]11/07 17:07:38 ys0 cnd: connect 14400/arq/v32/lapm/v42bis11/07 17:07:38 ys0 cnd: found: 14400/arq/v32/lapm/v42bis[0a] ** found **11/07 17:07:38 ys0 waiting for line to clear (vtime=3), read: ~[ff]}#[c0]!}!} } }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&}+})~11/07 17:07:39 ys0 looking for utmp entry... (my pid: 2986)11/07 17:07:39 ys0 tio_set_flow_control( hard )11/07 17:07:39 ys0 print welcome banner (/etc/mgetty+sendfax/mgissue)11/07 17:07:39 ys0 getlogname (no opts), read:~[ff]}#[c0]!}!}!} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&v[a0]~~[ff]}#[c0]!}!}} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[a0]s~~[ff]}#[c0]!}!}#} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[fd][fa]~~[ff]}#[c0]!}!}$} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&][bc]~~[ff]}#[c0]!}!}%} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&} }5~~[ff]}#[c0]!}!}&} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[f6][e6]~~[ff]}#[c0]!}!}'} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[ab]o~~[ff]}#[c0]!}!}(} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[b6]k~~[ff]}#[c0]!}!})} }7}}&} } } } }%}&:[aa]/[9e]}'}}(}}-}#}&[eb][c2]~11/07 17:08:17 ##### failed dev=ttys0, pid=2986, got signal 1, exiting11/07 17:08:17 ys0 removing lock file--11/07 17:08:17 ys0 mgetty: interim release 1.1.36-jun1511/07 17:08:17 ys0 user id: 0, pid: 3121, parent pid: 111/07 17:08:17 ys0 reading configuration data for port 'ttys0'11/07 17:08:17 ys0 reading /etc/mgetty+sendfax/mgetty.config...another crash... and restart... ??what bogs me is that it should say it uses ppp with getlogname.here are config files:server:~ # egrep -v '(^#|^\\s*$|^\\s* *#)' /etc/mgetty+sendfax/login.config /autoppp/ - a_ppp /usr/sbin/pppd auth -chap +pap login debug* - - /bin/login @server:~ # egrep -v '(^#|^\\s*$|^\\s* *#)' /etc/mgetty+sendfax/mgetty.configdebug 7fax-id 49 115 xxxxxxxxspeed 38400init-chat at ok at&fx4&a3&b1&d2&h1&i0&k1&m4s7=60 okissue-file /etc/mgetty+sendfax/mgissuelogin-prompt \\c speed 38400toggle-dtr noserver:~ # egrep -v '(^#|^\\s*$|^\\s* *#)' /etc/ppp/options noipdefaultipcp-accept-localipcp-accept-remotenoauthcrtsctslockmodemasyncmap 0netmask 255.255.255.0nodetachlcp-echo-interval 30lcp-echo-failure 4lcp-max-configure 60lcp-restart 2idle 600noipxfile /etc/ppp/filtersproxyarploginms-dns 151.99.0.100ms-dns 151.99.125.1require-paprefuse-chapserver:~ # egrep -v '(^#|^\\s*$|^\\s* *#)' /etc/ppp/options.server -detachasyncmap 0modemcrtsctslockproxyarpms-dns 151.99.125.1ms-dns 8.8.4.4server:~ # egrep -v '(^#|^\\s*$|^\\s* *#)' /etc/ppp/options.ttys0 192.168.0.222:192.168.0.56 #serveraddress:clientadressnetmask 255.255.255.0 #the netmaskserver:~ # sysctl -e -p /etc/sysctl.conf net.ipv4.icmp_echo_ignore_broadcasts = 1net.ipv4.conf.all.rp_filter = 1net.ipv6.conf.all.disable_ipv6 = 1fs.inotify.max_user_watches = 65536net.ipv4.conf.default.promote_secondaries = 1net.ipv4.conf.all.promote_secondaries = 1net.ipv4.ip_forward = 1net.ipv4.tcp_ecn = 0the initial configuration (6+ years ago) was done following this guide: <url> ideas?",
    "present_kp": [
      "opensuse",
      "modem",
      "getty"
    ],
    "absent_kp": []
  },
  {
    "text": "mutex implementation on top of a minimalistic preemptive scheduler. in this question, i'm implementing some synchronization primitives in the standard library of an operating system. specifically, i want to implement mutexes and condition variables. this is on top of a microkernel with a preemptive scheduler (a thread has no way to prevent the scheduler from preempting it). i'm exploring how minimalistic the system can get while remaining powerful and efficient enough for my needs.from the hardware, i get a basic atomic primitive such as compare-and-swap or load-link/store-conditional. you can assume that the word size for these instructions is large enough to store a pointer or a thread identifier. furthermore all threads see the same memory.from the kernel, i get three primitives:sleep(): suspend the current thread until a thread has called wake(t) where t is the current thread. if the current thread's wake-up flag is already set then sleep() returns immediately. returning from sleep clears the wake-up flag.wake(t): wake thread t if it's asleep. if t isn't asleep then its wake-up flag is set and t's next call to sleep will return immediately. note that non-participating threads may call wake as far as the locking mechanism is concerned, it's thus possible for a thread's wake flag to become set non-deterministically.yield(): give all other threads that are not asleep a chance to run.how can i implement a mutex and condition variable api on top of these primitives?lock(m): if m is taken, sleep until it is free. mark m as taken.unlock(m): mark m as free. if some other thread is waiting for it to become free, that thread is woken up.wait(c, m): wait for the event c to happen. if c has already happened, don't block. when wait returns, it atomically locks the mutex m. when a thread notices c, the event is cleared.signal(c): signal an event on the condition c. this wakes up one thread that's waiting on c.a good solution must avoid starvation: if a thread tries to lock a mutex, it must eventually get it provided that every thread that acquires it releases it eventually. preferably, threads should obtain the lock on a first-come, first-served basis. (to give a counter-example, a last-come, first-served system would be bad because one thread could hog the mutex if it keeps acquiring it immediately after releasing it.)a solution is better if it avoids scheduling a thread that ends up doing no useful work. for example, systematically waking up all threads when something happens is not good enough.what is an efficient algorithm for implementing mutexes and synchronization variables? (note that i am not asking how to implement a spinlock! a spinlock is probably involved, but i expect answers to this question to explain how to set up wait queues and not just handwave that part.) efficiency may vary based on the amount of contention; the kind of systems i work on tend to have low contention in practice (but must not overly drain the battery when there is contention).(i expect answers to explain the algorithm in sufficient detail that a programmer could understand it, but a reference would be appreciated as well.)",
    "present_kp": [
      "synchronization",
      "threads"
    ],
    "absent_kp": [
      "operating systems",
      "concurrency",
      "mutual exclusion"
    ]
  },
  {
    "text": "ping doesn't work, but i can browse through the internet. pinging my default gateway is working properly and i can browse google and facebook in my browser. but, ping google.com and ping facebook.com on my terminal are not working.ping google.com (216.58.220.46) 56(84) bytes of data.is just stuck. i also tried to reinstall resolvconf with sudo apt-get remove --purge resolvconf && sudo apt-get install --reinstall resolvconf. but still it doesn't work.",
    "present_kp": [
      "terminal",
      "internet",
      "ping"
    ],
    "absent_kp": []
  },
  {
    "text": "solaris 8 start in console mode. i have a machine solaris-8 in my company that the motherboard was replaced yesterday.when starting the machine today, it automatically goes to console mode and i can't access to the login with the graphic mode.and i don't know why .i searched in the internet about that problem and about solaris-8 but no solutions . i want to access only to the graphic mode . can you help me please ?i also try after starting the machine in console mode, the command cat /.dt/startlog and i got this : --- /usr/dt/bin/xsession starting...--- starting /usr/openwin/bin/speckeysd--- xsession started by dtlogin--- starting /usr/dt/bin/dtsession_res -load -system--- sourcing //.dtprofile...--- sourcing /usr/dt/config/xsession.d/0010.dtpaths...--- sourcing /usr/dt/config/xsession.d/0015.sun.env...--- sourcing /usr/dt/config/xsession.d/0020.dtims...--- sourcing /usr/dt/config/xsession.d/0030.dttmpdir...--- sourcing /usr/dt/config/xsession.d/0040.xmbind...--- sourcing /usr/dt/config/xsession.d/1000.solregis...--- could not read //.profile--- starting /usr/dt/bin/dthello &--- starting /usr/dt/bin/dtsearchpath--- starting /usr/dt/bin/dtappgather &--- starting /usr/dt/bin/dsdm &--- session log file is /dev/null--- dtsourceprofile is 'true' (see //.dtprofile)--- execing /usr/dt/bin/dtsession with a /sbin/sh login shell ...--- starting desktop on /dev/pts/3/usr/dt/bin/ttsession[705]: startingx connection to :0.0 broken (explicit kill or server shutdown).can someone have an idea about this .?thank you",
    "present_kp": [
      "solaris"
    ],
    "absent_kp": []
  },
  {
    "text": "unlist update from update list opensuse. is there a way to stop opensuse from trying to install a particular update? everytime i have new updates, it tries to install kernel-desktop-3.11.10-25.1 (x64) along with a newer version (currently 3.19). if i leave it checked, the installation fails.. and if i uncheck it, next time i have updates this particular update reappears. it makes no sense to install it since i have a newer version available, so i would like to remove it from my recommended updates.edit: it is tangential to the question at hand, but the error currently displayed if i try to install the update is there is no update candidate for kernel-desktop-3.19.0-2.1.g1133f88.x86_64.",
    "present_kp": [
      "opensuse"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "how to run an executable file (web app) 24/7 and restart automatically when it breaks down?. i have an executable file on a server which is a full-fledged standalone web application. when i login to a server via ssh and run the file, the website become visible in the internet. obviously, because it's run via ssh by me, when i disconnect the website goes down. what's the idiomatic and easy way to run that file 24/7 and preferably re-launch when it goes down? it's ubuntu 15 but my question isn't only about it. i don't want to use any third-party solutions or web services, only the standard linux tools and applications.should i create a service for systemd?",
    "present_kp": [
      "ubuntu",
      "systemd",
      "services"
    ],
    "absent_kp": [
      "webserver"
    ]
  },
  {
    "text": "works on command line but not in shell script. i have a file formated like below:436541,000454056,smith,john,jsmith,<email> want to extract out ,jsmith and write it to another file test.txt.so i use:grep -o '\\,[a-z][a-z0-9]{1,7}' source.txt > test.txtfrom the command line and it works fine.when i use it from a shell script the test.txt file is empty#!/bin/bashgrep -o '\\,[a-z][a-z0-9]{1,7}' source.txt > test.txtany suggestions?",
    "present_kp": [
      "shell script",
      "grep"
    ],
    "absent_kp": []
  },
  {
    "text": "building quickfix on arch-arm. i am running arch linux arm on my raspberry pi, and am trying to install quickfix (<url>). i believe that i have correctly installed all of the dependencies (<url>) and have successfully built the software from source.unfortunately when i follow the test scripts (<url>), i get the following error:[alarm@alarm-rpi3 test]$ ./runut.sh 1026ut: no process foundat: no process found<ut> <output>c++/test/fieldconvertorstestcase.cpp:114: error: failure in integerconvertto: expected -<phone> but was -00failure: 1 out of 191 tests failed (1 failures).test time: 13.43 seconds. </output></ut>does anyone have any idea how i might go about resolving this issue? has anyone had any success running quickfix on arch linux?",
    "present_kp": [
      "raspberry pi"
    ],
    "absent_kp": [
      "compiling",
      "arch arm"
    ]
  },
  {
    "text": "using database licensed under creative commons attribution v3. i have access to a database which data is released under creative commons attribution v3.0i understand that using this database/data requires me to give credits on information origin in different ways.i wish to migrate this database to a different engine, and in the future use other data sources (for wish i don't know the license) to complement this data.can i do this as long as i keep crediting the original source of some information bits?",
    "present_kp": [
      "creative commons"
    ],
    "absent_kp": [
      "licensing",
      "open source"
    ]
  },
  {
    "text": "filesystems not mounting on boot?. i'm getting this error after rebooting:scanning for btrfs filesystems * stopping read required files in advance [ ok ] * starting mount filesystems on boot [fail] i tried the instructions here:ubuntu 13.04 to 13.10: filesystem check or mount failed(in summary: remount root read/write, run dpkg --configure -a,remount root read-only, and reboot), and no dice.ialso found a thread about getting rid of btrfs(how to get rid of the scanning for btrfs file systems atstart-up?),but i'm not sure if that's a good idea to try. this is all on a virtual machine and i do have a snapshot before i shutdown the system, that seems to be working. but it's going to be a problem if i can never shut down.",
    "present_kp": [
      "filesystems",
      "boot",
      "btrfs"
    ],
    "absent_kp": []
  },
  {
    "text": "letting a device access the internet through an ethernet port via a laptop. i have internet access to my laptop, over wi-fi. i have connected a device with an ethernet port (with an ethernet cable from my laptop to the device), and set up a local area network between the two, so that they can ping each other. now i want the device to access the internet, i.e., to forward internet from wi-fi on my laptop to the ethernet port of the laptop.how do i set this up if the laptop runs ubuntu?",
    "present_kp": [],
    "absent_kp": [
      "linux",
      "networking",
      "wifi",
      "ip",
      "connection sharing"
    ]
  },
  {
    "text": "why doesn't the more->create event menu item in gmail populate the calendar event with info?. whenever i choose create event, it just pops up a calendar window with the date set to today and the title set to untitled event. this used to fill in info from the message (at the very least the title).",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "google calendar"
    ]
  },
  {
    "text": "how can a problem be undecidable yet enumerable?. how can something be enumerable but be un-decidable ie, this states the halting set is un-decidable and enumerable. enumerable means it can be computed, ie has the same cardinality as natural numbers and can be computed by a program with an output. but if thats the case it should be decidable. or is decidability separated from computability? am i misunderstanding the intuition of the halting set?",
    "present_kp": [
      "computability"
    ],
    "absent_kp": [
      "undecidability",
      "halting problem"
    ]
  },
  {
    "text": "in fedora, how do i turn off the automatic dictionary suggestions?. i just installed fedora 19 in virtualbox using an image from virtualboxes.org. it suggests words from a dictionary wherever i type. it's slow and it won't let me type what i want, since it automatically inserts the topmost dictionary suggestion.how do i turn it off?",
    "present_kp": [
      "fedora",
      "dictionary"
    ],
    "absent_kp": [
      "terminal",
      "spell checking",
      "ibus"
    ]
  },
  {
    "text": "apache log file - referer url that doesn't exist. after recently having my shared-host linux server hacked (~25 wordpress installs, malicious code spidered throughout), i've started looking through my access log files to see where my traffic is coming from (was hoping to narrow down the point of entry, having minimal luck).i keep seeing entries where i can verify the referrer does not exist. for example:103.47.135.111 - - [19/apr/2016:01:14:53 -0600] get /wp-content/themes/wallstreet/style.css?ver=4.5 http/1.1 200 12562 http://my_domain.com/yqmmfkv/cara-pdkt-sama-cewek-lewat-hp.htm mozilla/5.0 (iphone; cpu iphone os 7_1_2 like mac os x) applewebkit/537.51.2 (khtml, like gecko) version/7.0 mobile/11d257 safari/9537.53the referrer (http://my_domain.com/yqmmfkv/cara-pdkt-sama-cewek-lewat-hp.htm) doesn't exist from what i can tell. it returns a 404, there's no mention of it using grep -r yqmmfkv, and doesn't seem to exist in my wp database. the style.css file does exist so i see why it's returning 200, but how can a page that doesn't exist be requesting it?further, what's the gain by spoofing the referrer?",
    "present_kp": [],
    "absent_kp": [
      "logs"
    ]
  },
  {
    "text": "why the language-specific optimization in the vim colorscheme is seemingly of no effect?. the following content is extracted from gruvbox.vim. it indicates that green and yellow have been set for different levels of markdown header. however, i can not see the difference from the above picture.hi! link markdownh1 gruvboxgreenboldhi! link markdownh2 gruvboxgreenboldhi! link markdownh3 gruvboxyellowboldhi! link markdownh4 gruvboxyellowboldhi! link markdownh5 gruvboxyellowhi! link markdownh6 gruvboxyellowedit: thanks for the comments below! i have confirmed that vim-markdown caused this, what should i do next?",
    "present_kp": [
      "colorscheme"
    ],
    "absent_kp": []
  },
  {
    "text": "how can i resize my encrypted root and home partitions, to give root more space?. i need to enlarge my / (root) partition, i have a lot of space on my /home partition so how can i do this? the drive is encrypted with luks.my system is fedora 20.i have another thread here which mentions system-config-lvm but this seems to be a outdated tool as it is not installed or in the repositories.gparted doesn't work as it doesn't support luks encryption.here is:~]$ sudo fdisk -l disk /dev/sda: 465.8 gib, 500107862016 bytes, 976773168 sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 bytesdisklabel type: gptdisk identifier: 7ae6e531-9898-4c7c-8c35-41b4fdb9374adevice start end size type/dev/sda1 2048 411647 200m efi system/dev/sda2 411648 <phone> 500m microsoft basic data/dev/sda3 <phone> 976773119 465.1g microsoft basic datadisk /dev/mapper/luks-e69b0b4c-a8e0-425f-988d-8c635729503b: 465.1 gib, 499370688512 bytes, 975333376 sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 bytesdisk /dev/mapper/fedora_hostname-swap: 3.8 gib, <phone> bytes, <phone> sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 bytesdisk /dev/mapper/fedora_hostname-root: 50 gib, <phone> bytes, 104857600 sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 bytesdisk /dev/mapper/luks-b7af1bce-82c4-4921-aac1-bce701e30256: 50 gib, <phone> bytes, 104853504 sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 bytesdisk /dev/mapper/fedora_hostname-home: 411.3 gib, 441639239680 bytes, 862576640 sectorsunits: sectors of 1 * 512 = 512 bytessector size (logical/physical): 512 bytes / 4096 bytesi/o size (minimum/optimal): 4096 bytes / 4096 byteshere is:~]$ df -hfilesystem size used avail use% mounted on/dev/dm-3 50g 45g 2.0g 96% /devtmpfs 1.9g 0 1.9g 0% /devtmpfs 1.9g 80k 1.9g 1% /dev/shmtmpfs 1.9g 9.0m 1.9g 1% /runtmpfs 1.9g 0 1.9g 0% /sys/fs/cgrouptmpfs 1.9g 20k 1.9g 1% /tmp/dev/sda2 477m 131m 317m 30% /boot/dev/sda1 200m 9.6m 191m 5% /boot/efi/dev/mapper/fedora_hostname-home 405g 202g 183g 53% /homehere is:]$ sudo lvdisplay --- logical volume --- lv path /dev/fedora_hostname/swap lv name swap vg name fedora_hostname lv uuid qqqrvr-toxx-j0m7-lth5-d8lr-auq3-ehj6a4 lv write access read/write lv creation host, time hostname.lan, 2014-03-24 15:51:10 +0000 lv status available # open 2 lv size 3.77 gib current le 964 segments 1 allocation inherit read ahead sectors auto - currently set to 256 block device 253:1 --- logical volume --- lv path /dev/fedora_hostname/home lv name home vg name fedora_hostname lv uuid in2lrz-16ul-vhh5-sqoe-yqlt-tmb3-5jm7ea lv write access read/write lv creation host, time hostname.lan, 2014-03-24 15:51:10 +0000 lv status available # open 1 lv size 411.31 gib current le 105295 segments 1 allocation inherit read ahead sectors auto - currently set to 256 block device 253:4 --- logical volume --- lv path /dev/fedora_hostname/root lv name root vg name fedora_hostname lv uuid bbwzcc-nhhd-s8km-mmgi-ugq0-8ybv-hclqgp lv write access read/write lv creation host, time hostname.lan, 2014-03-24 15:51:16 +0000 lv status available # open 1 lv size 50.00 gib current le 12800 segments 1 allocation inherit read ahead sectors auto - currently set to 256 block device 253:2",
    "present_kp": [
      "fedora",
      "partition",
      "encryption"
    ],
    "absent_kp": [
      "hard disk",
      "root filesystem"
    ]
  },
  {
    "text": "a banded interpolator, for any type and any interpolation method. this is an extension of my attributes system i wrote about in these questions:lvl 1 upgradeable attributeslvl2 upgradeable attributesit is unrelated to the core functionality under review in those questions, but i present them for reference.i wrote a banded interpolator. this takes a set of input ranges mapped to output values and, for an input value between any of the input ranges, returns a value interpolated between the two values of the bands the input value is between.eg.bands: [ 0:1, 10:2, 100:3 ], input: 0.5, linear interpolation.the input is between 0 and 10, so the output is the linear interpolation of 1 and 2, using delta value: \\$ rac{0.5}{10-0} = 0.05\\$ therefore the result is: \\$1 + 0.05(2-1) = 1.05\\$what's special about this implementation is that it works for any type of band key, any type of band value, and any method of interpolation. this is of particular use for me, since in game development i find myself needing to interpolate colours, vectors, etc. on top of the standard data types.implementationiinterpolator/// <summary>/// interface for interpolators./// </summary>/// <typeparam name=tresult>the type of value to interpolate.</typeparam>/// <typeparam name=tdelta>the type of the delta value.</typeparam>public interface iinterpolator<tresult, tdelta>{ /// <summary> /// interpolates between from and to by delta. /// </summary> tresult interpolate(tresult from, tresult to, tdelta delta);}bandedinterpolatedattributethis is the real meat and potatoes. for reference, the operator class is from the miscutils library, and allows you to perform generic operations such as addition and subtraction on any type, provided that type supports the required operator.public class bandedinterpolatedattribute<tkey, tresult> : iattribute<tresult>{ private iinterpolator<tresult, tkey> interpolator; private func<tkey> deltagetter; private idictionary<tkey, tresult> bands; public bandedinterpolatedattribute(func<tkey> deltagetter, idictionary<tkey, tresult> bands, iinterpolator<tresult, tkey> interpolator) { if (deltagetter == null) { throw new argumentnullexception(deltagetter); } if (bands == null) { throw new argumentnullexception(bands); } if (interpolator == null) { throw new argumentnullexception(interpolator); } this.bands = bands; this.deltagetter = deltagetter; this.interpolator = interpolator; } public tresult value { get { var orderedkeys = bands.keys.orderby(x => x); var lowestkey = orderedkeys.first(); var highestkey = orderedkeys.last(); var delta = deltagetter(); if (operator<tkey>.lessthanorequal(delta, lowestkey)) { return bands[lowestkey]; } else if (operator<tkey>.greaterthanorequal(delta, highestkey)) { return bands[highestkey]; } else { var lowband = orderedkeys.last(x => operator<tkey>.lessthan(x, delta)); var highband = orderedkeys.first(x => operator<tkey>.greaterthan(x, delta)); var normalizeddelta = operator<tkey>.divide(operator<tkey>.subtract(delta, lowband), operator<tkey>.subtract(highband, lowband)); return interpolator.interpolate(bands[lowband], bands[highband], normalizeddelta); } } }}usagevar randomgenerator = new system.random();var interpolatedattribute = new bandedinterpolatedattribute<double, vector3>( () => randomgenerator.nextdouble(), new dictionary<double, vector3>() { {0d, new vector3(0,0,0)}, {1d, new vector3(10,10,10)} }, new linearinterpolator<vector3, double>());for (var i = 0; i < 10; i++){ console.writeline(interpolatedattribute.value);}",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "mathematics",
      "generics"
    ]
  },
  {
    "text": "handling duplicate content & pagination with category description. i have an ecommerce site with paginated product categories.i would like to add a description for each category to improve the thin content problem ecommerce pages generally have.i would like this paragraph description to show on each page of its respective category, but how do i avoid the duplicate content issue.first thing that comes to mind is rel=canonical to point back to the first page, but according to yoast, that's not such a good idea:a common misconception is that the canonical on a paginated page should always point to page 1 in the series. this is not the case. when you do that, you run the risk of search engines not indexing links that appear on page 2, 3 etc. of your archives. this would cause older articles to drop out of the search results entirely.to me, this makes perfect sense. the products are different on each page.what suggestions do you have for the best way to handle this?",
    "present_kp": [
      "ecommerce",
      "categories",
      "thin content"
    ],
    "absent_kp": [
      "seo",
      "canonical url"
    ]
  },
  {
    "text": "generating words in given format. i am looking for an algorithm that will generate all possible combinations of words from given dictionary that satisfy given format.let me explain what i mean with format: for example, if the format is abcd means that we are looking for one word, length of the word must be 4 and because all the letters in format are different, all the letters in the word must be different.the format computer science means:1) we are looking for 2 words (one of length len(computer) = 8 and one of lenght len(science) = 7)2) the first char of the first word must be the same as the second char and the sixth char in the second word (letter c in format)3) the seventh char of the first word must be the same as the the forth and the last char in the second word (letter e in format)is it better to generate all the possible strings in given format and the look them up in the dictionary or somehow build strings using dictionary ?edit:my idea:1) split big dictionary (100 millions of words) into smaller ones based on word length.2) for first word get trough all the entries in particular dictionary and try to match first word, then continue with the next one, but with more restrictions.thank you for your help!",
    "present_kp": [
      "strings"
    ],
    "absent_kp": [
      "algorithms",
      "enumeration"
    ]
  },
  {
    "text": "how to build a supervised artificial neural network?. i am trying to build and train a machine learning data science algorithm that correctly predicts what president won in what county. i have the following information for training data.total population median age % bachelorsdeg or higher unemployment rate per capita income total households average household size % owner occupied housing % renter occupied housing % vacant housing median home value population growth house hold growth per capita income growth winneri am new to the field and this is my first time building an artificial neural network and i don't know what to do to start (so forgive me if my question is extremely broad). what i have done so far is read the wikipedia page for artificial neural networks. what i want to do next is implement supervised learning using the training data.i would appreciate any help getting started. please let me know if you have used any good tutorials or libraries to help build something similar. i was thinking of using the library lasagne.a few specific questions i have as i tried to use lasagne - what is the error i am to calculate when building an algorithm using training data? how many layers do i need and what does each layer signify?",
    "present_kp": [
      "machine learning",
      "neural network",
      "supervised learning"
    ],
    "absent_kp": [
      "algorithms"
    ]
  },
  {
    "text": "compare two files and print matches in the first file adding extra column. i have two different files with one column each. the file 1 has more info and i want a command to search the matches against the file 2 and then return the original file 1 with an extra column saying for example matchfile 1mg_134mg_560file 2mg_1mg_134outputmg_134 matchmg_560i tried to use join and grep -ff, but i would like to have this specific output. thanks",
    "present_kp": [],
    "absent_kp": [
      "file comparison"
    ]
  },
  {
    "text": "how to replace a disk in a non-redundant zfs pool?. i've been doing a bit of reading, and it looks like zfs doesn't like disks being removed from non-redundant arrays:you can use the zpool detach command to detach a device from a mirrored storage pool. for example:# zpool detach zeepool c2t1d0however, this operation is refused if there are no other valid replicas of the data. for example:# zpool detach newpool c1t2d0cannot detach c1t2d0: only applicable to mirror and replacing vdevsthe basic problem is understandable: removing the only copy of a piece of data (whether metadata or payload data) from an array would render that data unavailable.the examples for replacing devices in a zfs storage pool give a basic step-by-step description for how to replace a device in a storage pool: offline the disk, remove the disk, insert the replacement disk, run zpool replace to inform zfs of the change and online the disk. this obviously requires that the array does not depend on the disk being replaced, hence the array must have redundancy; if it does depend on the drive in question, this approach presents the same problem as above.what is the recommended way of replacing a disk in a non-redundant zfs array?assume that the existing disk is working properly, and assume that the replacement disk is at least the same size as the disk being replaced. (if the existing disk has failed, clearly all one could do is add a new disk and restore all files affected by the disk failure from backup.)",
    "present_kp": [
      "zfs"
    ],
    "absent_kp": [
      "linux"
    ]
  },
  {
    "text": "open webapplication from desktop application. doctor is end user of this applicationdoctor opens desktop application on his pc which is not developed by us. we provide interface to desktop application via interop dll's.desktop application call interface and through it they call our integration exe which includes some services which sits on doctors pc. this integration exe further creates session id, validates certificate on doctors pc with our database and at last it open browser with our webapplication created in angularjs.now i will explain what issues we face due to this..previously this was working because webapplication was in http and so was wcf service aka localhost service in http.client told we cannot host webapplication in http and we had to use https. but https webapplication cannot talk to local service hosted in http , so we had to change to use https for communicating with localhost services. so we had to introduce self signed certificates. this was also working ok till last month when chrome came with policy that it will not allow localhost certificate and suddenly on browser we get error about accepting certifcate.what does localhost service do?a. get access token by passing the session id to login the application from desktop application .b. pass xml message to desktop application to signc. get available printers in the network.d. intimate browser close event to desktop application to close the session.what we need to do nowfind a way to totally avoid localhost service so we need to change architecture or first come up with approach",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "web development",
      "web applications",
      "angular2"
    ]
  },
  {
    "text": "flashing nvram with u-boot 1.2.0. i tried to program spi flash nvram (s25fl064a) from u-boot, but it not allow to write:tftp 0x80000100 nvram.bincp.b 0x80000100 0x007b0000 0x00050000there is no error shown after cp.b command, just not allow to write. what can be the problem?flash memory structure, from u-boot 1.2.0 printenv:serial flash [bus:0 cs:0] : s25fl064a 8192kb, 128 sectors each 64kb7 cmdlinepart partitions found on mtd device spansionpartitions[0] = {.name = u-boot, .offset = 0x00000000,.size = 0x00020000 (128k) }partitions[1] = {.name = env1, .offset = 0x00020000,.size = 0x00010000 (64k) }partitions[2] = {.name = env2, .offset = 0x00030000,.size = 0x00010000 (64k) }partitions[3] = {.name = firmware_eh, .offset = 0x004a0000,.size = 0x002d0000 (2880k) }partitions[4] = {.name = nvram, .offset = 0x007b0000,.size = 0x00050000 (320k) }partitions[5] = {.name = ubfi1, .offset = 0x00040000,.size = 0x003b0000 (3776k) }partitions[6] = {.name = ubfi2, .offset = 0x003f0000,.size = 0x003b0000 (3776k) }creating 7 mtd partitions on spansion:0x00000000-0x00020000 : u-boot0x00020000-0x00030000 : env10x00030000-0x00040000 : env20x004a0000-0x00770000 : firmware_eh0x007b0000-0x00800000 : nvram0x00040000-0x003f0000 : ubfi10x003f0000-0x007a0000 : ubfi2",
    "present_kp": [
      "firmware",
      "memory",
      "spi"
    ],
    "absent_kp": [
      "linux",
      "serial communication"
    ]
  },
  {
    "text": "updating multiple entities at once using the data mapper pattern. i have been studying software architecture and design patterns for the past weeks, and for a week now i can't stop thinking about the performance problems that come with the flexibility of the data mapper pattern. in the book written by martin fowler, he gives an example of the pattern with some find methods and just one delete method, one update method and one insert method. so, when he has to update multiple objects, he takes multiple trips to the database. i started reading about the unit of work pattern in the same book, but it looks like by its implementation that it doesn't solve this problem either.is there a solution that solves this issues without losing too much flexibility?",
    "present_kp": [
      "design patterns",
      "performance",
      "software"
    ],
    "absent_kp": []
  },
  {
    "text": "google spreadsheet sumif aggregation - multiple strings in condition. how to use google spreadsheet sumif agregation function with more than one condition?what i currently have is formula:=sumif( a1:a50, match_this,b1:b50)but i want to improve it to have 2 conditions:=sumif( a1:a50, _one_of_(match_this, match_that),b1:b50)is there operand like my imaginary _one_of_ or what is the most simple, and correct way to handle this?",
    "present_kp": [],
    "absent_kp": [
      "worksheet function",
      "google spreadsheets"
    ]
  },
  {
    "text": "is there any *real* reason to use backtrack?. i have heard of backtrack, never used it, don't see the point. it doesn't use something that can read my mind and install the packages i am thinking about, it just uses apt-get. the other thing is, i had never even heard of backtrack until i looked at some youtube videos of 'how to hack stuff', hack being pejorative. i forgot about it until today, when i read this article. my question is, is there actually a reason to use backtrack as opposed to, say, debian? from where i'm standing it just looks like a sort of trendy thing teenagers do in order to relieve the boredom of living in suburbs and whatnot. what's more, it seems like people who try backtrack complain that they can't get the most basic things to work 'out of the box'.are the repositories actually different? or does it just 'look cool' in youtube videos and lifehacker articles?",
    "present_kp": [
      "backtrack"
    ],
    "absent_kp": [
      "distribution choice"
    ]
  },
  {
    "text": "aufs only changes permissions of the topmost directory. i have two writeable directories branch1 and branch2 tied together with aufs on debian 8 to the mount point union.mount options: br=branch1=rw:branch2=rwbranch1 and branch2 each contain a subdirectory dir with permissions 700. when i change the permissions with chmod 755 union/dir, only the first directory branch1/dir is altered, branch2/dir ramains as it is.problem: group and other users can't access union/dir even after setting chmod 755 because branch2/dir is still chmod 700.is there a way to make aufs apply changed permissions to all directories in the union or is it always limited to the topmost one?",
    "present_kp": [
      "permissions",
      "directory",
      "aufs"
    ],
    "absent_kp": []
  },
  {
    "text": "how to convert image results into data?. i have made an 3d solar exposure analysis for a 3d city model that determines how long a surface receive direct sunlight throughout the year. results are coloured surfaces and legend of coloures that explain how long the colour means. you can see the results in the attaching file. how can i report the results. how can i convert visualization into data? because i want to query the results of analysis",
    "present_kp": [
      "3d",
      "model"
    ],
    "absent_kp": [
      "raytracing"
    ]
  },
  {
    "text": "solving superstring exactly. what is known about exact complexity of the shortest superstring problem? can it be solved faster than $o^*(2^n)$? are there known algorithms that solve shortest superstring without reducing to tsp?upd: $o^*(\\cdot)$ suppresses polynomial factors.the shortest superstring problem is a problem whose answer is the shortest string which contains each string from a given set of strings. the question is about optimization extension of a famous np-hard problem shortest superstring(garey and johnson, p.228).",
    "present_kp": [
      "tsp"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "ds.algorithms",
      "graph theory",
      "exp time algorithms"
    ]
  },
  {
    "text": "is there evidence to suggest that receiving angry emails increases stress levels?. there are plenty of helpful descriptions of how to avoid angry emails. the reasoning is largely that it doesn't solve the problem. that is, sending an email whilst angry causes more problems for you than it solves. but what about the recipient? logically and analytically we know that people don't respond well to an emotive email. but is there statistical or experimental evidence of the changes in brain/body state (or behaviour) that occur when people receive emotive emails?my question is: is there evidence to suggest that receiving angry emails increases stress levels?",
    "present_kp": [
      "stress"
    ],
    "absent_kp": [
      "emotion",
      "communication"
    ]
  },
  {
    "text": "what is the difference between google webmaster tools and google search console?. i see many questions concerning the google search console and google webmaster tools. what is the major differences between the two services and which one should i be using for my website? is it possible to just use one or do i need to use both services to submit a sitemap?",
    "present_kp": [
      "google search console"
    ],
    "absent_kp": []
  },
  {
    "text": "hackerrank insertion sort part 2. i have started learning java recently and was looking into the challenges on sorting on hackerrank.i solved the following problemhackerrank on insertion sort.the challenge was :in insertion sort part 1, you sorted one element into an array. using the same approach repeatedly, can you sort an entire unsorted array?guideline: you already can place an element into a sorted array. how can you use that code to build up a sorted array, one element at a time? note that in the first step, when you consider an element with just the first element - that is already sorted since there's nothing to its left that is smaller.in this challenge, don't print every time you move an element. instead, print the array after each iteration of the insertion-sort, i.e., whenever the next element is placed at its correct position.since the array composed of just the first element is already sorted, begin printing from the second element and on.input format there will be two lines of input:the size of the arraya list of numbers that makes up the arrayoutput format : on each line, output the entire array at every iteration.sample input:61 4 3 5 6 2sample output: 1 4 3 5 6 2 1 3 4 5 6 2 1 3 4 5 6 2 1 3 4 5 6 2 1 2 3 4 5 6 i am trying to get better at writing good code for my solutions..please give me your suggestions .import java.util.scanner;public class insertionsortpart2 {public static void main(string[] args) { scanner keyboard = new scanner(system.in); int size = keyboard.nextint(); int[] array = new int[size]; for (int i = 0; i < array.length; i++) { array[i] = keyboard.nextint(); } array = insertionsort(array);}private static int[] insertionsort(int[] a) { for (int i = 1; i < a.length; i++) { // set key to value at index i int key = a[i]; // set j as i-1 to look for previous element int j = i - 1; while (j >= 0 && a[j] > key) { a[j + 1] = a[j]; j--; } a[j + 1] = key; for (int f = 0; f < a.length; f++) { system.out.print(a[f] + ); } system.out.println(); } return a; }}",
    "present_kp": [
      "java",
      "sorting",
      "insertion sort"
    ],
    "absent_kp": [
      "programming challenge"
    ]
  },
  {
    "text": "proper way to implement a dynamic array of non-default-constructible objects. as many other questions and answers already stated, there is no syntax in c++ which allows you to declare and fill a dynamic-sized array with non-default constructible objects. obj* array = new obj[size];here, if obj has a default constructor, it will be used to fill array with size default-constructed instances of obj, which is a problem.the most recurrent answers to this question mention vectors (here), or the mechanism used by vectors, the placement new (here). however, the former is not an option in my case, and i would like to avoid the latter because it looks plain dirty and messy to me (being used by the stl perhaps makes it a nice way to do things, but it really does look messy).edit: why vectors are not an option: this project is a challenge i want to test myself against, and i want to get my hands in the dirt as much as i can. if not using vectors means using placement news as stated below, then that is what i will do.i do realise that i complained about placement news being messy, and i also do realise that getting hands in the dirt does imply having to handle such mess.another recurrent answer is to use the curly braces to fill the array with non-default constructed objects:obj* array = new obj[2] {obj(foo), obj(bar)};that makes it a half-dynamic-sized array, if i may say. being allocated on the heap makes it not static, but the size has to be a compile-time constant, so i would not consider it fully dynamic (or at least not as much as i want it to be).the most obvious solution to me would be to declare the array as above, let it be filled with junk, default-constructed objects, and then re-fill it up with the correct objects, as follows:obj* array = new obj[size];for (int i = 0; i < size; i++){ array[i] = obj(whatever);}however, performance is a great deal in my program, and i am quite concerned about the performance impact of such methods. if size is 10000, the array would be filled with 10000 junk objects, which could be very time-expensive. then, the cost of the replacement afterwards could be even worse (while still possible to minimise with efficient use of the copy-and-swap idiom), and that too is a concern.instead, i was thinking of using a double malloc.obj** array = malloc(sizeof(obj*) * size);for (int i = 0; i < size; i++){ array[i] = malloc(sizeof(obj)); array[i] = new obj(whatever);}//...for (int i = 0; i < size; i++){ delete array[i]; free(array[i]);}free(array);but that looks totally not cache-friendly. and it just does not feel right having a pair of malloc (having only one already feels not okay). so here is my question: is there a nice and clean way that allows you to allocate uninitialised memory, and then fill it with custom-constructed objects, that does not degrade performance?edit: my real question is: are there other ways than the ones i mentioned above?(p.s.: i know that uninitialised memory does not go well with raii, and thus does not go well with nice and clean)",
    "present_kp": [
      "c++",
      "memory"
    ],
    "absent_kp": []
  },
  {
    "text": "overlap detection for laying out elements on a page. how would you simplify/improve the readability of this code? because even after my attempt to improve the readability i think it still looks messy. private bool intop = false; private bool inleft = false; private bool inright = false; private bool inbottom = false; private bool beyond = false; private list<dependencyobject> beyonddo = new list<dependencyobject>(); private list<dependencyobject> fullout = new list<dependencyobject>(); private list<dependencyobject> topleftdo = new list<dependencyobject>(); private list<dependencyobject> topdo = new list<dependencyobject>(); private list<dependencyobject> toprightdo = new list<dependencyobject>(); private list<dependencyobject> leftdo = new list<dependencyobject>(); private list<dependencyobject> currentpagedo = new list<dependencyobject>(); private list<dependencyobject> rightdo = new list<dependencyobject>(); private list<dependencyobject> bottomleftdo = new list<dependencyobject>(); private list<dependencyobject> bottomdo = new list<dependencyobject>(); private list<dependencyobject> bottomrightdo = new list<dependencyobject>(); private bool foreachchildin(dependencyobject mypage, ilist<dependencyobject> childlist) { var result = false; foreach (var item in childlist) { var itemresult = false; if (item is visual && mypage is visual) { var myvisual = item as visual; //relative position des myvisual zu visualelement point relativesartpoint = myvisual.transformtoancestor((visual)mypage) .transform(new point(0, 0)); var aw = (double)myvisual.getvalue(frameworkelement.actualwidthproperty); var ah = (double)myvisual.getvalue(frameworkelement.actualheightproperty); var relativeendhorizontal = relativesartpoint.x + aw; var relativeendvertikal = relativesartpoint.y + ah; point relativeendpoint = new point(relativeendhorizontal, relativeendvertikal); intop = (pagerect.top <= relativesartpoint.y); inbottom = (pagerect.bottom >= relativeendpoint.y); inleft = (pagerect.left <= relativesartpoint.x); inright = (pagerect.right >= relativeendpoint.x); beyond = (pagerect.top >= relativeendpoint.y) || (pagerect.bottom <= relativesartpoint.y) || (pagerect.left >= relativeendpoint.x) || (pagerect.right <= relativesartpoint.x); if (isin()) { result = true; itemresult = true; } else if (beyond) beyonddo.add(item); else if (((relativesartpoint.x == 0 && relativesartpoint.y == 0) || (istopoverlap()) && isleftoverlap()) && isrightoverlap() && isbottomoverlap()) fullout.add(item); else if (istopoverlap() && isleftoverlap()) topleftdo.add(item); else if (istopoverlap() && isrightoverlap()) toprightdo.add(item); else if (istopoverlap()) topdo.add(item); else if (isbottomoverlap() && isleftoverlap()) bottomleftdo.add(item); else if (isbottomoverlap() && isrightoverlap()) bottomrightdo.add(item); else if (isbottomoverlap()) bottomdo.add(item); else if (isrightoverlap()) rightdo.add(item); else if (isleftoverlap()) leftdo.add(item); } if (!itemresult) if (foreachchildin(item, item.getchilds().tolist())) result = true; else if ((visibility)item.getvalue(frameworkelement.visibilityproperty) == visibility.visible) //item.setvalue(frameworkelement.visibilityproperty, visibility.hidden); //this part is just for testing if (item is control) ((control)item).background = brushes.limegreen; else if (item is panel) ((panel)item).background = brushes.limegreen; } return result; }my attempt to improve readability by encapsulating conditions in meaningful methods:private bool isin(){ return intop && inleft && inright && inbottom;}private bool istopoverlap(){ return !beyond && !intop;}private bool isleftoverlap(){ return !beyond && !inleft;}private bool isrightoverlap(){ return !beyond && !inright;}private bool isbottomoverlap(){ return !beyond && !inbottom;}disclaimerthis code isn't in production it is just for testing purposes.to answer the question about what and how many combinations are possible here are all possible combination to make it a bit more visual think about a numpad:we have 9 basic positions.number 5 represents isin(). number 1, 2, 3, 4, 6, 7, 8, 9 are represented by beyond. after these basic positions we come to the overlapping if a do covers number 5 (partly or full) +7,8,9 it is represented by istopoverlap()or1,4,7 it is represented by isleftoverlap()or9,6,3 it is represented by isrightoverlap()or1,2,3 it is represented by isbottomoverlap()now we get nearly all possible combinations because we can check for intersections on the corners, but there could do which covers more than that they are represented by ((relativesartpoint.x == 0 && relativesartpoint.y == 0) || (istopoverlap()) && isleftoverlap()) && isrightoverlap() && isbottomoverlap()if some of you is interested in what the current code looks likehere a link to so creating an intelligent documentpaginator ...",
    "present_kp": [],
    "absent_kp": [
      "c#",
      "wpf",
      "layout"
    ]
  },
  {
    "text": "reading environment variables of various types. i need to extract some data from the environment variables using go. this data can be string, boolean or integer, so i ended up writing three functions.package mainimport ( fmt os strconv)func getstrenv(key string) string { val := os.getenv(key) if val == { panic(fmt.sprintf(some error msg)) } return val}func getintenv(key string) int { val := getstrenv(key) ret, err := strconv.atoi(val) if err != nil { panic(fmt.sprintf(some error)) } return ret}func getboolenv(key string) bool { val := getstrenv(key) ret, err := strconv.parsebool(val) if err != nil { panic(fmt.sprintf(some error)) } return ret}which works, but in a language like python, i would just create one function getenv(key, type_var), which would go through various passes depending on the type_var provided. is there a way to produce similar result with go?",
    "present_kp": [
      "go"
    ],
    "absent_kp": []
  },
  {
    "text": "how to create a file with the name specified in ascii encoding?. i want to create a file that is called ascii 007, which is the bell symbol, which is not printable. i tried nano $'', but that just created a file called ?; cat ? print the test content, that i placed in the file.so how do i create a file, with a name set by the ascii encoding and not plainly spelled out?",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "filenames"
    ]
  },
  {
    "text": "find the binary gap of a number n. for example, number 9 has binary representation 1001 and contains a binary gap of length 2. the number 529 has binary representation <phone> and contains two binary gaps: one of length 4 and one of length 3. the number 20 has binary representation 10100 and contains one binary gap of length 1. the number 15 has binary representation 1111 and has no binary gaps.i'd like to know how this would be performance wise, and if there is a better way to do it.public int solution(int n) { int binarygap = 0; string binarystring = integer.tobinarystring(n); char[] characters = binarystring.tochararray(); int j = 0; character c; for (int i = 0; i < characters.length; i++) { c = characters[i]; if (c.equals('0')) { j += 1; } if (c.equals('1')) { if (j > binarygap ){ binarygap = j; } j = 0; } } system.out.println(binarygap); return binarygap;}",
    "present_kp": [
      "performance"
    ],
    "absent_kp": [
      "java",
      "beginner",
      "programming challenge"
    ]
  },
  {
    "text": "how to get columns from unsorted rows in pandas? (mallet). my data (the doc-topics output from a mallet topic model) has the following shape:0 000cbac90fcc47efad081a929d74ab4c 0 0.3571185904395461 19 0.3113396339935042 4 0.12325835735304397 10 0.10409710001928904 8 0.04929547912982593 1 0.026833654459159112 2 0.01605333272832067 6 0.0048677134975701405 11 0.0019476615596546681 17 0.001908921062167065 14 0.0016877826048433426 5 5.256520178505095e-4 12 2.6155079718746636e-4 15 2.1354275518902175e-4 16 1.4885824861864537e-4 18 1.0362646846573807e-4 3 9.802082006786611e-5 9 9.641623707017035e-5 13 9.348016118039801e-5 7 5.0625647445916464e-5 1 002d2e8fbf8f40399fb52c12fe6d79a1 2 0.4893657941273363 19 0.31683989601254264 5 0.14250187050440621 4 0.020578111489117222 8 0.012792452390528172 10 0.012232805681991418 11 9.110846196785881e-4 17 8.170410538631972e-4 12 6.349213666458032e-4 15 5.18380595356186e-4 0 4.750799583739948e-4 6 3.65757686209981e-4 16 3.613572723378424e-4 14 2.8022169390809563e-4 1 2.5184798205700335e-4 18 2.5155594892638147e-4 3 2.3794809156182638e-4 9 2.3405292457801712e-4 13 2.2692552394855585e-4 7 1.228950766326711e-4 2 0046e05d3731491da4d9bab51d6ea36a 16 0.652945776661391 8 0.07953971245258269 0 0.06617734607073089 19 0.059407148715209045 4 0.02302855863782211 5 0.019674895033989195 11 0.014047819199510685 17 0.01259778154009113 2 0.012346407436534609 10 0.012058449719318621 12 0.009789716972385079 15 0.0079927997057698 6 0.005639539660456337 14 0.004320678460350115 1 0.0038831902561877263 18 0.0038786874597068794 3 0.0036688708127993316 9 0.003608812064842682 13 0.0034989161965088794 7 0.001894892943813293 etc...each row (representing a document) has an index column, an id column, and 40 more columns that represent the 20 topics present.the shape i'm trying to get is one where each topic number is it's own column and rows contain just the index, id, and topic proportions, e.g.:i id 0 1 20 000cbac90fcc47efad081a929d74ab4c 0.3571185904395461 0.2346339935042 0.1884010001928904etc...it seems like this could be accomplished with pivots, but the topic numbers being out of order (sorted by relevance in rows) makes this a head scratcher...how would one accomplish this?",
    "present_kp": [
      "pandas",
      "topic model"
    ],
    "absent_kp": [
      "python",
      "nlp",
      "lda"
    ]
  },
  {
    "text": "best practice for defense agaist hotlinking and scraping images from your site. i'm trying to determine the best way to handle a few issues i've come up with on handling images for my site.background:a small site that houses movie information. i have an admin section to upload multiple movies images per movie.image files would be hosted on a cdn so access would pretty much be open.references to each image will be stored in the database.i would like to:1) make sure i can prevent hot-linking as much as possible2) have the filename some what obfuscated to prevent a scraper from just increment an id parameter in the url.so far, i'm using a random string generator to come up with the image names which i believe takes care of #2.looking for an answer to #1 and also any advice and best practices.",
    "present_kp": [],
    "absent_kp": [
      "web development",
      "asp.net"
    ]
  },
  {
    "text": "report/process only using the last entry made by the user in a google form. i have a form where students can enter choices: for instance the specialisation they want to pursue, and the semester when they will start that specialisation. an example entry form is here, but it has not much interest, other than add addition data to the example processing sheet. you can copy the sheet locally to edit it, and it will still pull the form data over. i decided not to use the option on the form to allow only one entry per student as students often change their mind, make a new entry several months later. they were told that only their last entry will be considered at a specific deadline.i wish to have some reporting in place that shows an overview of all choices, lists the students per specialisation etc... but only taking into account their last entry, and without deleting previous entries made. to look up the last entry for a specific user, it is easy using:query(importrange(1l3v0hin69avvcv-4hx7m39w6zsubzeak2l0jdulp0ny,form responses 1!a:e),select max(col1), col2, col3, col4 where col2 contains '&c1&' group by col2,col3,col4 order by max(col1) desc limit 1,0)the e-mail (or part of it would be stored in c1). the trick is the limit 1 clause at the end combined with the order by clause.but this no longer works when trying to filter for the whole cohort following a specialisation at a specific start date, or counting the amount of students per specialisation, etc. this is where i could use some help. maybe adding a column outdated and filling that in via an array formula could be an option, but i struggled with making that work on the original response spreadsheet.",
    "present_kp": [],
    "absent_kp": [
      "google spreadsheets",
      "google apps",
      "google forms"
    ]
  },
  {
    "text": "why dd takes too long?. i need to copy one disk to another. i tried with the command below and it takes nearly a day to copy 1 tb of disk. dd if=/dev/sda of=/dev/sdb i have tried the same on a unix system with the command below and it completes within a few hoursdd if=/dev/sda of=/dev/rdskwhat is the alternative i could use to copy from disk to disk as faster?",
    "present_kp": [
      "dd"
    ],
    "absent_kp": [
      "hard disk"
    ]
  },
  {
    "text": "trouble in script with spaces in filename. i've got a script that scp's a file from remote host back to local. sometimes the file names contain spaces. scp does not like spaces in its file names. for some reason my attempts at handling the spaces have not resulted in the correct scp path.code:path=/var/root/documents/myfile og-v1.2.3.pkgscp $path <email>/users/me/desktopresults incannot find directory: var/root/documents/myfilecannot find directory: og-v1.2.3.pkgenclosing path in quotes $path gives the same error.swapping the spaces for escaped spaces also is not working, although as far as i can tell it should:esc_path=${path/' '/'\\ '}although printing the escaped path shows that the edit worked:echo $esc_path> /var/root/documents/myfile\\ og-v1.2.3.pkg",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "shell",
      "scripting",
      "quoting",
      "escape characters"
    ]
  },
  {
    "text": "how to install freebsd 10 from usb hard drive?. i need to install freebsd 10 on an old pc with no cd drive but it has a usb port. i'm on a laptop running windows 8.1 and have downloaded the freebsd 10 dvd iso image. i have an external usb hard drive. i have the dvd iso image. how do i go about preparing the external hdd with the files so that i can boot and install from this external hdd? i tried unetbootin from windows but it does not recognize the external usb hdd.",
    "present_kp": [
      "freebsd"
    ],
    "absent_kp": [
      "system installation"
    ]
  },
  {
    "text": "explanations of responses to real graphic harm. i want to know answers to the following questions :why do i feel curious sometimes to check out sites of real accidents such as documenting reality or live leak ?why do i feel nauseous when i have seen a few of these events, such as videos / images of real motorcycle accidents ?i am confused that i feel both occasionally (every 3 months say) curious to see what really happens to people in these accidents as well as feel physically ill once i have seen that.i suppose this is somewhat similar to the reason people slow down to take a look at a motor vehicle accident while driving past on the highway.i guess what i am also interested in is -- how is it possible for people to feel turned on by this same content -- such as self harmers or psychopaths? is there a causal emotional chain that could be explained the reactions of such people as compared with the feeling of aversion ... or is such arousal just random and unexplainable?",
    "present_kp": [
      "emotion"
    ],
    "absent_kp": [
      "social cognition"
    ]
  },
  {
    "text": "desktop notifications for queue items - updated code. a while ago i took one of @simon's scripts and updated it to make it more geared towards normal users (no offense mods) and this question was created. but the link to the github is no longer correct and the code has changed quite a bit to get it to work on firefox and chrome (and opera and icedragon and safari).i would like to know if my code is following userscript and javascript standards and if there is anything that i can do to improve the efficiency of the code itself.here is the current next versionnotification.requestpermission();var key_next = 'nextreload';var delay = 120 * 1000; //120,000 milliseconds = 2 minutesvar currenttime = date.now ? date.now() : new date().gettime();var lasttime = gm_getvalue(key_next, 0);var nexttime = currenttime + delay;gm_setvalue(key_next, nexttime);var timediff = math.abs(lasttime - currenttime);settimeout(function(){ window.location.reload(); }, delay);var notificationtitle = (document.title.split(' - ')[1] + ' review queue').replace(' stack exchange', '.se');// a way to detect that the script is being executed because of an automatic script reload, not by the user.if (timediff <= delay * 2) { var reviewcount = 0; var reviewitems = document.getelementsbyclassname('dashboard-num'); for (var i = 0; i < reviewitems.length; i++){ if (reviewitems[i].parentnode.classname != 'dashboard-count dashboard-faded'){ reviewcount += parseint((reviewitems[i].getattribute(title)).replace(',', ''), 10); console.log(reviewitems[i]); } } console.log(reviewcount); if (reviewcount > 0) { var details = { body: reviewcount + ' review items', icon: '<url> } var n = new notification(notificationtitle, details); n.onclick = function(){ window.focus(); this.cancel(); } settimeout(n.close.bind(n), 100000); // magic number is time to notification disappear }}you can follow development or participate in development at github as well.review queue notifier",
    "present_kp": [
      "javascript",
      "userscript"
    ],
    "absent_kp": [
      "stackexchange"
    ]
  },
  {
    "text": "the size of output in circuit complexity. in circuit complexity we have one circuit for each input size. the size of the output is determined solely by the size of the input.so it seems to me that taken in its strict sense there are functions computable in $\\mathsf{p}$ over $\\{0,1\\}^*$ which are not computable in $\\mathsf{p/poly}$.this is partly caused by using $\\{0,1,b\\}$ in the turing machine modelwhile in circuit model we only have $\\{0,1\\}$.is there a nice standard way to deal with this issue that would work well for small complexity classes(e.g. it shouldn't change the complexity of computing and of inputs too much,so encoding/decoding inputs/outputs is not a good solution)?is there a simple modification of turing machine model or circuit model which would make them correspond without this issue?",
    "present_kp": [
      "circuit complexity"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "turing machines"
    ]
  },
  {
    "text": "does a c# event have to have an object type as its first parameter?. i have a tcpclient class. it has several clientevents. originally it followed the standard patternpublic delegate void clientevent(object sender, clienteventargs e);only tcpclient uses this event. but i am pretty determined to keep things as standard as possible (all event based things i've seen use object sender). however what i don't see the point of, is having to cast sender to tcpclient every time. private static void client_onreconnect(object sender, clienteventargs e) { tcpclient client = (tcpclient)sender; }is there any reason i shouldn't just usepublic delegate void clientevent(tcpclient client, clienteventargs e);as my event?",
    "present_kp": [
      "c#"
    ],
    "absent_kp": []
  },
  {
    "text": "if $\\log xy=\\log x+\\log y$ then why multiplication is harder than addition?. someone told me that the $\\log$ function was introduced to make the calculation easier. if we have to calculate $xy$, we can calculate instead $\\log x+\\log y$ since $\\log xy=\\log x+\\log y$. how this can make the calculation easier? maybe from a mathematician point of view but what about a computer scientist's point of view?if it makes the calcualtion easier then why people do not use it to simplify the complexity of the multiplication algorithms?from my own thinking, this transformation makes the calculation more difficult. how can we calculate the $\\log x$ and $\\exp x$ functions in a computer?am i right? any suggestions please? thank you for your time.",
    "present_kp": [
      "algorithms"
    ],
    "absent_kp": [
      "complexity theory",
      "reference request",
      "education"
    ]
  },
  {
    "text": "how to get a position of a specific image within another image?. i have many png screenshots with an identical piece of graphic in each of them. the piece has the same dimensions in all of the images.what command line program can i use to find the position of it in each of the files (fed to one by one)?",
    "present_kp": [
      "images"
    ],
    "absent_kp": [
      "scripting"
    ]
  },
  {
    "text": "right choice of accuracy metric or loss function. i am developing a predictive model in sports vertical. as the game will progress, my model will predict the winning probability of each team playing. the problem i am facing is to what metric would be appropriate to quantify accuracy for the model. what i have in mind to quantify accuracy is as follows :consider n matches for which my model predicts the winning probability of team a at time instance t1, t2 ... tn. for each match, i will quantify the loss as the hinge loss at that time. i.e. if probability greater than threshold and team_a actually won, then accurate. as the game progresses, model gets new info and i can expect the model performance to improve, so i thought about giving weights to loss function acc. to time of prediction also. i.e. if model predicts wrongly at later point of the game then it should be penalized heavily. but i think it can be better. any leads on the apt. loss function for this is highly appreciated.hoping to learn something great from the answers.",
    "present_kp": [
      "loss function"
    ],
    "absent_kp": [
      "machine learning",
      "deep learning"
    ]
  },
  {
    "text": "action queue system. i'm currently working on a jrpg style turn-based game and i read an article about that an action queue is necessary for these types of games, so i wrote one.it basically has 4 methods:.add (add an object to the queue).remove (remove an object from the queue, might be useful if some entity dies mid fight and shouldn't action if it's still in the queue).removefirst (remove the first object from the queue after it invoked its action function e.g attack, defend, spell etc.).reset (resets the whole queue to an empty array [], could be useful if the player kills the target and the battle ends, then the queue should also be emptied)the queue looks rather complex in code and the arrays i'm putting these in feel a bit awkward to access. generally the code feels poorly written and inefficient, which is why i'm asking for a code review.function keys(object) { return object.keys(object);}let queue = { attackqueue: [], add: function(object) { let propname = keys(object), array = [], outerarr = []; for (let i = 0; i < propname.length; i++) { if (propname[i] === name) { outerarr.push(object[propname[i]]); } else if (propname[i] === command || propname[i] === hitchance) { array.push([propname[i], object[propname[i]]]); } } outerarr.push(array); queue.attackqueue.push(outerarr); }, remove: function(object) { for (let i = 0; i < queue.attackqueue.length; i++) { if (object.name === queue.attackqueue[i][0]) { queue.attackqueue.splice([i], 1); } } }, sort: function() { queue.attackqueue.sort(function(a, b) { if (a[1][0][1] < b[1][0][1]) { return 1; } }) }, removefirst: function() { queue.attackqueue.shift(); }, reset: function() { queue.attackqueue = []; }}function executeround() { let length = queue.attackqueue.length, arr = queue.attackqueue; while (queue.attackqueue.length !== 0) { window[arr[0][1][1][1].tolowercase()](); // i used tolowercase just in case the commands would have been wrote in uppercase console.log(removed entity + arr[0][0] + !); queue.removefirst(); }}function attack() { console.log(attack);}function defend() { console.log(defend);}// examplelet player1 = { name: player1, hitchance: 9000, command: attack}// add player1 to the queuequeue.add(player1);// execute function executeroundexecuteround();console.log(queue.attackqueue) // --> removed entitiy player1 !",
    "present_kp": [
      "game"
    ],
    "absent_kp": [
      "javascript"
    ]
  },
  {
    "text": "example string class in c. i wrote this small example piece of oop being implemented in pure c. i wanted it to be reviewed for the following points:portabilityperformanceand especiallyusabilityhow does it lookimplementation: typedef char xcfstring;struct xcfstringstatic { void *(*initwithcstring)(const char *);};struct xcfstringclass { void (*release)(void); size_t length; char *value;};// pointer to current classxcfstring **xcfstringctx = null;// release methodvoid xcfstring__release(void){ assert(xcfstringctx != null); xcfstring *ctx = *xcfstringctx; free(((char *)ctx) - sizeof(struct xcfstringclass));}// init methodvoid *xcfstring__initwithcstring(const char *str){ size_t str_len = strlen(str); struct xcfstringclass *data = malloc(sizeof(* data) + str_len + 1); if (!data) return null; char *str_val = ((char *)data) + sizeof(* data); memcpy(str_val, str, str_len + 1); data->length = str_len; data->value = str_val; data->release = xcfstring__release; return data->value;}struct xcfstringstatic xcfstringstatic = {.initwithcstring = xcfstring__initwithcstring};#define priv_getmacroname1(_0, _1, macroname, ...) macroname#define getmacroname1(macroname, args...) priv_getmacroname1(_0, ##args, macroname ## _1, macroname ## _0)(args)#define xcfstring_0() (xcfstringstatic)#define xcfstring_1(_var) (xcfstringctx=&(_var), ((struct xcfstringclass *)(((char *)_var) - sizeof(struct xcfstringclass))))// switch between xcfstring_0 and xcfstring_1, gnuc only#define xcfstring(args...) getmacroname1(xcfstring, ##args)test code for main.cint main(int argc, const char **argv){ // pointer to our string class xcfstring *string = null; // initialize string with hallo welt! string = xcfstring().initwithcstring(hallo welt!); // print it as if it were a normal string fprintf(stderr, string : %s , string); fprintf(stderr, length : %zu , strlen(string)); // get the properties from the string fprintf(stderr, str.value : %s , xcfstring(string)->value); fprintf(stderr, str.length : %zu , xcfstring(string)->length); // release the string xcfstring(string)->release();}",
    "present_kp": [
      "c",
      "strings"
    ],
    "absent_kp": [
      "object oriented"
    ]
  },
  {
    "text": "syncevolution: comparison was impossible and no carddav sync anymore. i have an ubuntu phone and it use syncevolution as backend for the contacts. i use command lines to have my carddav contacts on my phone. but since i switched from self signed certificate to letsencrypt (related or not), i have tons of errors.$ syncevolution owncloud contacts[warning] owncloud: ignoring username , it is not needed[info] @default/9frfrenchholiday: inactive[info] @default/9rd2q8ps5e2r48skvidunfkoms8: inactive[info] @default/addressbook: inactive[info] @default/calendar: inactive[info] @default/memo: inactive[info] @default/todo: inactive[warning] owncloud: ignoring username , it is not needed[info @owncloud] target side of local sync ready[info @owncloud] @owncloud/addressbook: inactive[info @owncloud] @owncloud/calendar: inactive[info @owncloud] @owncloud/memo: inactive[info @owncloud] @owncloud/todo: inactive[info @owncloud] @owncloud/contacts: using configured database=[censored!][info @owncloud] @owncloud/contacts: starting slow sync, two-way (peer is server)[info @owncloud] @owncloud/contacts: slow sync done unsuccessfully[error @owncloud] @owncloud/contacts: local, status 20048[error @owncloud] error code from synthesis engine local, status 20048synchronization failed, see /home/phablet/.cache/syncevolution/target_+config@owncloud-2017-04-19-10-34-a/syncevolution-log.html for details.changes applied during synchronization (@owncloud):+---------------|-----------------------|-----------------------|-con-+| | @owncloud | @default | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 || slow, 0 kb sent by client, 0 kb received || unexpected slow sync (local, status 22000) |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start wed apr 19 10:34:14 2017, duration 0:01min || unexpected slow sync (local, status 22000) |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+first error encountered: local, status 20048doing a slow synchronization may lead to duplicated items orlost data when the server merges items incorrectly. choosinga different synchronization mode may be the better alternative.restart synchronization of affected source(s) with one of thefollowing sync modes to recover from this problem: slow, refresh-from-server, refresh-from-clientanalyzing the current state: syncevolution --status target-config@owncloud contactsrunning with one of the three modes: syncevolution --sync [slow|refresh-from-remote|refresh-from-local] target-config@owncloud contacts[error] error code from syncevolution unexpected slow sync (local, status 22000): failure on target side @owncloud of local sync[info] @default/contacts: inactive[error] @default/contacts: aborted on behalf of user (local, status 20017)[info] creating complete data backup after sync (enabled with dumpdata and needed for printchanges)synchronization failed, see /home/phablet/.cache/syncevolution/owncloud-2017-04-19-10-34/syncevolution-log.html for details.changes applied during synchronization:+---------------|-----------------------|-----------------------|-con-+| | @default | @owncloud | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 || unexpected slow sync (local, status 22000) |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start wed apr 19 10:34:13 2017, duration 0:02min || unexpected slow sync (local, status 22000) |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+first error encountered: local, status 20048doing a slow synchronization may lead to duplicated items orlost data when the server merges items incorrectly. choosinga different synchronization mode may be the better alternative.so i decided to try some things i don't remember exactly (like forcing sync with refresh from local/remote) and changed the end of previous log by:first error encountered: local, status 20048doing a slow synchronization may lead to duplicated items orlost data when the server merges items incorrectly. choosinga different synchronization mode may be the better alternative.restart synchronization of affected source(s) with one of thefollowing sync modes to recover from this problem: slow, refresh-from-server, refresh-from-clientanalyzing the current state: syncevolution --status owncloud contactsrunning with one of the three modes: syncevolution --sync [slow|refresh-from-remote|refresh-from-local] owncloud contactsthen:data modified @default during synchronization:*** @default/calendar ***comparison was impossible.since this step, i'm not able anymore to delete contact from my phone and make it sync on the server (to delete the contact on the server itself), instead the contact is just cleared (any information disappear but the contact is still here and keep firstname and lastname). i can sync contact created on the server on my phone and send contacts created on my phone on the server.it seems the backup database is corrupted but i'm not able to reset completely my config. i just wanted to start by zero but i can't find any way to do this. :'(phablet@ubuntu-phablet:~$ syncevolution --print-sessions owncloud/home/phablet/.cache/syncevolution/owncloud-2017-04-20-11-04-b+---------------|-----------------------|-----------------------|-con-+| | local | remote | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 || two-way, 0 kb sent by client, 0 kb received || item(s) in database backup: 2 before sync, 2 after it |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start thu apr 20 11:04:51 2017, duration 0:05min || synchronization completed successfully |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+/home/phablet/.cache/syncevolution/owncloud-2017-04-20-11-05+---------------|-----------------------|-----------------------|-con-+| | local | remote | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 || two-way, 0 kb sent by client, 0 kb received || item(s) in database backup: 2 before sync, 2 after it |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start thu apr 20 11:05:24 2017, duration 0:05min || synchronization completed successfully |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----++phablet@ubuntu-phablet:~$ syncevolution --restore /home/phablet/.cache/syncevolution/owncloud-2017-04-20-11-05 --before owncloud contacts[info] 9frfrenchholiday: inactive[info] 9rd2q8ps5e2r48skvidunfkoms8: inactive[info] addressbook: inactive[info] calendar: inactive[info] memo: inactive[info] todo: inactive[info] contacts: restore from backupdata changes to be applied locally during restore:*** contacts ***comparison was impossible.[info] contacts: started[info] contacts: restore done successfully[info] item changes that were applied locally during restore:[info] +---------------------------------------|-----------------------------+[info] | | local |[info] | source | new | mod | del | err |total|[info] +---------------------------------------+-----+-----+-----+-----+-----+[info] | contacts | 0 | 0 | 0 | 0 | 2 |[info] +---------------------------------------+-----+-----+-----+-----+-----+[info] the same incremental changes will be applied to the server during the next sync.[info] use -sync refresh-from-client to replace the complete data on the server.+phablet@ubuntu-phablet:~$ syncevolution --sync=refresh-from-client owncloud contacts[warning] owncloud: ignoring username , it is not needed[info] @default/9frfrenchholiday: inactive[info] @default/9rd2q8ps5e2r48skvidunfkoms8: inactive[info] @default/addressbook: inactive[info] @default/calendar: inactive[info] @default/memo: inactive[info] @default/todo: inactive[warning] owncloud: ignoring username , it is not needed[info @owncloud] target side of local sync ready[info @owncloud] @owncloud/addressbook: inactive[info @owncloud] @owncloud/calendar: inactive[info @owncloud] @owncloud/memo: inactive[info @owncloud] @owncloud/todo: inactive[info @owncloud] @owncloud/contacts: using configured database=[censored!][info @owncloud] @owncloud/contacts: starting first time sync from client (peer is server)[info @owncloud] @owncloud/contacts: sent 2/2[info] @default/contacts: starting slow sync from client (peer is client)[info] creating complete data backup of datastore contacts before sync (enabled with dumpdata and needed for printchanges)@default data changes to be applied during synchronization:*** @default/contacts ***comparison was impossible.[info] @default/contacts: deleting test estse[info] @default/contacts: deleting gvv[info] @default/contacts: deleting 2/2[info] @default/contacts: started[info] @default/contacts: adding test estse[info] @default/contacts: adding gvv[info] @default/contacts: received 2[info @owncloud] @owncloud/contacts: started[info] @default/contacts: slow sync done successfully[info @owncloud] @owncloud/contacts: first time sync done successfullysynchronization successful.changes applied during synchronization (@owncloud):+---------------|-----------------------|-----------------------|-con-+| | @owncloud | @default | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 || refresh-from-local, 0 kb sent by client, 0 kb received |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start thu apr 20 11:24:17 2017, duration 0:04min || synchronization completed successfully |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+[info] creating complete data backup after sync (enabled with dumpdata and needed for printchanges)synchronization successful.changes applied during synchronization:+---------------|-----------------------|-----------------------|-con-+| | @default | @owncloud | fli || source | new | mod | del | err | new | mod | del | err | cts |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| contacts | 2 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 || refresh-from-remote, 0 kb sent by client, 0 kb received || item(s) in database backup: 2 before sync, 2 after it |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+| start thu apr 20 11:24:17 2017, duration 0:04min || synchronization completed successfully |+---------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+data modified @default during synchronization:*** @default/contacts ***comparison was impossible.",
    "present_kp": [
      "synchronization"
    ],
    "absent_kp": []
  },
  {
    "text": "how do i enable port forwarding but only for some ips and block others?. i have a device running linux and currently all of my network traffic is going through it before going to my wifi router. i used arp spoofing to get between my devices and my router and used the following command to enable port forwarding:echo 1 > /proc/sys/net/ipv4/ip_forwardas an example, how could i allow packets from 192.168.0.2 and block packets from 192.168.0.3?",
    "present_kp": [
      "linux",
      "ip",
      "port forwarding"
    ],
    "absent_kp": [
      "networking"
    ]
  },
  {
    "text": "can a linux user have multiple primary user groups?. how many primary groups can an individual linux user have? if they can have more than one, how does one go about assigning multiple primary groups to a user? if it's just one, what's the cause?",
    "present_kp": [
      "linux",
      "group"
    ],
    "absent_kp": [
      "accounts"
    ]
  },
  {
    "text": "angularjs directive architecture: where to put parameters?. i'm using a charts-plugin (morris.js) in my angularjs application. i'm building a directive for each type of chart.the plugin is called like this:new morris.line({ // id of the element in which to draw the chart. element: 'myfirstchart', // chart data records -- each entry in this array corresponds to a point on // the chart. data: [ { year: '2008', value: 20 }, { year: '2009', value: 10 }, { year: '2010', value: 5 }, { year: '2011', value: 5 }, { year: '2012', value: 20 } ], // the name of the data record attribute that contains x-values. xkey: 'year', // a list of names of data record attributes that contain y-values. ykeys: ['value'], // labels for the ykeys -- will be displayed when you hover over the // chart. labels: ['value']});the first step is just to include this code into my link-function:angular.module('app') .directive('donutchart', function () { return { link: function (scope, element, attrs) { new morris.bar({ element: element[0].id, data: [ { age: '20', value: 20 }, { age: '25', value: 10 }, { age: '30', value: 5 }, { age: '40', value: 5 }, { age: '50', value: 20 } ], xkey: 'age', ykeys: ['amount'], labels: ['views'] }); } };});but i don't like it to manipulate the directive when i want to change the data. so i save every attribute inside the scope inside the controller. but, is this the 'right' way to do it? or should i use a config variable to store very attribute? like:var config = { bar_labels: ['views'] }and then inside the controller:$scope.bar_labels = bar_labels",
    "present_kp": [
      "architecture",
      "angularjs"
    ],
    "absent_kp": []
  },
  {
    "text": "what exactly is posix?. i see posix mentioned often and everywhere, and i had assumed it to be the baseline unix standard.. until i noticed the following excerpt on a wikipedia page: the open group the open group is most famous as the certifying body for the unix trademark, and its publication of the single unix specification technical standard, which extends the posix standards and is the official definition of a unix system. if the official definition of a unix system is an extension of posix, then what exactly is posix? ,,, it surely seems to be a touchstone of the unix world, but i don't know how it fits into the overall picture.",
    "present_kp": [
      "posix",
      "standard"
    ],
    "absent_kp": []
  },
  {
    "text": "why are complexity notations called asymptotic?. why do we use the term asymptotic in complexity. although i know what an asymptote is, but what is an asymptote doing here?",
    "present_kp": [
      "notation"
    ],
    "absent_kp": [
      "complexity theory",
      "algorithm analysis",
      "terminology",
      "landau notation"
    ]
  },
  {
    "text": "parsing json using jsoncpp. i left questions in the comments strategically, since i think it's easier to answer questions this way.basically what my small class does is abstracts away functionality that was originally in a function.this class reads json form a file and creates an object which i can use to traverse the json. i understand that if something can be made into a function it shouldn't be made into a class, but i need to practice.below i outlined things i'm looking for. choose one or choose all.looking for:did i use references & correctly#include header files correctlya way to initialize object like so: root rate(test.json, [query][results][rate]) (syntax can be different)best practice advicenot looking for (at least not yet):exceptions and error handlingadvice form c programmersroot.h#ifndef root_h#define root_h// should header files always be included in root.h as opposed to root.cpp?#include <fstream>#include <string> // seems like i do not need to include this string container, why? //is it because json/json.h contains it?#include json/json.h // would i ever create a class with a dependency like this one? // jsoncpp.sourceforge.net/annotated.htmlclass root{private: std::ifstream m_json;public: json::value m_root; json::value m_query; root(const std::string&); ~root();};#endif // root_hroot.cpp#include root.hroot::root(const std::string & filename) : m_json(filename, std::ifstream::binary)// is std::ifstream::binary ok to put it in here like this ^?// it's working, but would that be good practice?{ m_json >> m_root; m_json.close(); // do i need .close() here?}root::~root(){}main.cpp#include <iostream>#include root.hint main(){ root rate(test.json); rate.m_query = rate.m_root[query][items]; // is it ok to assign member to a member like so, // as opposed to just a variable? // how can i instantiate my object like the line below? // root rate(test.json, [query][results][rate]); // syntax does not have to match precisely? for(const auto & it : rate.m_query) { std::cout << it << std::endl; }}test.json{ query: { count: 3, items: [ {item: 4}, {item: 3}, {item: 2} ] }",
    "present_kp": [
      "parsing",
      "json"
    ],
    "absent_kp": [
      "c++",
      "c++11"
    ]
  },
  {
    "text": "using messaging queue as async mysql writes. i read some articles about developers who takes rabbitmq and produce from php messages to write to mysql.they do this to make the page speedup and not wait for mysql to return an answer. so in my case, since i want to write to mysql every page request in my site, and yet php does not have thread pooling, this i assume can make the page render much faster.i have 2 questions: how does that makes mysql more free? does it? how can this architecture scale? (in my speciphic use case as described above.)",
    "present_kp": [
      "php",
      "mysql"
    ],
    "absent_kp": [
      "message queue"
    ]
  },
  {
    "text": "restore a disk from a snapshot in xen 4.6. i created a snapshot with lvcreate -n snap01.vm01 -l 5g -s vg0/vm01.eclabs.denow i did some stuff on my disk i don't want to keep and want to revert it to the snapshot point.how do i restore the snapshot?i tried to copy the snapshot with dd like:dd if=/dev/vg0/snap01.vm01 | pv | dd of=/dev/vg0/vm01.eclabs.de-restorebut although the file is only 5gb the dd process continues to copy things for hours. is this sthe correct way?",
    "present_kp": [
      "dd",
      "xen",
      "snapshot"
    ],
    "absent_kp": []
  },
  {
    "text": "how to improve my game?. i'm building a game. it is going well at the moment, but i'm not quite happy with my code because is not working the way i want to, due my low knowledge of c#. i was wondering if you guys could help me out to improve it by giving me some ideas and tips.this is how i'm checking if the user has completed the levels.public partial class mainmenu : phoneapplicationpage{public mainmenu(){ initializecomponent(); readstar1(); readstar2();}private void btnbatland_click(object sender, routedeventargs e){ navigationservice.navigate(new uri(/1star/mainpage.xaml, urikind.relative));}private async task readstar1(){ storagefolder local = windows.storage.applicationdata.current.localfolder; if (local != null) { var datafolder = await local.getfolderasync(level); var file = await datafolder.openstreamforreadasync(star1.txt); string readtxt; using (streamreader streamreader = new streamreader(file)) { readtxt = streamreader.readtoend(); } if (readtxt == star1) star2_lock.visibility = visibility.collapsed; star1_1.visibility = visibility.collapsed; }}private async task readstar2(){ storagefolder local = windows.storage.applicationdata.current.localfolder; if (local != null) { var datafolder = await local.getfolderasync(level); var file = await datafolder.openstreamforreadasync(star2.txt); string readtxt; using (streamreader streamreader = new streamreader(file)) { readtxt = streamreader.readtoend(); } if (readtxt == star2) star3_lock.visibility = visibility.collapsed; }}sometimes it takes 1-4 seconds to load the mainmenu, then after 1-3 to load the function readstar1() and readstar2(). what could i do to improve its speed, so that the users don't even notice it has changed?",
    "present_kp": [
      "c#",
      "game"
    ],
    "absent_kp": []
  },
  {
    "text": "add multiple subdirectories under the same parent directory to path. i have installed some tools and put it under $home/tools/ and each tool has its own /bin directory that contains the executable program. i now have the path to each individual /bin in my $home/.bashrc file like this:export path=$path:$home/tools/tool1/binexport path=$path:$home/tools/tool2/bin...i'm wondering if it's ok to write the following for all the tools?export path=$path:$home/toolsif it doesn't work, what is the best way to do this?",
    "present_kp": [
      "path"
    ],
    "absent_kp": []
  },
  {
    "text": "why do .net books talk about stack vs heap memory allocation?. it seems like every .net book talks about value types vs reference types and makes it a point to (often incorrectly) state where each type is stored - the heap or the stack. usually it's in the first few chapters and presented as some all-important fact. i think it's even covered on certification exams. why does stack vs heap even matter to (beginner) .net developers? you allocate stuff and it just works, right?",
    "present_kp": [
      ".net"
    ],
    "absent_kp": []
  },
  {
    "text": "how to get sound working in chroot(linux on android). i have fedora 21 kde running on sony xperia tablet z and it seems my device sound card and m-audio(m-track) usb sound card is detected.but yet no audio output. what is best way to solve this issue?",
    "present_kp": [
      "fedora",
      "audio",
      "kde",
      "android"
    ],
    "absent_kp": []
  },
  {
    "text": "good resources to learn loopy belief propagation. what are some of the good references to understand loopy belief propagation and the need for it? i am looking for both theory and applications (for instance in coding/information and learning theory).",
    "present_kp": [],
    "absent_kp": [
      "reference request",
      "it.information theory"
    ]
  },
  {
    "text": "how do i extract a copy of an unknown firmware from a hardware device?. appreciate it's a broad question, but despite days of googling i haven't found straight forward explanation of the general principle of how to capture or copy an unkown firmware from a piece of hardware. i gather once you have it you can begin to use various tools to analyse it, but what i want to understand is how to get it in the first place. from what i understand you need to connect to it via a jtag or uart connection , after that i'm a bit lost.",
    "present_kp": [
      "hardware",
      "firmware"
    ],
    "absent_kp": []
  },
  {
    "text": "misunderstanding the baker-gill-solovay oracle and obtaining $logspace^a=pspace^a$. baker, gill and solovay [1] gave an oracle $a$ relative to which $p^a=pspace^a$. the oracle is the very simple $pspace^a$-complete language$$a = \\{\\langle m, x, 1^n angle | m^a ext{ accepts } x ext{ using }<n ext{ tape slots} \\}.$$(this inductive definition of $a$ is sound because no machine can query beyond its means and ask $a$ whether he himself will accept his input string, because he would have to query $a$ and write $1^n$ on the oracle tape. if he is still writing, then clearly he has not accepted, and so $a$ says no.)the proof that $p^a=pspace^a$ is likewise simple: suppose that $l\\in pspace^a$. then a $p(n)$-space machine $m$ accepts $l$. given an input $x$, a $p^a$-machine $t$ for $l$ is: write $\\langle m, x, 1^{p(|x|)} angle$ on the oracle tape, query $a$, and accept iff $a$ says yes. so $pspace^a\\subseteq p^a \\quad\\square$but in fact $t$ is not only a $p^a$-machine, $t$ is even a $logspace^a$-machine! hence $pspace^a\\subseteq logspace^a$. but the space hierarchy theorem says this cannot be the case. bgs even remark that the reduction $t$ performs can be performed in logarithmic space, but they do not use that fact to come to my conclusion.clearly i have made a mistake somewhere. where?(one response might be that while a $pspace$ machine can use only polynomially much tape for its work, it can write exponentially long queries to the oracle. denote by $pspace^{a[poly]}$ the class of languages solvable by a $pspace$-machine which makes only polynomially long queries to $a$. then the space hierarchy theorem for $logspace^a\\subsetneq pspace^{a[poly]}$ goes through as usual)[1] baker, theodore, john gill, and robert solovay. relativizations of the p=?np question. siam journal on computing 4.4 (1975): 431-442.",
    "present_kp": [
      "relativization"
    ],
    "absent_kp": [
      "complexity theory",
      "complexity classes",
      "space complexity",
      "oracle machines"
    ]
  },
  {
    "text": "boundary conditions for the advection equation discretized by a finite difference method. i am trying to find some resources to help explain how to choose boundary conditions when using finite difference methods to solve pdes.the books and notes which i currently have access to all say similar things:the general rules governing stability in the presence of boundaries are far too complicated for an introductory text; they require sophisticated mathematical machinery(a. iserles a first course in the numerical analysis of differential equations)for example, when trying to implement the 2-step leapfrog method for the advection equation:$u_i^{n+1} = u_i^{n-1} + \\mu (u_{i+1}^n - u_{i-1}^n)$using matlabm = 100; n = 100;mu = 0.5;c = [mu 0 -mu];f = @(x)(exp(-100*(x-0.5).^2));u = zeros (m, n);x = 1/(m+1) * (1:m);u(:,1) = f(x);u(:,2) = f(x + mu/(m+1));for i = 3:n hold off; u(:,i) = conv(u(:,i-1),c,'same') + u(:,i-2); plot(x, u(:,i)); axis( [ 0 1 0 2] ) drawnow;endthe solution behaves nicely until it reaches the boundary, when it very suddenly starts behaving badly.where can i learn how to handle boundary conditions like this?",
    "present_kp": [
      "pde",
      "finite difference",
      "boundary conditions",
      "advection"
    ],
    "absent_kp": []
  },
  {
    "text": "complexity of optimization over unitary group. what is the computational complexity of optimizing various functions over the unitary group $\\mathcal{u}(n)$? a typical task, arising often in quantum information theory, would be maximizing a quantity of type $\\mathrm{tr}aubu^{\\dagger}$ (or higher order polynomials in $u$) over all unitary matrices $u$. is this type of optimization efficiently (perhaps approximately) computable, or is it np-hard? (maybe this is well known, but i've been unable to find any general references)",
    "present_kp": [
      "optimization",
      "quantum information"
    ],
    "absent_kp": [
      "cc.complexity theory",
      "reference request"
    ]
  },
  {
    "text": "confusion regarding generating self signed certificate for application portal developed using liferay. we have a application portal developed using liferay bundled with tomcat. there are two application servers running liferay and we use httpd as a front-end which forwards requests to application server using load balancing . for load balancing in apache httpd , we are using mod_proxy_balancer .now , there is a requirement for us to enable ssl for the application portal . initially my plan is to try with self signed certificate . my confusion is whether i need to generate certificate for httpd or tomcat . since httpd does not serve any content and just forwards request , if i generate self signed certificate for httpd , only the homepage of application portal will be ssl enabled , rest of the webpages including sign in will not be using ssl. in that case i can generate certificate for tomcat so that all webpages are served using ssl. kindly suggest how to proceed.",
    "present_kp": [
      "apache httpd",
      "tomcat",
      "liferay"
    ],
    "absent_kp": [
      "rhel",
      "certificates"
    ]
  },
  {
    "text": "calculating tangential electric field intensity on the boundary. i have an object with surface charge $\\sigma$ for which i want to caclulate tangential electric field which would correspond to mathematical formulation:$$ec{e}(ec{x}) = abla_x \\int rac{\\sigma_y}{|ec{x} - ec{y}|} ds_y$$where afterwards normal component $ec{n} (ec{e} \\cdot ec{n})$ is substracted. for now i have tried to put this surface charge on surface mesh nodes and then transforming the integral to summations (skipping singularity) assuming that integral value on triangle is average of it on nodes. in this way my calculation totally fails.as looking why it does not work i started to suspect that higly singular kernel in the integral. to overcome it i look on some different ways:interpolating the charge density piecwise linearly and then doing the integrationpush the charges inside the suface about a size of mesh trianglewhat other options are available and which do you recommend? also would it help if i calculate potential either of theese methods and afterwards taking derivative of it?",
    "present_kp": [],
    "absent_kp": [
      "electromagnetism"
    ]
  },
  {
    "text": "generic sudoku solver might have too many iterations. i'm trying to implement a generic sudoku solver (with n x n puzzles). the puzzle itself is contained in the class feld with:typedef size_t point;class feld { public: // containing all the possible values in binary, eg: 7 means this could be 0,1,2 std::vector<point> pos; point l0; // length of the vector pos (n^2 for a nxn puzzle) point l1; // sqrt(l0) point l2; // sqrt(l1) point l12; // l1*l2 ...}one of the functions tries to find a box-line interaction. this is done here (entry point is the function m3):bool m3core(feld &feld, point viv, const std::function<point (point,point)> &fun, const point ignorer,const std::function<point (point)> &offr,const point ignorec,const std::function<point (point)> &offc) { //reduce access const point l2 = feld.l2; // remove the unwanted values for (point i = 0; i < l2; i++) { // this is part of the intersection if (i == ignorer) { continue; } for (point ii = 0, off = offr(i); ii < l2; ii++) { viv ^= viv & feld.pos[fun(off,ii)]; } } // we are left with no values to compare if (!viv) { return 0; } // compare bool change = 0; for (point i = 0; i < l2; i++) { // this is part of the intersection if (i == ignorec) { continue; } for (point ii = 0, off = offc(i); ii < l2; ii++) { if (viv & feld.pos[fun(off,ii)]) { #ifndef ndebug m3counter++; printf(found m3 ); #endif change = 1; feld.pos[fun(off,ii)] &= ~viv; } } } return change;}bool m3(feld &feld) { //reduce access const point l1 = feld.l1; const point l2 = feld.l2; const point l12 = feld.l12; //col & box for (point boxrow = 0; boxrow < l2; boxrow++) { for (point boxcol = 0; boxcol < l2; boxcol++) { for (point inbox = 0,boxoff = boxrow*l12 + boxcol*l2 ; inbox < l2; inbox++) { // add the possibilities of the horizontal intersection point vivver = 0; point vivhor = 0; for (point i = 0, offhor = boxoff + inbox*l1, offver = boxoff + inbox; i < l2; i++) { vivhor |= feld.pos[offhor + i]; vivver |= feld.pos[offver + i*l1]; } // define lambdas - this are used to calculate the coordinates to compare box - line auto offhorbox = [=] (const point i) { return i*l1 + boxoff; }; auto offverbox = [=] (const point i) { return boxoff + i; }; auto offhorline = [=] (const point i) { return i*l2 + inbox*l1 + boxrow*l12; }; auto offverline = [=] (const point i) { return i*l12 + inbox + boxcol*l2; }; auto funhor = [=] (const point off,const point ii) { return off + ii; }; auto funver = [=] (const point off,const point ii) { return off + ii*l1; }; // run the core code if (m3core(feld,vivhor,funhor,inbox,offhorbox,boxcol,offhorline) || m3core(feld,vivhor,funhor,boxcol,offhorline,inbox,offhorbox) || m3core(feld,vivver,funver,inbox,offverbox,boxrow,offverline) || m3core(feld,vivver,funver,boxrow,offverline,inbox,offverbox)) { return 1; } } } } return 0;}this does work, but the only problem is that it is quite slow.i tried to embrace functional programming to decrease dry, but maybe i've overdone it. i would be happy to receive any suggestion to improve performance and also readability since this certainly could also be improved.since it was asked, here is the file where this function is used. it can be build with make final (or one of the other recipes. but i have to warn you that the code is poorly commented. i do not expect anybody to go trough my gibberish, this is just to give some background and a working example.",
    "present_kp": [
      "performance",
      "sudoku"
    ],
    "absent_kp": [
      "c++"
    ]
  },
  {
    "text": "simple generic linq expression generation method. here is my generic method for creating linq expression based on field name of a type, operator (as enumerations of operators generated from xsd) and value of field private expression<func<t, bool>> getcriteriapredicate<t>(string fieldname, operatorref selectedoperator, string value) { propertydescriptor prop = typedescriptor.getproperties(typeof(goodsworksservice)).find(fieldname, true); if (prop != null) { //value as object object fieldvalue = null; //guid if (prop.propertytype == typeof(guid?)) { fieldvalue = new guid(value) as guid?; } //integer if (prop.propertytype == typeof(int?) || prop.propertytype == typeof(int)) { int intvalue; if (int32.tryparse(value, out intvalue)) { fieldvalue = intvalue; } } //datetime if (prop.propertytype == typeof(datetime?) || prop.propertytype == typeof(datetime)) { datetime datetimevalue; if (datetime.tryparse(value, out datetimevalue)) { fieldvalue = datetimevalue; } } //string if (prop.propertytype == typeof(string)) { fieldvalue = value; } var parameter = expression.parameter(typeof(t)); switch (selectedoperator) { // = case operatorref.item: { var body = expression.equal(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // != case operatorref.item1: // <> case operatorref.item2: { var body = expression.notequal(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // < case operatorref.item3: { var body = expression.lessthan(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // <= case operatorref.item4: { var body = expression.lessthanorequal(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // > case operatorref.item5: { var body = expression.greaterthan(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // >= case operatorref.item6: { var body = expression.greaterthanorequal(expression.property(parameter, prop.name), expression.constant(fieldvalue)); return expression.lambda<func<t, bool>>(body, parameter); } //by containing string in field case operatorref.like: { methodinfo contains = typeof(string).getmethod(contains); var body = expression.call(expression.property(parameter, prop.name), contains, expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } // - = default: { var body = expression.equal(expression.property(parameter, prop.name), expression.constant(fieldvalue, prop.propertytype)); return expression.lambda<func<t, bool>>(body, parameter); } } } return null; }",
    "present_kp": [
      "linq"
    ],
    "absent_kp": [
      "c#"
    ]
  },
  {
    "text": "how to run multiple ssh commands parallel and store outputs into variables. i have tried to write a shell script which logins in multiple hosts via ssh, execute some commands, and print execution summary. so far, i have written a script which works in sequential way. but it's slow, i want to rewrite it in a parallel way. i know i can use & to run multiple ssh commands parallel, and use command substitution to store subshell output into variable. but i cannot combine them correctly.so far, i came out these code. but it still runs in sequential way.#!/bin/bashhosts=('host-1' 'host-2' 'host-3')cmd='sleep $[ (( $random % 20 ) + 1) /10 ]s && echo hello world'i=0for host in ${hosts[@]}; do var1=$(ssh $host $cmd &) echo i = $i outputs[i]=$var1 ((i++))doneecho 'wait'waitecho ${outputs[@]",
    "present_kp": [
      "shell"
    ],
    "absent_kp": []
  },
  {
    "text": "intermittent silent failures when receiving email. ive had a company host my website and email for the last six months or so and im having intermittent and silent failures where emails sent to me are not received. the sender never receives a delivery notification failure message.this has happened on multiple domains (@gmail.com, @microsoft.com)ive experienced it happening first hand when i sent a mail to myselffrom another account but i was unable to reproduce the error.its very rare (one in every 300 emails or so)the mails are not routed to my junk folder :)obviously im worried about the effect this has on my business but what can i do? i dont believe i have enough information to diagnose the problem (neither does my hosting company when i presented them with the same information) should i switch to another host?",
    "present_kp": [
      "email"
    ],
    "absent_kp": [
      "web hosting"
    ]
  },
  {
    "text": "creating a specific chrome window and use it as drop-down search window. i am using a simple script runs as toggle.sh process1 which toggles visibility of process1 if it exists and if it doesn't exist then it launches process1. it is really simple but useful. i use it for several applications such as terminal, kate, nautilus and lyx. (each works like a drop down terminal with an assigned shortcut in gnome) however i need a more sophisticated way to achieve this with a specific chrome window. this is because the restriction of this script is there must be one-to-one correspondence between process-name and window-id. any ideas how i can achieve this ? edit :to be more clear i want to toggle visibility of a window of chrome (for search purposes) and if it doesn't exists then create that window. one of the below might solve it but i couldn't find a way to do it : - run an instance of chrome with a different process name and single-process option. (creating a symbolic link to chrome and naming it as dropdown-chrome-4-search wont work) for creation: create a chrome new-window change its title to say chrome-4-dropdown. for toggling: in the script get the id of the window with title chrome-4-dropdown-purposes to toggle. (don't know how to do the first creation step in the script)",
    "present_kp": [
      "gnome"
    ],
    "absent_kp": [
      "linux",
      "x11",
      "wmctrl"
    ]
  },
  {
    "text": "not able to find output files for multiple input using for loop. i am trying to use a for loop to use multiple files for trimmomatic but the output files are kept in a different directory that has pre-installed directories with input names. but when i am running the command, it is not able to detect the sub directories:/home/samarpana/archive/3_trimmomatic/sample_x_r1.fastq (no such file or directory). the output directories are named as sample_x_r1, sample_y_r2 etc.. what has to edited so that the output directory reads only the file name and not its extension (i.e .fastq in this case).the command that i am using is given below.for file in *.fastq; do java7 -xmx8g -jar /opt/apps/trimmomatic-0.30/trimmomatic-0.30.jar pe -threads 12 -phred33 /home/samarpana/archive/project_asthma_exome_25062015/fastq/$file /home/samarpana/archive/3_trimmomatic/$file illuminaclip:/home/samarpana/scratch/adapters/truseq3-pe.fa:2:30:10 crop:98 headcrop:3 slidingwindow:25:20 minlen:50; done",
    "present_kp": [],
    "absent_kp": [
      "bash",
      "shell"
    ]
  },
  {
    "text": "mount mtp android device in linux mint 17.1. i need help in mounting my asus android device in linux mint 17.1 (mtp). my pc didn't see my device, so i tried following the answer in this page:<url> when i click on connect i get the following error:listing raw device(s)mtpfs: symbol lookup error: mtpfs: undefined symbol: libmtp_detect_raw_devicesi tried searching, but i didn't get a solution.any help?",
    "present_kp": [
      "mount",
      "android",
      "mtp"
    ],
    "absent_kp": []
  },
  {
    "text": "identifier for the completed stage of a process: 0, 99, something else?. say, that you are handling a multi-step process (like a complex registration form, with a number of steps the user has go through in order). you need to be able to save the current state of the process (e.g. so the user can come back to that registration form later and continue form the step where they were left off).obviously, youll probably want to give each step an identifier you can refer to: 1, 2, 3, 4, etc. your logic will check for this step_id (or whatever you call it) to render the appropriate data.the question: how would you identify the stage after the final step, like the completed registration state (say, that you have to give that last step its own id, thats how your logic is structured). would it be a 0, 999, a non-integer value, something else entirely?",
    "present_kp": [
      "logic"
    ],
    "absent_kp": [
      "naming",
      "meta programming"
    ]
  },
  {
    "text": "add events dispatching for actionscript framework robotlegs. i have the following function in a service classprotected function writetofile():void{ var destinationfile:file = file.applicationstoragedirectory.resolvepath(_newpath); var fs:filestream = new filestream(); fs.open(destinationfile, filemode.write); fs.writebytes(_buffer, 0, _buffer.length); fs.close(); }this service class should dispatch a successfulcreatelocalfileevent when writetofile is successful and an unsuccessfulcreatelocalfileevent if writetofile is unsuccessful.i know that filestream functions open and writebytes may throw ioerror if there is any problems. and all these filestream functions all have void as return types.i believe i need try catch, but i am not entirely sure how to do so.please advise.this question is replicated at <url> experimenting which site has better answers for such a question.",
    "present_kp": [
      "actionscript"
    ],
    "absent_kp": [
      "exception handling",
      "actionscript 3",
      "error handling"
    ]
  },
  {
    "text": "is an avoidance of incest/inbreeding learned or instinctive?. is the natural avoidance of incest something that is learned or is the human brain programmed by instinct to have a negative response to incest? this of course would have an evolutionary advantage and would hence make perfect sense.",
    "present_kp": [
      "evolution"
    ],
    "absent_kp": [
      "learning",
      "sexuality",
      "behavior",
      "anthropology"
    ]
  },
  {
    "text": "how can i replace a specific string within a line inside a text file. $ cat text.txtmy name is stevenmy age is 10i like dogswhat command will be fitting so that echo kate will replace steven on text.txt?",
    "present_kp": [
      "replace"
    ],
    "absent_kp": [
      "bash",
      "shell",
      "scripting"
    ]
  },
  {
    "text": "timestamp saved history file. i've seen a lot of documentation on how to timestamp the output of the history command. but how would you go about time-stamping a saved history file? for example i have a server setup to save each users bash history to /root/history/.bash_history-$user. this is done through a line in /root/.bash_profileexport histfile=/root/history/.bash_hist-$(who -m | awk '{print $1}')i have added the line:export histtimeformat=%d/%m/%y %t to /root/.bash_profile and sourced it. however timestamps are not put in the files, you only see them when you run the history command. how can i set this up to do both?edit:i have added the lines in my .bashrc file as suggested:export histsize=3000export histfilesize=5000export histfile=/root/history/.bash_hist-$(who -m | awk '{print $1}')format_history () { perl -i -e '$/=undef;my $string=<>;$string=~s/#([0-9] {10}.* .*$)/# .localtime($1).# #$1/ge;print $string;' /root/history/.bash_hist-$(who -m | awk '{print $1}')}export histtimeformat=%d/%m/%y %t shopt -s histappendprompt_command=history -a;format_history;$prompt_commandnow when i try to open my history file, using vim, cat or less, i see:command i ran#thu mar wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec wed dec 31 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 18:00:31 1969 14:26:02 2016edit 3:after making latest changes:# fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016## fri apr 1 15:26:35 2016##1459542395command",
    "present_kp": [
      "bash"
    ],
    "absent_kp": [
      "command history"
    ]
  },
  {
    "text": "how to resolve lsp violation based on minimum precondition. i have a class party that has a constructor that takes a collection<foo>. i plan to have two subclasses npcparty and playerparty. all party instances have an upper limit on the size of the input collection (6). however, an npcparty has a lower bound of 1, while a playerparty has a lower bound of 0 (or rather, there is an implied minimum bound because a list cannot have a negative size). this is a violation of lsp because the npcparty strengthens the preconditions in terms of the size of the input collection.an npcparty is intended to be immutable; meaning that the only foos it will ever have, are those that are specified in the constructor. a playerparty's foos can be changed at runtime, either in order, or reference/value.public class party { // collection must not be null // collection size must not exceed party_limit public party(list<foo> foos) { objects.requirenonnull(foos); if (foos.size() > party_limit) { throw new illegalargumentexception(foos exceeds party limit of + party_limit); } }}public class npcparty extends party { // additional precondition that there must be at least 1 foo in the collection public npcparty(list<foo> foos) { super(foos); if (foos.size() < 1) { throw new illegalargumentexception(foos must contain at least 1 foo); } }}public class playerparty extends party { // no additional preconditions public playerparty(list<foo> foos) { super(foos); }}in what ways can i resolve this violation, such that an npcparty is allowed to have a minimum bound?edit: i'm going to give an example of how i might test this.suppose i had a class abstractpartyunittests that tested the minimum contract of all party implementations.public class abstractpartyunittests { @test(expected = nullpointerexception.class) public void testnullconstructor() { createparty(null); } @test public void testconstructorwithemptylist() { party = createparty(new arraylist<foo>()); asserttrue(party != null); } @test(expected = illegalargumentexception.class) public void testconstructorthatexceedsmaximumsize() { party = createparty(stream.generate(foo::new) .limit(party_limit + 1) .collect(collectors.tolist())); } protected abstract party createparty(list<foo> foos); private party party;}with subclasses for playerparty and npcpartypublic class playerpartyunittests extends abstractpartyunittests { @override protected party createparty(list<foo> foos) { return new playerparty(foos); }}andpublic class npcpartyunittests extends abstractpartyunittests { @test public void testconstructorthatmeetsminimumsize() { party = createparty(stream.generate(foo::new) .limit(1) .collect(collectors.tolist()); asserttrue(party != null); } @test(expected = illegalargumentexception.class) public void testconstructorthatdoesnotmeetminimumsize() { party = createparty(new arraylist<foo>()); } @override protected party createparty(list<foo> foos) { return new npcparty(foos); }}all of the test cases would pass, with the exception of testconstructorwithemptylist while running as an npcpartyunittests. the constructor would fail, and as such, the test would fail.now, i could remove that test from the abstractpartyunittests class, as it does not really apply to all types of party; but then anywhere i have a party, i may not be able to have a 1:1 replacement of npcparty.",
    "present_kp": [],
    "absent_kp": [
      "java",
      "design patterns",
      "object oriented design",
      "liskov substitution"
    ]
  },
  {
    "text": "preforming some async operations with rx.js. i tried to come up with a good challenge to learn some rx.js programming and i came up with this chain of operations below. as well as a bit of code that works and does these things. take github usernamecreate folder based on username (/repos-${user})get all repos for username (<url>}/repos)get the hash of the repo datacreate file where name is hash and content is repoi'm looking for insights and optimizations, shortcuts, etc, to make this better.here's the code.import { join } from 'path'import axios from 'axios'import rx from 'rx'import promise from 'bluebird'import crypto from 'crypto'import fs from 'fs-extra'import debug from 'debug'let debug = debug('github-repos')promise.promisifyall(fs)let { ensuredirasync, outputjsonasync } = fsfunction getrepos (user) { let theurl = '<url>}/repos' return axios.get(theurl) .then(result => { debug('got results back for ${user}') return result.data })}function gethash (json) { let text = json.stringify(json) return crypto.createhash('md5').update(text).digest('hex')}function createdir (user) { return ensuredirasync(join(__dirname, '/repos-${user}'))}function createfile (user, hash, data) { let file = join(__dirname, '/repos-${user}/${hash}.json') return outputjsonasync(file, data).then(x => file)}let ghuser$ = rx.observable.from(['reggi', 'jackofseattle', 'nolanlawson'])let ensureuser$ = ghuser$ .do((u) => debug('creating directory for: ${u}')) .flatmap(u => createdir(u))let getrepos$ = ghuser$ .do((u) => debug('fetching user repos for: ${u}')) .flatmap(u => getrepos(u))let repos$ = getrepos$ .flatmap(repos => repos.map(repo => ({hash: gethash(repo), repo}))) // create hash for eachlet filewriter$ = repos$ .map(repo => ({user: repo.repo.owner.login, hash: repo.hash, repo: repo.repo})) .flatmap(({user, hash, repo}) => { return createfile(user, hash, repo) }) .do((file) => debug('wrote a new repo to json ${file}')) .toarray()let repossubscription = filewriter$.subscribe( function (x) { debug('subscription') }, function (err) { console.log('error: %s', err) }, function (e) { debug('completed') });",
    "present_kp": [],
    "absent_kp": [
      "javascript",
      "reactive programming"
    ]
  },
  {
    "text": "do i need to pass my website url in google analytics?. i have just noticed that google analytic is providing analytic code with following parameter : ga('create', 'ua-xxxxxxxx-x', 'auto');but in some sites i have noticed like : ga('create', 'ua-xxxxxxxx-x', '<url>');so is there any different effect between auto and actual web url ?",
    "present_kp": [
      "google analytics"
    ],
    "absent_kp": []
  },
  {
    "text": "what are post clicks on facebook. similar to my previous question. i started a short paid ad campaign for my page. once i opened a new page insights, i saw the engagement box, which says:what are post clicks? all posts on my page are not clickable. i thought that a facebook user can't click on a post itself. he or she can only click on share, like or comment.how can i have 14 post clicks, if my page has zero likes, zero comments and zero shares? from where did that 49 came from? what am i missing?btw: i asked the same question on facebook community.",
    "present_kp": [
      "facebook"
    ],
    "absent_kp": [
      "facebook pages"
    ]
  },
  {
    "text": "pipes vs process substitution. while trying the cat $@ trick to read from either standard input or given files, it turned out that pipe and process substitution handle a missing trailing newline differently:printf %s foo > test.txtunset replywhile readdo :done < <(cat test.txt)echo $reply # prints foounset replycat test.txt | while readdo :doneecho $reply # prints nothing!is this by design? is this feature documented anywhere?d'oh! @fered had the right idea - it's just another example of how variable values are lost because piped commands are run in a subshell.",
    "present_kp": [
      "pipe",
      "process substitution"
    ],
    "absent_kp": [
      "bash"
    ]
  },
  {
    "text": "2-dimensional dynamic set retrieval. for the following, $(w,x) >= (y,z)$ iff $w >= y$ and $x >= z$.i have a list, $l$, of $k$ points with integer coordinates ranging from $0$ to $n-1$. each point has an associated set. i would like a data structure that can perform the following:$include(x,y,i)$ - include the element $i$ to all of the sets associated with a point $p$, where $p >= (x,y)$$remove(x,y,i)$ - remove the element $i$ from all of the sets associated with a point $p$, where $p >= (x,y)$$retrieve(x,y)$ - retrieve the set associated with point $p = (x,y)$my intuition is telling me that $include$ and $remove$ should be possible in something like $ ext{polylog}(k)$ and $retrieve$ should be possible in something like $ ext{polylog}(k) imes ( ext{size of set})$. the 2-dimensional aspect of this is stumping me, however.motivation: this data structure could be very useful for quickly calculating edit distances for a data set i'm using at work.",
    "present_kp": [],
    "absent_kp": [
      "ds.algorithms",
      "ds.data structures",
      "dynamic algorithms"
    ]
  },
  {
    "text": "is event chaining considered good practice?. from time to time i've encountered scenarios where several complex conditions need to be met prior to triggering an event. furthermore, most listeners also run additional checks to determine the course of action. this got me thinking whether a better solution would be to think in terms of smaller events and let them trigger inside each other.chaining events would allow me to weave in any additional listeners later on with fairly low effort (possible violation of yagni?). my code would consist of simple easily understood elements, which shouldn't be difficult for others to understand.however, the possible downsides to this solution would be the fact that should something happen to go wrong in the chain (e.g false event triggering due to human error), it would be quite difficult to catch the bug.is event chaining a good ideatm? if not, what are the alternative methods to keep event related code getting cluttered?",
    "present_kp": [],
    "absent_kp": [
      "event programming"
    ]
  },
  {
    "text": "prove that $l = \\{ a^ib^jc^k | i < j \\ and \\ i+2j +3 < k \\}$ is not cfg. can someone help me prove that $l = \\{ a^ib^jc^k | i < j \\ and \\ i+2j+3 < k \\}$ is not a context free language? i've tried applying the pumping lemma for cfgs and proving case by case (taking x=uvw, at first v is int $a^+$, then v is in $a^+b^+$ etc.but i'm failing to find a contradiction). any help is welcomed.\\ps: the suggestion does not solve my problem. i know the technique of applying the pumping lemma for cfg to prome a language is not context free, but i don't know how to use it on this particular language.",
    "present_kp": [
      "context free",
      "pumping lemma"
    ],
    "absent_kp": [
      "formal grammars"
    ]
  },
  {
    "text": "get email addresses from gmail message body. i've found this lovely script from another thread:get e-mail addresses from gmail messages received.it works great! however, what i'm trying to do is pull the contact info from the message body, as a lot of our older emails came from the same <email> address.all of these emails are incoming (via wordpress contact form 7) and they all have the same message body. the first line in the message is always: from: name <<email> would i need to do to capture the name and email into a spreadsheet?ideally, the a column would capture the name and b column would capture the email address.",
    "present_kp": [
      "gmail"
    ],
    "absent_kp": [
      "google contacts",
      "export"
    ]
  },
  {
    "text": "attach google docs to a gmail message. i can only link and not attach google docs.so, if the recipient does not have google drive, i have to download a converted document and upload it again.this is very time consuming and inefficient.how can i send immediately a converted version of a document?can the conversion be executed in the cloud (without downloading/uploading)?this is what already happens from docx to gdoc, when editing a docx.",
    "present_kp": [
      "gmail",
      "google drive"
    ],
    "absent_kp": []
  }
]